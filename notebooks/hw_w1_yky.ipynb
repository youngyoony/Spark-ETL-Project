{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker 1\n",
      "World 1\n",
      "Hello 4\n",
      "Python 1\n",
      "Spark 1\n"
     ]
    }
   ],
   "source": [
    "# Spark Hello World\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"WordCount\").getOrCreate()\n",
    "\n",
    "text = \"Hello Spark Hello Python Hello Docker Hello World\"\n",
    "words = spark.sparkContext.parallelize(text.split(\" \"))\n",
    "wordCounts = words.map(lambda word: (word, 1)). reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "for wc in wordCounts.collect():\n",
    "    print(wc[0], wc[1])\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.app.id', 'local-1717048920277'), ('spark.executor.id', 'driver'), ('spark.app.name', 'spark-context-test'), ('spark.driver.port', '34115'), ('spark.driver.extraJavaOptions', '-Dio.netty.tryReflectionSetAccessible=true'), ('spark.driver.host', '76bea6c276dc'), ('spark.app.startTime', '1717048920223'), ('spark.rdd.compress', 'True'), ('spark.serializer.objectStreamReset', '100'), ('spark.master', 'local[*]'), ('spark.submit.pyFiles', ''), ('spark.submit.deployMode', 'client'), ('spark.executor.extraJavaOptions', '-Dio.netty.tryReflectionSetAccessible=true'), ('spark.ui.showConsoleProgress', 'true')]\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "spark_conf = SparkConf().setAppName(\"spark-context-test\")\n",
    "spark = SparkContext.getOrCreate(conf=spark_conf)\n",
    "print(spark.getConf().getAll())  # 현재 설정 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, jovyan\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .master(\"local\")\n",
    "        .appName(\"spark-session-test\")\n",
    "        ## .config(\"spark.some.config.option\", \"some-value\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "print(f\"Hello, {spark.sparkContext.sparkUser()}\")\n",
    "\n",
    "# enableHiveSupport()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 확인\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Parental Rating: string (nullable = true)\n",
      " |-- Rating: double (nullable = true)\n",
      " |-- Number of Votes: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"./data/IMDb Top TV Series.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+------+---------------+--------------------+\n",
      "|              Title|     Year|Parental Rating|Rating|Number of Votes|         Description|\n",
      "+-------------------+---------+---------------+------+---------------+--------------------+\n",
      "| 1. Game of Thrones|2011–2019|          TV-MA|   9.2|           2.3M|Nine noble famili...|\n",
      "|    2. Breaking Bad|2008–2013|          TV-MA|   9.5|           2.1M|A chemistry teach...|\n",
      "| 3. Stranger Things|2016–2025|          TV-14|   8.7|           1.3M|When a young boy ...|\n",
      "|         4. Friends|1994–2004|          TV-14|   8.9|           1.1M|Follows the perso...|\n",
      "|5. The Walking Dead|2010–2022|          TV-MA|   8.1|           1.1M|Sheriff Deputy Ri...|\n",
      "+-------------------+---------+---------------+------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+---------------+------+---------------+--------------------+\n",
      "|             Title|     Year|Parental Rating|Rating|Number of Votes|         Description|\n",
      "+------------------+---------+---------------+------+---------------+--------------------+\n",
      "|1. Game of Thrones|2011–2019|          TV-MA|   9.2|           2.3M|Nine noble famili...|\n",
      "|   2. Breaking Bad|2008–2013|          TV-MA|   9.5|           2.1M|A chemistry teach...|\n",
      "|3. Stranger Things|2016–2025|          TV-14|   8.7|           1.3M|When a young boy ...|\n",
      "+------------------+---------+---------------+------+---------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('csv') \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"./data/IMDb Top TV Series.csv\")\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Title', 'string'),\n",
       " ('Year', 'string'),\n",
       " ('Parental Rating', 'string'),\n",
       " ('Rating', 'double'),\n",
       " ('Number of Votes', 'string'),\n",
       " ('Description', 'string')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, LongType, BooleanType, FloatType\n",
    "# https://spark.apache.org/docs/latest/sql-ref-datatypes.html\n",
    "\n",
    "schema = StructType([\n",
    "      StructField(\"Title\", StringType(), True),\n",
    "      StructField(\"Year\", LongType(), True),\n",
    "      StructField(\"Parental Rating\", StringType(), False),\n",
    "      StructField(\"Rating\", FloatType(), True),\n",
    "      StructField(\"Number of Votes\", StringType(), True),\n",
    "      StructField(\"Description\", StringType(), True)\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Year: long (nullable = true)\n",
      " |-- Parental Rating: string (nullable = true)\n",
      " |-- Rating: float (nullable = true)\n",
      " |-- Number of Votes: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.schema(schema).json(\"./data/IMDb Top TV Series.csv\")\n",
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
