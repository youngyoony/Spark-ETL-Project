[2024-09-13T00:00:15.653+0000] {processor.py:157} INFO - Started process (PID=72290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:00:15.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:00:15.658+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:00:15.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:00:15.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:00:15.708+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:00:15.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:00:15.721+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:00:15.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:00:15.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-13T00:00:45.982+0000] {processor.py:157} INFO - Started process (PID=72300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:00:45.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:00:45.991+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:00:45.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:00:46.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:00:46.047+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:00:46.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:00:46.063+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:00:46.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:00:46.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-13T00:01:16.299+0000] {processor.py:157} INFO - Started process (PID=72310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:01:16.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:01:16.305+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:01:16.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:01:16.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:01:16.342+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:01:16.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:01:16.355+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:01:16.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:01:16.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-13T00:01:46.648+0000] {processor.py:157} INFO - Started process (PID=72320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:01:46.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:01:46.651+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:01:46.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:01:46.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:01:46.694+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:01:46.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:01:46.703+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:01:46.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:01:46.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-13T00:02:17.154+0000] {processor.py:157} INFO - Started process (PID=72330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:02:17.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:02:17.158+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:02:17.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:02:17.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:02:17.195+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:02:17.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:02:17.206+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:02:17.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:02:17.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-13T00:02:47.541+0000] {processor.py:157} INFO - Started process (PID=72340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:02:47.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:02:47.543+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:02:47.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:02:47.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:02:47.577+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:02:47.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:02:47.589+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:02:47.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:02:47.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-13T00:03:17.981+0000] {processor.py:157} INFO - Started process (PID=72350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:03:17.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:03:17.984+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:03:17.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:03:17.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:03:18.011+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:03:18.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:03:18.022+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:03:18.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:03:18.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-13T00:03:48.408+0000] {processor.py:157} INFO - Started process (PID=72360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:03:48.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:03:48.432+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:03:48.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:03:48.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:03:48.476+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:03:48.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:03:48.492+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:03:48.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:03:48.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-13T00:04:18.900+0000] {processor.py:157} INFO - Started process (PID=72370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:04:18.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:04:18.906+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:04:18.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:04:18.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:04:18.942+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:04:18.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:04:18.956+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:04:18.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:04:18.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-13T00:04:49.215+0000] {processor.py:157} INFO - Started process (PID=72380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:04:49.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:04:49.217+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:04:49.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:04:49.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:04:49.243+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:04:49.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:04:49.253+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:04:49.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:04:49.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-13T00:05:19.526+0000] {processor.py:157} INFO - Started process (PID=72390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:05:19.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:05:19.539+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:05:19.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:05:19.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:05:19.585+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:05:19.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:05:19.600+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:05:19.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:05:19.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T00:05:50.022+0000] {processor.py:157} INFO - Started process (PID=72400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:05:50.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:05:50.025+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:05:50.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:05:50.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:05:50.054+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:05:50.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:05:50.064+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:05:50.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:05:50.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-13T00:06:20.458+0000] {processor.py:157} INFO - Started process (PID=72410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:06:20.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:06:20.462+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:06:20.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:06:20.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:06:20.521+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:06:20.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:06:20.536+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:06:20.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:06:20.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-13T00:06:50.796+0000] {processor.py:157} INFO - Started process (PID=72420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:06:50.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:06:50.799+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:06:50.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:06:50.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:06:50.826+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:06:50.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:06:50.838+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:06:50.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:06:50.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-13T00:07:21.276+0000] {processor.py:157} INFO - Started process (PID=72430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:07:21.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:07:21.280+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:07:21.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:07:21.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:07:21.343+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:07:21.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:07:21.355+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:07:21.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:07:21.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T00:07:51.601+0000] {processor.py:157} INFO - Started process (PID=72440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:07:51.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:07:51.604+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:07:51.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:07:51.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:07:51.633+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:07:51.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:07:51.641+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:07:51.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:07:51.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-13T00:08:21.966+0000] {processor.py:157} INFO - Started process (PID=72450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:08:21.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:08:21.971+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:08:21.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:08:22.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:08:22.034+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:08:22.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:08:22.048+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:08:22.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:08:22.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-13T00:08:52.342+0000] {processor.py:157} INFO - Started process (PID=72460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:08:52.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:08:52.344+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:08:52.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:08:52.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:08:52.379+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:08:52.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:08:52.393+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:08:52.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:08:52.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-13T00:09:22.796+0000] {processor.py:157} INFO - Started process (PID=72470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:09:22.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:09:22.800+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:09:22.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:09:22.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:09:22.862+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:09:22.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:09:22.875+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:09:22.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:09:22.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-13T00:09:53.137+0000] {processor.py:157} INFO - Started process (PID=72480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:09:53.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:09:53.146+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:09:53.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:09:53.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:09:53.216+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:09:53.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:09:53.230+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:09:53.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:09:53.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-13T00:10:23.619+0000] {processor.py:157} INFO - Started process (PID=72490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:10:23.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:10:23.635+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:10:23.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:10:23.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:10:23.698+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:10:23.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:10:23.714+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:10:23.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:10:23.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-13T00:10:53.968+0000] {processor.py:157} INFO - Started process (PID=72500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:10:53.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:10:53.971+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:10:53.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:10:53.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:10:53.999+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:10:53.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:10:54.009+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:10:54.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:10:54.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-13T00:11:24.429+0000] {processor.py:157} INFO - Started process (PID=72510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:11:24.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:11:24.437+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:11:24.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:11:24.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:11:24.476+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:11:24.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:11:24.488+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:11:24.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:11:24.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-13T00:11:54.877+0000] {processor.py:157} INFO - Started process (PID=72520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:11:54.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:11:54.883+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:11:54.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:11:54.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:11:54.955+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:11:54.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:11:54.969+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:11:54.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:11:54.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-13T00:12:25.177+0000] {processor.py:157} INFO - Started process (PID=72530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:12:25.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:12:25.179+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:12:25.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:12:25.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:12:25.205+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:12:25.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:12:25.218+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:12:25.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:12:25.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-13T00:12:55.664+0000] {processor.py:157} INFO - Started process (PID=72540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:12:55.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:12:55.668+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:12:55.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:12:55.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:12:55.735+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:12:55.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:12:55.755+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:12:55.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:12:55.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-13T00:13:26.056+0000] {processor.py:157} INFO - Started process (PID=72550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:13:26.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:13:26.060+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:13:26.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:13:26.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:13:26.096+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:13:26.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:13:26.110+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:13:26.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:13:26.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-13T00:13:56.495+0000] {processor.py:157} INFO - Started process (PID=72560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:13:56.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:13:56.497+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:13:56.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:13:56.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:13:56.533+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:13:56.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:13:56.557+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:13:56.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:13:56.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-13T00:14:26.935+0000] {processor.py:157} INFO - Started process (PID=72570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:14:26.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:14:26.939+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:14:26.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:14:26.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:14:26.986+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:14:26.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:14:26.997+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:14:26.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:14:27.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-13T00:14:57.261+0000] {processor.py:157} INFO - Started process (PID=72580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:14:57.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:14:57.264+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:14:57.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:14:57.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:14:57.299+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:14:57.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:14:57.311+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:14:57.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:14:57.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-13T00:15:27.660+0000] {processor.py:157} INFO - Started process (PID=72590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:15:27.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:15:27.664+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:15:27.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:15:27.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:15:27.720+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:15:27.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:15:27.733+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:15:27.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:15:27.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-13T00:15:57.995+0000] {processor.py:157} INFO - Started process (PID=72600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:15:57.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:15:57.998+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:15:57.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:15:58.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:15:58.032+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:15:58.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:15:58.044+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:15:58.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:15:58.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-13T00:16:28.377+0000] {processor.py:157} INFO - Started process (PID=72610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:16:28.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:16:28.382+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:16:28.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:16:28.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:16:28.439+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:16:28.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:16:28.450+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:16:28.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:16:28.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-13T00:16:58.725+0000] {processor.py:157} INFO - Started process (PID=72620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:16:58.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:16:58.729+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:16:58.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:16:58.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:16:58.760+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:16:58.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:16:58.771+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:16:58.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:16:58.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-13T00:17:29.140+0000] {processor.py:157} INFO - Started process (PID=72629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:17:29.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:17:29.146+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:17:29.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:17:29.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:17:29.186+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:17:29.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:17:29.199+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:17:29.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:17:29.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-13T00:17:59.444+0000] {processor.py:157} INFO - Started process (PID=72640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:17:59.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:17:59.449+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:17:59.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:17:59.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:17:59.475+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:17:59.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:17:59.487+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:17:59.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:17:59.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-13T00:18:29.946+0000] {processor.py:157} INFO - Started process (PID=72649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:18:29.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:18:29.955+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:18:29.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:18:29.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:18:29.996+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:18:29.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:18:30.009+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:18:30.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:18:30.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-13T00:19:00.323+0000] {processor.py:157} INFO - Started process (PID=72660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:19:00.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:19:00.330+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:19:00.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:19:00.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:19:00.372+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:19:00.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:19:00.397+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:19:00.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:19:00.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-13T00:19:30.748+0000] {processor.py:157} INFO - Started process (PID=72670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:19:30.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:19:30.752+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:19:30.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:19:30.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:19:30.778+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:19:30.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:19:30.788+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:19:30.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:19:30.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-13T00:20:01.097+0000] {processor.py:157} INFO - Started process (PID=72679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:20:01.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:20:01.101+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:20:01.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:20:01.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:20:01.160+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:20:01.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:20:01.174+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:20:01.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:20:01.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T00:20:31.390+0000] {processor.py:157} INFO - Started process (PID=72690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:20:31.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:20:31.395+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:20:31.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:20:31.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:20:31.429+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:20:31.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:20:31.445+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:20:31.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:20:31.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-13T00:21:01.897+0000] {processor.py:157} INFO - Started process (PID=72700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:21:01.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:21:01.901+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:21:01.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:21:01.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:21:01.928+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:21:01.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:21:01.937+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:21:01.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:21:01.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-13T00:21:32.374+0000] {processor.py:157} INFO - Started process (PID=72710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:21:32.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:21:32.381+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:21:32.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:21:32.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:21:32.434+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:21:32.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:21:32.450+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:21:32.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:21:32.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-13T00:22:02.706+0000] {processor.py:157} INFO - Started process (PID=72720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:22:02.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:22:02.711+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:22:02.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:22:02.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:22:02.753+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:22:02.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:22:02.765+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:22:02.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:22:02.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-13T00:22:33.226+0000] {processor.py:157} INFO - Started process (PID=72729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:22:33.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:22:33.232+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:22:33.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:22:33.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:22:33.281+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:22:33.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:22:33.315+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:22:33.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:22:33.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-13T00:23:03.645+0000] {processor.py:157} INFO - Started process (PID=72740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:23:03.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:23:03.671+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:23:03.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:23:03.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:23:03.714+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:23:03.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:23:03.729+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:23:03.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:23:03.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-13T00:23:34.017+0000] {processor.py:157} INFO - Started process (PID=72750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:23:34.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:23:34.024+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:23:34.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:23:34.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:23:34.080+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:23:34.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:23:34.093+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:23:34.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:23:34.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-13T00:24:04.523+0000] {processor.py:157} INFO - Started process (PID=72760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:24:04.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:24:04.528+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:24:04.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:24:04.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:24:04.568+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:24:04.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:24:04.581+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:24:04.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:24:04.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-13T00:24:34.938+0000] {processor.py:157} INFO - Started process (PID=72770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:24:34.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:24:34.943+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:24:34.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:24:34.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:24:34.993+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:24:34.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:24:35.007+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:24:35.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:24:35.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-13T00:25:05.343+0000] {processor.py:157} INFO - Started process (PID=72780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:25:05.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:25:05.348+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:25:05.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:25:05.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:25:05.385+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:25:05.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:25:05.399+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:25:05.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:25:05.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-13T00:25:35.656+0000] {processor.py:157} INFO - Started process (PID=72790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:25:35.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:25:35.662+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:25:35.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:25:35.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:25:35.699+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:25:35.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:25:35.712+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:25:35.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:25:35.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-13T00:26:06.064+0000] {processor.py:157} INFO - Started process (PID=72800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:26:06.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:26:06.069+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:26:06.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:26:06.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:26:06.132+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:26:06.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:26:06.145+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:26:06.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:26:06.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-13T00:26:36.370+0000] {processor.py:157} INFO - Started process (PID=72810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:26:36.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:26:36.373+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:26:36.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:26:36.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:26:36.401+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:26:36.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:26:36.412+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:26:36.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:26:36.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-13T00:27:06.644+0000] {processor.py:157} INFO - Started process (PID=72820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:27:06.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:27:06.647+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:27:06.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:27:06.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:27:06.683+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:27:06.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:27:06.696+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:27:06.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:27:06.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-13T00:27:36.963+0000] {processor.py:157} INFO - Started process (PID=72830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:27:36.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:27:36.967+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:27:36.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:27:36.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:27:37.005+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:27:37.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:27:37.018+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:27:37.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:27:37.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-13T00:28:07.405+0000] {processor.py:157} INFO - Started process (PID=72840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:28:07.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:28:07.410+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:28:07.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:28:07.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:28:07.449+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:28:07.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:28:07.462+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:28:07.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:28:07.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-13T00:28:37.714+0000] {processor.py:157} INFO - Started process (PID=72850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:28:37.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:28:37.721+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:28:37.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:28:37.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:28:37.933+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:28:37.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:28:37.949+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:28:37.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:28:37.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.249 seconds
[2024-09-13T00:29:08.207+0000] {processor.py:157} INFO - Started process (PID=72860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:29:08.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:29:08.212+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:29:08.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:29:08.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:29:08.251+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:29:08.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:29:08.261+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:29:08.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:29:08.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-13T00:29:38.503+0000] {processor.py:157} INFO - Started process (PID=72870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:29:38.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:29:38.516+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:29:38.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:29:38.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:29:38.561+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:29:38.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:29:38.574+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:29:38.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:29:38.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-13T00:30:08.857+0000] {processor.py:157} INFO - Started process (PID=73247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:30:08.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:30:08.864+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:30:08.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:30:08.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:30:08.934+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:30:08.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:30:08.950+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:30:08.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:30:08.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-13T00:30:39.301+0000] {processor.py:157} INFO - Started process (PID=73488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:30:39.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:30:39.311+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:30:39.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:30:39.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:30:39.389+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:30:39.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:30:39.404+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:30:39.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:30:39.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-13T00:31:09.629+0000] {processor.py:157} INFO - Started process (PID=73498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:31:09.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:31:09.634+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:31:09.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:31:09.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:31:09.681+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:31:09.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:31:09.692+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:31:09.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:31:09.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-13T00:31:39.969+0000] {processor.py:157} INFO - Started process (PID=73508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:31:39.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:31:39.974+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:31:39.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:31:39.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:31:40.017+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:31:40.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:31:40.028+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:31:40.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:31:40.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-13T00:32:10.349+0000] {processor.py:157} INFO - Started process (PID=73584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:32:10.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:32:10.355+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:32:10.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:32:10.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:32:10.391+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:32:10.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:32:10.402+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:32:10.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:32:10.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-13T00:32:40.696+0000] {processor.py:157} INFO - Started process (PID=73696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:32:40.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:32:40.700+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:32:40.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:32:40.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:32:40.748+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:32:40.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:32:40.760+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:32:40.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:32:40.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-13T00:33:11.025+0000] {processor.py:157} INFO - Started process (PID=73706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:33:11.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:33:11.029+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:33:11.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:33:11.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:33:11.076+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:33:11.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:33:11.088+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:33:11.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:33:11.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-13T00:33:41.325+0000] {processor.py:157} INFO - Started process (PID=73716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:33:41.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:33:41.329+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:33:41.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:33:41.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:33:41.365+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:33:41.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:33:41.376+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:33:41.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:33:41.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-13T00:34:11.719+0000] {processor.py:157} INFO - Started process (PID=73726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:34:11.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:34:11.723+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:34:11.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:34:11.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:34:11.795+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:34:11.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:34:11.806+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:34:11.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:34:11.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-13T00:34:42.015+0000] {processor.py:157} INFO - Started process (PID=73736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:34:42.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:34:42.019+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:34:42.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:34:42.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:34:42.105+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:34:42.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:34:42.117+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:34:42.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:34:42.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-13T00:35:12.365+0000] {processor.py:157} INFO - Started process (PID=73746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:35:12.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:35:12.371+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:35:12.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:35:12.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:35:12.414+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:35:12.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:35:12.428+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:35:12.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:35:12.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-13T00:35:42.774+0000] {processor.py:157} INFO - Started process (PID=73756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:35:42.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:35:42.778+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:35:42.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:35:42.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:35:42.868+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:35:42.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:35:42.881+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:35:42.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:35:42.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-13T00:36:13.049+0000] {processor.py:157} INFO - Started process (PID=73766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:36:13.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:36:13.053+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:36:13.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:36:13.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:36:13.097+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:36:13.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:36:13.106+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:36:13.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:36:13.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-13T00:36:43.467+0000] {processor.py:157} INFO - Started process (PID=73776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:36:43.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:36:43.470+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:36:43.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:36:43.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:36:43.499+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:36:43.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:36:43.515+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:36:43.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:36:43.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-13T00:37:13.845+0000] {processor.py:157} INFO - Started process (PID=73786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:37:13.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:37:13.848+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:37:13.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:37:13.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:37:13.909+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:37:13.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:37:13.920+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:37:13.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:37:13.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T00:37:44.284+0000] {processor.py:157} INFO - Started process (PID=73796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:37:44.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:37:44.287+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:37:44.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:37:44.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:37:44.330+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:37:44.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:37:44.349+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:37:44.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:37:44.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-13T00:38:14.592+0000] {processor.py:157} INFO - Started process (PID=73806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:38:14.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:38:14.597+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:38:14.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:38:14.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:38:14.632+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:38:14.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:38:14.645+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:38:14.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:38:14.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-13T00:38:44.886+0000] {processor.py:157} INFO - Started process (PID=73816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:38:44.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:38:44.890+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:38:44.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:38:44.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:38:44.928+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:38:44.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:38:44.941+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:38:44.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:38:44.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-13T00:39:15.331+0000] {processor.py:157} INFO - Started process (PID=73826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:39:15.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:39:15.336+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:39:15.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:39:15.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:39:15.394+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:39:15.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:39:15.408+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:39:15.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:39:15.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-13T00:39:45.802+0000] {processor.py:157} INFO - Started process (PID=73835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:39:45.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:39:45.808+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:39:45.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:39:45.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:39:45.869+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:39:45.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:39:45.885+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:39:45.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:39:45.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-13T00:40:16.030+0000] {processor.py:157} INFO - Started process (PID=73846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:40:16.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:40:16.034+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:40:16.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:40:16.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:40:16.056+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:40:16.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:40:16.067+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:40:16.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:40:16.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-13T00:40:46.433+0000] {processor.py:157} INFO - Started process (PID=73856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:40:46.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:40:46.440+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:40:46.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:40:46.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:40:46.506+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:40:46.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:40:46.519+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:40:46.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:40:46.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-13T00:41:16.800+0000] {processor.py:157} INFO - Started process (PID=73866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:41:16.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:41:16.804+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:41:16.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:41:16.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:41:16.830+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:41:16.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:41:16.839+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:41:16.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:41:16.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-13T00:41:47.144+0000] {processor.py:157} INFO - Started process (PID=73876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:41:47.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:41:47.149+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:41:47.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:41:47.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:41:47.217+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:41:47.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:41:47.232+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:41:47.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:41:47.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-13T00:42:17.499+0000] {processor.py:157} INFO - Started process (PID=73886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:42:17.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:42:17.504+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:42:17.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:42:17.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:42:17.540+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:42:17.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:42:17.556+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:42:17.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:42:17.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-13T00:42:47.911+0000] {processor.py:157} INFO - Started process (PID=73896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:42:47.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:42:47.914+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:42:47.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:42:47.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:42:47.942+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:42:47.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:42:47.953+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:42:47.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:42:47.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-13T00:43:18.188+0000] {processor.py:157} INFO - Started process (PID=73906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:43:18.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:43:18.208+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:43:18.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:43:18.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:43:18.253+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:43:18.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:43:18.267+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:43:18.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:43:18.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T00:43:48.519+0000] {processor.py:157} INFO - Started process (PID=73916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:43:48.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:43:48.523+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:43:48.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:43:48.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:43:48.585+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:43:48.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:43:48.601+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:43:48.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:43:48.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-13T00:44:18.884+0000] {processor.py:157} INFO - Started process (PID=73926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:44:18.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:44:18.894+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:44:18.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:44:18.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:44:18.950+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:44:18.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:44:18.963+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:44:18.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:44:18.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-13T00:44:49.207+0000] {processor.py:157} INFO - Started process (PID=73936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:44:49.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:44:49.219+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:44:49.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:44:49.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:44:49.259+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:44:49.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:44:49.289+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:44:49.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:44:49.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-13T00:45:19.522+0000] {processor.py:157} INFO - Started process (PID=73946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:45:19.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:45:19.528+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:45:19.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:45:19.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:45:19.585+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:45:19.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:45:19.599+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:45:19.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:45:19.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T00:45:49.939+0000] {processor.py:157} INFO - Started process (PID=73956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:45:49.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:45:49.943+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:45:49.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:45:49.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:45:49.981+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:45:49.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:45:49.993+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:45:49.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:45:50.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-13T00:46:20.244+0000] {processor.py:157} INFO - Started process (PID=73966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:46:20.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:46:20.247+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:46:20.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:46:20.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:46:20.279+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:46:20.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:46:20.290+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:46:20.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:46:20.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-13T00:46:50.670+0000] {processor.py:157} INFO - Started process (PID=73976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:46:50.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:46:50.674+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:46:50.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:46:50.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:46:50.728+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:46:50.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:46:50.749+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:46:50.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:46:50.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-13T00:47:20.992+0000] {processor.py:157} INFO - Started process (PID=73986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:47:20.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:47:20.997+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:47:20.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:47:21.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:47:21.024+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:47:21.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:47:21.036+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:47:21.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:47:21.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-13T00:47:51.343+0000] {processor.py:157} INFO - Started process (PID=73996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:47:51.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:47:51.345+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:47:51.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:47:51.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:47:51.386+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:47:51.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:47:51.400+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:47:51.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:47:51.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-13T00:48:21.734+0000] {processor.py:157} INFO - Started process (PID=74006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:48:21.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:48:21.747+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:48:21.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:48:21.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:48:21.798+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:48:21.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:48:21.818+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:48:21.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:48:21.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-13T00:48:52.071+0000] {processor.py:157} INFO - Started process (PID=74015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:48:52.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:48:52.080+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:48:52.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:48:52.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:48:52.123+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:48:52.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:48:52.135+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:48:52.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:48:52.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T00:49:22.404+0000] {processor.py:157} INFO - Started process (PID=74026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:49:22.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:49:22.413+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:49:22.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:49:22.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:49:22.490+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:49:22.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:49:22.507+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:49:22.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:49:22.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-13T00:49:52.799+0000] {processor.py:157} INFO - Started process (PID=74036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:49:52.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:49:52.809+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:49:52.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:49:52.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:49:52.863+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:49:52.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:49:52.877+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:49:52.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:49:52.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-13T00:50:23.156+0000] {processor.py:157} INFO - Started process (PID=74045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:50:23.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:50:23.163+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:50:23.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:50:23.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:50:23.216+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:50:23.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:50:23.239+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:50:23.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:50:23.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-13T00:50:53.557+0000] {processor.py:157} INFO - Started process (PID=74056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:50:53.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:50:53.565+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:50:53.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:50:53.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:50:53.628+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:50:53.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:50:53.647+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:50:53.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:50:53.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-13T00:51:23.911+0000] {processor.py:157} INFO - Started process (PID=74066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:51:23.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:51:23.918+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:51:23.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:51:23.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:51:23.974+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:51:23.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:51:23.989+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:51:23.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:51:23.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-13T00:51:54.317+0000] {processor.py:157} INFO - Started process (PID=74076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:51:54.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:51:54.323+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:51:54.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:51:54.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:51:54.362+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:51:54.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:51:54.381+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:51:54.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:51:54.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T00:52:24.692+0000] {processor.py:157} INFO - Started process (PID=74086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:52:24.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:52:24.699+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:52:24.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:52:24.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:52:24.745+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:52:24.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:52:24.757+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:52:24.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:52:24.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-13T00:52:55.004+0000] {processor.py:157} INFO - Started process (PID=74096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:52:55.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:52:55.010+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:52:55.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:52:55.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:52:55.047+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:52:55.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:52:55.060+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:52:55.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:52:55.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-13T00:53:25.375+0000] {processor.py:157} INFO - Started process (PID=74105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:53:25.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:53:25.381+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:53:25.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:53:25.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:53:25.424+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:53:25.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:53:25.438+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:53:25.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:53:25.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-13T00:53:55.832+0000] {processor.py:157} INFO - Started process (PID=74116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:53:55.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:53:55.840+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:53:55.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:53:55.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:53:55.896+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:53:55.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:53:55.910+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:53:55.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:53:55.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-13T00:54:26.202+0000] {processor.py:157} INFO - Started process (PID=74126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:54:26.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:54:26.220+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:54:26.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:54:26.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:54:26.261+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:54:26.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:54:26.291+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:54:26.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:54:26.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-13T00:54:56.513+0000] {processor.py:157} INFO - Started process (PID=74136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:54:56.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:54:56.524+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:54:56.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:54:56.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:54:56.578+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:54:56.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:54:56.591+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:54:56.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:54:56.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-13T00:55:26.935+0000] {processor.py:157} INFO - Started process (PID=74146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:55:26.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:55:26.946+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:55:26.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:55:26.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:55:26.999+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:55:26.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:55:27.013+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:55:27.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:55:27.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-13T00:55:57.345+0000] {processor.py:157} INFO - Started process (PID=74156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:55:57.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:55:57.350+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:55:57.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:55:57.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:55:57.404+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:55:57.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:55:57.420+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:55:57.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:55:57.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-13T00:56:27.698+0000] {processor.py:157} INFO - Started process (PID=74165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:56:27.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:56:27.703+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:56:27.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:56:27.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:56:27.763+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:56:27.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:56:27.777+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:56:27.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:56:27.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-13T00:56:58.226+0000] {processor.py:157} INFO - Started process (PID=74173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:56:58.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:56:58.231+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:56:58.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:56:58.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:56:58.289+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:56:58.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:56:58.301+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:56:58.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:56:58.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-13T00:57:28.551+0000] {processor.py:157} INFO - Started process (PID=74183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:57:28.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:57:28.559+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:57:28.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:57:28.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:57:28.617+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:57:28.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:57:28.640+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:57:28.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:57:28.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-13T00:57:58.824+0000] {processor.py:157} INFO - Started process (PID=74193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:57:58.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:57:58.849+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:57:58.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:57:58.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:57:58.900+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:57:58.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:57:58.917+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:57:58.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:57:58.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-13T00:58:29.122+0000] {processor.py:157} INFO - Started process (PID=74203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:58:29.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:58:29.128+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:58:29.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:58:29.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:58:29.191+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:58:29.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:58:29.204+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:58:29.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:58:29.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-13T00:58:59.431+0000] {processor.py:157} INFO - Started process (PID=74213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:58:59.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:58:59.440+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:58:59.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:58:59.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:58:59.523+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:58:59.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:58:59.540+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:58:59.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:58:59.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-13T00:59:29.722+0000] {processor.py:157} INFO - Started process (PID=74223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:59:29.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T00:59:29.728+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:59:29.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:59:29.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T00:59:29.767+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:59:29.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T00:59:29.778+0000] {logging_mixin.py:151} INFO - [2024-09-13T00:59:29.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-11T01:00:00+00:00, run_after=2024-09-12T01:00:00+00:00
[2024-09-13T00:59:29.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-13T01:00:00.204+0000] {processor.py:157} INFO - Started process (PID=74233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:00:00.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:00:00.212+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:00:00.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:00:00.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:00:00.293+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:00:00.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:00:00.312+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:00:00.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:00:00.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-13T01:00:30.564+0000] {processor.py:157} INFO - Started process (PID=74243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:00:30.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:00:30.570+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:00:30.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:00:30.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:00:30.630+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:00:30.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:00:30.643+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:00:30.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:00:30.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-13T01:01:00.885+0000] {processor.py:157} INFO - Started process (PID=74253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:01:00.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:01:00.900+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:01:00.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:01:00.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:01:00.942+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:01:00.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:01:00.954+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:01:00.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:01:00.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-13T01:01:31.208+0000] {processor.py:157} INFO - Started process (PID=74263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:01:31.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:01:31.215+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:01:31.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:01:31.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:01:31.291+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:01:31.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:01:31.306+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:01:31.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:01:31.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-13T01:02:01.577+0000] {processor.py:157} INFO - Started process (PID=74273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:02:01.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:02:01.583+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:02:01.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:02:01.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:02:01.632+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:02:01.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:02:01.647+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:02:01.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:02:01.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-13T01:02:31.886+0000] {processor.py:157} INFO - Started process (PID=74283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:02:31.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:02:31.896+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:02:31.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:02:31.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:02:31.991+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:02:31.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:02:32.017+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:02:32.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:02:32.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.377 seconds
[2024-09-13T01:03:02.378+0000] {processor.py:157} INFO - Started process (PID=74293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:03:02.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:03:02.387+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:03:02.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:03:02.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:03:02.467+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:03:02.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:03:02.490+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:03:02.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:03:02.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-13T01:03:32.717+0000] {processor.py:157} INFO - Started process (PID=74303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:03:32.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:03:32.728+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:03:32.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:03:32.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:03:32.809+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:03:32.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:03:32.830+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:03:32.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:03:32.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-13T01:04:03.051+0000] {processor.py:157} INFO - Started process (PID=74313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:04:03.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:04:03.062+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:04:03.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:04:03.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:04:03.155+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:04:03.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:04:03.176+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:04:03.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:04:03.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-13T01:04:33.409+0000] {processor.py:157} INFO - Started process (PID=74323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:04:33.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:04:33.421+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:04:33.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:04:33.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:04:33.518+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:04:33.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:04:33.535+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:04:33.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:04:33.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-13T01:05:03.806+0000] {processor.py:157} INFO - Started process (PID=74333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:05:03.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:05:03.817+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:05:03.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:05:03.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:05:03.894+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:05:03.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:05:03.915+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:05:03.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:05:03.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-13T01:05:34.146+0000] {processor.py:157} INFO - Started process (PID=74343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:05:34.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:05:34.158+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:05:34.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:05:34.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:05:34.220+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:05:34.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:05:34.242+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:05:34.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:05:34.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.366 seconds
[2024-09-13T01:06:05.517+0000] {processor.py:157} INFO - Started process (PID=74356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:06:05.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:06:05.525+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:06:05.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:06:05.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:06:05.620+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:06:05.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:06:05.643+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:06:05.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:06:05.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-13T01:06:35.866+0000] {processor.py:157} INFO - Started process (PID=74366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:06:35.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:06:35.873+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:06:35.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:06:35.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:06:35.978+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:06:35.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:06:35.999+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:06:35.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:06:36.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-13T01:07:06.217+0000] {processor.py:157} INFO - Started process (PID=74376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:07:06.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:07:06.223+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:07:06.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:07:06.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:07:06.308+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:07:06.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:07:06.328+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:07:06.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:07:06.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-13T01:07:36.571+0000] {processor.py:157} INFO - Started process (PID=74386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:07:36.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:07:36.575+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:07:36.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:07:36.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:07:36.625+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:07:36.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:07:36.641+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:07:36.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:07:36.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-13T01:08:07.004+0000] {processor.py:157} INFO - Started process (PID=74396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:08:07.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:08:07.012+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:08:07.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:08:07.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:08:07.082+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:08:07.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:08:07.120+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:08:07.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:08:07.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-13T01:08:37.385+0000] {processor.py:157} INFO - Started process (PID=74406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:08:37.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:08:37.393+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:08:37.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:08:37.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:08:37.487+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:08:37.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:08:37.510+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:08:37.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:08:37.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-13T01:09:07.747+0000] {processor.py:157} INFO - Started process (PID=74416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:09:07.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:09:07.756+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:09:07.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:09:07.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:09:07.849+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:09:07.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:09:07.874+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:09:07.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:09:07.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-13T01:09:38.077+0000] {processor.py:157} INFO - Started process (PID=74425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:09:38.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:09:38.084+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:09:38.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:09:38.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:09:38.149+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:09:38.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:09:38.167+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:09:38.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:09:38.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-13T01:10:08.441+0000] {processor.py:157} INFO - Started process (PID=74435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:10:08.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:10:08.458+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:10:08.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:10:08.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:10:08.526+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:10:08.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:10:08.573+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:10:08.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:10:08.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-13T01:10:38.829+0000] {processor.py:157} INFO - Started process (PID=74445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:10:38.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:10:38.839+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:10:38.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:10:38.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:10:38.930+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:10:38.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:10:38.949+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:10:38.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:10:38.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-13T01:11:09.208+0000] {processor.py:157} INFO - Started process (PID=74456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:11:09.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:11:09.213+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:11:09.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:11:09.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:11:09.299+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:11:09.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:11:09.320+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:11:09.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:11:09.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-13T01:11:39.572+0000] {processor.py:157} INFO - Started process (PID=74466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:11:39.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:11:39.585+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:11:39.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:11:39.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:11:39.665+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:11:39.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:11:39.689+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:11:39.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:11:39.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.367 seconds
[2024-09-13T01:12:10.230+0000] {processor.py:157} INFO - Started process (PID=74475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:12:10.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:12:10.244+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:12:10.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:12:10.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:12:10.336+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:12:10.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:12:10.377+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:12:10.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:12:10.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-09-13T01:12:40.509+0000] {processor.py:157} INFO - Started process (PID=74485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:12:40.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:12:40.532+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:12:40.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:12:40.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:12:40.610+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:12:40.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:12:40.630+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:12:40.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:12:40.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-13T01:13:10.988+0000] {processor.py:157} INFO - Started process (PID=74495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:13:10.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:13:11.003+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:13:11.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:13:11.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:13:11.111+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:13:11.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:13:11.130+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:13:11.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:13:11.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-09-13T01:13:41.336+0000] {processor.py:157} INFO - Started process (PID=74506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:13:41.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:13:41.343+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:13:41.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:13:41.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:13:41.411+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:13:41.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:13:41.428+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:13:41.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:13:41.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-13T01:14:11.791+0000] {processor.py:157} INFO - Started process (PID=74516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:14:11.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:14:11.803+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:14:11.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:14:11.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:14:11.863+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:14:11.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:14:11.902+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:14:11.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:14:11.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-13T01:14:42.175+0000] {processor.py:157} INFO - Started process (PID=74525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:14:42.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:14:42.187+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:14:42.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:14:42.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:14:42.278+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:14:42.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:14:42.300+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:14:42.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:14:42.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.371 seconds
[2024-09-13T01:15:12.863+0000] {processor.py:157} INFO - Started process (PID=74536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:15:12.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:15:12.872+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:15:12.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:15:12.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:15:12.955+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:15:12.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:15:12.976+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:15:12.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:15:12.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-13T01:15:43.213+0000] {processor.py:157} INFO - Started process (PID=74546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:15:43.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:15:43.239+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:15:43.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:15:43.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:15:43.302+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:15:43.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:15:43.324+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:15:43.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:15:43.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-13T01:16:13.498+0000] {processor.py:157} INFO - Started process (PID=74556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:16:13.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:16:13.510+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:16:13.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:16:13.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:16:13.576+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:16:13.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:16:13.598+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:16:13.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:16:13.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-13T01:16:43.918+0000] {processor.py:157} INFO - Started process (PID=74566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:16:43.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:16:43.940+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:16:43.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:16:43.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:16:44.010+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:16:44.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:16:44.031+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:16:44.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:16:44.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-13T01:17:14.213+0000] {processor.py:157} INFO - Started process (PID=74575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:17:14.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:17:14.223+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:17:14.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:17:14.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:17:14.310+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:17:14.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:17:14.333+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:17:14.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:17:14.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-13T01:17:44.664+0000] {processor.py:157} INFO - Started process (PID=74586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:17:44.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:17:44.672+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:17:44.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:17:44.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:17:44.729+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:17:44.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:17:44.953+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:17:44.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:17:44.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.306 seconds
[2024-09-13T01:18:15.059+0000] {processor.py:157} INFO - Started process (PID=74596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:18:15.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:18:15.068+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:18:15.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:18:15.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:18:15.148+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:18:15.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:18:15.168+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:18:15.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:18:15.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-13T01:18:45.350+0000] {processor.py:157} INFO - Started process (PID=74606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:18:45.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:18:45.359+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:18:45.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:18:45.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:18:45.444+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:18:45.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:18:45.464+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:18:45.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:18:45.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-13T01:19:15.848+0000] {processor.py:157} INFO - Started process (PID=74614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:19:15.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:19:15.869+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:19:15.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:19:15.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:19:15.954+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:19:15.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:19:15.975+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:19:15.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:19:15.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-13T01:19:46.344+0000] {processor.py:157} INFO - Started process (PID=74626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:19:46.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:19:46.351+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:19:46.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:19:46.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:19:46.437+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:19:46.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:19:46.456+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:19:46.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:19:46.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-13T01:20:16.626+0000] {processor.py:157} INFO - Started process (PID=74636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:20:16.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:20:16.636+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:20:16.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:20:16.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:20:16.735+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:20:16.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:20:16.754+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:20:16.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:20:16.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-13T01:20:47.029+0000] {processor.py:157} INFO - Started process (PID=74646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:20:47.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:20:47.034+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:20:47.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:20:47.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:20:47.130+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:20:47.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:20:47.361+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:20:47.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:20:47.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.354 seconds
[2024-09-13T01:21:17.614+0000] {processor.py:157} INFO - Started process (PID=74656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:21:17.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:21:17.634+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:21:17.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:21:17.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:21:17.699+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:21:17.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:21:17.719+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:21:17.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:21:17.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-13T01:21:47.893+0000] {processor.py:157} INFO - Started process (PID=74666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:21:47.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:21:47.899+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:21:47.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:21:47.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:21:47.951+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:21:47.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:21:47.970+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:21:47.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:21:47.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-13T01:22:18.161+0000] {processor.py:157} INFO - Started process (PID=74676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:22:18.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:22:18.166+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:22:18.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:22:18.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:22:18.241+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:22:18.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:22:18.262+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:22:18.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:22:18.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-13T01:22:48.506+0000] {processor.py:157} INFO - Started process (PID=74686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:22:48.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:22:48.510+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:22:48.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:22:48.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:22:48.546+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:22:48.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:22:48.560+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:22:48.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:22:48.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-13T01:23:18.834+0000] {processor.py:157} INFO - Started process (PID=74696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:23:18.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:23:18.843+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:23:18.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:23:18.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:23:18.924+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:23:18.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:23:18.948+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:23:18.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:23:18.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-13T01:23:49.348+0000] {processor.py:157} INFO - Started process (PID=74706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:23:49.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:23:49.360+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:23:49.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:23:49.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:23:49.439+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:23:49.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:23:49.461+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:23:49.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:23:49.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-13T01:24:19.706+0000] {processor.py:157} INFO - Started process (PID=74716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:24:19.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:24:19.712+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:24:19.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:24:19.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:24:19.797+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:24:19.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:24:19.818+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:24:19.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:24:19.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-13T01:24:50.048+0000] {processor.py:157} INFO - Started process (PID=74726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:24:50.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:24:50.058+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:24:50.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:24:50.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:24:50.140+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:24:50.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:24:50.160+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:24:50.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:24:50.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-13T01:25:20.410+0000] {processor.py:157} INFO - Started process (PID=74736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:25:20.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:25:20.418+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:25:20.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:25:20.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:25:20.503+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:25:20.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:25:20.527+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:25:20.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:25:20.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-13T01:25:50.861+0000] {processor.py:157} INFO - Started process (PID=74746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:25:50.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:25:50.879+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:25:50.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:25:50.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:25:50.990+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:25:50.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:25:51.040+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:25:51.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:25:51.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.220 seconds
[2024-09-13T01:26:21.266+0000] {processor.py:157} INFO - Started process (PID=74756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:26:21.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:26:21.279+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:26:21.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:26:21.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:26:21.371+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:26:21.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:26:21.390+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:26:21.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:26:21.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.361 seconds
[2024-09-13T01:26:51.908+0000] {processor.py:157} INFO - Started process (PID=74766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:26:51.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:26:51.916+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:26:51.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:26:51.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:26:52.039+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:26:52.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:26:52.240+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:26:52.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:26:52.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.346 seconds
[2024-09-13T01:27:22.488+0000] {processor.py:157} INFO - Started process (PID=74775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:27:22.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:27:22.496+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:27:22.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:27:22.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:27:22.585+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:27:22.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:27:22.607+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:27:22.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:27:22.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-13T01:27:52.792+0000] {processor.py:157} INFO - Started process (PID=74786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:27:52.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:27:52.798+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:27:52.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:27:52.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:27:52.859+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:27:52.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:27:52.878+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:27:52.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:27:52.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-13T01:28:23.230+0000] {processor.py:157} INFO - Started process (PID=74796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:28:23.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:28:23.240+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:28:23.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:28:23.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:28:23.343+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:28:23.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:28:23.364+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:28:23.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:28:23.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-13T01:28:53.654+0000] {processor.py:157} INFO - Started process (PID=74806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:28:53.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:28:53.662+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:28:53.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:28:53.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:28:53.778+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:28:53.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:28:53.803+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:28:53.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:28:53.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-09-13T01:29:24.013+0000] {processor.py:157} INFO - Started process (PID=74816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:29:24.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:29:24.022+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:29:24.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:29:24.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:29:24.123+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:29:24.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:29:24.144+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:29:24.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:29:24.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.346 seconds
[2024-09-13T01:29:54.666+0000] {processor.py:157} INFO - Started process (PID=74826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:29:54.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:29:54.674+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:29:54.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:29:54.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:29:54.762+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:29:54.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:29:54.784+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:29:54.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:29:54.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-13T01:30:24.972+0000] {processor.py:157} INFO - Started process (PID=74836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:30:24.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:30:24.984+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:30:24.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:30:25.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:30:25.062+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:30:25.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:30:25.081+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:30:25.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:30:25.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-13T01:30:55.372+0000] {processor.py:157} INFO - Started process (PID=74846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:30:55.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:30:55.380+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:30:55.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:30:55.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:30:55.470+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:30:55.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:30:55.490+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:30:55.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:30:55.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-13T01:31:25.767+0000] {processor.py:157} INFO - Started process (PID=74855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:31:25.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:31:25.779+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:31:25.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:31:25.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:31:25.854+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:31:25.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:31:25.874+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:31:25.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:31:25.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-13T01:31:56.132+0000] {processor.py:157} INFO - Started process (PID=74864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:31:56.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:31:56.143+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:31:56.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:31:56.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:31:56.201+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:31:56.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:31:56.219+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:31:56.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:31:56.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-13T01:32:26.490+0000] {processor.py:157} INFO - Started process (PID=74876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:32:26.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:32:26.503+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:32:26.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:32:26.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:32:26.565+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:32:26.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:32:26.586+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:32:26.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:32:26.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.340 seconds
[2024-09-13T01:32:57.052+0000] {processor.py:157} INFO - Started process (PID=74886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:32:57.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:32:57.074+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:32:57.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:32:57.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:32:57.140+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:32:57.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:32:57.367+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:32:57.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:32:57.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.333 seconds
[2024-09-13T01:33:27.670+0000] {processor.py:157} INFO - Started process (PID=74896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:33:27.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:33:27.701+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:33:27.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:33:27.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:33:27.783+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:33:27.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:33:27.803+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:33:27.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:33:27.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-13T01:33:57.997+0000] {processor.py:157} INFO - Started process (PID=74906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:33:57.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:33:58.004+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:33:58.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:33:58.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:33:58.090+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:33:58.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:33:58.107+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:33:58.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:33:58.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-13T01:34:28.409+0000] {processor.py:157} INFO - Started process (PID=74916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:34:28.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:34:28.415+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:34:28.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:34:28.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:34:28.503+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:34:28.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:34:28.524+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:34:28.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:34:28.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-13T01:34:58.928+0000] {processor.py:157} INFO - Started process (PID=74926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:34:58.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:34:58.944+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:34:58.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:34:58.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:34:59.027+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:34:59.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:34:59.049+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:34:59.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:34:59.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-13T01:35:29.337+0000] {processor.py:157} INFO - Started process (PID=74936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:35:29.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:35:29.346+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:35:29.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:35:29.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:35:29.435+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:35:29.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:35:29.464+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:35:29.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:35:29.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.351 seconds
[2024-09-13T01:36:00.038+0000] {processor.py:157} INFO - Started process (PID=74946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:36:00.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:36:00.045+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:36:00.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:36:00.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:36:00.215+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:36:00.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:36:00.234+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:36:00.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:36:00.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.221 seconds
[2024-09-13T01:36:30.414+0000] {processor.py:157} INFO - Started process (PID=74955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:36:30.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:36:30.445+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:36:30.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:36:30.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:36:30.506+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:36:30.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:36:30.527+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:36:30.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:36:30.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-13T01:37:00.815+0000] {processor.py:157} INFO - Started process (PID=74966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:37:00.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:37:00.825+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:37:00.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:37:00.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:37:00.910+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:37:00.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:37:00.931+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:37:00.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:37:00.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-13T01:37:31.221+0000] {processor.py:157} INFO - Started process (PID=74975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:37:31.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:37:31.246+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:37:31.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:37:31.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:37:31.312+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:37:31.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:37:31.332+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:37:31.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:37:31.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-13T01:38:01.634+0000] {processor.py:157} INFO - Started process (PID=74986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:38:01.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:38:01.642+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:38:01.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:38:01.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:38:01.703+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:38:01.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:38:01.727+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:38:01.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:38:01.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-13T01:38:32.022+0000] {processor.py:157} INFO - Started process (PID=74995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:38:32.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:38:32.031+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:38:32.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:38:32.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:38:32.122+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:38:32.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:38:32.145+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:38:32.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:38:32.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.364 seconds
[2024-09-13T01:39:02.749+0000] {processor.py:157} INFO - Started process (PID=75006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:39:02.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:39:02.765+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:39:02.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:39:02.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:39:02.856+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:39:02.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:39:03.341+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:39:03.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:39:03.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.621 seconds
[2024-09-13T01:39:33.672+0000] {processor.py:157} INFO - Started process (PID=75016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:39:33.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:39:33.693+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:39:33.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:39:33.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:39:33.734+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:39:33.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:39:33.750+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:39:33.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:39:33.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T01:40:03.973+0000] {processor.py:157} INFO - Started process (PID=75026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:40:03.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:40:03.977+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:40:03.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:40:03.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:40:04.013+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:40:04.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:40:04.025+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:40:04.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:40:04.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-13T01:40:34.284+0000] {processor.py:157} INFO - Started process (PID=75036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:40:34.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:40:34.288+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:40:34.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:40:34.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:40:34.321+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:40:34.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:40:34.331+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:40:34.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:40:34.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-13T01:41:04.678+0000] {processor.py:157} INFO - Started process (PID=75046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:41:04.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:41:04.683+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:41:04.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:41:04.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:41:04.734+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:41:04.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:41:04.746+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:41:04.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:41:04.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-13T01:41:34.977+0000] {processor.py:157} INFO - Started process (PID=75056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:41:34.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:41:34.979+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:41:34.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:41:34.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:41:35.006+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:41:35.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:41:35.017+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:41:35.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:41:35.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.210 seconds
[2024-09-13T01:42:05.319+0000] {processor.py:157} INFO - Started process (PID=75066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:42:05.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:42:05.324+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:42:05.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:42:05.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:42:05.369+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:42:05.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:42:05.457+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:42:05.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:42:05.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-13T01:42:35.791+0000] {processor.py:157} INFO - Started process (PID=75076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:42:35.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:42:35.795+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:42:35.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:42:35.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:42:35.822+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:42:35.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:42:35.832+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:42:35.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:42:35.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-13T01:43:06.148+0000] {processor.py:157} INFO - Started process (PID=75085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:43:06.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:43:06.154+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:43:06.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:43:06.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:43:06.199+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:43:06.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:43:06.213+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:43:06.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:43:06.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-13T01:43:36.511+0000] {processor.py:157} INFO - Started process (PID=75096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:43:36.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:43:36.514+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:43:36.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:43:36.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:43:36.538+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:43:36.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:43:36.548+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:43:36.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:43:36.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-13T01:44:06.874+0000] {processor.py:157} INFO - Started process (PID=75106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:44:06.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:44:06.881+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:44:06.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:44:06.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:44:06.915+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:44:06.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:44:06.926+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:44:06.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:44:06.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-13T01:44:37.242+0000] {processor.py:157} INFO - Started process (PID=75116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:44:37.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:44:37.247+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:44:37.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:44:37.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:44:37.275+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:44:37.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:44:37.433+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:44:37.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:44:37.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.202 seconds
[2024-09-13T01:45:07.571+0000] {processor.py:157} INFO - Started process (PID=75125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:45:07.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:45:07.577+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:45:07.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:45:07.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:45:07.645+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:45:07.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:45:07.657+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:45:07.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:45:07.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-13T01:45:37.892+0000] {processor.py:157} INFO - Started process (PID=75136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:45:37.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:45:37.896+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:45:37.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:45:37.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:45:37.921+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:45:37.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:45:37.930+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:45:37.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:45:37.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-13T01:46:08.293+0000] {processor.py:157} INFO - Started process (PID=75146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:46:08.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:46:08.300+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:46:08.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:46:08.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:46:08.339+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:46:08.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:46:08.350+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:46:08.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:46:08.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T01:46:38.561+0000] {processor.py:157} INFO - Started process (PID=75156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:46:38.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:46:38.563+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:46:38.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:46:38.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:46:38.589+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:46:38.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:46:38.600+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:46:38.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:46:38.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-13T01:47:09.027+0000] {processor.py:157} INFO - Started process (PID=75166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:47:09.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:47:09.032+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:47:09.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:47:09.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:47:09.080+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:47:09.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:47:09.093+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:47:09.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:47:09.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-13T01:47:39.422+0000] {processor.py:157} INFO - Started process (PID=75176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:47:39.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:47:39.424+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:47:39.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:47:39.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:47:39.447+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:47:39.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:47:39.616+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:47:39.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:47:39.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.206 seconds
[2024-09-13T01:48:09.724+0000] {processor.py:157} INFO - Started process (PID=75186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:48:09.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:48:09.731+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:48:09.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:48:09.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:48:09.777+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:48:09.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:48:09.792+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:48:09.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:48:09.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-13T01:48:40.081+0000] {processor.py:157} INFO - Started process (PID=75196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:48:40.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:48:40.086+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:48:40.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:48:40.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:48:40.118+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:48:40.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:48:40.129+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:48:40.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:48:40.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-13T01:49:10.478+0000] {processor.py:157} INFO - Started process (PID=75206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:49:10.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:49:10.481+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:49:10.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:49:10.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:49:10.511+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:49:10.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:49:10.522+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:49:10.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:49:10.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-13T01:49:40.803+0000] {processor.py:157} INFO - Started process (PID=75216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:49:40.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:49:40.812+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:49:40.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:49:40.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:49:40.865+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:49:40.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:49:40.877+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:49:40.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:49:40.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-13T01:50:11.181+0000] {processor.py:157} INFO - Started process (PID=75226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:50:11.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:50:11.189+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:50:11.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:50:11.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:50:11.252+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:50:11.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:50:11.265+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:50:11.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:50:11.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-13T01:50:41.610+0000] {processor.py:157} INFO - Started process (PID=75236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:50:41.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:50:41.614+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:50:41.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:50:41.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:50:41.648+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:50:41.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:50:41.840+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:50:41.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:50:41.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.244 seconds
[2024-09-13T01:51:11.934+0000] {processor.py:157} INFO - Started process (PID=75246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:51:11.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:51:11.939+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:51:11.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:51:11.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:51:11.971+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:51:11.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:51:11.981+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:51:11.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:51:11.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-13T01:51:42.390+0000] {processor.py:157} INFO - Started process (PID=75256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:51:42.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:51:42.393+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:51:42.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:51:42.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:51:42.432+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:51:42.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:51:42.445+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:51:42.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:51:42.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-13T01:52:12.801+0000] {processor.py:157} INFO - Started process (PID=75266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:52:12.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:52:12.819+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:52:12.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:52:12.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:52:12.870+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:52:12.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:52:12.883+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:52:12.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:52:12.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-13T01:52:43.228+0000] {processor.py:157} INFO - Started process (PID=75276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:52:43.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:52:43.232+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:52:43.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:52:43.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:52:43.259+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:52:43.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:52:43.271+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:52:43.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:52:43.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-13T01:53:13.640+0000] {processor.py:157} INFO - Started process (PID=75286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:53:13.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:53:13.657+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:53:13.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:53:13.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:53:13.699+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:53:13.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:53:13.711+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:53:13.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:53:13.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.265 seconds
[2024-09-13T01:53:44.251+0000] {processor.py:157} INFO - Started process (PID=75296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:53:44.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:53:44.259+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:53:44.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:53:44.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:53:44.313+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:53:44.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:53:44.475+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:53:44.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:53:44.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.238 seconds
[2024-09-13T01:54:14.624+0000] {processor.py:157} INFO - Started process (PID=75305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:54:14.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:54:14.630+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:54:14.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:54:14.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:54:14.675+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:54:14.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:54:14.692+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:54:14.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:54:14.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-13T01:54:45.006+0000] {processor.py:157} INFO - Started process (PID=75316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:54:45.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:54:45.018+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:54:45.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:54:45.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:54:45.060+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:54:45.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:54:45.073+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:54:45.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:54:45.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-13T01:55:15.401+0000] {processor.py:157} INFO - Started process (PID=75326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:55:15.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:55:15.407+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:55:15.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:55:15.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:55:15.469+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:55:15.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:55:15.485+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:55:15.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:55:15.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-13T01:55:45.844+0000] {processor.py:157} INFO - Started process (PID=75336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:55:45.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:55:45.849+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:55:45.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:55:45.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:55:45.900+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:55:45.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:55:45.915+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:55:45.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:55:45.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-13T01:56:16.253+0000] {processor.py:157} INFO - Started process (PID=75346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:56:16.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:56:16.259+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:56:16.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:56:16.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:56:16.317+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:56:16.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:56:16.330+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:56:16.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:56:16.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.239 seconds
[2024-09-13T01:56:46.568+0000] {processor.py:157} INFO - Started process (PID=75356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:56:46.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:56:46.575+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:56:46.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:56:46.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:56:46.612+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:56:46.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:56:46.723+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:56:46.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:56:46.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-13T01:57:17.071+0000] {processor.py:157} INFO - Started process (PID=75366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:57:17.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:57:17.074+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:57:17.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:57:17.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:57:17.097+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:57:17.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:57:17.106+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:57:17.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:57:17.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-13T01:57:47.484+0000] {processor.py:157} INFO - Started process (PID=75376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:57:47.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:57:47.489+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:57:47.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:57:47.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:57:47.533+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:57:47.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:57:47.545+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:57:47.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:57:47.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-13T01:58:17.900+0000] {processor.py:157} INFO - Started process (PID=75386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:58:17.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:58:17.904+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:58:17.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:58:17.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:58:17.929+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:58:17.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:58:17.938+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:58:17.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:58:17.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-13T01:58:48.272+0000] {processor.py:157} INFO - Started process (PID=75396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:58:48.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:58:48.275+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:58:48.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:58:48.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:58:48.319+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:58:48.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:58:48.331+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:58:48.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:58:48.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-13T01:59:18.715+0000] {processor.py:157} INFO - Started process (PID=75406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:59:18.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:59:18.719+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:59:18.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:59:18.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:59:18.745+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:59:18.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:59:18.755+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:59:18.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:59:18.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-09-13T01:59:49.031+0000] {processor.py:157} INFO - Started process (PID=75415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:59:49.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T01:59:49.035+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:59:49.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:59:49.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T01:59:49.081+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:59:49.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T01:59:49.185+0000] {logging_mixin.py:151} INFO - [2024-09-13T01:59:49.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T01:59:49.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-13T02:00:19.466+0000] {processor.py:157} INFO - Started process (PID=75426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:00:19.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:00:19.472+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:00:19.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:00:19.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:00:19.537+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:00:19.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:00:19.556+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:00:19.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:00:19.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-13T02:00:49.795+0000] {processor.py:157} INFO - Started process (PID=75435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:00:49.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:00:49.804+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:00:49.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:00:49.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:00:49.847+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:00:49.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:00:49.861+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:00:49.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:00:49.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-13T02:01:20.188+0000] {processor.py:157} INFO - Started process (PID=75446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:01:20.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:01:20.191+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:01:20.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:01:20.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:01:20.230+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:01:20.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:01:20.247+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:01:20.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:01:20.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-13T02:01:50.621+0000] {processor.py:157} INFO - Started process (PID=75456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:01:50.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:01:50.626+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:01:50.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:01:50.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:01:50.665+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:01:50.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:01:50.678+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:01:50.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:01:50.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-13T02:02:21.078+0000] {processor.py:157} INFO - Started process (PID=75466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:02:21.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:02:21.081+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:02:21.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:02:21.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:02:21.119+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:02:21.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:02:21.132+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:02:21.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:02:21.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.230 seconds
[2024-09-13T02:02:51.397+0000] {processor.py:157} INFO - Started process (PID=75474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:02:51.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:02:51.404+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:02:51.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:02:51.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:02:51.445+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:02:51.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:02:51.623+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:02:51.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:02:51.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.240 seconds
[2024-09-13T02:03:21.869+0000] {processor.py:157} INFO - Started process (PID=75485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:03:21.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:03:21.877+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:03:21.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:03:21.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:03:21.916+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:03:21.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:03:21.929+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:03:21.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:03:21.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-13T02:03:52.217+0000] {processor.py:157} INFO - Started process (PID=75496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:03:52.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:03:52.219+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:03:52.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:03:52.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:03:52.244+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:03:52.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:03:52.255+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:03:52.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:03:52.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-13T02:04:22.698+0000] {processor.py:157} INFO - Started process (PID=75506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:04:22.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:04:22.714+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:04:22.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:04:22.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:04:22.751+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:04:22.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:04:22.773+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:04:22.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:04:22.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T02:04:53.051+0000] {processor.py:157} INFO - Started process (PID=75516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:04:53.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:04:53.055+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:04:53.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:04:53.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:04:53.093+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:04:53.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:04:53.106+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:04:53.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:04:53.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-13T02:05:23.495+0000] {processor.py:157} INFO - Started process (PID=75525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:05:23.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:05:23.509+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:05:23.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:05:23.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:05:23.579+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:05:23.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:05:23.593+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:05:23.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:05:23.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.260 seconds
[2024-09-13T02:05:53.845+0000] {processor.py:157} INFO - Started process (PID=75535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:05:53.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:05:53.863+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:05:53.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:05:53.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:05:53.912+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:05:53.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:05:54.074+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:05:54.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:05:54.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.243 seconds
[2024-09-13T02:06:24.316+0000] {processor.py:157} INFO - Started process (PID=75545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:06:24.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:06:24.323+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:06:24.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:06:24.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:06:24.379+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:06:24.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:06:24.392+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:06:24.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:06:24.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T02:06:54.724+0000] {processor.py:157} INFO - Started process (PID=75556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:06:54.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:06:54.729+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:06:54.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:06:54.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:06:54.755+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:06:54.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:06:54.766+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:06:54.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:06:54.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-13T02:07:25.071+0000] {processor.py:157} INFO - Started process (PID=75565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:07:25.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:07:25.077+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:07:25.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:07:25.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:07:25.138+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:07:25.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:07:25.152+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:07:25.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:07:25.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T02:07:55.404+0000] {processor.py:157} INFO - Started process (PID=75576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:07:55.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:07:55.407+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:07:55.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:07:55.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:07:55.432+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:07:55.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:07:55.441+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:07:55.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:07:55.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-13T02:08:25.791+0000] {processor.py:157} INFO - Started process (PID=75586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:08:25.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:08:25.799+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:08:25.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:08:25.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:08:25.837+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:08:25.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:08:25.998+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:08:25.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:08:26.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.218 seconds
[2024-09-13T02:08:56.124+0000] {processor.py:157} INFO - Started process (PID=75595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:08:56.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:08:56.130+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:08:56.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:08:56.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:08:56.170+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:08:56.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:08:56.330+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:08:56.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:08:56.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.222 seconds
[2024-09-13T02:09:26.600+0000] {processor.py:157} INFO - Started process (PID=75606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:09:26.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:09:26.603+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:09:26.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:09:26.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:09:26.671+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:09:26.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:09:26.685+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:09:26.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:09:26.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-13T02:09:56.936+0000] {processor.py:157} INFO - Started process (PID=75615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:09:56.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:09:56.947+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:09:56.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:09:56.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:09:56.989+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:09:56.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:09:57.002+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:09:57.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:09:57.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-13T02:10:27.366+0000] {processor.py:157} INFO - Started process (PID=75626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:10:27.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:10:27.372+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:10:27.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:10:27.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:10:27.435+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:10:27.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:10:27.463+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:10:27.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:10:27.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-13T02:10:57.682+0000] {processor.py:157} INFO - Started process (PID=75636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:10:57.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:10:57.686+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:10:57.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:10:57.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:10:57.736+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:10:57.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:10:57.748+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:10:57.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:10:57.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-13T02:11:28.011+0000] {processor.py:157} INFO - Started process (PID=75645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:11:28.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:11:28.017+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:11:28.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:11:28.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:11:28.059+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:11:28.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:11:28.222+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:11:28.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:11:28.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.228 seconds
[2024-09-13T02:11:58.418+0000] {processor.py:157} INFO - Started process (PID=75656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:11:58.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:11:58.428+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:11:58.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:11:58.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:11:58.473+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:11:58.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:11:58.703+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:11:58.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:11:58.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.299 seconds
[2024-09-13T02:12:28.794+0000] {processor.py:157} INFO - Started process (PID=75666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:12:28.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:12:28.797+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:12:28.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:12:28.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:12:28.857+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:12:28.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:12:28.869+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:12:28.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:12:28.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-13T02:12:59.118+0000] {processor.py:157} INFO - Started process (PID=75676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:12:59.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:12:59.121+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:12:59.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:12:59.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:12:59.161+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:12:59.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:12:59.176+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:12:59.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:12:59.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-13T02:13:29.570+0000] {processor.py:157} INFO - Started process (PID=75685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:13:29.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:13:29.577+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:13:29.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:13:29.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:13:29.633+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:13:29.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:13:29.646+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:13:29.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:13:29.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T02:13:59.882+0000] {processor.py:157} INFO - Started process (PID=75695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:13:59.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:13:59.886+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:13:59.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:13:59.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:13:59.927+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:13:59.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:13:59.942+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:13:59.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:13:59.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-13T02:14:30.319+0000] {processor.py:157} INFO - Started process (PID=75705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:14:30.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:14:30.339+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:14:30.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:14:30.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:14:30.386+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:14:30.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:14:30.559+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:14:30.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:14:30.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.255 seconds
[2024-09-13T02:15:00.637+0000] {processor.py:157} INFO - Started process (PID=75716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:15:00.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:15:00.655+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:15:00.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:15:00.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:15:00.703+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:15:00.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:15:00.898+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:15:00.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:15:00.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.275 seconds
[2024-09-13T02:15:31.223+0000] {processor.py:157} INFO - Started process (PID=75725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:15:31.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:15:31.230+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:15:31.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:15:31.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:15:31.283+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:15:31.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:15:31.297+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:15:31.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:15:31.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T02:16:01.576+0000] {processor.py:157} INFO - Started process (PID=75736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:16:01.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:16:01.581+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:16:01.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:16:01.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:16:01.631+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:16:01.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:16:01.654+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:16:01.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:16:01.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T02:16:31.888+0000] {processor.py:157} INFO - Started process (PID=75746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:16:31.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:16:31.908+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:16:31.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:16:31.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:16:31.947+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:16:31.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:16:31.960+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:16:31.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:16:31.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T02:17:02.216+0000] {processor.py:157} INFO - Started process (PID=75756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:17:02.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:17:02.222+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:17:02.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:17:02.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:17:02.262+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:17:02.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:17:02.274+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:17:02.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:17:02.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.227 seconds
[2024-09-13T02:17:32.621+0000] {processor.py:157} INFO - Started process (PID=75766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:17:32.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:17:32.631+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:17:32.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:17:32.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:17:32.668+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:17:32.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:17:32.840+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:17:32.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:17:32.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.255 seconds
[2024-09-13T02:18:02.997+0000] {processor.py:157} INFO - Started process (PID=75775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:18:02.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:18:03.001+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:18:03.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:18:03.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:18:03.044+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:18:03.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:18:03.217+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:18:03.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:18:03.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.248 seconds
[2024-09-13T02:18:33.415+0000] {processor.py:157} INFO - Started process (PID=75786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:18:33.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:18:33.423+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:18:33.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:18:33.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:18:33.476+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:18:33.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:18:33.489+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:18:33.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:18:33.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-13T02:19:03.835+0000] {processor.py:157} INFO - Started process (PID=75794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:19:03.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:19:03.841+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:19:03.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:19:03.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:19:03.891+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:19:03.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:19:03.904+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:19:03.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:19:03.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T02:19:34.219+0000] {processor.py:157} INFO - Started process (PID=75805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:19:34.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:19:34.233+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:19:34.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:19:34.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:19:34.283+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:19:34.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:19:34.296+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:19:34.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:19:34.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-13T02:20:04.720+0000] {processor.py:157} INFO - Started process (PID=75816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:20:04.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:20:04.728+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:20:04.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:20:04.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:20:04.792+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:20:04.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:20:04.816+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:20:04.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:20:04.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.277 seconds
[2024-09-13T02:20:35.281+0000] {processor.py:157} INFO - Started process (PID=75826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:20:35.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:20:35.287+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:20:35.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:20:35.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:20:35.335+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:20:35.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:20:35.484+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:20:35.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:20:35.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.218 seconds
[2024-09-13T02:21:05.621+0000] {processor.py:157} INFO - Started process (PID=75836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:21:05.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:21:05.627+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:21:05.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:21:05.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:21:05.667+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:21:05.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:21:05.827+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:21:05.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:21:05.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.221 seconds
[2024-09-13T02:21:36.046+0000] {processor.py:157} INFO - Started process (PID=75846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:21:36.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:21:36.053+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:21:36.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:21:36.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:21:36.123+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:21:36.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:21:36.139+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:21:36.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:21:36.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-13T02:22:06.416+0000] {processor.py:157} INFO - Started process (PID=75856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:22:06.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:22:06.424+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:22:06.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:22:06.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:22:06.472+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:22:06.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:22:06.484+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:22:06.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:22:06.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T02:22:37.009+0000] {processor.py:157} INFO - Started process (PID=75865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:22:37.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:22:37.021+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:22:37.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:22:37.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:22:37.120+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:22:37.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:22:37.144+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:22:37.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:22:37.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-13T02:23:07.374+0000] {processor.py:157} INFO - Started process (PID=75876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:23:07.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:23:07.382+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:23:07.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:23:07.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:23:07.459+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:23:07.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:23:07.488+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:23:07.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:23:07.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.312 seconds
[2024-09-13T02:23:38.088+0000] {processor.py:157} INFO - Started process (PID=75886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:23:38.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:23:38.094+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:23:38.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:23:38.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:23:38.147+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:23:38.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:23:38.362+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:23:38.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:23:38.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.306 seconds
[2024-09-13T02:24:08.423+0000] {processor.py:157} INFO - Started process (PID=75896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:24:08.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:24:08.443+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:24:08.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:24:08.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:24:08.502+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:24:08.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:24:08.680+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:24:08.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:24:08.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.270 seconds
[2024-09-13T02:24:39.092+0000] {processor.py:157} INFO - Started process (PID=75906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:24:39.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:24:39.112+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:24:39.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:24:39.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:24:39.166+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:24:39.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:24:39.181+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:24:39.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:24:39.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-13T02:25:09.718+0000] {processor.py:157} INFO - Started process (PID=75914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:25:09.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:25:09.723+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:25:09.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:25:09.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:25:09.780+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:25:09.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:25:09.795+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:25:09.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:25:09.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-13T02:25:40.293+0000] {processor.py:157} INFO - Started process (PID=75926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:25:40.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:25:40.295+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:25:40.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:25:40.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:25:40.333+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:25:40.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:25:40.345+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:25:40.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:25:40.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-13T02:26:10.954+0000] {processor.py:157} INFO - Started process (PID=75936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:26:10.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:26:10.968+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:26:10.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:26:10.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:26:11.016+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:26:11.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:26:11.033+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:26:11.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:26:11.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.251 seconds
[2024-09-13T02:26:41.973+0000] {processor.py:157} INFO - Started process (PID=75945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:26:41.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:26:41.977+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:26:41.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:26:41.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:26:42.035+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:26:42.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:26:42.192+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:26:42.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:26:42.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-09-13T02:27:45.245+0000] {processor.py:157} INFO - Started process (PID=75956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:27:45.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:27:45.248+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:27:45.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:27:45.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:27:45.275+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:27:45.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:27:45.361+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:27:45.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:27:45.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-13T02:28:15.756+0000] {processor.py:157} INFO - Started process (PID=75968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:28:15.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:28:15.760+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:28:15.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:28:15.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:28:15.817+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:28:15.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:28:15.985+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:28:15.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:28:15.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.246 seconds
[2024-09-13T02:32:40.001+0000] {processor.py:157} INFO - Started process (PID=75978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:32:40.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:32:40.005+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:32:40.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:32:40.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:32:40.051+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:32:40.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:32:40.064+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:32:40.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:32:40.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-13T02:50:31.789+0000] {processor.py:157} INFO - Started process (PID=75988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:50:31.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T02:50:31.794+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:50:31.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:50:31.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T02:50:31.864+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:50:31.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T02:50:31.888+0000] {logging_mixin.py:151} INFO - [2024-09-13T02:50:31.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T02:50:31.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-13T03:30:02.747+0000] {processor.py:157} INFO - Started process (PID=75998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T03:30:02.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T03:30:02.752+0000] {logging_mixin.py:151} INFO - [2024-09-13T03:30:02.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T03:30:02.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T03:30:02.799+0000] {logging_mixin.py:151} INFO - [2024-09-13T03:30:02.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T03:30:02.817+0000] {logging_mixin.py:151} INFO - [2024-09-13T03:30:02.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T03:30:02.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-13T03:45:40.607+0000] {processor.py:157} INFO - Started process (PID=76010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T03:45:40.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T03:45:40.616+0000] {logging_mixin.py:151} INFO - [2024-09-13T03:45:40.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T03:45:40.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T03:45:40.669+0000] {logging_mixin.py:151} INFO - [2024-09-13T03:45:40.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T03:45:40.906+0000] {logging_mixin.py:151} INFO - [2024-09-13T03:45:40.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T03:45:40.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.353 seconds
[2024-09-13T04:26:09.507+0000] {processor.py:157} INFO - Started process (PID=76019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T04:26:09.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T04:26:09.520+0000] {logging_mixin.py:151} INFO - [2024-09-13T04:26:09.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T04:26:09.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T04:26:09.617+0000] {logging_mixin.py:151} INFO - [2024-09-13T04:26:09.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T04:26:09.844+0000] {logging_mixin.py:151} INFO - [2024-09-13T04:26:09.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T04:26:09.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.361 seconds
[2024-09-13T04:26:40.285+0000] {processor.py:157} INFO - Started process (PID=76029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T04:26:40.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T04:26:40.288+0000] {logging_mixin.py:151} INFO - [2024-09-13T04:26:40.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T04:26:40.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T04:26:40.502+0000] {logging_mixin.py:151} INFO - [2024-09-13T04:26:40.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T04:26:40.511+0000] {logging_mixin.py:151} INFO - [2024-09-13T04:26:40.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T04:26:40.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.236 seconds
[2024-09-13T05:27:06.412+0000] {processor.py:157} INFO - Started process (PID=76039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T05:27:06.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T05:27:06.423+0000] {logging_mixin.py:151} INFO - [2024-09-13T05:27:06.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T05:27:06.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T05:27:06.468+0000] {logging_mixin.py:151} INFO - [2024-09-13T05:27:06.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T05:27:06.480+0000] {logging_mixin.py:151} INFO - [2024-09-13T05:27:06.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T05:27:06.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-13T05:27:36.860+0000] {processor.py:157} INFO - Started process (PID=76050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T05:27:36.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T05:27:36.865+0000] {logging_mixin.py:151} INFO - [2024-09-13T05:27:36.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T05:27:36.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T05:27:36.907+0000] {logging_mixin.py:151} INFO - [2024-09-13T05:27:36.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T05:27:36.920+0000] {logging_mixin.py:151} INFO - [2024-09-13T05:27:36.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T05:27:36.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-13T06:07:02.282+0000] {processor.py:157} INFO - Started process (PID=76062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T06:07:02.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T06:07:02.292+0000] {logging_mixin.py:151} INFO - [2024-09-13T06:07:02.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T06:07:02.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T06:07:02.356+0000] {logging_mixin.py:151} INFO - [2024-09-13T06:07:02.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T06:07:02.381+0000] {logging_mixin.py:151} INFO - [2024-09-13T06:07:02.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T06:07:02.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.327 seconds
[2024-09-13T06:07:32.928+0000] {processor.py:157} INFO - Started process (PID=76072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T06:07:32.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T06:07:32.932+0000] {logging_mixin.py:151} INFO - [2024-09-13T06:07:32.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T06:07:32.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T06:07:32.980+0000] {logging_mixin.py:151} INFO - [2024-09-13T06:07:32.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T06:07:33.112+0000] {logging_mixin.py:151} INFO - [2024-09-13T06:07:33.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T06:07:33.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-13T06:12:51.418+0000] {processor.py:157} INFO - Started process (PID=76082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T06:12:51.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T06:12:51.423+0000] {logging_mixin.py:151} INFO - [2024-09-13T06:12:51.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T06:12:51.442+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T06:12:51.485+0000] {logging_mixin.py:151} INFO - [2024-09-13T06:12:51.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T06:12:51.831+0000] {logging_mixin.py:151} INFO - [2024-09-13T06:12:51.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T06:12:51.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.424 seconds
[2024-09-13T06:28:04.113+0000] {processor.py:157} INFO - Started process (PID=76092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T06:28:04.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T06:28:04.124+0000] {logging_mixin.py:151} INFO - [2024-09-13T06:28:04.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T06:28:04.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T06:28:04.333+0000] {logging_mixin.py:151} INFO - [2024-09-13T06:28:04.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T06:28:04.342+0000] {logging_mixin.py:151} INFO - [2024-09-13T06:28:04.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T06:28:04.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.258 seconds
[2024-09-13T06:28:34.623+0000] {processor.py:157} INFO - Started process (PID=76101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T06:28:34.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T06:28:34.634+0000] {logging_mixin.py:151} INFO - [2024-09-13T06:28:34.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T06:28:34.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T06:28:34.678+0000] {logging_mixin.py:151} INFO - [2024-09-13T06:28:34.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T06:28:34.713+0000] {logging_mixin.py:151} INFO - [2024-09-13T06:28:34.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T06:28:34.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-13T07:49:30.799+0000] {processor.py:157} INFO - Started process (PID=76112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T07:49:30.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T07:49:30.807+0000] {logging_mixin.py:151} INFO - [2024-09-13T07:49:30.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T07:49:30.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T07:49:30.855+0000] {logging_mixin.py:151} INFO - [2024-09-13T07:49:30.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T07:49:30.866+0000] {logging_mixin.py:151} INFO - [2024-09-13T07:49:30.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T07:49:30.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-13T08:03:55.899+0000] {processor.py:157} INFO - Started process (PID=76123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T08:03:55.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T08:03:55.905+0000] {logging_mixin.py:151} INFO - [2024-09-13T08:03:55.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T08:03:55.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T08:03:56.001+0000] {logging_mixin.py:151} INFO - [2024-09-13T08:03:56.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T08:03:56.033+0000] {logging_mixin.py:151} INFO - [2024-09-13T08:03:56.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T08:03:56.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.368 seconds
[2024-09-13T08:04:46.866+0000] {processor.py:157} INFO - Started process (PID=76134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T08:04:46.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T08:04:46.872+0000] {logging_mixin.py:151} INFO - [2024-09-13T08:04:46.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T08:04:46.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T08:04:46.945+0000] {logging_mixin.py:151} INFO - [2024-09-13T08:04:46.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T08:04:47.131+0000] {logging_mixin.py:151} INFO - [2024-09-13T08:04:47.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T08:04:47.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.278 seconds
[2024-09-13T08:05:17.473+0000] {processor.py:157} INFO - Started process (PID=76144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T08:05:17.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T08:05:17.482+0000] {logging_mixin.py:151} INFO - [2024-09-13T08:05:17.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T08:05:17.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T08:05:17.511+0000] {logging_mixin.py:151} INFO - [2024-09-13T08:05:17.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T08:05:17.614+0000] {logging_mixin.py:151} INFO - [2024-09-13T08:05:17.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T08:05:17.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-13T09:11:29.485+0000] {processor.py:157} INFO - Started process (PID=76152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T09:11:29.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T09:11:29.490+0000] {logging_mixin.py:151} INFO - [2024-09-13T09:11:29.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T09:11:29.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T09:11:29.644+0000] {logging_mixin.py:151} INFO - [2024-09-13T09:11:29.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T09:11:29.651+0000] {logging_mixin.py:151} INFO - [2024-09-13T09:11:29.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T09:11:29.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-09-13T10:51:41.423+0000] {processor.py:157} INFO - Started process (PID=76164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T10:51:41.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T10:51:41.436+0000] {logging_mixin.py:151} INFO - [2024-09-13T10:51:41.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T10:51:41.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T10:51:41.523+0000] {logging_mixin.py:151} INFO - [2024-09-13T10:51:41.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T10:51:41.571+0000] {logging_mixin.py:151} INFO - [2024-09-13T10:51:41.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T10:51:41.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-13T12:13:28.684+0000] {processor.py:157} INFO - Started process (PID=76173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T12:13:28.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T12:13:28.695+0000] {logging_mixin.py:151} INFO - [2024-09-13T12:13:28.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T12:13:28.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T12:13:28.813+0000] {logging_mixin.py:151} INFO - [2024-09-13T12:13:28.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T12:13:28.871+0000] {logging_mixin.py:151} INFO - [2024-09-13T12:13:28.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T12:13:28.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.309 seconds
[2024-09-13T12:19:37.013+0000] {processor.py:157} INFO - Started process (PID=76185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T12:19:37.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T12:19:37.023+0000] {logging_mixin.py:151} INFO - [2024-09-13T12:19:37.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T12:19:37.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T12:19:37.084+0000] {logging_mixin.py:151} INFO - [2024-09-13T12:19:37.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T12:19:37.292+0000] {logging_mixin.py:151} INFO - [2024-09-13T12:19:37.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T12:19:37.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.308 seconds
[2024-09-13T12:36:36.264+0000] {processor.py:157} INFO - Started process (PID=76196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T12:36:36.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T12:36:36.272+0000] {logging_mixin.py:151} INFO - [2024-09-13T12:36:36.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T12:36:36.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T12:36:36.385+0000] {logging_mixin.py:151} INFO - [2024-09-13T12:36:36.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T12:36:36.585+0000] {logging_mixin.py:151} INFO - [2024-09-13T12:36:36.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T12:36:36.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.438 seconds
[2024-09-13T12:37:07.054+0000] {processor.py:157} INFO - Started process (PID=76206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T12:37:07.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T12:37:07.059+0000] {logging_mixin.py:151} INFO - [2024-09-13T12:37:07.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T12:37:07.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T12:37:07.240+0000] {logging_mixin.py:151} INFO - [2024-09-13T12:37:07.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T12:37:07.250+0000] {logging_mixin.py:151} INFO - [2024-09-13T12:37:07.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T12:37:07.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.212 seconds
[2024-09-13T13:20:22.487+0000] {processor.py:157} INFO - Started process (PID=76217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:20:22.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T13:20:22.498+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:20:22.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:20:22.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:20:22.566+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:20:22.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T13:20:22.594+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:20:22.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T13:20:22.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-13T13:20:52.831+0000] {processor.py:157} INFO - Started process (PID=76228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:20:52.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T13:20:52.842+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:20:52.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:20:52.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:20:52.907+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:20:52.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T13:20:52.930+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:20:52.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T13:20:52.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-13T13:21:27.032+0000] {processor.py:157} INFO - Started process (PID=76238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:21:27.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T13:21:27.037+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:21:27.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:21:27.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:21:27.086+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:21:27.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T13:21:27.107+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:21:27.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T13:21:27.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-13T13:22:20.102+0000] {processor.py:157} INFO - Started process (PID=76248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:22:20.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T13:22:20.107+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:22:20.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:22:20.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:22:20.165+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:22:20.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T13:22:20.342+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:22:20.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T13:22:20.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.259 seconds
[2024-09-13T13:22:50.639+0000] {processor.py:157} INFO - Started process (PID=76258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:22:50.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T13:22:50.645+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:22:50.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:22:50.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:22:50.692+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:22:50.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T13:22:50.827+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:22:50.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T13:22:50.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.201 seconds
[2024-09-13T13:23:38.878+0000] {processor.py:157} INFO - Started process (PID=76268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:23:38.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T13:23:38.883+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:23:38.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:23:38.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:23:39.168+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:23:39.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T13:23:39.179+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:23:39.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T13:23:39.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.314 seconds
[2024-09-13T13:24:09.508+0000] {processor.py:157} INFO - Started process (PID=76278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:24:09.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T13:24:09.558+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:24:09.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:24:09.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:24:09.628+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:24:09.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T13:24:09.648+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:24:09.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T13:24:09.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-13T13:24:39.812+0000] {processor.py:157} INFO - Started process (PID=76288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:24:39.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T13:24:39.817+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:24:39.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:24:39.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:24:39.863+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:24:39.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T13:24:39.880+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:24:39.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T13:24:39.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-13T13:25:58.295+0000] {processor.py:157} INFO - Started process (PID=76298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:25:58.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T13:25:58.311+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:25:58.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:25:58.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:25:58.374+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:25:58.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T13:25:58.388+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:25:58.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T13:25:58.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-13T13:42:22.973+0000] {processor.py:157} INFO - Started process (PID=76310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:42:22.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T13:42:22.979+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:42:22.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:42:23.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T13:42:23.071+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:42:23.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T13:42:23.479+0000] {logging_mixin.py:151} INFO - [2024-09-13T13:42:23.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T13:42:23.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.536 seconds
[2024-09-13T14:08:55.445+0000] {processor.py:157} INFO - Started process (PID=76320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:08:55.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T14:08:55.458+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:08:55.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:08:55.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:08:55.517+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:08:55.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T14:08:55.835+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:08:55.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T14:08:55.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.431 seconds
[2024-09-13T14:09:47.366+0000] {processor.py:157} INFO - Started process (PID=76330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:09:47.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T14:09:47.373+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:09:47.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:09:47.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:09:47.584+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:09:47.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T14:09:47.594+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:09:47.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T14:09:47.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.247 seconds
[2024-09-13T14:10:17.976+0000] {processor.py:157} INFO - Started process (PID=76340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:10:17.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T14:10:17.982+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:10:17.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:10:17.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:10:18.047+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:10:18.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T14:10:18.063+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:10:18.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T14:10:18.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-13T14:10:50.134+0000] {processor.py:157} INFO - Started process (PID=76350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:10:50.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T14:10:50.138+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:10:50.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:10:50.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:10:50.202+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:10:50.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T14:10:50.214+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:10:50.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T14:10:50.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-13T14:18:32.797+0000] {processor.py:157} INFO - Started process (PID=76360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:18:32.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T14:18:32.804+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:18:32.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:18:32.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:18:32.853+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:18:32.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T14:18:32.867+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:18:32.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T14:18:33.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.279 seconds
[2024-09-13T14:19:03.146+0000] {processor.py:157} INFO - Started process (PID=76370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:19:03.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T14:19:03.184+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:19:03.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:19:03.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:19:03.232+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:19:03.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T14:19:03.385+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:19:03.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T14:19:03.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.252 seconds
[2024-09-13T14:38:41.512+0000] {processor.py:157} INFO - Started process (PID=76382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:38:41.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T14:38:41.524+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:38:41.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:38:41.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:38:41.609+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:38:41.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T14:38:41.812+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:38:41.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T14:38:41.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.324 seconds
[2024-09-13T14:39:12.142+0000] {processor.py:157} INFO - Started process (PID=76392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:39:12.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T14:39:12.147+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:39:12.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:39:12.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:39:12.312+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:39:12.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T14:39:12.321+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:39:12.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T14:39:12.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-09-13T14:43:31.129+0000] {processor.py:157} INFO - Started process (PID=76400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:43:31.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T14:43:31.144+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:43:31.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:43:31.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:43:31.183+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:43:31.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T14:43:31.195+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:43:31.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T14:43:31.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-13T14:44:30.289+0000] {processor.py:157} INFO - Started process (PID=76412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:44:30.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T14:44:30.293+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:44:30.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:44:30.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:44:30.349+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:44:30.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T14:44:30.362+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:44:30.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T14:44:30.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-13T14:45:00.608+0000] {processor.py:157} INFO - Started process (PID=76422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:45:00.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T14:45:00.629+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:45:00.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:45:00.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T14:45:00.670+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:45:00.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T14:45:00.696+0000] {logging_mixin.py:151} INFO - [2024-09-13T14:45:00.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T14:45:00.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.248 seconds
[2024-09-13T15:13:26.617+0000] {processor.py:157} INFO - Started process (PID=76433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:13:26.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:13:26.624+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:13:26.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:13:26.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:13:26.691+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:13:26.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:13:26.948+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:13:26.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:13:26.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.349 seconds
[2024-09-13T15:14:02.838+0000] {processor.py:157} INFO - Started process (PID=76443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:14:02.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:14:02.851+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:14:02.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:14:02.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:14:02.906+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:14:02.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:14:03.079+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:14:03.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:14:03.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.261 seconds
[2024-09-13T15:14:33.135+0000] {processor.py:157} INFO - Started process (PID=76454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:14:33.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:14:33.137+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:14:33.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:14:33.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:14:33.263+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:14:33.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:14:33.271+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:14:33.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:14:33.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-13T15:15:13.867+0000] {processor.py:157} INFO - Started process (PID=76462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:15:13.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:15:13.871+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:15:13.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:15:13.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:15:13.923+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:15:13.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:15:13.936+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:15:13.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:15:13.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-13T15:16:09.097+0000] {processor.py:157} INFO - Started process (PID=76475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:16:09.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:16:09.102+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:16:09.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:16:09.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:16:09.139+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:16:09.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:16:09.153+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:16:09.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:16:09.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-13T15:16:39.479+0000] {processor.py:157} INFO - Started process (PID=76486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:16:39.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:16:39.483+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:16:39.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:16:39.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:16:39.519+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:16:39.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:16:39.530+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:16:39.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:16:39.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.223 seconds
[2024-09-13T15:25:56.829+0000] {processor.py:157} INFO - Started process (PID=76496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:25:56.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:25:56.835+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:25:56.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:25:56.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:25:56.912+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:25:56.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:25:57.146+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:25:57.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:25:57.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.341 seconds
[2024-09-13T15:26:27.691+0000] {processor.py:157} INFO - Started process (PID=76506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:26:27.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:26:27.736+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:26:27.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:26:27.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:26:27.808+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:26:27.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:26:28.000+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:26:28.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:26:28.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.323 seconds
[2024-09-13T15:35:08.154+0000] {processor.py:157} INFO - Started process (PID=76515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:35:08.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:35:08.163+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:35:08.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:35:08.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:35:08.475+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:35:08.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:35:08.493+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:35:08.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:35:08.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.361 seconds
[2024-09-13T15:46:03.659+0000] {processor.py:157} INFO - Started process (PID=76527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:46:03.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:46:03.672+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:46:03.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:46:03.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:46:03.711+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:46:03.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:46:03.725+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:46:03.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:46:03.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-13T15:46:34.003+0000] {processor.py:157} INFO - Started process (PID=76538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:46:34.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:46:34.012+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:46:34.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:46:34.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:46:34.072+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:46:34.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:46:34.088+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:46:34.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:46:34.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-13T15:52:40.780+0000] {processor.py:157} INFO - Started process (PID=76546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:52:40.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:52:40.795+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:52:40.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:52:40.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:52:40.833+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:52:40.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:52:41.081+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:52:41.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:52:41.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.327 seconds
[2024-09-13T15:53:29.067+0000] {processor.py:157} INFO - Started process (PID=76558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:53:29.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:53:29.073+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:53:29.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:53:29.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:53:29.113+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:53:29.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:53:29.281+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:53:29.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:53:29.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.224 seconds
[2024-09-13T15:53:59.733+0000] {processor.py:157} INFO - Started process (PID=76568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:53:59.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:53:59.737+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:53:59.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:53:59.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:53:59.931+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:53:59.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:53:59.942+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:53:59.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:53:59.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.223 seconds
[2024-09-13T15:55:14.377+0000] {processor.py:157} INFO - Started process (PID=76578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:55:14.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:55:14.389+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:55:14.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:55:14.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:55:14.591+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:55:14.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:55:14.599+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:55:14.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:55:14.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.243 seconds
[2024-09-13T15:55:52.946+0000] {processor.py:157} INFO - Started process (PID=76590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:55:52.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:55:53.070+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:55:53.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:55:53.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:55:53.108+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:55:53.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:55:53.117+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:55:53.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:55:53.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-09-13T15:56:23.487+0000] {processor.py:157} INFO - Started process (PID=76600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:56:23.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T15:56:23.490+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:56:23.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:56:23.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T15:56:23.516+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:56:23.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T15:56:23.531+0000] {logging_mixin.py:151} INFO - [2024-09-13T15:56:23.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T15:56:23.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-13T16:16:41.846+0000] {processor.py:157} INFO - Started process (PID=76610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:16:41.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:16:41.855+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:16:41.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:16:41.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:16:41.892+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:16:41.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:16:41.908+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:16:41.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:16:41.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-13T16:17:12.272+0000] {processor.py:157} INFO - Started process (PID=76619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:17:12.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:17:12.279+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:17:12.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:17:12.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:17:12.322+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:17:12.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:17:12.337+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:17:12.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:17:12.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-13T16:24:18.874+0000] {processor.py:157} INFO - Started process (PID=76630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:24:18.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:24:18.880+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:24:18.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:24:18.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:24:18.953+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:24:18.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:24:18.983+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:24:18.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:24:19.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-13T16:24:57.136+0000] {processor.py:157} INFO - Started process (PID=76640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:24:57.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:24:57.141+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:24:57.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:24:57.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:24:57.188+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:24:57.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:24:57.201+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:24:57.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:24:57.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-13T16:25:27.566+0000] {processor.py:157} INFO - Started process (PID=76652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:25:27.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:25:27.573+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:25:27.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:25:27.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:25:27.633+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:25:27.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:25:27.647+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:25:27.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:25:27.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-13T16:26:58.889+0000] {processor.py:157} INFO - Started process (PID=76662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:26:58.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:26:58.899+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:26:58.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:26:58.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:26:58.957+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:26:58.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:26:58.970+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:26:58.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:26:58.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T16:27:30.182+0000] {processor.py:157} INFO - Started process (PID=76672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:27:30.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:27:30.184+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:27:30.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:27:30.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:27:30.212+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:27:30.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:27:30.230+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:27:30.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:27:30.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-13T16:28:00.609+0000] {processor.py:157} INFO - Started process (PID=76682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:28:00.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:28:00.613+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:28:00.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:28:00.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:28:00.659+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:28:00.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:28:00.673+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:28:00.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:28:00.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-13T16:32:51.334+0000] {processor.py:157} INFO - Started process (PID=76694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:32:51.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:32:51.338+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:32:51.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:32:51.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:32:51.389+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:32:51.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:32:51.412+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:32:51.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:32:51.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-13T16:33:21.702+0000] {processor.py:157} INFO - Started process (PID=76704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:33:21.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:33:21.706+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:33:21.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:33:21.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:33:21.750+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:33:21.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:33:21.763+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:33:21.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:33:21.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-13T16:36:46.861+0000] {processor.py:157} INFO - Started process (PID=76714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:36:46.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:36:46.866+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:36:46.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:36:46.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:36:46.918+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:36:46.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:36:46.931+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:36:46.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:36:46.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-13T16:38:14.544+0000] {processor.py:157} INFO - Started process (PID=76724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:38:14.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:38:14.549+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:38:14.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:38:14.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:38:14.610+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:38:14.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:38:14.625+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:38:14.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:38:14.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-13T16:38:44.941+0000] {processor.py:157} INFO - Started process (PID=76734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:38:44.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:38:44.945+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:38:44.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:38:44.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:38:44.971+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:38:44.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:38:44.982+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:38:44.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:38:44.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-13T16:39:23.010+0000] {processor.py:157} INFO - Started process (PID=76742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:39:23.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:39:23.019+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:39:23.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:39:23.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:39:23.065+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:39:23.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:39:23.077+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:39:23.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:39:23.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-13T16:40:21.934+0000] {processor.py:157} INFO - Started process (PID=76753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:40:21.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:40:21.943+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:40:21.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:40:21.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:40:22.005+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:40:22.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:40:22.022+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:40:22.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:40:22.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-13T16:40:52.211+0000] {processor.py:157} INFO - Started process (PID=76764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:40:52.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:40:52.215+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:40:52.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:40:52.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:40:52.246+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:40:52.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:40:52.256+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:40:52.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:40:52.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-13T16:45:06.637+0000] {processor.py:157} INFO - Started process (PID=76773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:45:06.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:45:06.642+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:45:06.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:45:06.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:45:06.693+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:45:06.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:45:06.704+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:45:06.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:45:06.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-13T16:47:48.412+0000] {processor.py:157} INFO - Started process (PID=76786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:47:48.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:47:48.418+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:47:48.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:47:48.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:47:48.466+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:47:48.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:47:48.479+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:47:48.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:47:48.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-13T16:48:18.741+0000] {processor.py:157} INFO - Started process (PID=76796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:48:18.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T16:48:18.745+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:48:18.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:48:18.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T16:48:18.782+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:48:18.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T16:48:18.797+0000] {logging_mixin.py:151} INFO - [2024-09-13T16:48:18.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T16:48:18.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-13T17:27:45.065+0000] {processor.py:157} INFO - Started process (PID=76805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:27:45.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:27:45.069+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:27:45.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:27:45.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:27:45.101+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:27:45.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:27:45.113+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:27:45.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:27:45.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-13T17:28:15.381+0000] {processor.py:157} INFO - Started process (PID=76815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:28:15.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:28:15.386+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:28:15.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:28:15.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:28:15.427+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:28:15.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:28:15.440+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:28:15.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:28:15.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-13T17:45:55.023+0000] {processor.py:157} INFO - Started process (PID=76826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:45:55.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:45:55.029+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:45:55.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:45:55.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:45:55.085+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:45:55.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:45:55.097+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:45:55.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:45:55.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-13T17:46:43.056+0000] {processor.py:157} INFO - Started process (PID=76838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:46:43.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:46:43.062+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:46:43.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:46:43.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:46:43.128+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:46:43.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:46:43.142+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:46:43.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:46:43.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-13T17:47:13.395+0000] {processor.py:157} INFO - Started process (PID=76848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:47:13.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:47:13.400+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:47:13.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:47:13.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:47:13.453+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:47:13.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:47:13.468+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:47:13.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:47:13.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-13T17:48:14.787+0000] {processor.py:157} INFO - Started process (PID=76857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:48:14.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:48:14.795+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:48:14.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:48:14.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:48:14.846+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:48:14.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:48:14.863+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:48:14.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:48:14.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-13T17:48:45.120+0000] {processor.py:157} INFO - Started process (PID=76868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:48:45.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:48:45.122+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:48:45.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:48:45.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:48:45.155+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:48:45.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:48:45.167+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:48:45.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:48:45.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-13T17:50:28.556+0000] {processor.py:157} INFO - Started process (PID=76880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:50:28.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:50:28.565+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:50:28.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:50:28.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:50:28.623+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:50:28.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:50:28.636+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:50:28.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:50:28.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-13T17:51:04.840+0000] {processor.py:157} INFO - Started process (PID=76890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:51:04.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:51:04.846+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:51:04.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:51:04.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:51:04.895+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:51:04.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:51:04.909+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:51:04.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:51:04.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-13T17:51:35.106+0000] {processor.py:157} INFO - Started process (PID=76900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:51:35.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:51:35.109+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:51:35.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:51:35.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:51:35.135+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:51:35.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:51:35.147+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:51:35.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:51:35.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-13T17:52:18.192+0000] {processor.py:157} INFO - Started process (PID=76910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:52:18.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:52:18.199+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:52:18.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:52:18.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:52:18.251+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:52:18.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:52:18.263+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:52:18.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:52:18.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T17:53:00.366+0000] {processor.py:157} INFO - Started process (PID=76920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:53:00.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:53:00.380+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:53:00.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:53:00.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:53:00.447+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:53:00.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:53:00.472+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:53:00.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:53:00.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-13T17:53:30.671+0000] {processor.py:157} INFO - Started process (PID=76930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:53:30.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:53:30.676+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:53:30.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:53:30.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:53:30.704+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:53:30.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:53:30.715+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:53:30.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:53:30.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-13T17:54:24.954+0000] {processor.py:157} INFO - Started process (PID=76940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:54:24.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:54:24.967+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:54:24.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:54:24.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:54:25.015+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:54:25.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:54:25.038+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:54:25.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:54:25.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-13T17:55:07.305+0000] {processor.py:157} INFO - Started process (PID=76950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:55:07.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:55:07.310+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:55:07.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:55:07.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:55:07.362+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:55:07.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:55:07.376+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:55:07.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:55:07.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-13T17:55:37.667+0000] {processor.py:157} INFO - Started process (PID=76960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:55:37.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:55:37.687+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:55:37.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:55:37.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:55:37.729+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:55:37.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:55:37.743+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:55:37.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:55:37.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-13T17:56:18.011+0000] {processor.py:157} INFO - Started process (PID=76970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:56:18.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:56:18.017+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:56:18.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:56:18.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:56:18.057+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:56:18.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:56:18.072+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:56:18.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:56:18.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-13T17:56:48.382+0000] {processor.py:157} INFO - Started process (PID=76980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:56:48.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:56:48.384+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:56:48.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:56:48.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:56:48.415+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:56:48.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:56:48.425+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:56:48.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:56:48.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-13T17:57:38.663+0000] {processor.py:157} INFO - Started process (PID=76990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:57:38.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:57:38.668+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:57:38.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:57:38.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:57:38.727+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:57:38.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:57:38.739+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:57:38.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:57:38.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-13T17:58:43.017+0000] {processor.py:157} INFO - Started process (PID=77000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:58:43.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:58:43.024+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:58:43.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:58:43.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:58:43.071+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:58:43.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:58:43.086+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:58:43.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:58:43.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T17:59:13.375+0000] {processor.py:157} INFO - Started process (PID=77010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:59:13.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T17:59:13.378+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:59:13.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:59:13.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T17:59:13.404+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:59:13.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T17:59:13.415+0000] {logging_mixin.py:151} INFO - [2024-09-13T17:59:13.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T17:59:13.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-13T18:01:54.804+0000] {processor.py:157} INFO - Started process (PID=77021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:01:54.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:01:54.809+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:01:54.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:01:54.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:01:54.893+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:01:54.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:01:54.915+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:01:54.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:01:54.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-13T18:02:25.153+0000] {processor.py:157} INFO - Started process (PID=77032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:02:25.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:02:25.159+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:02:25.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:02:25.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:02:25.195+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:02:25.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:02:25.208+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:02:25.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:02:25.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-13T18:02:55.454+0000] {processor.py:157} INFO - Started process (PID=77042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:02:55.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:02:55.456+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:02:55.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:02:55.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:02:55.480+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:02:55.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:02:55.491+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:02:55.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:02:55.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-13T18:03:25.737+0000] {processor.py:157} INFO - Started process (PID=77052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:03:25.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:03:25.739+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:03:25.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:03:25.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:03:25.764+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:03:25.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:03:25.773+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:03:25.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:03:25.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-13T18:03:56.073+0000] {processor.py:157} INFO - Started process (PID=77062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:03:56.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:03:56.075+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:03:56.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:03:56.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:03:56.104+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:03:56.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:03:56.116+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:03:56.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:03:56.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-13T18:04:26.417+0000] {processor.py:157} INFO - Started process (PID=77072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:04:26.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:04:26.421+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:04:26.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:04:26.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:04:26.469+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:04:26.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:04:26.483+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:04:26.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:04:26.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-13T18:04:56.825+0000] {processor.py:157} INFO - Started process (PID=77082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:04:56.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:04:56.828+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:04:56.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:04:56.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:04:56.861+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:04:56.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:04:56.880+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:04:56.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:04:56.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-13T18:05:27.254+0000] {processor.py:157} INFO - Started process (PID=77092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:05:27.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:05:27.268+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:05:27.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:05:27.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:05:27.313+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:05:27.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:05:27.330+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:05:27.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:05:27.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-13T18:05:57.621+0000] {processor.py:157} INFO - Started process (PID=77102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:05:57.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:05:57.629+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:05:57.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:05:57.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:05:57.714+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:05:57.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:05:57.755+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:05:57.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:05:57.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-13T18:06:27.989+0000] {processor.py:157} INFO - Started process (PID=77112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:06:27.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:06:27.994+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:06:27.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:06:28.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:06:28.055+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:06:28.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:06:28.073+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:06:28.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:06:28.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-13T18:06:58.405+0000] {processor.py:157} INFO - Started process (PID=77122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:06:58.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:06:58.410+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:06:58.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:06:58.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:06:58.460+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:06:58.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:06:58.474+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:06:58.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:06:58.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-13T18:07:28.849+0000] {processor.py:157} INFO - Started process (PID=77131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:07:28.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:07:28.855+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:07:28.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:07:28.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:07:28.909+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:07:28.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:07:28.924+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:07:28.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:07:28.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-13T18:07:59.325+0000] {processor.py:157} INFO - Started process (PID=77142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:07:59.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:07:59.346+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:07:59.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:07:59.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:07:59.433+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:07:59.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:07:59.454+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:07:59.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:07:59.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-13T18:08:29.847+0000] {processor.py:157} INFO - Started process (PID=77152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:08:29.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:08:29.857+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:08:29.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:08:29.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:08:29.901+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:08:29.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:08:29.916+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:08:29.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:08:29.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-13T18:09:00.275+0000] {processor.py:157} INFO - Started process (PID=77162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:09:00.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:09:00.288+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:09:00.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:09:00.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:09:00.329+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:09:00.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:09:00.341+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:09:00.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:09:00.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T18:09:30.723+0000] {processor.py:157} INFO - Started process (PID=77172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:09:30.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:09:30.728+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:09:30.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:09:30.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:09:30.772+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:09:30.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:09:30.787+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:09:30.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:09:30.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-13T18:10:01.000+0000] {processor.py:157} INFO - Started process (PID=77182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:10:01.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:10:01.019+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:10:01.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:10:01.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:10:01.068+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:10:01.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:10:01.086+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:10:01.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:10:01.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-13T18:10:31.418+0000] {processor.py:157} INFO - Started process (PID=77192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:10:31.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:10:31.421+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:10:31.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:10:31.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:10:31.468+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:10:31.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:10:31.491+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:10:31.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:10:31.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-13T18:11:01.774+0000] {processor.py:157} INFO - Started process (PID=77202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:11:01.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:11:01.782+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:11:01.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:11:01.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:11:01.840+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:11:01.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:11:01.855+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:11:01.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:11:01.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-13T18:11:32.039+0000] {processor.py:157} INFO - Started process (PID=77212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:11:32.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:11:32.046+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:11:32.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:11:32.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:11:32.102+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:11:32.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:11:32.118+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:11:32.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:11:32.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-13T18:12:02.449+0000] {processor.py:157} INFO - Started process (PID=77222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:12:02.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:12:02.456+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:12:02.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:12:02.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:12:02.512+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:12:02.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:12:02.529+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:12:02.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:12:02.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-13T18:12:32.892+0000] {processor.py:157} INFO - Started process (PID=77232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:12:32.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:12:32.903+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:12:32.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:12:32.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:12:32.964+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:12:32.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:12:32.980+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:12:32.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:12:32.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-13T18:13:03.217+0000] {processor.py:157} INFO - Started process (PID=77242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:13:03.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:13:03.222+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:13:03.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:13:03.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:13:03.261+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:13:03.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:13:03.281+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:13:03.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:13:03.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-13T18:13:33.627+0000] {processor.py:157} INFO - Started process (PID=77252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:13:33.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:13:33.636+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:13:33.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:13:33.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:13:33.686+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:13:33.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:13:33.701+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:13:33.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:13:33.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-13T18:14:04.050+0000] {processor.py:157} INFO - Started process (PID=77261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:14:04.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:14:04.055+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:14:04.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:14:04.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:14:04.112+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:14:04.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:14:04.126+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:14:04.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:14:04.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-13T18:14:34.497+0000] {processor.py:157} INFO - Started process (PID=77271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:14:34.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:14:34.503+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:14:34.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:14:34.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:14:34.567+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:14:34.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:14:34.582+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:14:34.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:14:34.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-13T18:15:04.867+0000] {processor.py:157} INFO - Started process (PID=77282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:15:04.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:15:04.873+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:15:04.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:15:04.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:15:04.933+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:15:04.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:15:04.950+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:15:04.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:15:04.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-13T18:15:35.213+0000] {processor.py:157} INFO - Started process (PID=77292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:15:35.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:15:35.228+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:15:35.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:15:35.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:15:35.292+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:15:35.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:15:35.325+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:15:35.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:15:35.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-13T18:16:05.554+0000] {processor.py:157} INFO - Started process (PID=77302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:16:05.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:16:05.561+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:16:05.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:16:05.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:16:05.624+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:16:05.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:16:05.641+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:16:05.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:16:05.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-13T18:16:35.939+0000] {processor.py:157} INFO - Started process (PID=77312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:16:35.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:16:35.944+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:16:35.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:16:35.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:16:36.009+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:16:36.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:16:36.025+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:16:36.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:16:36.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-13T18:17:06.305+0000] {processor.py:157} INFO - Started process (PID=77321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:17:06.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:17:06.313+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:17:06.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:17:06.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:17:06.406+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:17:06.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:17:06.430+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:17:06.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:17:06.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-13T18:17:36.819+0000] {processor.py:157} INFO - Started process (PID=77331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:17:36.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:17:36.824+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:17:36.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:17:36.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:17:36.873+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:17:36.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:17:36.893+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:17:36.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:17:36.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-13T18:18:07.144+0000] {processor.py:157} INFO - Started process (PID=77342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:18:07.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:18:07.152+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:18:07.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:18:07.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:18:07.225+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:18:07.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:18:07.249+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:18:07.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:18:07.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-13T18:18:37.528+0000] {processor.py:157} INFO - Started process (PID=77352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:18:37.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:18:37.555+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:18:37.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:18:37.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:18:37.624+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:18:37.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:18:37.645+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:18:37.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:18:37.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-13T18:19:07.846+0000] {processor.py:157} INFO - Started process (PID=77362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:19:07.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:19:07.850+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:19:07.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:19:07.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:19:07.918+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:19:07.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:19:07.943+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:19:07.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:19:07.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-13T18:19:38.304+0000] {processor.py:157} INFO - Started process (PID=77371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:19:38.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:19:38.311+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:19:38.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:19:38.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:19:38.394+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:19:38.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:19:38.410+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:19:38.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:19:38.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-13T18:20:08.678+0000] {processor.py:157} INFO - Started process (PID=77381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:20:08.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:20:08.683+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:20:08.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:20:08.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:20:08.722+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:20:08.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:20:08.738+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:20:08.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:20:08.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-13T18:20:39.006+0000] {processor.py:157} INFO - Started process (PID=77392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:20:39.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:20:39.011+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:20:39.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:20:39.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:20:39.071+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:20:39.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:20:39.087+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:20:39.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:20:39.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-13T18:21:09.313+0000] {processor.py:157} INFO - Started process (PID=77402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:21:09.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:21:09.316+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:21:09.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:21:09.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:21:09.355+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:21:09.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:21:09.367+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:21:09.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:21:09.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-13T18:21:39.716+0000] {processor.py:157} INFO - Started process (PID=77411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:21:39.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:21:39.726+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:21:39.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:21:39.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:21:39.789+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:21:39.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:21:39.821+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:21:39.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:21:39.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-13T18:22:10.083+0000] {processor.py:157} INFO - Started process (PID=77422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:22:10.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:22:10.090+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:22:10.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:22:10.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:22:10.139+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:22:10.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:22:10.156+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:22:10.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:22:10.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-13T18:22:40.407+0000] {processor.py:157} INFO - Started process (PID=77431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:22:40.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:22:40.413+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:22:40.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:22:40.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:22:40.458+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:22:40.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:22:40.482+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:22:40.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:22:40.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T18:23:10.740+0000] {processor.py:157} INFO - Started process (PID=77442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:23:10.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:23:10.745+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:23:10.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:23:10.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:23:10.789+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:23:10.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:23:10.816+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:23:10.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:23:10.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-13T18:23:41.112+0000] {processor.py:157} INFO - Started process (PID=77452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:23:41.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:23:41.117+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:23:41.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:23:41.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:23:41.170+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:23:41.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:23:41.185+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:23:41.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:23:41.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-13T18:24:11.389+0000] {processor.py:157} INFO - Started process (PID=77462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:24:11.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:24:11.394+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:24:11.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:24:11.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:24:11.448+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:24:11.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:24:11.462+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:24:11.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:24:11.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-13T18:24:41.648+0000] {processor.py:157} INFO - Started process (PID=77472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:24:41.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:24:41.652+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:24:41.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:24:41.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:24:41.686+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:24:41.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:24:41.700+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:24:41.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:24:41.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-13T18:25:11.966+0000] {processor.py:157} INFO - Started process (PID=77482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:25:11.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:25:11.969+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:25:11.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:25:11.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:25:11.999+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:25:11.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:25:12.011+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:25:12.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:25:12.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-13T18:25:42.357+0000] {processor.py:157} INFO - Started process (PID=77492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:25:42.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:25:42.363+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:25:42.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:25:42.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:25:42.415+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:25:42.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:25:42.429+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:25:42.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:25:42.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-13T18:26:12.717+0000] {processor.py:157} INFO - Started process (PID=77502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:26:12.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:26:12.722+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:26:12.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:26:12.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:26:12.761+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:26:12.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:26:12.778+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:26:12.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:26:12.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-13T18:26:43.150+0000] {processor.py:157} INFO - Started process (PID=77512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:26:43.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:26:43.163+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:26:43.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:26:43.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:26:43.230+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:26:43.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:26:43.244+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:26:43.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:26:43.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-13T18:27:13.576+0000] {processor.py:157} INFO - Started process (PID=77522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:27:13.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:27:13.581+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:27:13.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:27:13.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:27:13.648+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:27:13.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:27:13.663+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:27:13.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:27:13.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-13T18:27:44.051+0000] {processor.py:157} INFO - Started process (PID=77532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:27:44.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:27:44.057+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:27:44.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:27:44.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:27:44.113+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:27:44.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:27:44.126+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:27:44.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:27:44.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-13T18:28:14.413+0000] {processor.py:157} INFO - Started process (PID=77542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:28:14.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:28:14.418+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:28:14.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:28:14.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:28:14.470+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:28:14.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:28:14.483+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:28:14.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:28:14.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T18:28:44.747+0000] {processor.py:157} INFO - Started process (PID=77552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:28:44.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:28:44.754+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:28:44.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:28:44.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:28:44.830+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:28:44.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:28:44.845+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:28:44.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:28:44.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-13T18:29:15.006+0000] {processor.py:157} INFO - Started process (PID=77562) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:29:15.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:29:15.009+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:29:15.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:29:15.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:29:15.037+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:29:15.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:29:15.049+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:29:15.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:29:15.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-13T18:29:45.341+0000] {processor.py:157} INFO - Started process (PID=77572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:29:45.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:29:45.345+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:29:45.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:29:45.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:29:45.393+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:29:45.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:29:45.405+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:29:45.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:29:45.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-13T18:30:15.669+0000] {processor.py:157} INFO - Started process (PID=77582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:30:15.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:30:15.677+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:30:15.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:30:15.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:30:15.757+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:30:15.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:30:15.776+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:30:15.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:30:15.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-13T18:30:46.027+0000] {processor.py:157} INFO - Started process (PID=77592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:30:46.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:30:46.038+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:30:46.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:30:46.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:30:46.089+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:30:46.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:30:46.102+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:30:46.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:30:46.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-13T18:31:16.480+0000] {processor.py:157} INFO - Started process (PID=77602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:31:16.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:31:16.501+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:31:16.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:31:16.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:31:16.550+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:31:16.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:31:16.564+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:31:16.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:31:16.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-13T18:31:46.825+0000] {processor.py:157} INFO - Started process (PID=77612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:31:46.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:31:46.837+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:31:46.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:31:46.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:31:46.928+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:31:46.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:31:46.943+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:31:46.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:31:46.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-13T18:32:17.160+0000] {processor.py:157} INFO - Started process (PID=77622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:32:17.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:32:17.164+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:32:17.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:32:17.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:32:17.200+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:32:17.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:32:17.213+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:32:17.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:32:17.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-13T18:32:47.442+0000] {processor.py:157} INFO - Started process (PID=77632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:32:47.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:32:47.446+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:32:47.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:32:47.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:32:47.473+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:32:47.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:32:47.485+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:32:47.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:32:47.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-13T18:33:17.802+0000] {processor.py:157} INFO - Started process (PID=77642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:33:17.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:33:17.807+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:33:17.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:33:17.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:33:17.864+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:33:17.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:33:17.880+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:33:17.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:33:17.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-13T18:33:48.198+0000] {processor.py:157} INFO - Started process (PID=77652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:33:48.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:33:48.200+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:33:48.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:33:48.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:33:48.229+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:33:48.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:33:48.243+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:33:48.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:33:48.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-13T18:34:18.470+0000] {processor.py:157} INFO - Started process (PID=77662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:34:18.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:34:18.475+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:34:18.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:34:18.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:34:18.537+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:34:18.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:34:18.550+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:34:18.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:34:18.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-13T18:34:48.804+0000] {processor.py:157} INFO - Started process (PID=77672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:34:48.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:34:48.808+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:34:48.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:34:48.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:34:48.835+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:34:48.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:34:48.849+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:34:48.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:34:48.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-13T18:35:19.161+0000] {processor.py:157} INFO - Started process (PID=77682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:35:19.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:35:19.164+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:35:19.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:35:19.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:35:19.190+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:35:19.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:35:19.203+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:35:19.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:35:19.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-13T18:35:49.541+0000] {processor.py:157} INFO - Started process (PID=77692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:35:49.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:35:49.545+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:35:49.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:35:49.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:35:49.647+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:35:49.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:35:49.664+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:35:49.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:35:49.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-13T18:36:19.852+0000] {processor.py:157} INFO - Started process (PID=77701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:36:19.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:36:19.860+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:36:19.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:36:19.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:36:19.936+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:36:19.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:36:19.952+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:36:19.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:36:19.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-13T18:36:50.204+0000] {processor.py:157} INFO - Started process (PID=77712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:36:50.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:36:50.206+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:36:50.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:36:50.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:36:50.233+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:36:50.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:36:50.244+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:36:50.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:36:50.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-13T18:37:20.643+0000] {processor.py:157} INFO - Started process (PID=77722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:37:20.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:37:20.653+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:37:20.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:37:20.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:37:20.782+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:37:20.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:37:20.810+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:37:20.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:37:20.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-09-13T18:37:50.927+0000] {processor.py:157} INFO - Started process (PID=77732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:37:50.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:37:50.932+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:37:50.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:37:50.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:37:50.984+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:37:50.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:37:50.997+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:37:50.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:37:51.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T18:38:21.591+0000] {processor.py:157} INFO - Started process (PID=77742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:38:21.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:38:21.598+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:38:21.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:38:21.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:38:21.647+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:38:21.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:38:21.661+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:38:21.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:38:21.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-13T18:38:51.959+0000] {processor.py:157} INFO - Started process (PID=77752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:38:51.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:38:51.973+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:38:51.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:38:51.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:38:52.020+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:38:52.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:38:52.034+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:38:52.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:38:52.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-13T18:39:22.349+0000] {processor.py:157} INFO - Started process (PID=77762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:39:22.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:39:22.358+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:39:22.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:39:22.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:39:22.436+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:39:22.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:39:22.470+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:39:22.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:39:22.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-13T18:39:52.646+0000] {processor.py:157} INFO - Started process (PID=77772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:39:52.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:39:52.649+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:39:52.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:39:52.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:39:52.675+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:39:52.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:39:52.685+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:39:52.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:39:52.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-13T18:40:23.001+0000] {processor.py:157} INFO - Started process (PID=77781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:40:23.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:40:23.006+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:40:23.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:40:23.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:40:23.047+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:40:23.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:40:23.068+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:40:23.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:40:23.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-13T18:40:53.405+0000] {processor.py:157} INFO - Started process (PID=77792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:40:53.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:40:53.408+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:40:53.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:40:53.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:40:53.437+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:40:53.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:40:53.447+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:40:53.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:40:53.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-13T18:41:23.764+0000] {processor.py:157} INFO - Started process (PID=77802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:41:23.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:41:23.787+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:41:23.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:41:23.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:41:23.832+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:41:23.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:41:23.849+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:41:23.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:41:23.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-13T18:41:54.134+0000] {processor.py:157} INFO - Started process (PID=77812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:41:54.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:41:54.138+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:41:54.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:41:54.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:41:54.173+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:41:54.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:41:54.186+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:41:54.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:41:54.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-13T18:42:24.475+0000] {processor.py:157} INFO - Started process (PID=77822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:42:24.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:42:24.489+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:42:24.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:42:24.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:42:24.529+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:42:24.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:42:24.546+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:42:24.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:42:24.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-13T18:42:54.717+0000] {processor.py:157} INFO - Started process (PID=77832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:42:54.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:42:54.722+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:42:54.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:42:54.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:42:54.764+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:42:54.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:42:54.777+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:42:54.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:42:54.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-13T18:43:25.012+0000] {processor.py:157} INFO - Started process (PID=77840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:43:25.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:43:25.017+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:43:25.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:43:25.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:43:25.073+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:43:25.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:43:25.092+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:43:25.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:43:25.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-13T18:43:55.370+0000] {processor.py:157} INFO - Started process (PID=77851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:43:55.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:43:55.378+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:43:55.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:43:55.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:43:55.460+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:43:55.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:43:55.485+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:43:55.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:43:55.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-13T18:44:25.759+0000] {processor.py:157} INFO - Started process (PID=77862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:44:25.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:44:25.766+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:44:25.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:44:25.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:44:25.820+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:44:25.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:44:25.841+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:44:25.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:44:25.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-13T18:44:56.113+0000] {processor.py:157} INFO - Started process (PID=77871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:44:56.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:44:56.122+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:44:56.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:44:56.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:44:56.213+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:44:56.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:44:56.235+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:44:56.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:44:56.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-13T18:45:26.424+0000] {processor.py:157} INFO - Started process (PID=77882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:45:26.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:45:26.431+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:45:26.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:45:26.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:45:26.468+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:45:26.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:45:26.481+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:45:26.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:45:26.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-13T18:47:15.014+0000] {processor.py:157} INFO - Started process (PID=77892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:47:15.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:47:15.021+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:47:15.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:47:15.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:47:15.070+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:47:15.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:47:15.085+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:47:15.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:47:15.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-13T18:47:45.264+0000] {processor.py:157} INFO - Started process (PID=77904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:47:45.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:47:45.272+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:47:45.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:47:45.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:47:45.328+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:47:45.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:47:45.342+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:47:45.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:47:45.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-13T18:48:15.557+0000] {processor.py:157} INFO - Started process (PID=77914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:48:15.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:48:15.580+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:48:15.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:48:15.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:48:15.624+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:48:15.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:48:15.646+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:48:15.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:48:15.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-13T18:48:45.806+0000] {processor.py:157} INFO - Started process (PID=77924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:48:45.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:48:45.809+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:48:45.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:48:45.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:48:45.851+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:48:45.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:48:45.865+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:48:45.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:48:45.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-13T18:49:16.148+0000] {processor.py:157} INFO - Started process (PID=77933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:49:16.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:49:16.156+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:49:16.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:49:16.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:49:16.203+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:49:16.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:49:16.218+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:49:16.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:49:16.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-13T18:49:46.593+0000] {processor.py:157} INFO - Started process (PID=77943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:49:46.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:49:46.604+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:49:46.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:49:46.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:49:46.647+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:49:46.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:49:46.662+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:49:46.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:49:46.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-13T18:50:17.019+0000] {processor.py:157} INFO - Started process (PID=77954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:50:17.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:50:17.024+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:50:17.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:50:17.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:50:17.075+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:50:17.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:50:17.093+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:50:17.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:50:17.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T18:50:47.307+0000] {processor.py:157} INFO - Started process (PID=77964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:50:47.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:50:47.312+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:50:47.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:50:47.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:50:47.360+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:50:47.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:50:47.375+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:50:47.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:50:47.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-13T18:51:17.614+0000] {processor.py:157} INFO - Started process (PID=77974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:51:17.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:51:17.618+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:51:17.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:51:17.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:51:17.654+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:51:17.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:51:17.668+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:51:17.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:51:17.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-13T18:51:47.975+0000] {processor.py:157} INFO - Started process (PID=77984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:51:47.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:51:47.977+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:51:47.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:51:47.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:51:48.014+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:51:48.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:51:48.023+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:51:48.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:51:48.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-13T18:52:18.388+0000] {processor.py:157} INFO - Started process (PID=77994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:52:18.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:52:18.394+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:52:18.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:52:18.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:52:18.434+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:52:18.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:52:18.449+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:52:18.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:52:18.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-13T18:52:48.719+0000] {processor.py:157} INFO - Started process (PID=78004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:52:48.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:52:48.726+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:52:48.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:52:48.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:52:48.800+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:52:48.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:52:48.814+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:52:48.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:52:48.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-13T18:53:19.105+0000] {processor.py:157} INFO - Started process (PID=78014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:53:19.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:53:19.111+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:53:19.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:53:19.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:53:19.159+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:53:19.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:53:19.171+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:53:19.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:53:19.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T18:53:49.388+0000] {processor.py:157} INFO - Started process (PID=78023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:53:49.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:53:49.395+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:53:49.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:53:49.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:53:49.485+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:53:49.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:53:49.501+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:53:49.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:53:49.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-13T18:54:19.702+0000] {processor.py:157} INFO - Started process (PID=78032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:54:19.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:54:19.706+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:54:19.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:54:19.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:54:19.752+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:54:19.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:54:19.766+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:54:19.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:54:19.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-13T18:54:50.138+0000] {processor.py:157} INFO - Started process (PID=78044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:54:50.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:54:50.142+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:54:50.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:54:50.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:54:50.183+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:54:50.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:54:50.206+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:54:50.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:54:50.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-13T18:55:20.444+0000] {processor.py:157} INFO - Started process (PID=78054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:55:20.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:55:20.447+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:55:20.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:55:20.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:55:20.485+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:55:20.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:55:20.502+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:55:20.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:55:20.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-13T18:55:51.250+0000] {processor.py:157} INFO - Started process (PID=78064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:55:51.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:55:51.258+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:55:51.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:55:51.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:55:51.310+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:55:51.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:55:51.329+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:55:51.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:55:51.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-13T18:56:46.247+0000] {processor.py:157} INFO - Started process (PID=78073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:56:46.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:56:46.251+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:56:46.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:56:46.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:56:46.291+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:56:46.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:56:46.306+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:56:46.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:56:46.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-13T18:57:16.580+0000] {processor.py:157} INFO - Started process (PID=78086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:57:16.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:57:16.583+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:57:16.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:57:16.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:57:16.620+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:57:16.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:57:16.629+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:57:16.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:57:16.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-13T18:57:46.974+0000] {processor.py:157} INFO - Started process (PID=78095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:57:46.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:57:46.979+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:57:46.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:57:46.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:57:47.031+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:57:47.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:57:47.046+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:57:47.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:57:47.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-13T18:58:17.259+0000] {processor.py:157} INFO - Started process (PID=78106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:58:17.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:58:17.263+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:58:17.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:58:17.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:58:17.301+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:58:17.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:58:17.310+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:58:17.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:58:17.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-13T18:58:47.620+0000] {processor.py:157} INFO - Started process (PID=78115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:58:47.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:58:47.625+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:58:47.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:58:47.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:58:47.674+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:58:47.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:58:47.690+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:58:47.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:58:47.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-13T18:59:17.939+0000] {processor.py:157} INFO - Started process (PID=78126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:59:17.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:59:17.944+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:59:17.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:59:17.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:59:17.970+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:59:17.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:59:17.980+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:59:17.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:59:17.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-13T18:59:48.310+0000] {processor.py:157} INFO - Started process (PID=78136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:59:48.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T18:59:48.329+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:59:48.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:59:48.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T18:59:48.375+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:59:48.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T18:59:48.388+0000] {logging_mixin.py:151} INFO - [2024-09-13T18:59:48.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T18:59:48.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-13T19:00:18.624+0000] {processor.py:157} INFO - Started process (PID=78146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:00:18.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:00:18.629+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:00:18.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:00:18.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:00:18.665+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:00:18.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:00:18.678+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:00:18.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:00:18.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-13T19:00:48.910+0000] {processor.py:157} INFO - Started process (PID=78156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:00:48.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:00:48.913+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:00:48.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:00:48.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:00:48.939+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:00:48.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:00:48.948+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:00:48.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:00:48.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-13T19:01:19.249+0000] {processor.py:157} INFO - Started process (PID=78166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:01:19.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:01:19.254+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:01:19.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:01:19.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:01:19.311+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:01:19.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:01:19.324+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:01:19.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:01:19.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-13T19:01:49.595+0000] {processor.py:157} INFO - Started process (PID=78176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:01:49.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:01:49.612+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:01:49.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:01:49.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:01:49.686+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:01:49.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:01:49.706+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:01:49.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:01:49.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-13T19:02:19.957+0000] {processor.py:157} INFO - Started process (PID=78186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:02:19.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:02:19.962+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:02:19.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:02:19.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:02:19.999+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:02:19.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:02:20.011+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:02:20.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:02:20.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-13T19:02:50.225+0000] {processor.py:157} INFO - Started process (PID=78195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:02:50.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:02:50.238+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:02:50.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:02:50.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:02:50.303+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:02:50.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:02:50.320+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:02:50.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:02:50.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-13T19:03:20.499+0000] {processor.py:157} INFO - Started process (PID=78206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:03:20.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:03:20.503+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:03:20.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:03:20.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:03:20.538+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:03:20.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:03:20.552+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:03:20.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:03:20.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-13T19:03:50.744+0000] {processor.py:157} INFO - Started process (PID=78216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:03:50.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:03:50.747+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:03:50.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:03:50.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:03:50.773+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:03:50.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:03:50.782+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:03:50.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:03:50.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-13T19:04:21.045+0000] {processor.py:157} INFO - Started process (PID=78225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:04:21.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:04:21.050+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:04:21.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:04:21.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:04:21.116+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:04:21.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:04:21.132+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:04:21.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:04:21.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-13T19:04:51.316+0000] {processor.py:157} INFO - Started process (PID=78236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:04:51.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:04:51.319+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:04:51.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:04:51.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:04:51.345+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:04:51.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:04:51.355+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:04:51.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:04:51.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-13T19:05:21.645+0000] {processor.py:157} INFO - Started process (PID=78245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:05:21.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:05:21.649+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:05:21.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:05:21.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:05:21.690+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:05:21.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:05:21.702+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:05:21.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:05:21.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-13T19:05:51.977+0000] {processor.py:157} INFO - Started process (PID=78256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:05:51.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:05:51.983+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:05:51.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:05:51.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:05:52.034+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:05:52.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:05:52.048+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:05:52.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:05:52.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T19:06:22.300+0000] {processor.py:157} INFO - Started process (PID=78266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:06:22.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:06:22.303+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:06:22.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:06:22.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:06:22.329+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:06:22.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:06:22.339+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:06:22.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:06:22.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-13T19:06:52.694+0000] {processor.py:157} INFO - Started process (PID=78276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:06:52.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:06:52.700+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:06:52.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:06:52.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:06:52.772+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:06:52.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:06:52.787+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:06:52.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:06:52.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-13T19:07:23.035+0000] {processor.py:157} INFO - Started process (PID=78286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:07:23.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:07:23.040+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:07:23.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:07:23.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:07:23.102+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:07:23.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:07:23.115+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:07:23.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:07:23.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-13T19:07:53.405+0000] {processor.py:157} INFO - Started process (PID=78296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:07:53.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:07:53.411+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:07:53.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:07:53.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:07:53.460+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:07:53.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:07:53.479+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:07:53.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:07:53.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-13T19:08:23.827+0000] {processor.py:157} INFO - Started process (PID=78306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:08:23.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:08:23.847+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:08:23.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:08:23.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:08:23.890+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:08:23.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:08:23.903+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:08:23.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:08:23.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-13T19:08:54.145+0000] {processor.py:157} INFO - Started process (PID=78316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:08:54.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:08:54.152+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:08:54.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:08:54.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:08:54.192+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:08:54.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:08:54.209+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:08:54.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:08:54.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-13T19:09:24.538+0000] {processor.py:157} INFO - Started process (PID=78326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:09:24.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:09:24.542+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:09:24.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:09:24.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:09:24.595+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:09:24.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:09:24.609+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:09:24.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:09:24.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-13T19:09:54.955+0000] {processor.py:157} INFO - Started process (PID=78336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:09:54.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:09:54.967+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:09:54.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:09:55.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:09:55.039+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:09:55.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:09:55.078+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:09:55.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:09:55.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-13T19:10:25.316+0000] {processor.py:157} INFO - Started process (PID=78346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:10:25.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:10:25.324+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:10:25.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:10:25.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:10:25.363+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:10:25.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:10:25.376+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:10:25.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:10:25.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-13T19:10:55.698+0000] {processor.py:157} INFO - Started process (PID=78355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:10:55.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:10:55.704+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:10:55.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:10:55.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:10:55.771+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:10:55.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:10:55.791+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:10:55.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:10:55.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-13T19:11:26.090+0000] {processor.py:157} INFO - Started process (PID=78366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:11:26.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:11:26.095+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:11:26.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:11:26.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:11:26.149+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:11:26.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:11:26.163+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:11:26.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:11:26.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-13T19:11:56.449+0000] {processor.py:157} INFO - Started process (PID=78376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:11:56.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:11:56.455+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:11:56.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:11:56.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:11:56.504+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:11:56.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:11:56.525+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:11:56.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:11:56.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-13T19:12:26.798+0000] {processor.py:157} INFO - Started process (PID=78385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:12:26.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:12:26.808+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:12:26.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:12:26.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:12:26.868+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:12:26.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:12:26.882+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:12:26.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:12:26.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-13T19:12:57.137+0000] {processor.py:157} INFO - Started process (PID=78395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:12:57.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:12:57.142+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:12:57.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:12:57.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:12:57.203+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:12:57.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:12:57.218+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:12:57.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:12:57.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-13T19:13:27.528+0000] {processor.py:157} INFO - Started process (PID=78406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:13:27.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:13:27.537+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:13:27.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:13:27.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:13:27.650+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:13:27.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:13:27.669+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:13:27.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:13:27.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-13T19:13:57.824+0000] {processor.py:157} INFO - Started process (PID=78415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:13:57.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:13:57.831+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:13:57.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:13:57.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:13:57.883+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:13:57.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:13:57.898+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:13:57.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:13:57.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-13T19:14:28.232+0000] {processor.py:157} INFO - Started process (PID=78426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:14:28.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:14:28.238+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:14:28.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:14:28.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:14:28.291+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:14:28.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:14:28.306+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:14:28.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:14:28.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T19:14:58.736+0000] {processor.py:157} INFO - Started process (PID=78436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:14:58.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:14:58.741+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:14:58.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:14:58.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:14:58.788+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:14:58.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:14:58.802+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:14:58.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:14:58.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T19:15:29.187+0000] {processor.py:157} INFO - Started process (PID=78446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:15:29.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:15:29.192+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:15:29.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:15:29.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:15:29.248+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:15:29.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:15:29.268+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:15:29.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:15:29.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-13T19:15:59.584+0000] {processor.py:157} INFO - Started process (PID=78456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:15:59.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:15:59.595+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:15:59.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:15:59.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:15:59.643+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:15:59.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:15:59.660+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:15:59.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:15:59.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-13T19:16:29.916+0000] {processor.py:157} INFO - Started process (PID=78466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:16:29.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:16:29.923+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:16:29.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:16:29.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:16:29.982+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:16:29.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:16:29.997+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:16:29.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:16:30.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-13T19:17:00.357+0000] {processor.py:157} INFO - Started process (PID=78476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:17:00.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:17:00.368+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:17:00.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:17:00.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:17:00.501+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:17:00.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:17:00.514+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:17:00.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:17:00.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-13T19:17:30.648+0000] {processor.py:157} INFO - Started process (PID=78486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:17:30.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:17:30.653+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:17:30.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:17:30.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:17:30.721+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:17:30.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:17:30.735+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:17:30.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:17:30.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-13T19:18:00.985+0000] {processor.py:157} INFO - Started process (PID=78496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:18:00.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:18:00.992+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:18:00.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:18:01.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:18:01.058+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:18:01.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:18:01.072+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:18:01.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:18:01.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-13T19:18:31.347+0000] {processor.py:157} INFO - Started process (PID=78506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:18:31.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:18:31.353+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:18:31.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:18:31.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:18:31.397+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:18:31.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:18:31.426+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:18:31.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:18:31.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-13T19:19:01.936+0000] {processor.py:157} INFO - Started process (PID=78516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:19:01.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:19:01.944+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:19:01.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:19:01.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:19:02.048+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:19:02.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:19:02.102+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:19:02.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:19:02.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-09-13T19:19:32.621+0000] {processor.py:157} INFO - Started process (PID=78526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:19:32.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:19:32.627+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:19:32.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:19:32.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:19:32.681+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:19:32.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:19:32.695+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:19:32.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:19:32.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-13T19:20:03.013+0000] {processor.py:157} INFO - Started process (PID=78536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:20:03.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:20:03.020+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:20:03.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:20:03.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:20:03.083+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:20:03.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:20:03.132+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:20:03.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:20:03.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-13T19:20:33.305+0000] {processor.py:157} INFO - Started process (PID=78546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:20:33.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:20:33.309+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:20:33.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:20:33.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:20:33.348+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:20:33.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:20:33.362+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:20:33.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:20:33.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-13T19:21:03.704+0000] {processor.py:157} INFO - Started process (PID=78556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:21:03.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:21:03.707+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:21:03.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:21:03.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:21:03.742+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:21:03.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:21:03.756+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:21:03.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:21:03.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-13T19:21:34.009+0000] {processor.py:157} INFO - Started process (PID=78566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:21:34.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:21:34.014+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:21:34.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:21:34.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:21:34.071+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:21:34.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:21:34.088+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:21:34.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:21:34.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-13T19:22:04.440+0000] {processor.py:157} INFO - Started process (PID=78575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:22:04.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:22:04.457+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:22:04.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:22:04.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:22:04.506+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:22:04.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:22:04.521+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:22:04.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:22:04.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-13T19:22:34.876+0000] {processor.py:157} INFO - Started process (PID=78586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:22:34.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:22:34.880+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:22:34.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:22:34.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:22:34.922+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:22:34.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:22:34.940+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:22:34.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:22:34.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-13T19:23:05.300+0000] {processor.py:157} INFO - Started process (PID=78596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:23:05.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:23:05.314+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:23:05.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:23:05.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:23:05.364+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:23:05.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:23:05.386+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:23:05.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:23:05.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-13T19:23:35.705+0000] {processor.py:157} INFO - Started process (PID=78605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:23:35.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:23:35.713+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:23:35.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:23:35.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:23:35.756+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:23:35.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:23:35.776+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:23:35.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:23:35.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-13T19:24:05.966+0000] {processor.py:157} INFO - Started process (PID=78616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:24:05.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:24:05.971+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:24:05.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:24:05.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:24:06.009+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:24:06.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:24:06.032+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:24:06.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:24:06.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-13T19:24:36.369+0000] {processor.py:157} INFO - Started process (PID=78626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:24:36.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:24:36.374+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:24:36.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:24:36.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:24:36.410+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:24:36.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:24:36.423+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:24:36.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:24:36.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-13T19:25:06.753+0000] {processor.py:157} INFO - Started process (PID=78636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:25:06.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:25:06.760+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:25:06.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:25:06.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:25:06.798+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:25:06.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:25:06.811+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:25:06.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:25:06.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-13T19:25:37.040+0000] {processor.py:157} INFO - Started process (PID=78645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:25:37.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:25:37.052+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:25:37.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:25:37.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:25:37.127+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:25:37.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:25:37.151+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:25:37.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:25:37.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-13T19:26:07.409+0000] {processor.py:157} INFO - Started process (PID=78656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:26:07.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:26:07.413+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:26:07.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:26:07.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:26:07.453+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:26:07.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:26:07.472+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:26:07.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:26:07.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-13T19:26:37.811+0000] {processor.py:157} INFO - Started process (PID=78665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:26:37.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:26:37.816+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:26:37.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:26:37.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:26:37.874+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:26:37.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:26:37.888+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:26:37.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:26:37.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-13T19:27:08.073+0000] {processor.py:157} INFO - Started process (PID=78675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:27:08.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:27:08.078+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:27:08.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:27:08.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:27:08.134+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:27:08.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:27:08.147+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:27:08.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:27:08.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T19:27:38.490+0000] {processor.py:157} INFO - Started process (PID=78686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:27:38.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:27:38.494+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:27:38.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:27:38.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:27:38.553+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:27:38.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:27:38.569+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:27:38.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:27:38.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-13T19:28:08.831+0000] {processor.py:157} INFO - Started process (PID=78696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:28:08.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:28:08.838+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:28:08.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:28:08.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:28:08.885+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:28:08.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:28:08.916+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:28:08.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:28:08.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-13T19:28:39.095+0000] {processor.py:157} INFO - Started process (PID=78706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:28:39.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:28:39.099+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:28:39.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:28:39.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:28:39.126+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:28:39.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:28:39.135+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:28:39.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:28:39.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-13T19:29:09.425+0000] {processor.py:157} INFO - Started process (PID=78716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:29:09.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:29:09.430+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:29:09.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:29:09.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:29:09.467+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:29:09.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:29:09.480+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:29:09.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:29:09.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-13T19:29:39.751+0000] {processor.py:157} INFO - Started process (PID=78726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:29:39.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:29:39.753+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:29:39.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:29:39.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:29:39.781+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:29:39.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:29:39.792+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:29:39.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:29:39.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-13T19:30:10.106+0000] {processor.py:157} INFO - Started process (PID=78735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:30:10.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:30:10.121+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:30:10.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:30:10.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:30:10.164+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:30:10.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:30:10.178+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:30:10.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:30:10.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-13T19:30:40.540+0000] {processor.py:157} INFO - Started process (PID=78746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:30:40.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:30:40.562+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:30:40.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:30:40.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:30:40.606+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:30:40.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:30:40.620+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:30:40.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:30:40.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T19:31:10.896+0000] {processor.py:157} INFO - Started process (PID=78756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:31:10.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:31:10.902+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:31:10.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:31:10.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:31:10.966+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:31:10.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:31:10.990+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:31:10.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:31:11.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-13T19:32:04.957+0000] {processor.py:157} INFO - Started process (PID=78766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:32:04.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:32:04.960+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:32:04.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:32:04.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:32:04.995+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:32:04.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:32:05.011+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:32:05.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:32:05.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-13T19:32:47.279+0000] {processor.py:157} INFO - Started process (PID=78778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:32:47.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:32:47.289+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:32:47.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:32:47.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:32:47.340+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:32:47.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:32:47.398+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:32:47.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:32:47.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-13T19:33:17.653+0000] {processor.py:157} INFO - Started process (PID=78787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:33:17.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:33:17.658+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:33:17.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:33:17.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:33:17.707+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:33:17.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:33:17.718+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:33:17.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:33:17.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-13T19:34:38.808+0000] {processor.py:157} INFO - Started process (PID=78798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:34:38.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:34:38.812+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:34:38.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:34:38.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:34:38.865+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:34:38.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:34:38.886+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:34:38.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:34:38.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-13T19:35:09.160+0000] {processor.py:157} INFO - Started process (PID=78809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:35:09.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:35:09.166+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:35:09.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:35:09.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:35:09.223+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:35:09.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:35:09.240+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:35:09.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:35:09.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-13T19:35:39.442+0000] {processor.py:157} INFO - Started process (PID=78820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:35:39.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:35:39.444+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:35:39.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:35:39.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:35:39.475+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:35:39.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:35:39.486+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:35:39.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:35:39.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-13T19:36:09.798+0000] {processor.py:157} INFO - Started process (PID=78830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:36:09.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:36:09.801+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:36:09.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:36:09.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:36:09.837+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:36:09.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:36:09.849+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:36:09.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:36:09.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-13T19:36:40.122+0000] {processor.py:157} INFO - Started process (PID=78840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:36:40.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:36:40.131+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:36:40.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:36:40.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:36:40.223+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:36:40.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:36:40.243+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:36:40.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:36:40.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-13T19:37:10.629+0000] {processor.py:157} INFO - Started process (PID=78850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:37:10.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:37:10.634+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:37:10.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:37:10.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:37:10.683+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:37:10.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:37:10.697+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:37:10.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:37:10.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-13T19:37:40.978+0000] {processor.py:157} INFO - Started process (PID=78860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:37:40.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:37:40.983+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:37:40.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:37:41.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:37:41.040+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:37:41.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:37:41.055+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:37:41.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:37:41.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-13T19:38:11.312+0000] {processor.py:157} INFO - Started process (PID=78870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:38:11.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:38:11.317+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:38:11.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:38:11.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:38:11.371+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:38:11.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:38:11.386+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:38:11.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:38:11.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-13T19:38:41.773+0000] {processor.py:157} INFO - Started process (PID=78880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:38:41.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:38:41.778+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:38:41.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:38:41.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:38:41.831+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:38:41.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:38:41.856+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:38:41.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:38:41.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-13T19:39:12.099+0000] {processor.py:157} INFO - Started process (PID=78890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:39:12.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:39:12.106+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:39:12.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:39:12.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:39:12.166+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:39:12.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:39:12.180+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:39:12.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:39:12.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T19:39:42.396+0000] {processor.py:157} INFO - Started process (PID=78900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:39:42.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:39:42.399+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:39:42.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:39:42.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:39:42.440+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:39:42.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:39:42.456+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:39:42.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:39:42.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-13T19:40:12.744+0000] {processor.py:157} INFO - Started process (PID=78910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:40:12.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:40:12.746+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:40:12.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:40:12.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:40:12.771+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:40:12.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:40:12.781+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:40:12.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:40:12.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-13T19:40:43.053+0000] {processor.py:157} INFO - Started process (PID=78920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:40:43.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:40:43.063+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:40:43.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:40:43.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:40:43.104+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:40:43.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:40:43.122+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:40:43.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:40:43.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-13T19:41:13.370+0000] {processor.py:157} INFO - Started process (PID=78930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:41:13.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:41:13.381+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:41:13.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:41:13.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:41:13.472+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:41:13.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:41:13.510+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:41:13.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:41:13.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-13T19:41:43.665+0000] {processor.py:157} INFO - Started process (PID=78939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:41:43.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:41:43.670+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:41:43.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:41:43.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:41:43.715+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:41:43.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:41:43.729+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:41:43.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:41:43.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T19:42:14.103+0000] {processor.py:157} INFO - Started process (PID=78949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:42:14.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:42:14.108+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:42:14.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:42:14.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:42:14.151+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:42:14.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:42:14.168+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:42:14.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:42:14.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-13T19:42:44.435+0000] {processor.py:157} INFO - Started process (PID=78960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:42:44.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:42:44.453+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:42:44.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:42:44.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:42:44.487+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:42:44.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:42:44.503+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:42:44.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:42:44.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-13T19:43:14.862+0000] {processor.py:157} INFO - Started process (PID=78970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:43:14.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:43:14.867+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:43:14.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:43:14.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:43:14.910+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:43:14.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:43:14.925+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:43:14.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:43:14.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-13T19:43:45.187+0000] {processor.py:157} INFO - Started process (PID=78980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:43:45.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:43:45.192+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:43:45.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:43:45.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:43:45.228+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:43:45.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:43:45.240+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:43:45.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:43:45.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-13T19:44:15.512+0000] {processor.py:157} INFO - Started process (PID=78990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:44:15.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:44:15.516+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:44:15.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:44:15.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:44:15.541+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:44:15.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:44:15.552+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:44:15.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:44:15.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-13T19:44:45.873+0000] {processor.py:157} INFO - Started process (PID=79000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:44:45.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:44:45.879+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:44:45.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:44:45.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:44:45.914+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:44:45.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:44:45.927+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:44:45.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:44:45.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-13T19:45:16.237+0000] {processor.py:157} INFO - Started process (PID=79010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:45:16.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:45:16.242+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:45:16.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:45:16.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:45:16.303+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:45:16.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:45:16.317+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:45:16.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:45:16.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-13T19:45:46.486+0000] {processor.py:157} INFO - Started process (PID=79020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:45:46.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:45:46.488+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:45:46.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:45:46.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:45:46.517+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:45:46.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:45:46.527+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:45:46.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:45:46.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-13T19:46:16.868+0000] {processor.py:157} INFO - Started process (PID=79030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:46:16.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:46:16.876+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:46:16.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:46:16.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:46:16.930+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:46:16.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:46:16.948+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:46:16.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:46:16.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-13T19:46:47.210+0000] {processor.py:157} INFO - Started process (PID=79038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:46:47.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:46:47.219+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:46:47.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:46:47.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:46:47.268+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:46:47.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:46:47.304+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:46:47.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:46:47.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-13T19:47:17.641+0000] {processor.py:157} INFO - Started process (PID=79049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:47:17.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:47:17.648+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:47:17.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:47:17.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:47:17.690+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:47:17.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:47:17.707+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:47:17.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:47:17.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T19:47:47.975+0000] {processor.py:157} INFO - Started process (PID=79060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:47:47.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:47:47.980+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:47:47.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:47:47.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:47:48.014+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:47:48.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:47:48.024+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:47:48.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:47:48.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-13T19:48:18.349+0000] {processor.py:157} INFO - Started process (PID=79070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:48:18.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:48:18.361+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:48:18.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:48:18.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:48:18.484+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:48:18.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:48:18.508+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:48:18.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:48:18.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-09-13T19:48:48.664+0000] {processor.py:157} INFO - Started process (PID=79080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:48:48.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:48:48.669+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:48:48.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:48:48.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:48:48.726+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:48:48.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:48:48.740+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:48:48.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:48:48.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-13T19:49:19.101+0000] {processor.py:157} INFO - Started process (PID=79090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:49:19.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:49:19.106+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:49:19.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:49:19.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:49:19.168+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:49:19.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:49:19.184+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:49:19.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:49:19.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-13T19:49:49.398+0000] {processor.py:157} INFO - Started process (PID=79099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:49:49.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:49:49.403+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:49:49.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:49:49.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:49:49.435+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:49:49.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:49:49.449+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:49:49.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:49:49.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-13T19:50:19.699+0000] {processor.py:157} INFO - Started process (PID=79110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:50:19.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:50:19.704+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:50:19.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:50:19.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:50:19.747+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:50:19.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:50:19.773+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:50:19.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:50:19.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T19:50:50.042+0000] {processor.py:157} INFO - Started process (PID=79120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:50:50.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:50:50.050+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:50:50.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:50:50.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:50:50.132+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:50:50.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:50:50.147+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:50:50.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:50:50.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-13T19:51:20.362+0000] {processor.py:157} INFO - Started process (PID=79129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:51:20.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:51:20.377+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:51:20.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:51:20.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:51:20.421+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:51:20.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:51:20.434+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:51:20.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:51:20.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-13T19:51:50.673+0000] {processor.py:157} INFO - Started process (PID=79140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:51:50.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:51:50.684+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:51:50.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:51:50.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:51:50.744+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:51:50.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:51:50.768+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:51:50.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:51:50.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-13T19:52:21.002+0000] {processor.py:157} INFO - Started process (PID=79150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:52:21.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:52:21.006+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:52:21.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:52:21.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:52:21.042+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:52:21.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:52:21.057+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:52:21.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:52:21.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-13T19:52:51.419+0000] {processor.py:157} INFO - Started process (PID=79160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:52:51.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:52:51.430+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:52:51.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:52:51.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:52:51.478+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:52:51.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:52:51.503+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:52:51.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:52:51.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-13T19:53:21.703+0000] {processor.py:157} INFO - Started process (PID=79170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:53:21.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:53:21.706+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:53:21.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:53:21.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:53:21.742+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:53:21.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:53:21.756+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:53:21.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:53:21.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-13T19:53:52.030+0000] {processor.py:157} INFO - Started process (PID=79180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:53:52.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:53:52.033+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:53:52.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:53:52.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:53:52.063+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:53:52.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:53:52.077+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:53:52.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:53:52.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-13T19:54:22.444+0000] {processor.py:157} INFO - Started process (PID=79189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:54:22.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:54:22.461+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:54:22.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:54:22.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:54:22.501+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:54:22.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:54:22.514+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:54:22.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:54:22.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-13T19:54:52.876+0000] {processor.py:157} INFO - Started process (PID=79200) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:54:52.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:54:52.881+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:54:52.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:54:52.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:54:52.919+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:54:52.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:54:52.935+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:54:52.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:54:52.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-13T19:55:23.240+0000] {processor.py:157} INFO - Started process (PID=79210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:55:23.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:55:23.244+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:55:23.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:55:23.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:55:23.285+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:55:23.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:55:23.297+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:55:23.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:55:23.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-13T19:55:53.540+0000] {processor.py:157} INFO - Started process (PID=79220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:55:53.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:55:53.545+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:55:53.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:55:53.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:55:53.571+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:55:53.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:55:53.583+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:55:53.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:55:53.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-13T19:56:23.941+0000] {processor.py:157} INFO - Started process (PID=79230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:56:23.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:56:23.947+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:56:23.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:56:23.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:56:24.014+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:56:24.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:56:24.030+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:56:24.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:56:24.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-13T19:56:54.392+0000] {processor.py:157} INFO - Started process (PID=79240) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:56:54.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:56:54.399+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:56:54.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:56:54.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:56:54.468+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:56:54.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:56:54.486+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:56:54.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:56:54.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-13T19:57:24.674+0000] {processor.py:157} INFO - Started process (PID=79250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:57:24.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:57:24.689+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:57:24.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:57:24.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:57:24.729+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:57:24.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:57:24.742+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:57:24.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:57:24.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-13T19:57:54.994+0000] {processor.py:157} INFO - Started process (PID=79260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:57:54.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:57:55.000+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:57:55.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:57:55.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:57:55.037+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:57:55.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:57:55.050+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:57:55.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:57:55.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-13T19:58:25.307+0000] {processor.py:157} INFO - Started process (PID=79270) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:58:25.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:58:25.311+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:58:25.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:58:25.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:58:25.341+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:58:25.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:58:25.352+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:58:25.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:58:25.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-13T19:58:55.671+0000] {processor.py:157} INFO - Started process (PID=79280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:58:55.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:58:55.677+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:58:55.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:58:55.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:58:55.712+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:58:55.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:58:55.725+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:58:55.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:58:55.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-13T19:59:26.056+0000] {processor.py:157} INFO - Started process (PID=79290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:59:26.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:59:26.058+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:59:26.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:59:26.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:59:26.092+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:59:26.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:59:26.101+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:59:26.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:59:26.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-13T19:59:56.589+0000] {processor.py:157} INFO - Started process (PID=79300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:59:56.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T19:59:56.597+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:59:56.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:59:56.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T19:59:56.694+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:59:56.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T19:59:56.714+0000] {logging_mixin.py:151} INFO - [2024-09-13T19:59:56.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T19:59:56.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-13T20:00:26.902+0000] {processor.py:157} INFO - Started process (PID=79310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:00:26.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:00:26.928+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:00:26.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:00:26.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:00:26.973+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:00:26.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:00:26.985+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:00:26.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:00:26.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-13T20:00:57.270+0000] {processor.py:157} INFO - Started process (PID=79320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:00:57.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:00:57.272+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:00:57.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:00:57.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:00:57.303+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:00:57.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:00:57.316+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:00:57.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:00:57.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-13T20:01:27.667+0000] {processor.py:157} INFO - Started process (PID=79330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:01:27.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:01:27.673+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:01:27.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:01:27.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:01:27.716+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:01:27.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:01:27.728+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:01:27.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:01:27.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-13T20:01:57.908+0000] {processor.py:157} INFO - Started process (PID=79340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:01:57.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:01:57.912+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:01:57.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:01:57.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:01:57.936+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:01:57.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:01:57.946+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:01:57.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:01:57.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-13T20:02:28.302+0000] {processor.py:157} INFO - Started process (PID=79350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:02:28.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:02:28.312+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:02:28.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:02:28.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:02:28.358+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:02:28.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:02:28.370+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:02:28.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:02:28.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-13T20:02:58.625+0000] {processor.py:157} INFO - Started process (PID=79360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:02:58.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:02:58.628+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:02:58.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:02:58.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:02:58.654+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:02:58.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:02:58.664+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:02:58.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:02:58.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-13T20:03:28.957+0000] {processor.py:157} INFO - Started process (PID=79370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:03:28.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:03:28.961+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:03:28.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:03:28.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:03:28.999+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:03:28.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:03:29.012+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:03:29.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:03:29.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-13T20:03:59.287+0000] {processor.py:157} INFO - Started process (PID=79380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:03:59.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:03:59.290+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:03:59.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:03:59.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:03:59.317+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:03:59.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:03:59.326+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:03:59.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:03:59.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-13T20:04:29.642+0000] {processor.py:157} INFO - Started process (PID=79390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:04:29.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:04:29.647+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:04:29.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:04:29.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:04:29.681+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:04:29.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:04:29.694+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:04:29.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:04:29.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-13T20:04:59.918+0000] {processor.py:157} INFO - Started process (PID=79400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:04:59.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:04:59.922+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:04:59.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:04:59.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:04:59.950+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:04:59.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:04:59.963+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:04:59.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:04:59.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-13T20:05:30.345+0000] {processor.py:157} INFO - Started process (PID=79410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:05:30.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:05:30.353+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:05:30.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:05:30.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:05:30.407+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:05:30.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:05:30.420+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:05:30.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:05:30.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T20:06:00.702+0000] {processor.py:157} INFO - Started process (PID=79420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:06:00.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:06:00.710+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:06:00.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:06:00.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:06:00.777+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:06:00.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:06:00.795+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:06:00.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:06:00.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-13T20:06:31.014+0000] {processor.py:157} INFO - Started process (PID=79430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:06:31.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:06:31.028+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:06:31.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:06:31.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:06:31.103+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:06:31.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:06:31.127+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:06:31.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:06:31.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-13T20:07:01.373+0000] {processor.py:157} INFO - Started process (PID=79440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:07:01.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:07:01.384+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:07:01.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:07:01.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:07:01.435+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:07:01.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:07:01.448+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:07:01.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:07:01.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-13T20:07:31.787+0000] {processor.py:157} INFO - Started process (PID=79450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:07:31.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:07:31.799+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:07:31.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:07:31.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:07:31.843+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:07:31.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:07:31.856+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:07:31.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:07:31.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-13T20:08:02.076+0000] {processor.py:157} INFO - Started process (PID=79460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:08:02.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:08:02.079+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:08:02.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:08:02.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:08:02.113+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:08:02.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:08:02.124+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:08:02.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:08:02.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-13T20:08:32.477+0000] {processor.py:157} INFO - Started process (PID=79470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:08:32.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:08:32.483+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:08:32.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:08:32.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:08:32.543+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:08:32.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:08:32.561+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:08:32.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:08:32.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-13T20:09:02.956+0000] {processor.py:157} INFO - Started process (PID=79480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:09:02.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:09:02.983+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:09:02.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:09:03.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:09:03.031+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:09:03.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:09:03.057+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:09:03.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:09:03.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-13T20:09:33.260+0000] {processor.py:157} INFO - Started process (PID=79490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:09:33.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:09:33.264+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:09:33.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:09:33.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:09:33.301+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:09:33.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:09:33.314+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:09:33.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:09:33.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-13T20:10:03.679+0000] {processor.py:157} INFO - Started process (PID=79500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:10:03.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:10:03.683+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:10:03.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:10:03.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:10:03.726+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:10:03.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:10:03.740+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:10:03.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:10:03.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-13T20:10:34.003+0000] {processor.py:157} INFO - Started process (PID=79510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:10:34.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:10:34.009+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:10:34.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:10:34.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:10:34.043+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:10:34.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:10:34.056+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:10:34.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:10:34.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-13T20:11:04.312+0000] {processor.py:157} INFO - Started process (PID=79520) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:11:04.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:11:04.318+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:11:04.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:11:04.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:11:04.354+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:11:04.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:11:04.367+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:11:04.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:11:04.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-13T20:11:34.662+0000] {processor.py:157} INFO - Started process (PID=79530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:11:34.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:11:34.667+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:11:34.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:11:34.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:11:34.704+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:11:34.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:11:34.716+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:11:34.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:11:34.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-13T20:12:04.972+0000] {processor.py:157} INFO - Started process (PID=79540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:12:04.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:12:04.976+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:12:04.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:12:04.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:12:05.001+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:12:05.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:12:05.013+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:12:05.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:12:05.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-13T20:12:35.354+0000] {processor.py:157} INFO - Started process (PID=79550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:12:35.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:12:35.369+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:12:35.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:12:35.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:12:35.437+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:12:35.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:12:35.457+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:12:35.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:12:35.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-13T20:13:05.674+0000] {processor.py:157} INFO - Started process (PID=79560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:13:05.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:13:05.682+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:13:05.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:13:05.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:13:05.736+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:13:05.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:13:05.754+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:13:05.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:13:05.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-13T20:13:36.009+0000] {processor.py:157} INFO - Started process (PID=79569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:13:36.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:13:36.029+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:13:36.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:13:36.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:13:36.085+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:13:36.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:13:36.101+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:13:36.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:13:36.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-13T20:14:06.272+0000] {processor.py:157} INFO - Started process (PID=79580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:14:06.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:14:06.278+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:14:06.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:14:06.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:14:06.313+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:14:06.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:14:06.325+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:14:06.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:14:06.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-13T20:14:36.772+0000] {processor.py:157} INFO - Started process (PID=79589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:14:36.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:14:36.779+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:14:36.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:14:36.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:14:36.844+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:14:36.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:14:36.859+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:14:36.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:14:36.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-13T20:15:07.192+0000] {processor.py:157} INFO - Started process (PID=79599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:15:07.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:15:07.199+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:15:07.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:15:07.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:15:07.251+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:15:07.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:15:07.264+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:15:07.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:15:07.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-13T20:15:37.512+0000] {processor.py:157} INFO - Started process (PID=79609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:15:37.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:15:37.547+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:15:37.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:15:37.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:15:37.614+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:15:37.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:15:37.639+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:15:37.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:15:37.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-13T20:16:07.828+0000] {processor.py:157} INFO - Started process (PID=79620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:16:07.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:16:07.833+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:16:07.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:16:07.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:16:07.889+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:16:07.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:16:07.902+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:16:07.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:16:07.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-13T20:16:38.261+0000] {processor.py:157} INFO - Started process (PID=79630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:16:38.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:16:38.286+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:16:38.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:16:38.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:16:38.333+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:16:38.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:16:38.355+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:16:38.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:16:38.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-13T20:17:08.555+0000] {processor.py:157} INFO - Started process (PID=79640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:17:08.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:17:08.578+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:17:08.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:17:08.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:17:08.638+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:17:08.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:17:08.653+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:17:08.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:17:08.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-13T20:17:39.038+0000] {processor.py:157} INFO - Started process (PID=79650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:17:39.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:17:39.047+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:17:39.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:17:39.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:17:39.109+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:17:39.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:17:39.124+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:17:39.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:17:39.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-13T20:18:09.370+0000] {processor.py:157} INFO - Started process (PID=79658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:18:09.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:18:09.375+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:18:09.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:18:09.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:18:09.425+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:18:09.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:18:09.438+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:18:09.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:18:09.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-13T20:18:39.723+0000] {processor.py:157} INFO - Started process (PID=79670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:18:39.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:18:39.729+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:18:39.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:18:39.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:18:39.761+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:18:39.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:18:39.772+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:18:39.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:18:39.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-13T20:19:10.105+0000] {processor.py:157} INFO - Started process (PID=79680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:19:10.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:19:10.121+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:19:10.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:19:10.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:19:10.169+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:19:10.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:19:10.183+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:19:10.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:19:10.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-13T20:19:40.382+0000] {processor.py:157} INFO - Started process (PID=79689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:19:40.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:19:40.387+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:19:40.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:19:40.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:19:40.415+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:19:40.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:19:40.428+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:19:40.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:19:40.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-13T20:20:10.802+0000] {processor.py:157} INFO - Started process (PID=79699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:20:10.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:20:10.808+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:20:10.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:20:10.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:20:10.866+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:20:10.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:20:10.881+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:20:10.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:20:10.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T20:20:41.160+0000] {processor.py:157} INFO - Started process (PID=79710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:20:41.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:20:41.168+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:20:41.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:20:41.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:20:41.223+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:20:41.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:20:41.236+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:20:41.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:20:41.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-13T20:21:11.476+0000] {processor.py:157} INFO - Started process (PID=79720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:21:11.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:21:11.483+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:21:11.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:21:11.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:21:11.539+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:21:11.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:21:11.553+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:21:11.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:21:11.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T20:21:41.785+0000] {processor.py:157} INFO - Started process (PID=79730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:21:41.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:21:41.798+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:21:41.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:21:41.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:21:41.855+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:21:41.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:21:41.870+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:21:41.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:21:41.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-13T20:22:12.053+0000] {processor.py:157} INFO - Started process (PID=79740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:22:12.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:22:12.065+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:22:12.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:22:12.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:22:12.107+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:22:12.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:22:12.119+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:22:12.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:22:12.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-13T20:23:26.768+0000] {processor.py:157} INFO - Started process (PID=79750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:23:26.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:23:26.778+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:23:26.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:23:26.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:23:26.834+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:23:26.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:23:26.853+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:23:26.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:23:26.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-13T20:23:57.177+0000] {processor.py:157} INFO - Started process (PID=79761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:23:57.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:23:57.188+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:23:57.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:23:57.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:23:57.255+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:23:57.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:23:57.279+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:23:57.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:23:57.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-13T20:24:27.464+0000] {processor.py:157} INFO - Started process (PID=79772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:24:27.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:24:27.467+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:24:27.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:24:27.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:24:27.495+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:24:27.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:24:27.508+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:24:27.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:24:27.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-13T20:24:57.831+0000] {processor.py:157} INFO - Started process (PID=79782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:24:57.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:24:57.834+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:24:57.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:24:57.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:24:57.868+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:24:57.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:24:57.881+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:24:57.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:24:57.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-13T20:25:28.118+0000] {processor.py:157} INFO - Started process (PID=79792) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:25:28.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:25:28.121+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:25:28.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:25:28.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:25:28.149+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:25:28.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:25:28.159+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:25:28.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:25:28.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-13T20:25:58.410+0000] {processor.py:157} INFO - Started process (PID=79802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:25:58.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:25:58.414+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:25:58.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:25:58.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:25:58.440+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:25:58.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:25:58.452+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:25:58.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:25:58.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-13T20:26:28.768+0000] {processor.py:157} INFO - Started process (PID=79812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:26:28.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:26:28.773+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:26:28.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:26:28.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:26:28.808+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:26:28.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:26:28.821+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:26:28.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:26:28.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-13T20:26:59.172+0000] {processor.py:157} INFO - Started process (PID=79822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:26:59.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:26:59.175+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:26:59.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:26:59.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:26:59.204+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:26:59.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:26:59.218+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:26:59.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:26:59.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-13T20:27:54.748+0000] {processor.py:157} INFO - Started process (PID=79833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:27:54.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:27:54.754+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:27:54.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:27:54.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:27:54.806+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:27:54.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:27:54.821+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:27:54.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:27:54.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T20:34:51.421+0000] {processor.py:157} INFO - Started process (PID=79843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:34:51.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:34:51.439+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:34:51.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:34:51.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:34:51.505+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:34:51.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:34:51.522+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:34:51.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:34:51.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-13T20:35:21.723+0000] {processor.py:157} INFO - Started process (PID=79854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:35:21.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:35:21.728+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:35:21.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:35:21.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:35:21.760+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:35:21.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:35:21.771+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:35:21.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:35:21.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-13T20:37:45.326+0000] {processor.py:157} INFO - Started process (PID=79864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:37:45.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:37:45.333+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:37:45.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:37:45.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:37:45.405+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:37:45.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:37:45.431+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:37:45.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:37:45.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-13T20:40:50.724+0000] {processor.py:157} INFO - Started process (PID=79874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:40:50.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:40:50.731+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:40:50.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:40:50.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:40:50.777+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:40:50.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:40:50.791+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:40:50.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:40:50.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T20:41:21.138+0000] {processor.py:157} INFO - Started process (PID=79885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:41:21.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:41:21.143+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:41:21.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:41:21.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:41:21.180+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:41:21.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:41:21.193+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:41:21.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:41:21.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-13T20:41:57.037+0000] {processor.py:157} INFO - Started process (PID=79896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:41:57.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:41:57.040+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:41:57.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:41:57.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:41:57.067+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:41:57.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:41:57.080+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:41:57.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:41:57.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-13T20:42:27.449+0000] {processor.py:157} INFO - Started process (PID=79904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:42:27.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:42:27.456+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:42:27.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:42:27.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:42:27.505+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:42:27.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:42:27.519+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:42:27.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:42:27.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-13T20:43:16.670+0000] {processor.py:157} INFO - Started process (PID=79914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:43:16.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T20:43:16.675+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:43:16.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:43:16.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T20:43:16.726+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:43:16.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T20:43:16.740+0000] {logging_mixin.py:151} INFO - [2024-09-13T20:43:16.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T20:43:16.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-13T21:16:37.000+0000] {processor.py:157} INFO - Started process (PID=79924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T21:16:37.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T21:16:37.005+0000] {logging_mixin.py:151} INFO - [2024-09-13T21:16:37.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T21:16:37.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T21:16:37.043+0000] {logging_mixin.py:151} INFO - [2024-09-13T21:16:37.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T21:16:37.055+0000] {logging_mixin.py:151} INFO - [2024-09-13T21:16:37.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T21:16:37.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-13T22:26:36.184+0000] {processor.py:157} INFO - Started process (PID=79937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:26:36.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:26:36.192+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:26:36.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:26:36.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:26:36.250+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:26:36.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:26:36.268+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:26:36.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:26:36.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-13T22:27:06.557+0000] {processor.py:157} INFO - Started process (PID=79948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:27:06.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:27:06.564+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:27:06.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:27:06.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:27:06.617+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:27:06.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:27:06.639+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:27:06.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:27:06.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-13T22:27:36.964+0000] {processor.py:157} INFO - Started process (PID=79958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:27:36.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:27:36.967+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:27:36.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:27:36.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:27:36.993+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:27:36.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:27:37.003+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:27:37.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:27:37.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-13T22:28:07.309+0000] {processor.py:157} INFO - Started process (PID=79968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:28:07.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:28:07.314+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:28:07.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:28:07.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:28:07.378+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:28:07.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:28:07.397+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:28:07.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:28:07.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-13T22:28:37.553+0000] {processor.py:157} INFO - Started process (PID=79978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:28:37.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:28:37.555+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:28:37.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:28:37.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:28:37.584+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:28:37.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:28:37.595+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:28:37.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:28:37.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-13T22:29:07.835+0000] {processor.py:157} INFO - Started process (PID=79988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:29:07.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:29:07.838+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:29:07.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:29:07.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:29:07.874+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:29:07.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:29:07.889+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:29:07.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:29:07.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-13T22:29:38.204+0000] {processor.py:157} INFO - Started process (PID=79998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:29:38.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:29:38.213+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:29:38.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:29:38.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:29:38.257+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:29:38.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:29:38.273+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:29:38.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:29:38.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-13T22:30:08.538+0000] {processor.py:157} INFO - Started process (PID=80008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:30:08.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:30:08.556+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:30:08.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:30:08.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:30:08.599+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:30:08.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:30:08.612+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:30:08.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:30:08.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T22:30:38.884+0000] {processor.py:157} INFO - Started process (PID=80018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:30:38.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:30:38.896+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:30:38.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:30:38.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:30:38.938+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:30:38.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:30:38.961+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:30:38.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:30:38.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-13T22:31:09.356+0000] {processor.py:157} INFO - Started process (PID=80028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:31:09.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:31:09.365+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:31:09.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:31:09.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:31:09.413+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:31:09.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:31:09.425+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:31:09.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:31:09.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-13T22:31:39.734+0000] {processor.py:157} INFO - Started process (PID=80037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:31:39.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:31:39.749+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:31:39.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:31:39.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:31:39.813+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:31:39.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:31:39.831+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:31:39.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:31:39.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-13T22:32:10.101+0000] {processor.py:157} INFO - Started process (PID=80048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:32:10.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:32:10.113+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:32:10.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:32:10.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:32:10.175+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:32:10.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:32:10.189+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:32:10.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:32:10.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-13T22:32:40.461+0000] {processor.py:157} INFO - Started process (PID=80058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:32:40.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:32:40.484+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:32:40.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:32:40.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:32:40.530+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:32:40.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:32:40.543+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:32:40.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:32:40.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-13T22:33:10.873+0000] {processor.py:157} INFO - Started process (PID=80068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:33:10.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:33:10.876+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:33:10.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:33:10.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:33:10.919+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:33:10.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:33:10.940+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:33:10.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:33:10.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-13T22:33:41.271+0000] {processor.py:157} INFO - Started process (PID=80078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:33:41.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:33:41.276+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:33:41.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:33:41.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:33:41.343+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:33:41.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:33:41.357+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:33:41.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:33:41.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-13T22:34:11.565+0000] {processor.py:157} INFO - Started process (PID=80088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:34:11.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:34:11.569+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:34:11.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:34:11.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:34:11.616+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:34:11.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:34:11.634+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:34:11.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:34:11.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T22:34:42.038+0000] {processor.py:157} INFO - Started process (PID=80098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:34:42.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:34:42.043+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:34:42.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:34:42.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:34:42.091+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:34:42.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:34:42.104+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:34:42.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:34:42.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-13T22:35:12.362+0000] {processor.py:157} INFO - Started process (PID=80108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:35:12.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:35:12.367+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:35:12.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:35:12.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:35:12.414+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:35:12.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:35:12.427+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:35:12.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:35:12.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-13T22:35:42.636+0000] {processor.py:157} INFO - Started process (PID=80118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:35:42.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:35:42.640+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:35:42.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:35:42.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:35:42.678+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:35:42.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:35:42.691+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:35:42.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:35:42.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-13T22:36:13.111+0000] {processor.py:157} INFO - Started process (PID=80128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:36:13.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:36:13.123+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:36:13.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:36:13.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:36:13.182+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:36:13.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:36:13.196+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:36:13.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:36:13.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-13T22:36:43.466+0000] {processor.py:157} INFO - Started process (PID=80138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:36:43.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:36:43.470+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:36:43.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:36:43.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:36:43.528+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:36:43.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:36:43.542+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:36:43.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:36:43.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-13T22:37:13.786+0000] {processor.py:157} INFO - Started process (PID=80148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:37:13.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:37:13.793+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:37:13.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:37:13.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:37:13.844+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:37:13.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:37:13.870+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:37:13.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:37:13.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-13T22:37:44.147+0000] {processor.py:157} INFO - Started process (PID=80158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:37:44.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:37:44.152+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:37:44.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:37:44.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:37:44.189+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:37:44.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:37:44.201+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:37:44.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:37:44.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-13T22:38:14.528+0000] {processor.py:157} INFO - Started process (PID=80168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:38:14.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:38:14.533+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:38:14.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:38:14.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:38:14.575+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:38:14.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:38:14.587+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:38:14.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:38:14.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-13T22:38:44.822+0000] {processor.py:157} INFO - Started process (PID=80178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:38:44.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:38:44.827+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:38:44.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:38:44.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:38:44.864+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:38:44.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:38:44.877+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:38:44.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:38:44.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-13T22:39:15.170+0000] {processor.py:157} INFO - Started process (PID=80188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:39:15.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:39:15.172+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:39:15.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:39:15.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:39:15.200+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:39:15.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:39:15.212+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:39:15.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:39:15.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-13T22:39:45.603+0000] {processor.py:157} INFO - Started process (PID=80198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:39:45.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:39:45.620+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:39:45.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:39:45.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:39:45.662+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:39:45.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:39:45.675+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:39:45.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:39:45.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T22:40:16.057+0000] {processor.py:157} INFO - Started process (PID=80208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:40:16.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:40:16.066+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:40:16.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:40:16.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:40:16.107+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:40:16.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:40:16.130+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:40:16.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:40:16.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-13T22:40:46.427+0000] {processor.py:157} INFO - Started process (PID=80218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:40:46.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:40:46.431+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:40:46.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:40:46.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:40:46.467+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:40:46.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:40:46.480+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:40:46.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:40:46.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-13T22:41:16.821+0000] {processor.py:157} INFO - Started process (PID=80228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:41:16.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:41:16.831+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:41:16.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:41:16.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:41:16.872+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:41:16.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:41:16.886+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:41:16.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:41:16.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-13T22:41:47.238+0000] {processor.py:157} INFO - Started process (PID=80237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:41:47.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:41:47.244+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:41:47.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:41:47.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:41:47.283+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:41:47.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:41:47.295+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:41:47.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:41:47.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-13T22:42:17.647+0000] {processor.py:157} INFO - Started process (PID=80248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:42:17.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:42:17.660+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:42:17.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:42:17.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:42:17.725+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:42:17.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:42:17.748+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:42:17.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:42:17.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-13T22:42:48.027+0000] {processor.py:157} INFO - Started process (PID=80258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:42:48.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:42:48.030+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:42:48.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:42:48.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:42:48.111+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:42:48.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:42:48.135+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:42:48.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:42:48.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-13T22:43:18.393+0000] {processor.py:157} INFO - Started process (PID=80268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:43:18.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:43:18.398+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:43:18.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:43:18.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:43:18.434+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:43:18.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:43:18.447+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:43:18.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:43:18.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-13T22:43:48.763+0000] {processor.py:157} INFO - Started process (PID=80278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:43:48.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:43:48.770+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:43:48.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:43:48.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:43:48.874+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:43:48.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:43:48.888+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:43:48.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:43:48.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-13T22:44:19.071+0000] {processor.py:157} INFO - Started process (PID=80287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:44:19.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:44:19.095+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:44:19.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:44:19.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:44:19.143+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:44:19.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:44:19.157+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:44:19.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:44:19.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-13T22:44:49.439+0000] {processor.py:157} INFO - Started process (PID=80297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:44:49.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:44:49.443+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:44:49.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:44:49.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:44:49.501+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:44:49.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:44:49.517+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:44:49.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:44:49.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-13T22:45:19.777+0000] {processor.py:157} INFO - Started process (PID=80308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:45:19.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:45:19.783+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:45:19.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:45:19.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:45:19.830+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:45:19.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:45:19.844+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:45:19.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:45:19.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-13T22:45:50.092+0000] {processor.py:157} INFO - Started process (PID=80318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:45:50.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:45:50.098+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:45:50.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:45:50.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:45:50.137+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:45:50.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:45:50.163+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:45:50.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:45:50.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T22:46:20.487+0000] {processor.py:157} INFO - Started process (PID=80328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:46:20.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:46:20.512+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:46:20.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:46:20.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:46:20.557+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:46:20.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:46:20.570+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:46:20.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:46:20.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-13T22:46:50.804+0000] {processor.py:157} INFO - Started process (PID=80338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:46:50.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:46:50.809+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:46:50.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:46:50.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:46:50.849+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:46:50.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:46:50.863+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:46:50.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:46:50.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-13T22:47:21.142+0000] {processor.py:157} INFO - Started process (PID=80348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:47:21.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:47:21.149+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:47:21.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:47:21.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:47:21.191+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:47:21.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:47:21.206+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:47:21.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:47:21.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-13T22:47:51.450+0000] {processor.py:157} INFO - Started process (PID=80357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:47:51.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:47:51.458+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:47:51.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:47:51.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:47:51.500+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:47:51.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:47:51.513+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:47:51.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:47:51.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-13T22:48:21.758+0000] {processor.py:157} INFO - Started process (PID=80368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:48:21.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:48:21.766+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:48:21.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:48:21.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:48:21.814+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:48:21.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:48:21.829+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:48:21.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:48:21.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-13T22:48:52.137+0000] {processor.py:157} INFO - Started process (PID=80378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:48:52.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:48:52.145+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:48:52.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:48:52.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:48:52.185+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:48:52.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:48:52.198+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:48:52.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:48:52.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-13T22:49:22.608+0000] {processor.py:157} INFO - Started process (PID=80388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:49:22.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:49:22.614+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:49:22.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:49:22.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:49:22.652+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:49:22.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:49:22.667+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:49:22.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:49:22.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-13T22:49:53.008+0000] {processor.py:157} INFO - Started process (PID=80398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:49:53.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:49:53.013+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:49:53.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:49:53.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:49:53.055+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:49:53.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:49:53.069+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:49:53.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:49:53.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-13T22:50:23.279+0000] {processor.py:157} INFO - Started process (PID=80408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:50:23.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:50:23.283+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:50:23.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:50:23.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:50:23.314+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:50:23.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:50:23.326+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:50:23.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:50:23.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-13T22:50:53.704+0000] {processor.py:157} INFO - Started process (PID=80418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:50:53.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:50:53.708+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:50:53.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:50:53.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:50:53.760+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:50:53.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:50:53.774+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:50:53.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:50:53.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-13T22:51:24.022+0000] {processor.py:157} INFO - Started process (PID=80428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:51:24.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:51:24.027+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:51:24.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:51:24.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:51:24.074+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:51:24.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:51:24.087+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:51:24.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:51:24.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-13T22:51:54.455+0000] {processor.py:157} INFO - Started process (PID=80438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:51:54.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:51:54.460+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:51:54.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:51:54.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:51:54.494+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:51:54.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:51:54.507+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:51:54.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:51:54.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-13T22:52:24.791+0000] {processor.py:157} INFO - Started process (PID=80448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:52:24.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:52:24.796+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:52:24.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:52:24.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:52:24.837+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:52:24.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:52:24.850+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:52:24.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:52:24.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-13T22:52:55.158+0000] {processor.py:157} INFO - Started process (PID=80458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:52:55.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:52:55.162+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:52:55.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:52:55.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:52:55.194+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:52:55.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:52:55.204+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:52:55.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:52:55.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-13T22:53:25.643+0000] {processor.py:157} INFO - Started process (PID=80468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:53:25.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:53:25.647+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:53:25.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:53:25.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:53:25.694+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:53:25.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:53:25.713+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:53:25.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:53:25.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-13T22:53:56.055+0000] {processor.py:157} INFO - Started process (PID=80478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:53:56.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:53:56.069+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:53:56.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:53:56.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:53:56.109+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:53:56.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:53:56.136+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:53:56.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:53:56.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-13T22:54:26.390+0000] {processor.py:157} INFO - Started process (PID=80487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:54:26.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:54:26.395+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:54:26.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:54:26.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:54:26.434+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:54:26.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:54:26.446+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:54:26.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:54:26.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-13T22:54:56.678+0000] {processor.py:157} INFO - Started process (PID=80498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:54:56.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:54:56.681+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:54:56.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:54:56.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:54:56.713+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:54:56.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:54:56.726+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:54:56.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:54:56.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-13T22:55:27.030+0000] {processor.py:157} INFO - Started process (PID=80508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:55:27.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:55:27.035+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:55:27.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:55:27.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:55:27.082+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:55:27.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:55:27.096+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:55:27.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:55:27.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-13T22:55:57.434+0000] {processor.py:157} INFO - Started process (PID=80518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:55:57.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:55:57.437+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:55:57.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:55:57.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:55:57.475+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:55:57.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:55:57.489+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:55:57.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:55:57.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-13T22:56:27.781+0000] {processor.py:157} INFO - Started process (PID=80528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:56:27.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:56:27.788+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:56:27.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:56:27.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:56:27.871+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:56:27.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:56:27.887+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:56:27.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:56:27.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-13T22:56:58.139+0000] {processor.py:157} INFO - Started process (PID=80538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:56:58.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:56:58.146+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:56:58.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:56:58.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:56:58.202+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:56:58.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:56:58.216+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:56:58.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:56:58.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-13T22:57:28.476+0000] {processor.py:157} INFO - Started process (PID=80548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:57:28.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:57:28.482+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:57:28.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:57:28.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:57:28.567+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:57:28.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:57:28.582+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:57:28.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:57:28.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-13T22:57:58.947+0000] {processor.py:157} INFO - Started process (PID=80558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:57:58.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:57:58.952+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:57:58.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:57:58.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:57:58.989+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:57:58.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:57:59.004+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:57:59.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:57:59.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-13T22:58:29.386+0000] {processor.py:157} INFO - Started process (PID=80568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:58:29.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:58:29.395+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:58:29.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:58:29.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:58:29.453+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:58:29.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:58:29.470+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:58:29.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:58:29.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-13T22:58:59.759+0000] {processor.py:157} INFO - Started process (PID=80578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:58:59.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:58:59.773+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:58:59.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:58:59.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:58:59.817+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:58:59.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:58:59.842+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:58:59.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:58:59.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-13T22:59:30.146+0000] {processor.py:157} INFO - Started process (PID=80588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:59:30.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T22:59:30.153+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:59:30.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:59:30.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T22:59:30.242+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:59:30.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T22:59:30.262+0000] {logging_mixin.py:151} INFO - [2024-09-13T22:59:30.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T22:59:30.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-13T23:00:00.588+0000] {processor.py:157} INFO - Started process (PID=80596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:00:00.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T23:00:00.594+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:00:00.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:00:00.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:00:00.659+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:00:00.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T23:00:00.671+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:00:00.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T23:00:00.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-13T23:00:31.012+0000] {processor.py:157} INFO - Started process (PID=80608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:00:31.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T23:00:31.017+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:00:31.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:00:31.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:00:31.057+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:00:31.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T23:00:31.070+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:00:31.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T23:00:31.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-13T23:01:01.495+0000] {processor.py:157} INFO - Started process (PID=80618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:01:01.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T23:01:01.500+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:01:01.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:01:01.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:01:01.562+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:01:01.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T23:01:01.576+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:01:01.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T23:01:01.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-13T23:01:31.827+0000] {processor.py:157} INFO - Started process (PID=80628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:01:31.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T23:01:31.834+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:01:31.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:01:31.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:01:31.877+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:01:31.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T23:01:31.891+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:01:31.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T23:01:31.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-13T23:02:02.277+0000] {processor.py:157} INFO - Started process (PID=80637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:02:02.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T23:02:02.284+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:02:02.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:02:02.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:02:02.324+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:02:02.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T23:02:02.340+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:02:02.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T23:02:02.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-13T23:02:32.624+0000] {processor.py:157} INFO - Started process (PID=80648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:02:32.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T23:02:32.630+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:02:32.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:02:32.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:02:32.682+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:02:32.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T23:02:32.695+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:02:32.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T23:02:32.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-13T23:03:02.982+0000] {processor.py:157} INFO - Started process (PID=80657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:03:02.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T23:03:02.987+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:03:02.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:03:03.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:03:03.030+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:03:03.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T23:03:03.051+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:03:03.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T23:03:03.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-13T23:03:33.420+0000] {processor.py:157} INFO - Started process (PID=80668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:03:33.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T23:03:33.425+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:03:33.425+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:03:33.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:03:33.497+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:03:33.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T23:03:33.530+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:03:33.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T23:03:33.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-13T23:04:03.760+0000] {processor.py:157} INFO - Started process (PID=80678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:04:03.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T23:04:03.765+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:04:03.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:04:03.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:04:03.810+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:04:03.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T23:04:03.825+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:04:03.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T23:04:03.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-13T23:04:34.229+0000] {processor.py:157} INFO - Started process (PID=80688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:04:34.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T23:04:34.234+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:04:34.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:04:34.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:04:34.270+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:04:34.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T23:04:34.283+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:04:34.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T23:04:34.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-13T23:05:04.556+0000] {processor.py:157} INFO - Started process (PID=80698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:05:04.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T23:05:04.562+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:05:04.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:05:04.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:05:04.613+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:05:04.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T23:05:04.628+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:05:04.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T23:05:04.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-13T23:05:34.874+0000] {processor.py:157} INFO - Started process (PID=80708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:05:34.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T23:05:34.877+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:05:34.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:05:34.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:05:34.905+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:05:34.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T23:05:34.917+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:05:34.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T23:05:34.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-13T23:06:05.307+0000] {processor.py:157} INFO - Started process (PID=80718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:06:05.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T23:06:05.312+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:06:05.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:06:05.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:06:05.352+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:06:05.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T23:06:05.372+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:06:05.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T23:06:05.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-13T23:06:35.764+0000] {processor.py:157} INFO - Started process (PID=80728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:06:35.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T23:06:35.767+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:06:35.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:06:35.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:06:35.812+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:06:35.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-13T23:06:35.828+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:06:35.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-12T01:00:00+00:00, run_after=2024-09-13T01:00:00+00:00
[2024-09-13T23:06:35.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-13T23:23:43.626+0000] {processor.py:157} INFO - Started process (PID=80736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:23:43.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-13T23:23:43.632+0000] {logging_mixin.py:151} INFO - [2024-09-13T23:23:43.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-13T23:23:43.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
