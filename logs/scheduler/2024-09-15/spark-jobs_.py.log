[2024-09-15T01:04:57.692+0000] {processor.py:157} INFO - Started process (PID=182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:04:57.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:04:57.726+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:04:57.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:04:57.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:04:57.929+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:04:57.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:04:58.029+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:04:58.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:04:58.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.404 seconds
[2024-09-15T01:05:28.469+0000] {processor.py:157} INFO - Started process (PID=190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:05:28.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:05:28.486+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:05:28.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:05:28.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:05:28.689+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:05:28.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:05:28.738+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:05:28.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:05:28.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.378 seconds
[2024-09-15T01:05:59.189+0000] {processor.py:157} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:05:59.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:05:59.196+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:05:59.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:05:59.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:05:59.253+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:05:59.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:05:59.286+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:05:59.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:05:59.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T01:06:29.524+0000] {processor.py:157} INFO - Started process (PID=212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:06:29.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:06:29.536+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:06:29.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:06:29.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:06:29.619+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:06:29.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:06:29.640+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:06:29.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:06:29.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-15T01:07:00.166+0000] {processor.py:157} INFO - Started process (PID=222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:07:00.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:07:00.173+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:07:00.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:07:00.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:07:00.255+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:07:00.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:07:00.283+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:07:00.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:07:00.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-15T01:07:30.428+0000] {processor.py:157} INFO - Started process (PID=232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:07:30.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:07:30.433+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:07:30.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:07:30.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:07:30.504+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:07:30.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:07:30.532+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:07:30.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:07:30.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T01:08:00.948+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:08:00.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:08:00.961+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:08:00.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:08:00.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:08:01.026+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:08:01.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:08:01.046+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:08:01.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:08:01.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T01:08:31.516+0000] {processor.py:157} INFO - Started process (PID=252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:08:31.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:08:31.520+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:08:31.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:08:31.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:08:31.590+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:08:31.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:08:31.612+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:08:31.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:08:31.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T01:09:02.146+0000] {processor.py:157} INFO - Started process (PID=262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:09:02.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:09:02.151+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:09:02.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:09:02.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:09:02.247+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:09:02.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:09:02.297+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:09:02.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:09:02.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-09-15T01:09:32.503+0000] {processor.py:157} INFO - Started process (PID=272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:09:32.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:09:32.510+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:09:32.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:09:32.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:09:32.570+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:09:32.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:09:32.597+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:09:32.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:09:32.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T01:10:03.219+0000] {processor.py:157} INFO - Started process (PID=281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:10:03.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:10:03.227+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:10:03.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:10:03.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:10:03.337+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:10:03.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:10:03.361+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:10:03.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:10:03.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-15T01:10:33.891+0000] {processor.py:157} INFO - Started process (PID=291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:10:33.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:10:33.903+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:10:33.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:10:33.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:10:34.046+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:10:34.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:10:34.072+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:10:34.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:10:34.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.247 seconds
[2024-09-15T01:11:04.269+0000] {processor.py:157} INFO - Started process (PID=302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:11:04.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:11:04.279+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:11:04.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:11:04.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:11:04.337+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:11:04.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:11:04.351+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:11:04.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:11:04.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T01:12:04.178+0000] {processor.py:157} INFO - Started process (PID=183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:12:04.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:12:04.185+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:12:04.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:12:04.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:12:04.326+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:12:04.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:12:04.396+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:12:04.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:12:04.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.271 seconds
[2024-09-15T01:12:34.678+0000] {processor.py:157} INFO - Started process (PID=192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:12:34.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:12:34.683+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:12:34.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:12:34.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:12:34.766+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:12:34.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:12:34.787+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:12:34.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:12:34.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-15T01:13:05.133+0000] {processor.py:157} INFO - Started process (PID=203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:13:05.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:13:05.146+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:13:05.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:13:05.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:13:05.222+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:13:05.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:13:05.251+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:13:05.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:13:05.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-15T01:13:35.478+0000] {processor.py:157} INFO - Started process (PID=213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:13:35.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:13:35.487+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:13:35.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:13:35.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:13:35.573+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:13:35.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:13:35.593+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:13:35.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:13:35.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-15T01:14:05.848+0000] {processor.py:157} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:14:05.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:14:05.851+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:14:05.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:14:05.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:14:05.926+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:14:05.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:14:05.958+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:14:05.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:14:05.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T01:14:36.444+0000] {processor.py:157} INFO - Started process (PID=252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:14:36.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:14:36.450+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:14:36.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:14:36.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:14:36.490+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:14:36.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:14:36.505+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:14:36.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:14:36.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T01:15:06.923+0000] {processor.py:157} INFO - Started process (PID=632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:15:06.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:15:06.976+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:15:06.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:15:07.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:15:07.185+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:15:07.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:15:07.219+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:15:07.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:15:07.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.343 seconds
[2024-09-15T01:15:37.549+0000] {processor.py:157} INFO - Started process (PID=826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:15:37.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:15:37.565+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:15:37.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:15:37.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:15:37.693+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:15:37.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:15:37.720+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:15:37.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:15:37.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-09-15T01:16:07.859+0000] {processor.py:157} INFO - Started process (PID=836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:16:07.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:16:07.866+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:16:07.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:16:07.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:16:07.951+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:16:07.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:16:07.971+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:16:07.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:16:07.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T01:16:38.269+0000] {processor.py:157} INFO - Started process (PID=848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:16:38.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:16:38.276+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:16:38.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:16:38.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:16:38.348+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:16:38.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:16:38.388+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:16:38.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:16:38.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-15T01:17:08.924+0000] {processor.py:157} INFO - Started process (PID=995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:17:08.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:17:08.928+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:17:08.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:17:08.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:17:08.976+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:17:08.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:17:08.997+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:17:08.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:17:09.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T01:17:39.282+0000] {processor.py:157} INFO - Started process (PID=1035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:17:39.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:17:39.302+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:17:39.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:17:39.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:17:39.363+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:17:39.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:17:39.378+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:17:39.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:17:39.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T01:18:09.815+0000] {processor.py:157} INFO - Started process (PID=1044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:18:09.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:18:09.823+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:18:09.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:18:09.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:18:09.893+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:18:09.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:18:09.908+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:18:09.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:18:09.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T01:18:40.295+0000] {processor.py:157} INFO - Started process (PID=1055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:18:40.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:18:40.306+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:18:40.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:18:40.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:18:40.364+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:18:40.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:18:40.384+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:18:40.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:18:40.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T01:19:10.732+0000] {processor.py:157} INFO - Started process (PID=1065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:19:10.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:19:10.738+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:19:10.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:19:10.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:19:10.851+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:19:10.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:19:10.883+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:19:10.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:19:10.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-15T01:19:41.232+0000] {processor.py:157} INFO - Started process (PID=1075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:19:41.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:19:41.256+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:19:41.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:19:41.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:19:41.352+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:19:41.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:19:41.378+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:19:41.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:19:41.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-09-15T01:20:11.641+0000] {processor.py:157} INFO - Started process (PID=1085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:20:11.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:20:11.661+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:20:11.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:20:11.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:20:11.785+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:20:11.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:20:11.824+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:20:11.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:20:11.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.218 seconds
[2024-09-15T01:20:42.054+0000] {processor.py:157} INFO - Started process (PID=1095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:20:42.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:20:42.060+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:20:42.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:20:42.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:20:42.130+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:20:42.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:20:42.147+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:20:42.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:20:42.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T01:21:12.475+0000] {processor.py:157} INFO - Started process (PID=1105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:21:12.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:21:12.480+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:21:12.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:21:12.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:21:12.531+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:21:12.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:21:12.547+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:21:12.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:21:12.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T01:21:43.051+0000] {processor.py:157} INFO - Started process (PID=1115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:21:43.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:21:43.058+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:21:43.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:21:43.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:21:43.163+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:21:43.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:21:43.177+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:21:43.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:21:43.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-15T01:22:13.602+0000] {processor.py:157} INFO - Started process (PID=1125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:22:13.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:22:13.611+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:22:13.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:22:13.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:22:13.680+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:22:13.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:22:13.714+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:22:13.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:22:13.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-15T01:22:44.279+0000] {processor.py:157} INFO - Started process (PID=1135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:22:44.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:22:44.288+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:22:44.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:22:44.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:22:44.381+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:22:44.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:22:44.405+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:22:44.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:22:44.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-15T01:23:14.699+0000] {processor.py:157} INFO - Started process (PID=1145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:23:14.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:23:14.706+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:23:14.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:23:14.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:23:14.781+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:23:14.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:23:14.803+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:23:14.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:23:14.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T01:23:45.148+0000] {processor.py:157} INFO - Started process (PID=1155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:23:45.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:23:45.156+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:23:45.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:23:45.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:23:45.258+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:23:45.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:23:45.290+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:23:45.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:23:45.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-15T01:24:15.563+0000] {processor.py:157} INFO - Started process (PID=1165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:24:15.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:24:15.571+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:24:15.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:24:15.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:24:15.703+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:24:15.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:24:15.730+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:24:15.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:24:15.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-09-15T01:24:46.007+0000] {processor.py:157} INFO - Started process (PID=1175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:24:46.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:24:46.014+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:24:46.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:24:46.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:24:46.110+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:24:46.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:24:46.139+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:24:46.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:24:46.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-15T01:25:16.535+0000] {processor.py:157} INFO - Started process (PID=1185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:25:16.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:25:16.561+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:25:16.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:25:16.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:25:16.677+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:25:16.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:25:16.745+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:25:16.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:25:16.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.271 seconds
[2024-09-15T01:25:47.596+0000] {processor.py:157} INFO - Started process (PID=1195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:25:47.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:25:47.605+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:25:47.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:25:47.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:25:47.719+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:25:47.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:25:47.748+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:25:47.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:25:47.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-09-15T01:26:18.138+0000] {processor.py:157} INFO - Started process (PID=1205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:26:18.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:26:18.146+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:26:18.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:26:18.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:26:18.253+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:26:18.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:26:18.293+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:26:18.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:26:18.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-09-15T01:26:48.847+0000] {processor.py:157} INFO - Started process (PID=1215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:26:48.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:26:48.857+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:26:48.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:26:48.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:26:48.963+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:26:48.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:26:48.987+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:26:48.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:26:49.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-09-15T01:27:19.449+0000] {processor.py:157} INFO - Started process (PID=1225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:27:19.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:27:19.455+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:27:19.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:27:19.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:27:19.552+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:27:19.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:27:19.576+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:27:19.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:27:19.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-15T01:27:49.784+0000] {processor.py:157} INFO - Started process (PID=1234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:27:49.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:27:49.791+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:27:49.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:27:49.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:27:49.879+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:27:49.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:27:49.906+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:27:49.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:27:49.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-15T01:28:20.477+0000] {processor.py:157} INFO - Started process (PID=1245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:28:20.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:28:20.487+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:28:20.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:28:20.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:28:20.564+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:28:20.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:28:20.602+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:28:20.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:28:20.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-15T01:28:51.022+0000] {processor.py:157} INFO - Started process (PID=1255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:28:51.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:28:51.029+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:28:51.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:28:51.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:28:51.120+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:28:51.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:28:51.142+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:28:51.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:28:51.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-15T01:29:21.686+0000] {processor.py:157} INFO - Started process (PID=1265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:29:21.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:29:21.693+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:29:21.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:29:21.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:29:21.780+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:29:21.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:29:21.818+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:29:21.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:29:21.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-15T01:29:52.190+0000] {processor.py:157} INFO - Started process (PID=1275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:29:52.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:29:52.197+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:29:52.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:29:52.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:29:52.260+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:29:52.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:29:52.309+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:29:52.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:29:52.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T01:30:22.734+0000] {processor.py:157} INFO - Started process (PID=1284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:30:22.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:30:22.758+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:30:22.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:30:22.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:30:22.904+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:30:22.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:30:22.940+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:30:22.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:30:22.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.273 seconds
[2024-09-15T01:30:53.163+0000] {processor.py:157} INFO - Started process (PID=1984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:30:53.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:30:53.169+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:30:53.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:30:53.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:30:53.253+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:30:53.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:30:53.276+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:30:53.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:30:53.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T01:31:23.612+0000] {processor.py:157} INFO - Started process (PID=1994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:31:23.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:31:23.642+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:31:23.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:31:23.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:31:23.797+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:31:23.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:31:23.839+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:31:23.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:31:23.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.264 seconds
[2024-09-15T01:31:54.370+0000] {processor.py:157} INFO - Started process (PID=2004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:31:54.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:31:54.382+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:31:54.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:31:54.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:31:54.478+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:31:54.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:31:54.519+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:31:54.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:31:54.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.199 seconds
[2024-09-15T01:32:24.901+0000] {processor.py:157} INFO - Started process (PID=2012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:32:24.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:32:24.930+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:32:24.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:32:24.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:32:25.056+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:32:25.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:32:25.084+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:32:25.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:32:25.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.228 seconds
[2024-09-15T01:32:55.311+0000] {processor.py:157} INFO - Started process (PID=2024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:32:55.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:32:55.324+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:32:55.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:32:55.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:32:55.451+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:32:55.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:32:55.479+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:32:55.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:32:55.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-15T01:33:26.007+0000] {processor.py:157} INFO - Started process (PID=2034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:33:26.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:33:26.013+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:33:26.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:33:26.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:33:26.088+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:33:26.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:33:26.120+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:33:26.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:33:26.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-15T01:33:56.387+0000] {processor.py:157} INFO - Started process (PID=2044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:33:56.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:33:56.395+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:33:56.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:33:56.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:33:56.475+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:33:56.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:33:56.492+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:33:56.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:33:56.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-15T01:34:26.908+0000] {processor.py:157} INFO - Started process (PID=2054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:34:26.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:34:26.924+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:34:26.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:34:26.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:34:27.011+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:34:27.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:34:27.033+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:34:27.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:34:27.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-15T01:34:57.508+0000] {processor.py:157} INFO - Started process (PID=2064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:34:57.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:34:57.517+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:34:57.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:34:57.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:34:57.618+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:34:57.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:34:57.639+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:34:57.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:34:57.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-15T01:35:28.263+0000] {processor.py:157} INFO - Started process (PID=2074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:35:28.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:35:28.271+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:35:28.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:35:28.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:35:28.341+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:35:28.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:35:28.358+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:35:28.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:35:28.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T01:35:58.797+0000] {processor.py:157} INFO - Started process (PID=2084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:35:58.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:35:58.803+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:35:58.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:35:58.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:35:58.927+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:35:58.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:35:58.946+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:35:58.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:35:58.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-09-15T01:36:29.156+0000] {processor.py:157} INFO - Started process (PID=2093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:36:29.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:36:29.164+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:36:29.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:36:29.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:36:29.241+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:36:29.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:36:29.259+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:36:29.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:36:29.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-15T01:36:59.708+0000] {processor.py:157} INFO - Started process (PID=2104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:36:59.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:36:59.719+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:36:59.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:36:59.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:36:59.830+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:36:59.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:36:59.867+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:36:59.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:36:59.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-09-15T01:37:30.063+0000] {processor.py:157} INFO - Started process (PID=2114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:37:30.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:37:30.069+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:37:30.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:37:30.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:37:30.118+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:37:30.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:37:30.147+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:37:30.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:37:30.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T01:38:00.766+0000] {processor.py:157} INFO - Started process (PID=2124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:38:00.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:38:00.771+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:38:00.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:38:00.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:38:00.827+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:38:00.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:38:00.844+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:38:00.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:38:00.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T01:38:31.350+0000] {processor.py:157} INFO - Started process (PID=2134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:38:31.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:38:31.357+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:38:31.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:38:31.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:38:31.452+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:38:31.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:38:31.471+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:38:31.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:38:31.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-15T01:39:01.723+0000] {processor.py:157} INFO - Started process (PID=2144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:39:01.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:39:01.732+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:39:01.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:39:01.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:39:01.819+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:39:01.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:39:01.843+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:39:01.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:39:01.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-15T01:39:32.293+0000] {processor.py:157} INFO - Started process (PID=2153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:39:32.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:39:32.299+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:39:32.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:39:32.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:39:32.350+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:39:32.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:39:32.365+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:39:32.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:39:32.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T01:40:02.647+0000] {processor.py:157} INFO - Started process (PID=2164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:40:02.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:40:02.651+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:40:02.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:40:02.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:40:02.721+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:40:02.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:40:02.741+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:40:02.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:40:02.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T01:40:33.148+0000] {processor.py:157} INFO - Started process (PID=2174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:40:33.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:40:33.160+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:40:33.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:40:33.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:40:33.212+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:40:33.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:40:33.234+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:40:33.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:40:33.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T01:41:03.614+0000] {processor.py:157} INFO - Started process (PID=2184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:41:03.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:41:03.620+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:41:03.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:41:03.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:41:03.680+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:41:03.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:41:03.697+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:41:03.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:41:03.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T01:41:33.986+0000] {processor.py:157} INFO - Started process (PID=2193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:41:33.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:41:33.995+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:41:33.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:41:34.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:41:34.053+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:41:34.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:41:34.118+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:41:34.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:41:34.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-09-15T01:42:04.332+0000] {processor.py:157} INFO - Started process (PID=2204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:42:04.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:42:04.339+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:42:04.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:42:04.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:42:04.396+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:42:04.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:42:04.413+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:42:04.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:42:04.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T01:42:34.766+0000] {processor.py:157} INFO - Started process (PID=2214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:42:34.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:42:34.776+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:42:34.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:42:34.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:42:34.811+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:42:34.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:42:34.824+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:42:34.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:42:34.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T01:43:05.063+0000] {processor.py:157} INFO - Started process (PID=2224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:43:05.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:43:05.066+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:43:05.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:43:05.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:43:05.093+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:43:05.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:43:05.105+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:43:05.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:43:05.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-15T01:43:35.880+0000] {processor.py:157} INFO - Started process (PID=2233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:43:35.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:43:35.900+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:43:35.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:43:35.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:43:36.000+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:43:36.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:43:36.020+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:43:36.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:43:36.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-09-15T01:44:06.344+0000] {processor.py:157} INFO - Started process (PID=2243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:44:06.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:44:06.349+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:44:06.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:44:06.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:44:06.408+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:44:06.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:44:06.424+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:44:06.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:44:06.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T01:44:36.714+0000] {processor.py:157} INFO - Started process (PID=2254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:44:36.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:44:36.719+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:44:36.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:44:36.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:44:36.798+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:44:36.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:44:36.817+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:44:36.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:44:36.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T01:45:07.081+0000] {processor.py:157} INFO - Started process (PID=2263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:45:07.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:45:07.104+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:45:07.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:45:07.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:45:07.202+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:45:07.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:45:07.219+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:45:07.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:45:07.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-15T01:45:37.672+0000] {processor.py:157} INFO - Started process (PID=2274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:45:37.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:45:37.678+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:45:37.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:45:37.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:45:37.759+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:45:37.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:45:37.777+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:45:37.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:45:37.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-15T01:46:08.151+0000] {processor.py:157} INFO - Started process (PID=2284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:46:08.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:46:08.161+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:46:08.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:46:08.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:46:08.257+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:46:08.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:46:08.282+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:46:08.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:46:08.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-15T01:46:38.526+0000] {processor.py:157} INFO - Started process (PID=2293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:46:38.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:46:38.533+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:46:38.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:46:38.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:46:38.672+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:46:38.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:46:38.735+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:46:38.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:46:38.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.228 seconds
[2024-09-15T01:47:09.300+0000] {processor.py:157} INFO - Started process (PID=2304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:47:09.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:47:09.307+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:47:09.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:47:09.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:47:09.372+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:47:09.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:47:09.402+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:47:09.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:47:09.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-15T01:47:39.738+0000] {processor.py:157} INFO - Started process (PID=2313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:47:39.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:47:39.744+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:47:39.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:47:39.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:47:39.818+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:47:39.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:47:39.856+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:47:39.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:47:39.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T01:48:10.138+0000] {processor.py:157} INFO - Started process (PID=2324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:48:10.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:48:10.142+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:48:10.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:48:10.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:48:10.193+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:48:10.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:48:10.219+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:48:10.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:48:10.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T01:48:40.475+0000] {processor.py:157} INFO - Started process (PID=2332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:48:40.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:48:40.481+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:48:40.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:48:40.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:48:40.547+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:48:40.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:48:40.567+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:48:40.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:48:40.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T01:49:10.891+0000] {processor.py:157} INFO - Started process (PID=2344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:49:10.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:49:10.895+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:49:10.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:49:10.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:49:10.958+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:49:10.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:49:10.976+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:49:10.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:49:10.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T01:49:41.295+0000] {processor.py:157} INFO - Started process (PID=2354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:49:41.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:49:41.301+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:49:41.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:49:41.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:49:41.384+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:49:41.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:49:41.407+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:49:41.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:49:41.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-15T01:50:11.703+0000] {processor.py:157} INFO - Started process (PID=2363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:50:11.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:50:11.710+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:50:11.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:50:11.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:50:11.779+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:50:11.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:50:11.800+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:50:11.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:50:11.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T01:50:42.044+0000] {processor.py:157} INFO - Started process (PID=2373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:50:42.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:50:42.053+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:50:42.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:50:42.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:50:42.122+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:50:42.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:50:42.137+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:50:42.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:50:42.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-15T01:51:12.354+0000] {processor.py:157} INFO - Started process (PID=2384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:51:12.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:51:12.359+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:51:12.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:51:12.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:51:12.402+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:51:12.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:51:12.418+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:51:12.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:51:12.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T01:51:42.810+0000] {processor.py:157} INFO - Started process (PID=2393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:51:42.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:51:42.819+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:51:42.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:51:42.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:51:42.914+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:51:42.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:51:42.932+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:51:42.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:51:42.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-15T01:52:13.354+0000] {processor.py:157} INFO - Started process (PID=2403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:52:13.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:52:13.363+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:52:13.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:52:13.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:52:13.428+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:52:13.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:52:13.448+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:52:13.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:52:13.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T01:52:43.907+0000] {processor.py:157} INFO - Started process (PID=2414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:52:43.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:52:43.912+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:52:43.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:52:43.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:52:43.988+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:52:43.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:52:44.013+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:52:44.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:52:44.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T01:53:14.322+0000] {processor.py:157} INFO - Started process (PID=2424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:53:14.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:53:14.329+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:53:14.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:53:14.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:53:14.392+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:53:14.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:53:14.408+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:53:14.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:53:14.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T01:53:44.723+0000] {processor.py:157} INFO - Started process (PID=2434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:53:44.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:53:44.731+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:53:44.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:53:44.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:53:44.832+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:53:44.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:53:44.879+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:53:44.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:53:44.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-09-15T01:54:15.023+0000] {processor.py:157} INFO - Started process (PID=2443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:54:15.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:54:15.031+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:54:15.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:54:15.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:54:15.135+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:54:15.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:54:15.166+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:54:15.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:54:15.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-09-15T01:54:45.583+0000] {processor.py:157} INFO - Started process (PID=2454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:54:45.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:54:45.589+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:54:45.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:54:45.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:54:45.712+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:54:45.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:54:45.737+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:54:45.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:54:45.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-15T01:55:15.994+0000] {processor.py:157} INFO - Started process (PID=2464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:55:15.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:55:16.008+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:55:16.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:55:16.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:55:16.101+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:55:16.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:55:16.118+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:55:16.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:55:16.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-15T01:55:46.361+0000] {processor.py:157} INFO - Started process (PID=2474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:55:46.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:55:46.382+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:55:46.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:55:46.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:55:46.450+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:55:46.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:55:46.470+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:55:46.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:55:46.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-15T01:56:16.765+0000] {processor.py:157} INFO - Started process (PID=2484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:56:16.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:56:16.768+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:56:16.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:56:16.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:56:16.852+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:56:16.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:56:16.878+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:56:16.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:56:16.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T01:56:47.122+0000] {processor.py:157} INFO - Started process (PID=2494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:56:47.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:56:47.126+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:56:47.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:56:47.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:56:47.193+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:56:47.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:56:47.208+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:56:47.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:56:47.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T01:57:17.553+0000] {processor.py:157} INFO - Started process (PID=2504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:57:17.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:57:17.567+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:57:17.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:57:17.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:57:17.645+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:57:17.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:57:17.663+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:57:17.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:57:17.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-15T01:57:47.865+0000] {processor.py:157} INFO - Started process (PID=2513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:57:47.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:57:47.875+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:57:47.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:57:47.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:57:47.927+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:57:47.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:57:47.950+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:57:47.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:57:47.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T01:58:18.162+0000] {processor.py:157} INFO - Started process (PID=2524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:58:18.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:58:18.167+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:58:18.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:58:18.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:58:18.199+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:58:18.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:58:18.209+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:58:18.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:58:18.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-15T01:58:48.465+0000] {processor.py:157} INFO - Started process (PID=2533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:58:48.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:58:48.471+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:58:48.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:58:48.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:58:48.528+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:58:48.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:58:48.543+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:58:48.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:58:48.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T01:59:18.905+0000] {processor.py:157} INFO - Started process (PID=2544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:59:18.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:59:18.914+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:59:18.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:59:18.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:59:18.971+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:59:18.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:59:18.987+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:59:18.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:59:18.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T01:59:49.234+0000] {processor.py:157} INFO - Started process (PID=2554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:59:49.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T01:59:49.245+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:59:49.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:59:49.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T01:59:49.311+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:59:49.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T01:59:49.325+0000] {logging_mixin.py:151} INFO - [2024-09-15T01:59:49.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T01:59:49.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T02:00:19.757+0000] {processor.py:157} INFO - Started process (PID=2564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:00:19.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:00:19.764+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:00:19.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:00:19.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:00:19.830+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:00:19.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:00:19.847+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:00:19.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:00:19.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T02:00:50.116+0000] {processor.py:157} INFO - Started process (PID=2574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:00:50.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:00:50.120+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:00:50.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:00:50.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:00:50.187+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:00:50.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:00:50.203+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:00:50.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:00:50.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T02:01:20.450+0000] {processor.py:157} INFO - Started process (PID=2584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:01:20.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:01:20.457+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:01:20.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:01:20.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:01:20.517+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:01:20.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:01:20.533+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:01:20.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:01:20.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T02:01:50.823+0000] {processor.py:157} INFO - Started process (PID=2594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:01:50.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:01:50.829+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:01:50.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:01:50.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:01:50.892+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:01:50.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:01:50.907+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:01:50.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:01:50.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T02:02:21.207+0000] {processor.py:157} INFO - Started process (PID=2604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:02:21.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:02:21.212+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:02:21.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:02:21.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:02:21.276+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:02:21.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:02:21.293+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:02:21.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:02:21.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T02:02:51.602+0000] {processor.py:157} INFO - Started process (PID=2613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:02:51.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:02:51.617+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:02:51.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:02:51.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:02:51.692+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:02:51.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:02:51.717+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:02:51.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:02:51.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-15T02:03:21.973+0000] {processor.py:157} INFO - Started process (PID=2624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:03:21.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:03:21.980+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:03:21.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:03:22.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:03:22.057+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:03:22.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:03:22.074+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:03:22.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:03:22.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T02:03:52.382+0000] {processor.py:157} INFO - Started process (PID=2634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:03:52.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:03:52.387+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:03:52.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:03:52.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:03:52.460+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:03:52.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:03:52.487+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:03:52.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:03:52.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T02:04:22.847+0000] {processor.py:157} INFO - Started process (PID=2644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:04:22.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:04:22.854+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:04:22.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:04:22.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:04:22.934+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:04:22.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:04:22.960+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:04:22.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:04:22.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T02:04:53.259+0000] {processor.py:157} INFO - Started process (PID=2654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:04:53.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:04:53.264+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:04:53.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:04:53.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:04:53.349+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:04:53.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:04:53.375+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:04:53.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:04:53.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-15T02:05:23.634+0000] {processor.py:157} INFO - Started process (PID=2664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:05:23.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:05:23.645+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:05:23.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:05:23.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:05:23.712+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:05:23.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:05:23.745+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:05:23.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:05:23.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T02:05:54.171+0000] {processor.py:157} INFO - Started process (PID=2674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:05:54.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:05:54.177+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:05:54.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:05:54.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:05:54.237+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:05:54.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:05:54.258+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:05:54.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:05:54.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T02:06:24.480+0000] {processor.py:157} INFO - Started process (PID=2683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:06:24.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:06:24.487+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:06:24.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:06:24.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:06:24.551+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:06:24.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:06:24.575+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:06:24.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:06:24.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T02:06:54.772+0000] {processor.py:157} INFO - Started process (PID=2693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:06:54.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:06:54.778+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:06:54.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:06:54.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:06:54.864+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:06:54.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:06:54.879+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:06:54.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:06:54.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T02:07:25.412+0000] {processor.py:157} INFO - Started process (PID=2704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:07:25.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:07:25.437+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:07:25.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:07:25.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:07:25.563+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:07:25.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:07:25.600+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:07:25.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:07:25.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.246 seconds
[2024-09-15T02:07:55.806+0000] {processor.py:157} INFO - Started process (PID=2714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:07:55.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:07:55.813+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:07:55.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:07:55.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:07:55.884+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:07:55.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:07:55.905+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:07:55.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:07:55.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T02:08:26.307+0000] {processor.py:157} INFO - Started process (PID=2724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:08:26.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:08:26.313+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:08:26.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:08:26.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:08:26.387+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:08:26.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:08:26.405+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:08:26.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:08:26.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T02:08:56.704+0000] {processor.py:157} INFO - Started process (PID=2734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:08:56.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:08:56.708+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:08:56.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:08:56.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:08:56.755+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:08:56.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:08:56.777+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:08:56.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:08:56.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T02:09:27.167+0000] {processor.py:157} INFO - Started process (PID=2744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:09:27.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:09:27.174+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:09:27.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:09:27.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:09:27.241+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:09:27.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:09:27.261+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:09:27.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:09:27.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T02:09:57.492+0000] {processor.py:157} INFO - Started process (PID=2754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:09:57.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:09:57.498+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:09:57.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:09:57.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:09:57.551+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:09:57.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:09:57.565+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:09:57.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:09:57.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-15T02:10:27.938+0000] {processor.py:157} INFO - Started process (PID=2764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:10:27.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:10:27.942+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:10:27.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:10:27.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:10:28.029+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:10:28.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:10:28.060+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:10:28.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:10:28.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-15T02:10:58.313+0000] {processor.py:157} INFO - Started process (PID=2774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:10:58.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:10:58.319+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:10:58.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:10:58.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:10:58.380+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:10:58.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:10:58.397+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:10:58.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:10:58.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T02:11:28.775+0000] {processor.py:157} INFO - Started process (PID=2784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:11:28.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:11:28.781+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:11:28.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:11:28.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:11:28.848+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:11:28.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:11:28.864+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:11:28.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:11:28.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T02:11:59.538+0000] {processor.py:157} INFO - Started process (PID=2794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:11:59.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:11:59.542+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:11:59.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:11:59.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:11:59.607+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:11:59.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:11:59.627+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:11:59.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:11:59.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T02:12:29.966+0000] {processor.py:157} INFO - Started process (PID=2804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:12:29.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:12:30.009+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:12:30.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:12:30.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:12:30.155+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:12:30.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:12:30.183+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:12:30.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:12:30.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.240 seconds
[2024-09-15T02:13:00.329+0000] {processor.py:157} INFO - Started process (PID=2814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:13:00.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:13:00.337+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:13:00.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:13:00.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:13:00.408+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:13:00.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:13:00.424+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:13:00.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:13:00.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T02:13:31.198+0000] {processor.py:157} INFO - Started process (PID=2824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:13:31.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:13:31.204+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:13:31.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:13:31.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:13:31.262+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:13:31.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:13:31.284+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:13:31.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:13:31.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T02:14:01.695+0000] {processor.py:157} INFO - Started process (PID=2834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:14:01.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:14:01.702+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:14:01.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:14:01.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:14:01.761+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:14:01.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:14:01.784+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:14:01.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:14:01.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T02:14:32.173+0000] {processor.py:157} INFO - Started process (PID=2844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:14:32.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:14:32.178+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:14:32.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:14:32.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:14:32.238+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:14:32.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:14:32.261+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:14:32.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:14:32.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T02:15:02.711+0000] {processor.py:157} INFO - Started process (PID=2853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:15:02.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:15:02.715+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:15:02.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:15:02.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:15:02.774+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:15:02.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:15:02.791+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:15:02.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:15:02.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T02:15:33.007+0000] {processor.py:157} INFO - Started process (PID=2862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:15:33.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:15:33.012+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:15:33.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:15:33.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:15:33.071+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:15:33.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:15:33.089+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:15:33.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:15:33.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T02:16:03.396+0000] {processor.py:157} INFO - Started process (PID=2873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:16:03.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:16:03.402+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:16:03.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:16:03.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:16:03.479+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:16:03.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:16:03.502+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:16:03.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:16:03.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T02:16:33.838+0000] {processor.py:157} INFO - Started process (PID=2884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:16:33.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:16:33.848+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:16:33.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:16:33.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:16:33.912+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:16:33.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:16:33.928+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:16:33.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:16:33.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T02:17:04.170+0000] {processor.py:157} INFO - Started process (PID=2894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:17:04.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:17:04.179+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:17:04.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:17:04.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:17:04.251+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:17:04.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:17:04.271+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:17:04.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:17:04.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T02:17:34.549+0000] {processor.py:157} INFO - Started process (PID=2904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:17:34.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:17:34.556+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:17:34.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:17:34.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:17:34.664+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:17:34.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:17:34.692+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:17:34.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:17:34.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-15T02:18:04.928+0000] {processor.py:157} INFO - Started process (PID=2914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:18:04.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:18:04.938+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:18:04.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:18:04.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:18:05.026+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:18:05.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:18:05.045+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:18:05.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:18:05.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-15T02:18:35.366+0000] {processor.py:157} INFO - Started process (PID=2924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:18:35.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:18:35.372+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:18:35.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:18:35.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:18:35.433+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:18:35.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:18:35.451+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:18:35.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:18:35.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T02:19:05.951+0000] {processor.py:157} INFO - Started process (PID=2934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:19:05.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:19:05.956+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:19:05.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:19:05.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:19:06.018+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:19:06.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:19:06.034+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:19:06.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:19:06.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T02:19:36.343+0000] {processor.py:157} INFO - Started process (PID=2943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:19:36.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:19:36.349+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:19:36.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:19:36.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:19:36.411+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:19:36.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:19:36.427+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:19:36.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:19:36.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T02:20:06.866+0000] {processor.py:157} INFO - Started process (PID=2954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:20:06.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:20:06.870+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:20:06.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:20:06.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:20:06.933+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:20:06.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:20:06.952+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:20:06.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:20:06.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T02:20:37.285+0000] {processor.py:157} INFO - Started process (PID=2964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:20:37.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:20:37.293+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:20:37.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:20:37.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:20:37.380+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:20:37.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:20:37.398+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:20:37.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:20:37.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-15T02:21:07.774+0000] {processor.py:157} INFO - Started process (PID=2974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:21:07.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:21:07.791+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:21:07.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:21:07.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:21:07.971+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:21:07.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:21:07.991+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:21:07.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:21:08.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.237 seconds
[2024-09-15T02:21:38.172+0000] {processor.py:157} INFO - Started process (PID=2983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:21:38.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:21:38.179+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:21:38.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:21:38.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:21:38.236+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:21:38.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:21:38.252+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:21:38.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:21:38.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T02:22:08.590+0000] {processor.py:157} INFO - Started process (PID=2994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:22:08.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:22:08.594+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:22:08.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:22:08.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:22:08.633+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:22:08.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:22:08.647+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:22:08.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:22:08.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T02:22:38.877+0000] {processor.py:157} INFO - Started process (PID=3004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:22:38.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:22:38.884+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:22:38.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:22:38.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:22:38.923+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:22:38.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:22:38.937+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:22:38.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:22:38.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T02:23:09.248+0000] {processor.py:157} INFO - Started process (PID=3014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:23:09.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:23:09.252+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:23:09.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:23:09.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:23:09.284+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:23:09.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:23:09.299+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:23:09.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:23:09.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T02:23:39.621+0000] {processor.py:157} INFO - Started process (PID=3024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:23:39.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:23:39.628+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:23:39.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:23:39.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:23:39.689+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:23:39.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:23:39.712+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:23:39.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:23:39.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T02:24:09.964+0000] {processor.py:157} INFO - Started process (PID=3034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:24:09.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:24:09.971+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:24:09.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:24:09.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:24:10.040+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:24:10.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:24:10.059+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:24:10.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:24:10.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T02:24:40.315+0000] {processor.py:157} INFO - Started process (PID=3044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:24:40.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:24:40.323+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:24:40.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:24:40.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:24:40.361+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:24:40.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:24:40.375+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:24:40.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:24:40.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T02:25:10.726+0000] {processor.py:157} INFO - Started process (PID=3054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:25:10.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:25:10.728+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:25:10.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:25:10.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:25:10.753+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:25:10.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:25:10.769+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:25:10.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:25:10.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T02:25:41.095+0000] {processor.py:157} INFO - Started process (PID=3064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:25:41.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:25:41.100+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:25:41.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:25:41.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:25:41.170+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:25:41.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:25:41.188+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:25:41.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:25:41.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T02:26:11.428+0000] {processor.py:157} INFO - Started process (PID=3073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:26:11.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:26:11.443+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:26:11.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:26:11.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:26:11.494+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:26:11.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:26:11.521+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:26:11.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:26:11.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T02:26:41.778+0000] {processor.py:157} INFO - Started process (PID=3084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:26:41.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:26:41.795+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:26:41.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:26:41.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:26:41.844+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:26:41.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:26:41.872+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:26:41.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:26:41.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T02:27:12.295+0000] {processor.py:157} INFO - Started process (PID=3094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:27:12.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:27:12.299+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:27:12.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:27:12.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:27:12.351+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:27:12.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:27:12.368+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:27:12.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:27:12.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T02:27:42.691+0000] {processor.py:157} INFO - Started process (PID=3104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:27:42.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:27:42.694+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:27:42.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:27:42.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:27:42.736+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:27:42.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:27:42.752+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:27:42.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:27:42.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T02:28:13.181+0000] {processor.py:157} INFO - Started process (PID=3114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:28:13.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:28:13.187+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:28:13.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:28:13.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:28:13.242+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:28:13.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:28:13.258+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:28:13.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:28:13.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T02:28:43.544+0000] {processor.py:157} INFO - Started process (PID=3124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:28:43.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:28:43.549+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:28:43.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:28:43.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:28:43.595+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:28:43.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:28:43.611+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:28:43.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:28:43.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T02:29:14.041+0000] {processor.py:157} INFO - Started process (PID=3134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:29:14.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:29:14.045+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:29:14.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:29:14.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:29:14.116+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:29:14.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:29:14.145+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:29:14.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:29:14.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T02:29:44.362+0000] {processor.py:157} INFO - Started process (PID=3143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:29:44.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:29:44.368+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:29:44.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:29:44.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:29:44.433+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:29:44.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:29:44.466+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:29:44.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:29:44.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T02:30:14.834+0000] {processor.py:157} INFO - Started process (PID=3154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:30:14.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:30:14.843+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:30:14.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:30:14.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:30:14.885+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:30:14.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:30:14.901+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:30:14.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:30:14.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T02:30:45.305+0000] {processor.py:157} INFO - Started process (PID=3164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:30:45.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:30:45.310+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:30:45.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:30:45.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:30:45.373+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:30:45.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:30:45.389+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:30:45.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:30:45.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T02:31:15.758+0000] {processor.py:157} INFO - Started process (PID=3173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:31:15.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:31:15.764+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:31:15.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:31:15.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:31:15.831+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:31:15.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:31:15.847+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:31:15.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:31:15.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T02:31:46.107+0000] {processor.py:157} INFO - Started process (PID=3184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:31:46.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:31:46.118+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:31:46.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:31:46.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:31:46.157+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:31:46.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:31:46.174+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:31:46.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:31:46.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T02:32:16.498+0000] {processor.py:157} INFO - Started process (PID=3194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:32:16.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:32:16.502+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:32:16.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:32:16.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:32:16.574+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:32:16.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:32:16.597+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:32:16.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:32:16.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T02:32:46.995+0000] {processor.py:157} INFO - Started process (PID=3204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:32:46.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:32:47.005+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:32:47.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:32:47.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:32:47.084+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:32:47.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:32:47.108+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:32:47.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:32:47.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-15T02:33:17.355+0000] {processor.py:157} INFO - Started process (PID=3214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:33:17.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:33:17.367+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:33:17.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:33:17.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:33:17.499+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:33:17.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:33:17.522+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:33:17.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:33:17.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-09-15T02:33:47.674+0000] {processor.py:157} INFO - Started process (PID=3223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:33:47.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:33:47.686+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:33:47.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:33:47.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:33:47.802+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:33:47.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:33:47.828+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:33:47.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:33:47.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-09-15T02:34:18.196+0000] {processor.py:157} INFO - Started process (PID=3233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:34:18.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:34:18.203+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:34:18.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:34:18.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:34:18.255+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:34:18.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:34:18.279+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:34:18.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:34:18.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T02:34:48.511+0000] {processor.py:157} INFO - Started process (PID=3244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:34:48.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:34:48.516+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:34:48.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:34:48.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:34:48.556+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:34:48.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:34:48.568+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:34:48.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:34:48.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T02:35:18.902+0000] {processor.py:157} INFO - Started process (PID=3254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:35:18.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:35:18.907+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:35:18.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:35:18.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:35:18.965+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:35:18.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:35:18.982+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:35:18.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:35:18.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T02:35:49.346+0000] {processor.py:157} INFO - Started process (PID=3264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:35:49.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:35:49.363+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:35:49.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:35:49.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:35:49.448+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:35:49.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:35:49.483+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:35:49.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:35:49.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-15T02:36:19.976+0000] {processor.py:157} INFO - Started process (PID=3274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:36:19.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:36:20.005+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:36:20.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:36:20.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:36:20.103+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:36:20.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:36:20.136+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:36:20.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:36:20.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-09-15T02:36:50.477+0000] {processor.py:157} INFO - Started process (PID=3284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:36:50.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:36:50.482+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:36:50.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:36:50.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:36:50.565+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:36:50.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:36:50.597+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:36:50.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:36:50.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-15T02:37:21.241+0000] {processor.py:157} INFO - Started process (PID=3294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:37:21.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:37:21.246+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:37:21.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:37:21.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:37:21.294+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:37:21.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:37:21.325+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:37:21.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:37:21.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T02:37:51.604+0000] {processor.py:157} INFO - Started process (PID=3304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:37:51.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:37:51.610+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:37:51.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:37:51.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:37:51.709+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:37:51.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:37:51.735+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:37:51.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:37:51.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-15T02:38:22.060+0000] {processor.py:157} INFO - Started process (PID=3314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:38:22.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:38:22.070+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:38:22.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:38:22.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:38:22.192+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:38:22.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:38:22.223+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:38:22.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:38:22.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-09-15T02:38:52.492+0000] {processor.py:157} INFO - Started process (PID=3324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:38:52.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:38:52.497+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:38:52.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:38:52.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:38:52.587+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:38:52.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:38:52.615+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:38:52.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:38:52.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-15T02:39:22.968+0000] {processor.py:157} INFO - Started process (PID=3334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:39:22.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:39:22.974+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:39:22.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:39:22.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:39:23.059+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:39:23.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:39:23.079+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:39:23.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:39:23.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-15T02:39:53.400+0000] {processor.py:157} INFO - Started process (PID=3344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:39:53.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:39:53.408+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:39:53.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:39:53.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:39:53.488+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:39:53.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:39:53.513+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:39:53.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:39:53.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-15T02:40:23.794+0000] {processor.py:157} INFO - Started process (PID=3354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:40:23.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:40:23.802+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:40:23.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:40:23.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:40:23.864+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:40:23.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:40:23.881+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:40:23.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:40:23.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T02:40:54.237+0000] {processor.py:157} INFO - Started process (PID=3364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:40:54.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:40:54.243+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:40:54.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:40:54.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:40:54.305+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:40:54.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:40:54.330+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:40:54.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:40:54.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T02:41:24.572+0000] {processor.py:157} INFO - Started process (PID=3374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:41:24.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:41:24.579+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:41:24.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:41:24.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:41:24.640+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:41:24.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:41:24.662+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:41:24.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:41:24.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T02:41:54.895+0000] {processor.py:157} INFO - Started process (PID=3384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:41:54.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:41:54.903+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:41:54.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:41:54.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:41:54.961+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:41:54.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:41:54.977+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:41:54.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:41:54.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T02:42:25.268+0000] {processor.py:157} INFO - Started process (PID=3394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:42:25.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:42:25.277+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:42:25.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:42:25.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:42:25.346+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:42:25.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:42:25.364+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:42:25.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:42:25.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T02:42:55.626+0000] {processor.py:157} INFO - Started process (PID=3404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:42:55.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:42:55.637+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:42:55.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:42:55.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:42:55.711+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:42:55.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:42:55.732+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:42:55.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:42:55.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T02:43:26.187+0000] {processor.py:157} INFO - Started process (PID=3414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:43:26.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:43:26.195+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:43:26.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:43:26.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:43:26.265+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:43:26.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:43:26.286+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:43:26.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:43:26.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T02:43:56.744+0000] {processor.py:157} INFO - Started process (PID=3424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:43:56.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:43:56.748+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:43:56.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:43:56.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:43:56.818+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:43:56.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:43:56.842+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:43:56.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:43:56.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T02:44:27.198+0000] {processor.py:157} INFO - Started process (PID=3434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:44:27.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:44:27.205+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:44:27.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:44:27.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:44:27.265+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:44:27.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:44:27.291+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:44:27.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:44:27.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T02:44:57.547+0000] {processor.py:157} INFO - Started process (PID=3443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:44:57.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:44:57.558+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:44:57.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:44:57.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:44:57.621+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:44:57.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:44:57.638+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:44:57.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:44:57.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T02:45:27.875+0000] {processor.py:157} INFO - Started process (PID=3454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:45:27.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:45:27.885+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:45:27.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:45:27.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:45:27.960+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:45:27.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:45:27.977+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:45:27.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:45:27.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T02:45:58.241+0000] {processor.py:157} INFO - Started process (PID=3464) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:45:58.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:45:58.266+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:45:58.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:45:58.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:45:58.339+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:45:58.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:45:58.356+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:45:58.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:45:58.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-15T02:46:28.730+0000] {processor.py:157} INFO - Started process (PID=3474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:46:28.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:46:28.736+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:46:28.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:46:28.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:46:28.806+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:46:28.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:46:28.823+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:46:28.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:46:28.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T02:46:59.167+0000] {processor.py:157} INFO - Started process (PID=3484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:46:59.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:46:59.172+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:46:59.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:46:59.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:46:59.220+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:46:59.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:46:59.237+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:46:59.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:46:59.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T02:47:29.544+0000] {processor.py:157} INFO - Started process (PID=3494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:47:29.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:47:29.552+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:47:29.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:47:29.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:47:29.606+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:47:29.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:47:29.622+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:47:29.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:47:29.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T02:47:59.894+0000] {processor.py:157} INFO - Started process (PID=3504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:47:59.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:47:59.908+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:47:59.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:47:59.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:47:59.985+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:47:59.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:48:00.008+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:48:00.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:48:00.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-15T02:48:30.459+0000] {processor.py:157} INFO - Started process (PID=3513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:48:30.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:48:30.468+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:48:30.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:48:30.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:48:30.522+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:48:30.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:48:30.538+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:48:30.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:48:30.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T02:49:00.912+0000] {processor.py:157} INFO - Started process (PID=3524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:49:00.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:49:00.929+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:49:00.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:49:00.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:49:00.985+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:49:00.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:49:01.006+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:49:01.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:49:01.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T02:49:31.248+0000] {processor.py:157} INFO - Started process (PID=3534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:49:31.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:49:31.253+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:49:31.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:49:31.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:49:31.327+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:49:31.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:49:31.344+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:49:31.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:49:31.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T02:50:01.618+0000] {processor.py:157} INFO - Started process (PID=3544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:50:01.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:50:01.628+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:50:01.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:50:01.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:50:01.692+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:50:01.692+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:50:01.709+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:50:01.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:50:01.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T02:50:32.040+0000] {processor.py:157} INFO - Started process (PID=3554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:50:32.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:50:32.045+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:50:32.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:50:32.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:50:32.102+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:50:32.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:50:32.119+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:50:32.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:50:32.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T02:51:02.397+0000] {processor.py:157} INFO - Started process (PID=3564) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:51:02.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:51:02.403+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:51:02.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:51:02.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:51:02.456+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:51:02.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:51:02.480+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:51:02.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:51:02.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T02:51:32.818+0000] {processor.py:157} INFO - Started process (PID=3574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:51:32.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:51:32.825+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:51:32.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:51:32.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:51:32.895+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:51:32.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:51:32.914+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:51:32.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:51:32.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-15T02:52:03.268+0000] {processor.py:157} INFO - Started process (PID=3584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:52:03.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:52:03.290+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:52:03.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:52:03.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:52:03.394+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:52:03.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:52:03.407+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:52:03.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:52:03.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-15T02:52:33.833+0000] {processor.py:157} INFO - Started process (PID=3594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:52:33.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:52:33.845+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:52:33.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:52:33.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:52:33.919+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:52:33.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:52:33.937+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:52:33.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:52:33.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-15T02:53:04.229+0000] {processor.py:157} INFO - Started process (PID=3604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:53:04.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:53:04.234+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:53:04.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:53:04.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:53:04.284+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:53:04.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:53:04.299+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:53:04.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:53:04.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-15T02:53:34.774+0000] {processor.py:157} INFO - Started process (PID=3614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:53:34.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:53:34.777+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:53:34.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:53:34.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:53:34.839+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:53:34.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:53:34.862+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:53:34.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:53:34.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T02:54:05.210+0000] {processor.py:157} INFO - Started process (PID=3624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:54:05.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:54:05.215+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:54:05.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:54:05.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:54:05.268+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:54:05.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:54:05.283+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:54:05.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:54:05.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T02:54:35.806+0000] {processor.py:157} INFO - Started process (PID=3633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:54:35.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:54:35.812+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:54:35.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:54:35.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:54:35.883+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:54:35.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:54:35.901+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:54:35.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:54:35.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T02:55:06.199+0000] {processor.py:157} INFO - Started process (PID=3644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:55:06.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:55:06.208+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:55:06.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:55:06.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:55:06.268+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:55:06.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:55:06.284+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:55:06.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:55:06.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T02:55:36.679+0000] {processor.py:157} INFO - Started process (PID=3654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:55:36.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:55:36.689+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:55:36.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:55:36.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:55:36.749+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:55:36.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:55:36.781+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:55:36.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:55:36.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T02:56:07.238+0000] {processor.py:157} INFO - Started process (PID=3664) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:56:07.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:56:07.248+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:56:07.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:56:07.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:56:07.346+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:56:07.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:56:07.362+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:56:07.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:56:07.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-15T02:56:37.619+0000] {processor.py:157} INFO - Started process (PID=3673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:56:37.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:56:37.626+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:56:37.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:56:37.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:56:37.697+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:56:37.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:56:37.719+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:56:37.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:56:37.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T02:57:08.188+0000] {processor.py:157} INFO - Started process (PID=3684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:57:08.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:57:08.192+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:57:08.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:57:08.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:57:08.274+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:57:08.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:57:08.292+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:57:08.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:57:08.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T02:57:38.580+0000] {processor.py:157} INFO - Started process (PID=3694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:57:38.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:57:38.588+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:57:38.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:57:38.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:57:38.644+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:57:38.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:57:38.675+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:57:38.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:57:38.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T02:58:09.000+0000] {processor.py:157} INFO - Started process (PID=3704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:58:09.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:58:09.007+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:58:09.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:58:09.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:58:09.086+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:58:09.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:58:09.102+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:58:09.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:58:09.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T02:58:39.415+0000] {processor.py:157} INFO - Started process (PID=3714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:58:39.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:58:39.420+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:58:39.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:58:39.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:58:39.478+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:58:39.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:58:39.494+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:58:39.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:58:39.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T02:59:09.807+0000] {processor.py:157} INFO - Started process (PID=3724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:59:09.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:59:09.817+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:59:09.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:59:09.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:59:09.882+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:59:09.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:59:09.898+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:59:09.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:59:09.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T02:59:40.233+0000] {processor.py:157} INFO - Started process (PID=3732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:59:40.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T02:59:40.239+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:59:40.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:59:40.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T02:59:40.318+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:59:40.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T02:59:40.336+0000] {logging_mixin.py:151} INFO - [2024-09-15T02:59:40.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T02:59:40.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T03:00:10.606+0000] {processor.py:157} INFO - Started process (PID=3744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:00:10.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:00:10.611+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:00:10.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:00:10.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:00:10.684+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:00:10.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:00:10.702+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:00:10.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:00:10.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T03:00:41.030+0000] {processor.py:157} INFO - Started process (PID=3754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:00:41.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:00:41.048+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:00:41.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:00:41.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:00:41.118+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:00:41.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:00:41.134+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:00:41.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:00:41.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T03:01:11.403+0000] {processor.py:157} INFO - Started process (PID=3763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:01:11.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:01:11.411+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:01:11.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:01:11.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:01:11.473+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:01:11.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:01:11.499+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:01:11.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:01:11.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T03:01:41.922+0000] {processor.py:157} INFO - Started process (PID=3774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:01:41.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:01:41.926+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:01:41.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:01:41.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:01:41.994+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:01:41.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:01:42.011+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:01:42.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:01:42.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T03:02:12.341+0000] {processor.py:157} INFO - Started process (PID=3784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:02:12.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:02:12.350+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:02:12.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:02:12.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:02:12.421+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:02:12.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:02:12.438+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:02:12.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:02:12.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T03:02:42.773+0000] {processor.py:157} INFO - Started process (PID=3794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:02:42.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:02:42.779+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:02:42.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:02:42.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:02:42.851+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:02:42.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:02:42.867+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:02:42.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:02:42.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T03:03:13.196+0000] {processor.py:157} INFO - Started process (PID=3804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:03:13.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:03:13.200+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:03:13.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:03:13.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:03:13.282+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:03:13.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:03:13.300+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:03:13.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:03:13.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T03:03:43.581+0000] {processor.py:157} INFO - Started process (PID=3814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:03:43.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:03:43.586+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:03:43.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:03:43.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:03:43.650+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:03:43.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:03:43.674+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:03:43.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:03:43.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T03:04:13.930+0000] {processor.py:157} INFO - Started process (PID=3824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:04:13.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:04:13.943+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:04:13.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:04:13.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:04:14.012+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:04:14.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:04:14.029+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:04:14.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:04:14.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T03:04:44.425+0000] {processor.py:157} INFO - Started process (PID=3834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:04:44.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:04:44.435+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:04:44.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:04:44.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:04:44.511+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:04:44.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:04:44.528+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:04:44.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:04:44.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T03:05:14.875+0000] {processor.py:157} INFO - Started process (PID=3844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:05:14.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:05:14.881+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:05:14.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:05:14.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:05:14.952+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:05:14.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:05:14.974+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:05:14.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:05:14.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-15T03:05:45.307+0000] {processor.py:157} INFO - Started process (PID=3854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:05:45.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:05:45.313+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:05:45.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:05:45.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:05:45.386+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:05:45.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:05:45.414+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:05:45.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:05:45.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T03:06:15.698+0000] {processor.py:157} INFO - Started process (PID=3864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:06:15.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:06:15.705+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:06:15.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:06:15.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:06:15.777+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:06:15.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:06:15.794+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:06:15.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:06:15.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T03:06:46.197+0000] {processor.py:157} INFO - Started process (PID=3874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:06:46.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:06:46.202+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:06:46.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:06:46.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:06:46.267+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:06:46.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:06:46.284+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:06:46.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:06:46.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T03:07:16.607+0000] {processor.py:157} INFO - Started process (PID=3884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:07:16.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:07:16.616+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:07:16.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:07:16.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:07:16.682+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:07:16.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:07:16.701+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:07:16.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:07:16.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-15T03:07:47.019+0000] {processor.py:157} INFO - Started process (PID=3894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:07:47.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:07:47.027+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:07:47.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:07:47.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:07:47.101+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:07:47.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:07:47.123+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:07:47.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:07:47.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T03:08:17.571+0000] {processor.py:157} INFO - Started process (PID=3904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:08:17.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:08:17.575+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:08:17.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:08:17.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:08:17.659+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:08:17.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:08:17.676+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:08:17.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:08:17.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T03:08:47.939+0000] {processor.py:157} INFO - Started process (PID=3912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:08:47.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:08:47.946+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:08:47.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:08:47.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:08:48.015+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:08:48.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:08:48.032+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:08:48.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:08:48.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T03:09:18.375+0000] {processor.py:157} INFO - Started process (PID=3924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:09:18.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:09:18.383+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:09:18.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:09:18.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:09:18.455+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:09:18.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:09:18.472+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:09:18.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:09:18.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T03:09:48.782+0000] {processor.py:157} INFO - Started process (PID=3934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:09:48.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:09:48.794+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:09:48.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:09:48.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:09:48.832+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:09:48.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:09:48.846+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:09:48.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:09:48.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T03:10:19.199+0000] {processor.py:157} INFO - Started process (PID=3944) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:10:19.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:10:19.209+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:10:19.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:10:19.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:10:19.245+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:10:19.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:10:19.259+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:10:19.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:10:19.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T03:10:49.540+0000] {processor.py:157} INFO - Started process (PID=3954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:10:49.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:10:49.547+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:10:49.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:10:49.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:10:49.576+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:10:49.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:10:49.586+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:10:49.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:10:49.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-15T03:11:19.972+0000] {processor.py:157} INFO - Started process (PID=3964) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:11:19.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:11:19.992+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:11:19.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:11:20.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:11:20.077+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:11:20.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:11:20.095+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:11:20.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:11:20.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-15T03:11:50.506+0000] {processor.py:157} INFO - Started process (PID=3974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:11:50.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:11:50.513+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:11:50.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:11:50.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:11:50.588+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:11:50.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:11:50.609+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:11:50.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:11:50.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T03:12:20.976+0000] {processor.py:157} INFO - Started process (PID=3984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:12:20.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:12:20.980+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:12:20.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:12:21.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:12:21.057+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:12:21.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:12:21.076+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:12:21.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:12:21.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T03:12:51.393+0000] {processor.py:157} INFO - Started process (PID=3994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:12:51.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:12:51.397+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:12:51.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:12:51.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:12:51.471+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:12:51.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:12:51.489+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:12:51.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:12:51.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-15T03:13:21.835+0000] {processor.py:157} INFO - Started process (PID=4004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:13:21.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:13:21.843+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:13:21.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:13:21.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:13:21.935+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:13:21.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:13:21.956+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:13:21.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:13:21.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-15T03:13:52.254+0000] {processor.py:157} INFO - Started process (PID=4014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:13:52.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:13:52.260+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:13:52.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:13:52.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:13:52.623+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:13:52.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:13:52.639+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:13:52.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:13:52.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.408 seconds
[2024-09-15T03:14:22.979+0000] {processor.py:157} INFO - Started process (PID=4024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:14:22.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:14:22.986+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:14:22.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:14:23.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:14:23.071+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:14:23.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:14:23.090+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:14:23.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:14:23.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T03:14:53.256+0000] {processor.py:157} INFO - Started process (PID=4034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:14:53.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:14:53.260+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:14:53.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:14:53.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:14:53.337+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:14:53.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:14:53.351+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:14:53.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:14:53.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T03:15:23.791+0000] {processor.py:157} INFO - Started process (PID=4044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:15:23.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:15:23.796+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:15:23.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:15:23.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:15:23.878+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:15:23.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:15:23.893+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:15:23.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:15:23.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-15T03:15:54.193+0000] {processor.py:157} INFO - Started process (PID=4054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:15:54.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:15:54.198+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:15:54.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:15:54.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:15:54.280+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:15:54.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:15:54.295+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:15:54.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:15:54.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T03:16:24.620+0000] {processor.py:157} INFO - Started process (PID=4064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:16:24.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:16:24.628+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:16:24.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:16:24.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:16:24.779+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:16:24.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:16:24.802+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:16:24.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:16:24.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.201 seconds
[2024-09-15T03:16:55.017+0000] {processor.py:157} INFO - Started process (PID=4074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:16:55.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:16:55.023+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:16:55.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:16:55.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:16:55.111+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:16:55.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:16:55.135+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:16:55.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:16:55.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-15T03:17:25.435+0000] {processor.py:157} INFO - Started process (PID=4084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:17:25.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:17:25.441+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:17:25.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:17:25.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:17:25.518+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:17:25.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:17:25.540+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:17:25.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:17:25.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T03:17:55.845+0000] {processor.py:157} INFO - Started process (PID=4094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:17:55.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:17:55.857+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:17:55.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:17:55.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:17:55.990+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:17:55.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:17:56.014+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:17:56.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:17:56.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-09-15T03:18:26.340+0000] {processor.py:157} INFO - Started process (PID=4104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:18:26.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:18:26.345+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:18:26.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:18:26.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:18:26.433+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:18:26.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:18:26.455+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:18:26.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:18:26.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-15T03:18:56.955+0000] {processor.py:157} INFO - Started process (PID=4112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:18:56.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:18:56.963+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:18:56.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:18:57.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:18:57.063+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:18:57.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:18:57.083+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:18:57.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:18:57.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-15T03:19:27.439+0000] {processor.py:157} INFO - Started process (PID=4124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:19:27.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:19:27.449+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:19:27.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:19:27.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:19:27.595+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:19:27.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:19:27.655+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:19:27.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:19:27.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.246 seconds
[2024-09-15T03:19:58.148+0000] {processor.py:157} INFO - Started process (PID=4133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:19:58.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:19:58.158+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:19:58.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:19:58.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:19:58.267+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:19:58.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:19:58.285+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:19:58.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:19:58.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-15T03:20:28.649+0000] {processor.py:157} INFO - Started process (PID=4143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:20:28.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:20:28.656+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:20:28.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:20:28.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:20:28.762+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:20:28.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:20:28.781+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:20:28.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:20:28.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-09-15T03:20:59.222+0000] {processor.py:157} INFO - Started process (PID=4154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:20:59.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:20:59.230+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:20:59.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:20:59.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:20:59.355+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:20:59.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:20:59.390+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:20:59.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:20:59.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.191 seconds
[2024-09-15T03:21:29.586+0000] {processor.py:157} INFO - Started process (PID=4164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:21:29.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:21:29.592+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:21:29.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:21:29.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:21:29.670+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:21:29.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:21:29.687+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:21:29.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:21:29.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T03:22:00.118+0000] {processor.py:157} INFO - Started process (PID=4174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:22:00.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:22:00.124+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:22:00.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:22:00.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:22:00.203+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:22:00.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:22:00.227+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:22:00.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:22:00.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T03:22:30.374+0000] {processor.py:157} INFO - Started process (PID=4184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:22:30.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:22:30.380+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:22:30.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:22:30.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:22:30.429+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:22:30.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:22:30.446+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:22:30.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:22:30.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T03:23:00.754+0000] {processor.py:157} INFO - Started process (PID=4194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:23:00.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:23:00.765+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:23:00.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:23:00.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:23:00.804+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:23:00.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:23:00.827+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:23:00.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:23:00.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T03:23:31.056+0000] {processor.py:157} INFO - Started process (PID=4204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:23:31.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:23:31.062+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:23:31.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:23:31.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:23:31.123+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:23:31.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:23:31.169+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:23:31.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:23:31.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-15T03:24:01.378+0000] {processor.py:157} INFO - Started process (PID=4214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:24:01.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:24:01.389+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:24:01.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:24:01.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:24:01.474+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:24:01.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:24:01.497+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:24:01.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:24:01.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-15T03:24:31.773+0000] {processor.py:157} INFO - Started process (PID=4224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:24:31.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:24:31.778+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:24:31.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:24:31.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:24:31.839+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:24:31.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:24:31.854+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:24:31.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:24:31.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T03:25:02.297+0000] {processor.py:157} INFO - Started process (PID=4233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:25:02.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:25:02.305+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:25:02.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:25:02.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:25:02.402+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:25:02.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:25:02.422+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:25:02.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:25:02.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-15T03:25:32.684+0000] {processor.py:157} INFO - Started process (PID=4243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:25:32.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:25:32.692+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:25:32.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:25:32.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:25:32.766+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:25:32.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:25:32.788+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:25:32.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:25:32.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-15T03:26:03.113+0000] {processor.py:157} INFO - Started process (PID=4254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:26:03.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:26:03.122+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:26:03.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:26:03.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:26:03.226+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:26:03.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:26:03.252+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:26:03.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:26:03.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-15T03:26:33.753+0000] {processor.py:157} INFO - Started process (PID=4264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:26:33.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:26:33.768+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:26:33.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:26:33.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:26:33.871+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:26:33.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:26:33.902+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:26:33.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:26:33.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-09-15T03:27:04.180+0000] {processor.py:157} INFO - Started process (PID=4274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:27:04.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:27:04.191+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:27:04.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:27:04.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:27:04.297+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:27:04.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:27:04.325+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:27:04.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:27:04.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-09-15T03:27:34.569+0000] {processor.py:157} INFO - Started process (PID=4284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:27:34.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:27:34.582+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:27:34.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:27:34.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:27:34.668+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:27:34.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:27:34.691+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:27:34.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:27:34.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-15T03:28:04.964+0000] {processor.py:157} INFO - Started process (PID=4294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:28:04.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:28:04.982+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:28:04.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:28:05.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:28:05.059+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:28:05.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:28:05.085+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:28:05.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:28:05.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T03:28:35.438+0000] {processor.py:157} INFO - Started process (PID=4304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:28:35.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:28:35.449+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:28:35.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:28:35.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:28:35.569+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:28:35.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:28:35.591+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:28:35.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:28:35.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-15T03:29:05.789+0000] {processor.py:157} INFO - Started process (PID=4314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:29:05.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:29:05.801+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:29:05.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:29:05.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:29:05.881+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:29:05.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:29:05.901+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:29:05.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:29:05.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-15T03:29:36.231+0000] {processor.py:157} INFO - Started process (PID=4324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:29:36.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:29:36.239+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:29:36.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:29:36.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:29:36.372+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:29:36.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:29:36.406+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:29:36.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:29:36.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.202 seconds
[2024-09-15T03:30:06.580+0000] {processor.py:157} INFO - Started process (PID=4334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:30:06.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:30:06.598+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:30:06.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:30:06.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:30:06.665+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:30:06.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:30:06.681+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:30:06.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:30:06.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T03:30:37.207+0000] {processor.py:157} INFO - Started process (PID=4344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:30:37.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:30:37.218+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:30:37.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:30:37.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:30:37.359+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:30:37.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:30:37.379+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:30:37.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:30:37.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.235 seconds
[2024-09-15T03:31:07.646+0000] {processor.py:157} INFO - Started process (PID=4354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:31:07.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:31:07.655+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:31:07.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:31:07.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:31:07.745+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:31:07.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:31:07.766+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:31:07.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:31:07.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T03:31:38.306+0000] {processor.py:157} INFO - Started process (PID=4364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:31:38.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:31:38.313+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:31:38.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:31:38.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:31:38.429+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:31:38.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:31:38.467+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:31:38.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:31:38.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.184 seconds
[2024-09-15T03:32:08.722+0000] {processor.py:157} INFO - Started process (PID=4374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:32:08.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:32:08.729+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:32:08.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:32:08.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:32:08.786+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:32:08.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:32:08.802+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:32:08.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:32:08.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T03:32:39.102+0000] {processor.py:157} INFO - Started process (PID=4384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:32:39.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:32:39.109+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:32:39.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:32:39.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:32:39.171+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:32:39.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:32:39.202+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:32:39.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:32:39.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T03:33:09.557+0000] {processor.py:157} INFO - Started process (PID=4393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:33:09.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:33:09.565+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:33:09.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:33:09.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:33:09.676+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:33:09.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:33:09.701+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:33:09.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:33:09.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-15T03:33:39.930+0000] {processor.py:157} INFO - Started process (PID=4403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:33:39.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:33:39.985+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:33:39.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:33:40.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:33:40.082+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:33:40.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:33:40.115+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:33:40.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:33:40.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.223 seconds
[2024-09-15T03:34:10.296+0000] {processor.py:157} INFO - Started process (PID=4414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:34:10.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:34:10.309+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:34:10.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:34:10.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:34:10.387+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:34:10.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:34:10.416+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:34:10.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:34:10.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-15T03:34:40.884+0000] {processor.py:157} INFO - Started process (PID=4424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:34:40.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:34:40.903+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:34:40.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:34:40.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:34:40.989+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:34:40.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:34:41.010+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:34:41.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:34:41.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-15T03:35:11.256+0000] {processor.py:157} INFO - Started process (PID=4432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:35:11.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:35:11.265+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:35:11.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:35:11.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:35:11.387+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:35:11.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:35:11.408+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:35:11.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:35:11.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-15T03:35:41.717+0000] {processor.py:157} INFO - Started process (PID=4444) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:35:41.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:35:41.727+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:35:41.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:35:41.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:35:41.863+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:35:41.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:35:41.886+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:35:41.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:35:41.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-15T03:36:12.051+0000] {processor.py:157} INFO - Started process (PID=4454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:36:12.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:36:12.061+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:36:12.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:36:12.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:36:12.180+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:36:12.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:36:12.203+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:36:12.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:36:12.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-09-15T03:36:42.558+0000] {processor.py:157} INFO - Started process (PID=4463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:36:42.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:36:42.564+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:36:42.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:36:42.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:36:42.632+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:36:42.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:36:42.666+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:36:42.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:36:42.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-15T03:37:13.021+0000] {processor.py:157} INFO - Started process (PID=4474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:37:13.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:37:13.029+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:37:13.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:37:13.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:37:13.151+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:37:13.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:37:13.169+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:37:13.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:37:13.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-09-15T03:37:43.399+0000] {processor.py:157} INFO - Started process (PID=4484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:37:43.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:37:43.408+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:37:43.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:37:43.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:37:43.503+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:37:43.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:37:43.521+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:37:43.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:37:43.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-15T03:38:13.858+0000] {processor.py:157} INFO - Started process (PID=4494) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:38:13.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:38:13.868+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:38:13.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:38:13.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:38:13.947+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:38:13.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:38:13.967+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:38:13.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:38:13.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T03:38:44.363+0000] {processor.py:157} INFO - Started process (PID=4503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:38:44.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:38:44.371+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:38:44.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:38:44.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:38:44.439+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:38:44.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:38:44.459+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:38:44.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:38:44.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T03:39:14.976+0000] {processor.py:157} INFO - Started process (PID=4513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:39:14.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:39:14.991+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:39:14.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:39:15.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:39:15.111+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:39:15.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:39:15.158+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:39:15.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:39:15.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.231 seconds
[2024-09-15T03:39:45.488+0000] {processor.py:157} INFO - Started process (PID=4524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:39:45.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:39:45.497+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:39:45.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:39:45.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:39:45.560+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:39:45.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:39:45.576+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:39:45.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:39:45.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T03:40:15.830+0000] {processor.py:157} INFO - Started process (PID=4534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:40:15.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:40:15.838+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:40:15.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:40:15.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:40:15.882+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:40:15.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:40:15.895+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:40:15.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:40:15.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T03:40:46.657+0000] {processor.py:157} INFO - Started process (PID=4544) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:40:46.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:40:46.663+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:40:46.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:40:46.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:40:46.764+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:40:46.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:40:46.790+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:40:46.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:40:46.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-15T03:56:55.335+0000] {processor.py:157} INFO - Started process (PID=4554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:56:55.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:56:55.338+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:56:55.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:56:55.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:56:55.372+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:56:55.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:56:55.383+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:56:55.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:56:55.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T03:57:25.902+0000] {processor.py:157} INFO - Started process (PID=4566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:57:25.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:57:25.925+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:57:25.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:57:26.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:57:26.145+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:57:26.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:57:26.173+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:57:26.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:57:26.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.300 seconds
[2024-09-15T03:57:56.672+0000] {processor.py:157} INFO - Started process (PID=4576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:57:56.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T03:57:56.680+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:57:56.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:57:56.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T03:57:56.745+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:57:56.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T03:57:56.778+0000] {logging_mixin.py:151} INFO - [2024-09-15T03:57:56.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T03:57:56.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-15T04:14:30.744+0000] {processor.py:157} INFO - Started process (PID=4588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:14:30.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:14:30.755+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:14:30.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:14:30.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:14:30.949+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:14:30.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:14:31.020+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:14:31.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:14:31.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.321 seconds
[2024-09-15T04:15:01.464+0000] {processor.py:157} INFO - Started process (PID=4598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:15:01.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:15:01.469+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:15:01.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:15:01.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:15:01.535+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:15:01.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:15:01.560+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:15:01.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:15:01.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T04:15:31.951+0000] {processor.py:157} INFO - Started process (PID=4607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:15:31.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:15:31.957+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:15:31.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:15:31.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:15:32.027+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:15:32.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:15:32.050+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:15:32.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:15:32.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T04:16:02.327+0000] {processor.py:157} INFO - Started process (PID=4617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:16:02.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:16:02.338+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:16:02.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:16:02.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:16:02.418+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:16:02.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:16:02.440+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:16:02.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:16:02.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-15T04:16:32.709+0000] {processor.py:157} INFO - Started process (PID=4628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:16:32.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:16:32.721+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:16:32.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:16:32.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:16:32.792+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:16:32.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:16:32.811+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:16:32.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:16:32.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T04:17:03.115+0000] {processor.py:157} INFO - Started process (PID=4638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:17:03.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:17:03.125+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:17:03.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:17:03.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:17:03.196+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:17:03.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:17:03.214+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:17:03.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:17:03.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T04:17:33.705+0000] {processor.py:157} INFO - Started process (PID=4646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:17:33.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:17:33.710+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:17:33.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:17:33.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:17:33.784+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:17:33.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:17:33.800+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:17:33.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:17:33.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T04:18:04.289+0000] {processor.py:157} INFO - Started process (PID=4657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:18:04.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:18:04.294+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:18:04.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:18:04.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:18:04.363+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:18:04.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:18:04.379+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:18:04.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:18:04.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T04:18:34.641+0000] {processor.py:157} INFO - Started process (PID=4668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:18:34.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:18:34.645+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:18:34.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:18:34.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:18:34.691+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:18:34.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:18:34.706+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:18:34.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:18:34.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T04:19:05.121+0000] {processor.py:157} INFO - Started process (PID=4677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:19:05.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:19:05.128+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:19:05.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:19:05.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:19:05.189+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:19:05.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:19:05.207+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:19:05.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:19:05.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T04:19:35.503+0000] {processor.py:157} INFO - Started process (PID=4688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:19:35.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:19:35.509+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:19:35.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:19:35.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:19:35.578+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:19:35.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:19:35.609+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:19:35.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:19:35.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T04:20:05.868+0000] {processor.py:157} INFO - Started process (PID=4698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:20:05.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:20:05.880+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:20:05.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:20:05.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:20:05.941+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:20:05.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:20:05.960+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:20:05.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:20:05.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T04:20:36.355+0000] {processor.py:157} INFO - Started process (PID=4708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:20:36.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:20:36.359+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:20:36.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:20:36.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:20:36.410+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:20:36.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:20:36.429+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:20:36.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:20:36.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T04:21:06.930+0000] {processor.py:157} INFO - Started process (PID=4718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:21:06.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:21:06.939+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:21:06.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:21:06.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:21:06.999+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:21:06.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:21:07.021+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:21:07.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:21:07.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T04:21:37.425+0000] {processor.py:157} INFO - Started process (PID=4728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:21:37.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:21:37.433+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:21:37.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:21:37.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:21:37.498+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:21:37.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:21:37.534+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:21:37.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:21:37.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T04:22:07.875+0000] {processor.py:157} INFO - Started process (PID=4738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:22:07.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:22:07.897+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:22:07.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:22:07.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:22:07.971+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:22:07.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:22:07.996+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:22:07.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:22:08.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-15T04:22:38.387+0000] {processor.py:157} INFO - Started process (PID=4748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:22:38.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:22:38.393+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:22:38.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:22:38.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:22:38.436+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:22:38.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:22:38.452+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:22:38.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:22:38.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T04:23:08.811+0000] {processor.py:157} INFO - Started process (PID=4758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:23:08.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:23:08.821+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:23:08.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:23:08.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:23:08.852+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:23:08.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:23:08.883+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:23:08.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:23:08.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T04:23:39.353+0000] {processor.py:157} INFO - Started process (PID=4768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:23:39.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:23:39.359+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:23:39.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:23:39.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:23:39.407+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:23:39.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:23:39.442+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:23:39.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:23:39.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T04:24:09.698+0000] {processor.py:157} INFO - Started process (PID=4778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:24:09.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:24:09.704+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:24:09.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:24:09.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:24:09.772+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:24:09.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:24:09.799+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:24:09.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:24:09.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T04:24:40.099+0000] {processor.py:157} INFO - Started process (PID=4788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:24:40.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:24:40.104+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:24:40.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:24:40.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:24:40.146+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:24:40.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:24:40.165+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:24:40.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:24:40.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T04:25:10.501+0000] {processor.py:157} INFO - Started process (PID=4798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:25:10.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:25:10.506+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:25:10.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:25:10.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:25:10.551+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:25:10.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:25:10.577+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:25:10.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:25:10.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T04:25:40.808+0000] {processor.py:157} INFO - Started process (PID=4808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:25:40.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:25:40.813+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:25:40.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:25:40.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:25:40.888+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:25:40.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:25:40.905+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:25:40.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:25:40.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T04:26:11.111+0000] {processor.py:157} INFO - Started process (PID=4818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:26:11.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:26:11.116+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:26:11.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:26:11.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:26:11.160+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:26:11.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:26:11.196+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:26:11.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:26:11.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T04:26:41.589+0000] {processor.py:157} INFO - Started process (PID=4828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:26:41.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:26:41.595+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:26:41.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:26:41.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:26:41.651+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:26:41.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:26:41.674+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:26:41.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:26:41.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T04:27:12.142+0000] {processor.py:157} INFO - Started process (PID=4838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:27:12.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:27:12.147+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:27:12.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:27:12.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:27:12.213+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:27:12.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:27:12.230+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:27:12.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:27:12.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T04:27:42.492+0000] {processor.py:157} INFO - Started process (PID=4848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:27:42.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:27:42.499+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:27:42.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:27:42.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:27:42.544+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:27:42.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:27:42.562+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:27:42.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:27:42.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T04:28:12.907+0000] {processor.py:157} INFO - Started process (PID=4858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:28:12.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:28:12.910+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:28:12.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:28:12.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:28:12.958+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:28:12.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:28:12.974+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:28:12.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:28:12.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T04:28:43.443+0000] {processor.py:157} INFO - Started process (PID=4867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:28:43.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:28:43.448+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:28:43.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:28:43.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:28:43.505+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:28:43.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:28:43.525+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:28:43.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:28:43.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T04:29:13.785+0000] {processor.py:157} INFO - Started process (PID=4878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:29:13.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:29:13.792+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:29:13.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:29:13.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:29:13.833+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:29:13.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:29:13.850+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:29:13.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:29:13.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T04:45:35.893+0000] {processor.py:157} INFO - Started process (PID=4890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:45:35.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:45:35.904+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:45:35.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:45:35.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:45:35.999+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:45:35.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:45:36.025+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:45:36.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:45:36.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-15T04:46:06.354+0000] {processor.py:157} INFO - Started process (PID=4900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:46:06.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:46:06.362+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:46:06.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:46:06.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:46:06.437+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:46:06.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:46:06.458+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:46:06.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:46:06.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T04:46:36.656+0000] {processor.py:157} INFO - Started process (PID=4910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:46:36.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:46:36.661+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:46:36.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:46:36.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:46:36.703+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:46:36.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:46:36.716+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:46:36.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:46:36.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T04:47:07.070+0000] {processor.py:157} INFO - Started process (PID=4919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:47:07.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:47:07.075+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:47:07.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:47:07.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:47:07.130+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:47:07.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:47:07.153+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:47:07.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:47:07.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T04:47:37.342+0000] {processor.py:157} INFO - Started process (PID=4930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:47:37.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:47:37.344+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:47:37.344+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:47:37.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:47:37.386+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:47:37.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:47:37.414+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:47:37.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:47:37.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T04:48:07.828+0000] {processor.py:157} INFO - Started process (PID=4939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:48:07.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:48:07.836+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:48:07.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:48:07.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:48:07.885+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:48:07.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:48:07.914+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:48:07.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:48:07.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T04:48:38.178+0000] {processor.py:157} INFO - Started process (PID=4950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:48:38.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:48:38.182+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:48:38.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:48:38.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:48:38.214+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:48:38.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:48:38.237+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:48:38.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:48:38.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T04:49:08.587+0000] {processor.py:157} INFO - Started process (PID=4960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:49:08.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:49:08.592+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:49:08.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:49:08.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:49:08.638+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:49:08.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:49:08.658+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:49:08.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:49:08.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T04:49:38.903+0000] {processor.py:157} INFO - Started process (PID=4970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:49:38.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:49:38.906+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:49:38.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:49:38.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:49:38.938+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:49:38.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:49:38.953+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:49:38.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:49:38.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T04:50:09.368+0000] {processor.py:157} INFO - Started process (PID=4980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:50:09.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:50:09.379+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:50:09.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:50:09.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:50:09.437+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:50:09.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:50:09.452+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:50:09.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:50:09.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T04:50:39.830+0000] {processor.py:157} INFO - Started process (PID=4990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:50:39.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:50:39.835+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:50:39.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:50:39.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:50:39.870+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:50:39.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:50:39.889+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:50:39.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:50:39.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T04:51:10.254+0000] {processor.py:157} INFO - Started process (PID=4999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:51:10.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:51:10.268+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:51:10.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:51:10.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:51:10.335+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:51:10.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:51:10.356+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:51:10.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:51:10.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T04:51:40.599+0000] {processor.py:157} INFO - Started process (PID=5010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:51:40.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:51:40.604+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:51:40.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:51:40.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:51:40.650+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:51:40.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:51:40.665+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:51:40.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:51:40.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T04:52:11.016+0000] {processor.py:157} INFO - Started process (PID=5020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:52:11.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:52:11.019+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:52:11.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:52:11.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:52:11.058+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:52:11.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:52:11.070+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:52:11.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:52:11.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T04:52:41.486+0000] {processor.py:157} INFO - Started process (PID=5029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:52:41.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:52:41.491+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:52:41.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:52:41.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:52:41.538+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:52:41.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:52:41.566+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:52:41.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:52:41.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T04:53:11.803+0000] {processor.py:157} INFO - Started process (PID=5040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:53:11.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:53:11.808+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:53:11.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:53:11.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:53:11.867+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:53:11.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:53:11.884+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:53:11.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:53:11.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T04:53:42.245+0000] {processor.py:157} INFO - Started process (PID=5050) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:53:42.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:53:42.253+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:53:42.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:53:42.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:53:42.300+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:53:42.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:53:42.319+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:53:42.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:53:42.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T04:54:12.671+0000] {processor.py:157} INFO - Started process (PID=5059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:54:12.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:54:12.675+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:54:12.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:54:12.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:54:12.711+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:54:12.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:54:12.737+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:54:12.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:54:12.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T04:54:43.005+0000] {processor.py:157} INFO - Started process (PID=5070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:54:43.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:54:43.011+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:54:43.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:54:43.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:54:43.059+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:54:43.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:54:43.082+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:54:43.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:54:43.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T04:55:13.281+0000] {processor.py:157} INFO - Started process (PID=5080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:55:13.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:55:13.284+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:55:13.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:55:13.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:55:13.310+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:55:13.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:55:13.342+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:55:13.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:55:13.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T04:55:43.720+0000] {processor.py:157} INFO - Started process (PID=5090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:55:43.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:55:43.727+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:55:43.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:55:43.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:55:43.782+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:55:43.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:55:43.800+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:55:43.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:55:43.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T04:56:14.053+0000] {processor.py:157} INFO - Started process (PID=5100) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:56:14.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:56:14.056+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:56:14.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:56:14.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:56:14.104+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:56:14.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:56:14.117+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:56:14.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:56:14.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T04:56:44.483+0000] {processor.py:157} INFO - Started process (PID=5110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:56:44.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:56:44.487+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:56:44.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:56:44.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:56:44.541+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:56:44.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:56:44.573+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:56:44.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:56:44.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T04:57:14.929+0000] {processor.py:157} INFO - Started process (PID=5120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:57:14.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:57:14.934+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:57:14.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:57:14.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:57:14.989+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:57:14.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:57:15.003+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:57:15.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:57:15.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T04:57:45.370+0000] {processor.py:157} INFO - Started process (PID=5130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:57:45.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:57:45.374+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:57:45.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:57:45.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:57:45.416+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:57:45.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:57:45.431+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:57:45.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:57:45.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T04:58:15.723+0000] {processor.py:157} INFO - Started process (PID=5140) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:58:15.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:58:15.726+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:58:15.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:58:15.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:58:15.763+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:58:15.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:58:15.785+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:58:15.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:58:15.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T04:58:46.168+0000] {processor.py:157} INFO - Started process (PID=5150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:58:46.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:58:46.173+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:58:46.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:58:46.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:58:46.234+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:58:46.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:58:46.252+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:58:46.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:58:46.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T04:59:16.517+0000] {processor.py:157} INFO - Started process (PID=5159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:59:16.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:59:16.528+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:59:16.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:59:16.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:59:16.599+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:59:16.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:59:16.618+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:59:16.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:59:16.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T04:59:46.828+0000] {processor.py:157} INFO - Started process (PID=5170) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:59:46.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T04:59:46.833+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:59:46.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:59:46.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T04:59:46.875+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:59:46.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T04:59:46.905+0000] {logging_mixin.py:151} INFO - [2024-09-15T04:59:46.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T04:59:46.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T05:00:17.320+0000] {processor.py:157} INFO - Started process (PID=5179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:00:17.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:00:17.326+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:00:17.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:00:17.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:00:17.384+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:00:17.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:00:17.411+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:00:17.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:00:17.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T05:00:47.764+0000] {processor.py:157} INFO - Started process (PID=5190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:00:47.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:00:47.770+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:00:47.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:00:47.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:00:47.831+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:00:47.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:00:47.847+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:00:47.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:00:47.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T05:01:18.148+0000] {processor.py:157} INFO - Started process (PID=5199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:01:18.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:01:18.159+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:01:18.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:01:18.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:01:18.221+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:01:18.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:01:18.248+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:01:18.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:01:18.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T05:01:48.653+0000] {processor.py:157} INFO - Started process (PID=5210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:01:48.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:01:48.659+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:01:48.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:01:48.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:01:48.704+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:01:48.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:01:48.723+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:01:48.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:01:48.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T05:02:19.030+0000] {processor.py:157} INFO - Started process (PID=5220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:02:19.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:02:19.036+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:02:19.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:02:19.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:02:19.079+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:02:19.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:02:19.095+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:02:19.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:02:19.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T05:02:49.440+0000] {processor.py:157} INFO - Started process (PID=5230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:02:49.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:02:49.444+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:02:49.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:02:49.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:02:49.475+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:02:49.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:02:49.491+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:02:49.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:02:49.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T05:03:19.846+0000] {processor.py:157} INFO - Started process (PID=5239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:03:19.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:03:19.853+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:03:19.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:03:19.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:03:19.920+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:03:19.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:03:19.934+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:03:19.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:03:19.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T05:03:50.323+0000] {processor.py:157} INFO - Started process (PID=5250) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:03:50.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:03:50.329+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:03:50.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:03:50.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:03:50.381+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:03:50.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:03:50.398+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:03:50.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:03:50.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T05:04:20.677+0000] {processor.py:157} INFO - Started process (PID=5260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:04:20.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:04:20.682+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:04:20.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:04:20.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:04:20.717+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:04:20.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:04:20.732+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:04:20.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:04:20.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T05:04:51.073+0000] {processor.py:157} INFO - Started process (PID=5269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:04:51.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:04:51.079+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:04:51.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:04:51.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:04:51.129+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:04:51.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:04:51.143+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:04:51.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:04:51.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T05:05:21.424+0000] {processor.py:157} INFO - Started process (PID=5280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:05:21.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:05:21.432+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:05:21.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:05:21.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:05:21.466+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:05:21.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:05:21.483+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:05:21.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:05:21.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T05:05:51.830+0000] {processor.py:157} INFO - Started process (PID=5290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:05:51.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:05:51.836+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:05:51.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:05:51.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:05:51.897+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:05:51.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:05:51.914+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:05:51.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:05:51.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T05:06:22.130+0000] {processor.py:157} INFO - Started process (PID=5300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:06:22.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:06:22.144+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:06:22.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:06:22.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:06:22.186+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:06:22.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:06:22.206+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:06:22.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:06:22.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T05:06:52.457+0000] {processor.py:157} INFO - Started process (PID=5310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:06:52.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:06:52.459+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:06:52.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:06:52.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:06:52.494+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:06:52.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:06:52.509+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:06:52.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:06:52.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T05:07:22.884+0000] {processor.py:157} INFO - Started process (PID=5320) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:07:22.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:07:22.892+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:07:22.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:07:22.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:07:22.938+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:07:22.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:07:22.953+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:07:22.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:07:22.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T05:07:53.337+0000] {processor.py:157} INFO - Started process (PID=5330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:07:53.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:07:53.348+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:07:53.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:07:53.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:07:53.385+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:07:53.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:07:53.406+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:07:53.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:07:53.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T05:08:23.688+0000] {processor.py:157} INFO - Started process (PID=5340) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:08:23.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:08:23.699+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:08:23.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:08:23.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:08:23.761+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:08:23.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:08:23.778+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:08:23.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:08:23.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T05:08:54.031+0000] {processor.py:157} INFO - Started process (PID=5350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:08:54.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:08:54.034+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:08:54.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:08:54.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:08:54.066+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:08:54.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:08:54.083+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:08:54.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:08:54.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T05:09:24.503+0000] {processor.py:157} INFO - Started process (PID=5359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:09:24.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:09:24.508+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:09:24.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:09:24.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:09:24.561+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:09:24.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:09:24.577+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:09:24.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:09:24.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T05:09:54.970+0000] {processor.py:157} INFO - Started process (PID=5370) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:09:54.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:09:54.976+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:09:54.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:09:55.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:09:55.049+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:09:55.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:09:55.074+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:09:55.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:09:55.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T05:10:25.373+0000] {processor.py:157} INFO - Started process (PID=5380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:10:25.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:10:25.375+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:10:25.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:10:25.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:10:25.401+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:10:25.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:10:25.420+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:10:25.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:10:25.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T05:10:55.798+0000] {processor.py:157} INFO - Started process (PID=5390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:10:55.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:10:55.805+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:10:55.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:10:55.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:10:55.866+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:10:55.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:10:55.882+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:10:55.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:10:55.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T05:11:26.164+0000] {processor.py:157} INFO - Started process (PID=5400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:11:26.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:11:26.169+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:11:26.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:11:26.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:11:26.212+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:11:26.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:11:26.228+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:11:26.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:11:26.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T05:11:56.473+0000] {processor.py:157} INFO - Started process (PID=5410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:11:56.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:11:56.476+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:11:56.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:11:56.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:11:56.514+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:11:56.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:11:56.534+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:11:56.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:11:56.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T05:12:26.810+0000] {processor.py:157} INFO - Started process (PID=5420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:12:26.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:12:26.823+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:12:26.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:12:26.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:12:26.864+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:12:26.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:12:26.880+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:12:26.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:12:26.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T05:12:57.291+0000] {processor.py:157} INFO - Started process (PID=5430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:12:57.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:12:57.298+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:12:57.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:12:57.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:12:57.341+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:12:57.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:12:57.373+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:12:57.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:12:57.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T05:13:27.744+0000] {processor.py:157} INFO - Started process (PID=5440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:13:27.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:13:27.750+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:13:27.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:13:27.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:13:27.820+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:13:27.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:13:27.835+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:13:27.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:13:27.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T05:13:58.210+0000] {processor.py:157} INFO - Started process (PID=5450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:13:58.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:13:58.219+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:13:58.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:13:58.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:13:58.259+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:13:58.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:13:58.275+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:13:58.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:13:58.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T05:14:28.523+0000] {processor.py:157} INFO - Started process (PID=5460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:14:28.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:14:28.527+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:14:28.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:14:28.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:14:28.580+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:14:28.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:14:28.596+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:14:28.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:14:28.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T05:14:58.868+0000] {processor.py:157} INFO - Started process (PID=5468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:14:58.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:14:58.874+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:14:58.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:14:58.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:14:58.921+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:14:58.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:14:58.938+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:14:58.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:14:58.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T05:15:29.182+0000] {processor.py:157} INFO - Started process (PID=5480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:15:29.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:15:29.188+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:15:29.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:15:29.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:15:29.240+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:15:29.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:15:29.272+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:15:29.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:15:29.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T05:15:59.550+0000] {processor.py:157} INFO - Started process (PID=5489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:15:59.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:15:59.556+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:15:59.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:15:59.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:15:59.599+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:15:59.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:15:59.613+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:15:59.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:15:59.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T05:16:29.843+0000] {processor.py:157} INFO - Started process (PID=5500) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:16:29.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:16:29.847+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:16:29.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:16:29.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:16:29.907+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:16:29.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:16:29.940+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:16:29.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:16:29.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T05:17:00.200+0000] {processor.py:157} INFO - Started process (PID=5510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:17:00.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:17:00.217+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:17:00.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:17:00.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:17:00.260+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:17:00.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:17:00.290+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:17:00.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:17:00.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T05:17:30.534+0000] {processor.py:157} INFO - Started process (PID=5519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:17:30.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:17:30.540+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:17:30.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:17:30.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:17:30.582+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:17:30.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:17:30.595+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:17:30.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:17:30.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T05:18:00.889+0000] {processor.py:157} INFO - Started process (PID=5530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:18:00.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:18:00.894+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:18:00.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:18:00.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:18:00.951+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:18:00.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:18:00.968+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:18:00.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:18:00.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T05:18:31.238+0000] {processor.py:157} INFO - Started process (PID=5540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:18:31.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:18:31.240+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:18:31.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:18:31.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:18:31.275+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:18:31.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:18:31.292+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:18:31.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:18:31.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T05:19:01.624+0000] {processor.py:157} INFO - Started process (PID=5548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:19:01.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:19:01.629+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:19:01.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:19:01.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:19:01.687+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:19:01.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:19:01.707+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:19:01.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:19:01.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T05:19:31.920+0000] {processor.py:157} INFO - Started process (PID=5560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:19:31.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:19:31.923+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:19:31.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:19:31.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:19:31.955+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:19:31.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:19:31.972+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:19:31.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:19:31.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T05:20:02.356+0000] {processor.py:157} INFO - Started process (PID=5570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:20:02.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:20:02.361+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:20:02.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:20:02.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:20:02.425+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:20:02.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:20:02.449+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:20:02.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:20:02.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T05:20:32.835+0000] {processor.py:157} INFO - Started process (PID=5579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:20:32.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:20:32.848+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:20:32.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:20:32.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:20:32.913+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:20:32.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:20:32.930+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:20:32.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:20:32.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T05:21:03.192+0000] {processor.py:157} INFO - Started process (PID=5590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:21:03.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:21:03.199+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:21:03.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:21:03.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:21:03.278+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:21:03.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:21:03.297+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:21:03.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:21:03.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-15T05:21:33.496+0000] {processor.py:157} INFO - Started process (PID=5600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:21:33.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:21:33.501+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:21:33.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:21:33.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:21:33.534+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:21:33.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:21:33.549+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:21:33.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:21:33.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T05:22:03.956+0000] {processor.py:157} INFO - Started process (PID=5610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:22:03.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:22:03.961+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:22:03.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:22:03.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:22:04.031+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:22:04.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:22:04.047+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:22:04.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:22:04.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T05:22:34.454+0000] {processor.py:157} INFO - Started process (PID=5620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:22:34.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:22:34.459+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:22:34.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:22:34.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:22:34.500+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:22:34.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:22:34.525+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:22:34.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:22:34.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T05:23:04.813+0000] {processor.py:157} INFO - Started process (PID=5630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:23:04.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:23:04.820+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:23:04.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:23:04.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:23:04.878+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:23:04.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:23:04.894+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:23:04.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:23:04.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T05:23:35.236+0000] {processor.py:157} INFO - Started process (PID=5640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:23:35.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:23:35.239+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:23:35.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:23:35.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:23:35.267+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:23:35.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:23:35.302+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:23:35.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:23:35.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T05:24:05.703+0000] {processor.py:157} INFO - Started process (PID=5650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:24:05.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:24:05.715+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:24:05.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:24:05.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:24:05.784+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:24:05.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:24:05.800+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:24:05.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:24:05.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T05:24:36.158+0000] {processor.py:157} INFO - Started process (PID=5660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:24:36.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:24:36.161+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:24:36.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:24:36.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:24:36.195+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:24:36.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:24:36.228+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:24:36.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:24:36.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T05:25:06.594+0000] {processor.py:157} INFO - Started process (PID=5670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:25:06.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:25:06.601+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:25:06.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:25:06.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:25:06.667+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:25:06.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:25:06.697+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:25:06.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:25:06.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T05:25:37.024+0000] {processor.py:157} INFO - Started process (PID=5680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:25:37.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:25:37.044+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:25:37.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:25:37.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:25:37.114+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:25:37.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:25:37.136+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:25:37.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:25:37.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T05:26:07.483+0000] {processor.py:157} INFO - Started process (PID=5690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:26:07.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:26:07.490+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:26:07.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:26:07.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:26:07.535+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:26:07.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:26:07.566+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:26:07.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:26:07.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T05:26:37.799+0000] {processor.py:157} INFO - Started process (PID=5700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:26:37.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:26:37.802+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:26:37.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:26:37.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:26:37.829+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:26:37.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:26:37.844+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:26:37.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:26:37.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T05:27:08.245+0000] {processor.py:157} INFO - Started process (PID=5709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:27:08.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:27:08.251+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:27:08.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:27:08.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:27:08.317+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:27:08.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:27:08.337+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:27:08.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:27:08.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T05:27:38.614+0000] {processor.py:157} INFO - Started process (PID=5720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:27:38.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:27:38.624+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:27:38.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:27:38.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:27:38.676+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:27:38.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:27:38.696+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:27:38.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:27:38.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T05:28:09.010+0000] {processor.py:157} INFO - Started process (PID=5730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:28:09.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:28:09.017+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:28:09.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:28:09.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:28:09.093+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:28:09.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:28:09.116+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:28:09.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:28:09.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T05:28:39.464+0000] {processor.py:157} INFO - Started process (PID=5740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:28:39.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:28:39.470+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:28:39.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:28:39.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:28:39.519+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:28:39.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:28:39.536+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:28:39.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:28:39.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T05:29:09.842+0000] {processor.py:157} INFO - Started process (PID=5749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:29:09.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:29:09.850+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:29:09.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:29:09.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:29:09.923+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:29:09.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:29:09.954+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:29:09.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:29:09.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-15T05:29:40.317+0000] {processor.py:157} INFO - Started process (PID=5760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:29:40.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:29:40.324+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:29:40.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:29:40.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:29:40.374+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:29:40.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:29:40.394+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:29:40.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:29:40.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T05:30:10.823+0000] {processor.py:157} INFO - Started process (PID=5770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:30:10.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:30:10.842+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:30:10.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:30:10.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:30:10.907+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:30:10.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:30:10.931+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:30:10.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:30:10.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T05:30:41.191+0000] {processor.py:157} INFO - Started process (PID=5779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:30:41.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:30:41.197+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:30:41.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:30:41.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:30:41.276+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:30:41.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:30:41.301+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:30:41.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:30:41.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T05:31:11.578+0000] {processor.py:157} INFO - Started process (PID=5790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:31:11.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:31:11.585+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:31:11.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:31:11.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:31:11.660+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:31:11.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:31:11.691+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:31:11.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:31:11.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T05:31:41.946+0000] {processor.py:157} INFO - Started process (PID=5800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:31:41.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:31:41.952+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:31:41.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:31:41.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:31:42.020+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:31:42.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:31:42.045+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:31:42.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:31:42.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T05:32:12.281+0000] {processor.py:157} INFO - Started process (PID=5810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:32:12.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:32:12.287+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:32:12.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:32:12.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:32:12.371+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:32:12.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:32:12.404+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:32:12.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:32:12.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-15T05:32:42.813+0000] {processor.py:157} INFO - Started process (PID=5819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:32:42.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:32:42.818+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:32:42.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:32:42.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:32:42.860+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:32:42.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:32:42.880+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:32:42.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:32:42.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T05:33:13.281+0000] {processor.py:157} INFO - Started process (PID=5830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:33:13.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:33:13.285+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:33:13.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:33:13.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:33:13.317+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:33:13.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:33:13.333+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:33:13.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:33:13.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T05:33:43.751+0000] {processor.py:157} INFO - Started process (PID=5840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:33:43.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:33:43.762+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:33:43.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:33:43.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:33:43.861+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:33:43.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:33:43.879+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:33:43.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:33:43.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-15T05:34:14.070+0000] {processor.py:157} INFO - Started process (PID=5850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:34:14.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:34:14.074+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:34:14.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:34:14.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:34:14.118+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:34:14.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:34:14.141+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:34:14.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:34:14.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T05:34:44.532+0000] {processor.py:157} INFO - Started process (PID=5860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:34:44.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:34:44.537+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:34:44.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:34:44.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:34:44.582+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:34:44.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:34:44.609+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:34:44.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:34:44.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-15T05:35:14.918+0000] {processor.py:157} INFO - Started process (PID=5870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:35:14.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:35:14.921+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:35:14.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:35:14.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:35:14.953+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:35:14.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:35:14.980+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:35:14.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:35:14.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T05:35:45.324+0000] {processor.py:157} INFO - Started process (PID=5879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:35:45.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:35:45.329+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:35:45.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:35:45.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:35:45.391+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:35:45.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:35:45.408+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:35:45.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:35:45.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T05:36:15.689+0000] {processor.py:157} INFO - Started process (PID=5890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:36:15.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:36:15.693+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:36:15.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:36:15.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:36:15.740+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:36:15.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:36:15.761+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:36:15.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:36:15.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T05:36:46.104+0000] {processor.py:157} INFO - Started process (PID=5900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:36:46.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:36:46.110+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:36:46.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:36:46.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:36:46.172+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:36:46.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:36:46.196+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:36:46.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:36:46.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T05:37:16.463+0000] {processor.py:157} INFO - Started process (PID=5910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:37:16.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:37:16.468+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:37:16.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:37:16.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:37:16.508+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:37:16.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:37:16.533+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:37:16.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:37:16.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T05:37:46.852+0000] {processor.py:157} INFO - Started process (PID=5920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:37:46.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:37:46.855+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:37:46.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:37:46.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:37:46.890+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:37:46.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:37:46.912+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:37:46.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:37:46.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-15T05:38:17.329+0000] {processor.py:157} INFO - Started process (PID=5930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:38:17.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:38:17.335+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:38:17.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:38:17.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:38:17.394+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:38:17.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:38:17.420+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:38:17.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:38:17.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T05:38:47.665+0000] {processor.py:157} INFO - Started process (PID=5940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:38:47.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:38:47.667+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:38:47.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:38:47.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:38:47.714+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:38:47.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:38:47.730+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:38:47.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:38:47.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T05:39:18.111+0000] {processor.py:157} INFO - Started process (PID=5949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:39:18.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:39:18.118+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:39:18.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:39:18.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:39:18.177+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:39:18.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:39:18.198+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:39:18.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:39:18.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T05:39:48.436+0000] {processor.py:157} INFO - Started process (PID=5960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:39:48.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:39:48.439+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:39:48.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:39:48.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:39:48.484+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:39:48.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:39:48.507+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:39:48.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:39:48.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T05:40:18.937+0000] {processor.py:157} INFO - Started process (PID=5969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:40:18.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:40:18.944+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:40:18.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:40:18.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:40:19.004+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:40:19.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:40:19.023+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:40:19.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:40:19.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T05:40:49.341+0000] {processor.py:157} INFO - Started process (PID=5980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:40:49.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:40:49.346+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:40:49.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:40:49.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:40:49.404+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:40:49.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:40:49.422+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:40:49.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:40:49.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T05:41:19.819+0000] {processor.py:157} INFO - Started process (PID=5990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:41:19.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:41:19.826+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:41:19.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:41:19.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:41:19.874+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:41:19.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:41:19.900+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:41:19.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:41:19.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T05:41:50.153+0000] {processor.py:157} INFO - Started process (PID=6000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:41:50.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:41:50.157+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:41:50.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:41:50.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:41:50.197+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:41:50.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:41:50.220+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:41:50.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:41:50.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T05:42:20.553+0000] {processor.py:157} INFO - Started process (PID=6010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:42:20.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:42:20.559+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:42:20.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:42:20.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:42:20.616+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:42:20.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:42:20.632+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:42:20.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:42:20.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T05:42:50.934+0000] {processor.py:157} INFO - Started process (PID=6020) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:42:50.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:42:50.941+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:42:50.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:42:50.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:42:50.992+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:42:50.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:42:51.011+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:42:51.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:42:51.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T05:43:21.370+0000] {processor.py:157} INFO - Started process (PID=6030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:43:21.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:43:21.377+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:43:21.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:43:21.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:43:21.442+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:43:21.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:43:21.460+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:43:21.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:43:21.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T05:43:51.698+0000] {processor.py:157} INFO - Started process (PID=6040) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:43:51.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:43:51.702+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:43:51.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:43:51.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:43:51.741+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:43:51.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:43:51.761+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:43:51.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:43:51.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T05:44:22.180+0000] {processor.py:157} INFO - Started process (PID=6049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:44:22.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:44:22.197+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:44:22.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:44:22.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:44:22.261+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:44:22.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:44:22.285+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:44:22.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:44:22.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T05:44:52.536+0000] {processor.py:157} INFO - Started process (PID=6060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:44:52.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:44:52.543+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:44:52.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:44:52.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:44:52.592+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:44:52.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:44:52.609+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:44:52.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:44:52.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T05:45:22.928+0000] {processor.py:157} INFO - Started process (PID=6070) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:45:22.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:45:22.932+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:45:22.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:45:22.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:45:22.960+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:45:22.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:45:22.991+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:45:22.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:45:23.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T05:45:53.360+0000] {processor.py:157} INFO - Started process (PID=6079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:45:53.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:45:53.369+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:45:53.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:45:53.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:45:53.440+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:45:53.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:45:53.461+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:45:53.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:45:53.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T05:46:23.791+0000] {processor.py:157} INFO - Started process (PID=6090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:46:23.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:46:23.799+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:46:23.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:46:23.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:46:23.868+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:46:23.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:46:23.888+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:46:23.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:46:23.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T05:58:13.389+0000] {processor.py:157} INFO - Started process (PID=6099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:58:13.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:58:13.393+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:58:13.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:58:13.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:58:13.425+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:58:13.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:58:13.438+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:58:13.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:58:13.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T05:58:43.841+0000] {processor.py:157} INFO - Started process (PID=6112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:58:43.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:58:43.849+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:58:43.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:58:43.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:58:43.900+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:58:43.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:58:43.923+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:58:43.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:58:43.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T05:59:14.255+0000] {processor.py:157} INFO - Started process (PID=6122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:59:14.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:59:14.258+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:59:14.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:59:14.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:59:14.296+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:59:14.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:59:14.318+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:59:14.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:59:14.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T05:59:44.732+0000] {processor.py:157} INFO - Started process (PID=6132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:59:44.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T05:59:44.738+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:59:44.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:59:44.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T05:59:44.793+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:59:44.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T05:59:44.814+0000] {logging_mixin.py:151} INFO - [2024-09-15T05:59:44.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T05:59:44.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T06:00:15.087+0000] {processor.py:157} INFO - Started process (PID=6142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:00:15.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:00:15.092+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:00:15.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:00:15.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:00:15.165+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:00:15.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:00:15.184+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:00:15.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:00:15.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T06:00:45.481+0000] {processor.py:157} INFO - Started process (PID=6152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:00:45.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:00:45.483+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:00:45.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:00:45.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:00:45.521+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:00:45.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:00:45.551+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:00:45.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:00:45.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T06:01:15.920+0000] {processor.py:157} INFO - Started process (PID=6161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:01:15.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:01:15.925+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:01:15.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:01:15.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:01:15.984+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:01:15.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:01:16.013+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:01:16.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:01:16.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T06:01:46.221+0000] {processor.py:157} INFO - Started process (PID=6172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:01:46.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:01:46.223+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:01:46.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:01:46.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:01:46.259+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:01:46.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:01:46.275+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:01:46.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:01:46.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T06:02:16.711+0000] {processor.py:157} INFO - Started process (PID=6182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:02:16.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:02:16.718+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:02:16.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:02:16.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:02:16.780+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:02:16.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:02:16.802+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:02:16.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:02:16.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T06:02:47.089+0000] {processor.py:157} INFO - Started process (PID=6192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:02:47.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:02:47.092+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:02:47.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:02:47.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:02:47.132+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:02:47.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:02:47.148+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:02:47.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:02:47.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-15T06:03:17.540+0000] {processor.py:157} INFO - Started process (PID=6202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:03:17.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:03:17.545+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:03:17.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:03:17.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:03:17.599+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:03:17.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:03:17.614+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:03:17.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:03:17.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T06:03:47.922+0000] {processor.py:157} INFO - Started process (PID=6212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:03:47.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:03:47.925+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:03:47.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:03:47.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:03:47.960+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:03:47.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:03:47.987+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:03:47.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:03:48.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T06:04:18.319+0000] {processor.py:157} INFO - Started process (PID=6222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:04:18.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:04:18.326+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:04:18.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:04:18.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:04:18.381+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:04:18.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:04:18.404+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:04:18.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:04:18.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T06:04:48.812+0000] {processor.py:157} INFO - Started process (PID=6232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:04:48.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:04:48.816+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:04:48.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:04:48.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:04:48.856+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:04:48.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:04:48.872+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:04:48.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:04:48.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T06:05:19.205+0000] {processor.py:157} INFO - Started process (PID=6242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:05:19.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:05:19.211+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:05:19.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:05:19.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:05:19.265+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:05:19.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:05:19.294+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:05:19.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:05:19.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T06:05:49.538+0000] {processor.py:157} INFO - Started process (PID=6252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:05:49.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:05:49.543+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:05:49.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:05:49.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:05:49.586+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:05:49.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:05:49.610+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:05:49.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:05:49.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T06:06:20.014+0000] {processor.py:157} INFO - Started process (PID=6262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:06:20.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:06:20.017+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:06:20.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:06:20.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:06:20.077+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:06:20.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:06:20.095+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:06:20.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:06:20.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T06:06:50.383+0000] {processor.py:157} INFO - Started process (PID=6272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:06:50.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:06:50.388+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:06:50.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:06:50.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:06:50.428+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:06:50.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:06:50.454+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:06:50.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:06:50.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T06:07:20.878+0000] {processor.py:157} INFO - Started process (PID=6282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:07:20.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:07:20.883+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:07:20.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:07:20.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:07:20.937+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:07:20.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:07:20.966+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:07:20.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:07:20.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T06:07:51.316+0000] {processor.py:157} INFO - Started process (PID=6292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:07:51.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:07:51.319+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:07:51.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:07:51.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:07:51.364+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:07:51.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:07:51.380+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:07:51.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:07:51.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T06:08:21.683+0000] {processor.py:157} INFO - Started process (PID=6301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:08:21.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:08:21.689+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:08:21.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:08:21.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:08:21.745+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:08:21.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:08:21.765+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:08:21.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:08:21.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T06:08:52.197+0000] {processor.py:157} INFO - Started process (PID=6311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:08:52.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:08:52.200+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:08:52.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:08:52.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:08:52.244+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:08:52.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:08:52.261+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:08:52.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:08:52.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T06:09:22.637+0000] {processor.py:157} INFO - Started process (PID=6322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:09:22.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:09:22.641+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:09:22.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:09:22.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:09:22.685+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:09:22.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:09:22.716+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:09:22.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:09:22.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T06:09:52.980+0000] {processor.py:157} INFO - Started process (PID=6332) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:09:52.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:09:52.984+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:09:52.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:09:53.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:09:53.040+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:09:53.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:09:53.054+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:09:53.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:09:53.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T06:10:23.436+0000] {processor.py:157} INFO - Started process (PID=6342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:10:23.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:10:23.440+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:10:23.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:10:23.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:10:23.489+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:10:23.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:10:23.522+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:10:23.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:10:23.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T06:10:53.827+0000] {processor.py:157} INFO - Started process (PID=6352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:10:53.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:10:53.831+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:10:53.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:10:53.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:10:53.882+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:10:53.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:10:53.898+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:10:53.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:10:53.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T06:11:24.331+0000] {processor.py:157} INFO - Started process (PID=6362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:11:24.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:11:24.335+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:11:24.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:11:24.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:11:24.390+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:11:24.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:11:24.416+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:11:24.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:11:24.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T06:11:54.618+0000] {processor.py:157} INFO - Started process (PID=6372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:11:54.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:11:54.621+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:11:54.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:11:54.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:11:54.667+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:11:54.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:11:54.681+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:11:54.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:11:54.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T06:12:25.130+0000] {processor.py:157} INFO - Started process (PID=6380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:12:25.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:12:25.136+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:12:25.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:12:25.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:12:25.198+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:12:25.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:12:25.221+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:12:25.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:12:25.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T06:12:55.549+0000] {processor.py:157} INFO - Started process (PID=6392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:12:55.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:12:55.554+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:12:55.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:12:55.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:12:55.597+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:12:55.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:12:55.617+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:12:55.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:12:55.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T06:13:25.979+0000] {processor.py:157} INFO - Started process (PID=6402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:13:25.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:13:25.983+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:13:25.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:13:25.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:13:26.019+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:13:26.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:13:26.034+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:13:26.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:13:26.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T06:13:56.461+0000] {processor.py:157} INFO - Started process (PID=6412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:13:56.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:13:56.466+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:13:56.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:13:56.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:13:56.511+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:13:56.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:13:56.534+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:13:56.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:13:56.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T06:14:26.961+0000] {processor.py:157} INFO - Started process (PID=6422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:14:26.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:14:26.966+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:14:26.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:14:26.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:14:27.001+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:14:27.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:14:27.015+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:14:27.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:14:27.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T06:14:57.461+0000] {processor.py:157} INFO - Started process (PID=6432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:14:57.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:14:57.465+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:14:57.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:14:57.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:14:57.514+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:14:57.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:14:57.532+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:14:57.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:14:57.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T06:15:27.842+0000] {processor.py:157} INFO - Started process (PID=6442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:15:27.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:15:27.849+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:15:27.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:15:27.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:15:27.893+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:15:27.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:15:27.920+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:15:27.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:15:27.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T06:15:58.322+0000] {processor.py:157} INFO - Started process (PID=6452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:15:58.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:15:58.325+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:15:58.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:15:58.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:15:58.368+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:15:58.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:15:58.384+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:15:58.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:15:58.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T06:16:28.768+0000] {processor.py:157} INFO - Started process (PID=6462) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:16:28.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:16:28.774+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:16:28.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:16:28.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:16:28.830+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:16:28.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:16:28.848+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:16:28.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:16:28.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T06:16:59.247+0000] {processor.py:157} INFO - Started process (PID=6472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:16:59.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:16:59.252+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:16:59.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:16:59.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:16:59.288+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:16:59.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:16:59.306+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:16:59.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:16:59.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T06:17:29.676+0000] {processor.py:157} INFO - Started process (PID=6482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:17:29.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:17:29.681+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:17:29.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:17:29.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:17:29.732+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:17:29.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:17:29.749+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:17:29.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:17:29.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T06:18:00.003+0000] {processor.py:157} INFO - Started process (PID=6492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:18:00.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:18:00.010+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:18:00.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:18:00.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:18:00.047+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:18:00.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:18:00.061+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:18:00.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:18:00.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T06:18:30.430+0000] {processor.py:157} INFO - Started process (PID=6501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:18:30.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:18:30.435+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:18:30.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:18:30.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:18:30.486+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:18:30.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:18:30.512+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:18:30.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:18:30.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T06:19:00.880+0000] {processor.py:157} INFO - Started process (PID=6512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:19:00.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:19:00.883+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:19:00.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:19:00.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:19:00.921+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:19:00.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:19:00.947+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:19:00.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:19:00.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T06:19:31.334+0000] {processor.py:157} INFO - Started process (PID=6521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:19:31.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:19:31.342+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:19:31.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:19:31.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:19:31.401+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:19:31.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:19:31.421+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:19:31.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:19:31.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T06:20:01.722+0000] {processor.py:157} INFO - Started process (PID=6532) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:20:01.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:20:01.726+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:20:01.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:20:01.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:20:01.775+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:20:01.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:20:01.793+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:20:01.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:20:01.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T06:20:32.061+0000] {processor.py:157} INFO - Started process (PID=6540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:20:32.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:20:32.066+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:20:32.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:20:32.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:20:32.128+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:20:32.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:20:32.157+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:20:32.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:20:32.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T06:21:02.399+0000] {processor.py:157} INFO - Started process (PID=6552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:21:02.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:21:02.402+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:21:02.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:21:02.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:21:02.441+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:21:02.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:21:02.456+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:21:02.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:21:02.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T06:21:32.788+0000] {processor.py:157} INFO - Started process (PID=6561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:21:32.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:21:32.795+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:21:32.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:21:32.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:21:32.864+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:21:32.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:21:32.883+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:21:32.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:21:32.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T06:22:03.067+0000] {processor.py:157} INFO - Started process (PID=6572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:22:03.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:22:03.070+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:22:03.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:22:03.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:22:03.102+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:22:03.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:22:03.120+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:22:03.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:22:03.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T06:22:33.410+0000] {processor.py:157} INFO - Started process (PID=6580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:22:33.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:22:33.414+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:22:33.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:22:33.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:22:33.470+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:22:33.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:22:33.486+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:22:33.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:22:33.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T06:23:03.890+0000] {processor.py:157} INFO - Started process (PID=6592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:23:03.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:23:03.894+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:23:03.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:23:03.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:23:03.938+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:23:03.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:23:03.955+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:23:03.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:23:03.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T06:23:34.249+0000] {processor.py:157} INFO - Started process (PID=6602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:23:34.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:23:34.252+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:23:34.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:23:34.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:23:34.305+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:23:34.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:23:34.320+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:23:34.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:23:34.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T06:24:04.739+0000] {processor.py:157} INFO - Started process (PID=6612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:24:04.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:24:04.746+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:24:04.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:24:04.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:24:04.787+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:24:04.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:24:04.801+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:24:04.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:24:04.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T06:24:35.073+0000] {processor.py:157} INFO - Started process (PID=6622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:24:35.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:24:35.078+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:24:35.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:24:35.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:24:35.125+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:24:35.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:24:35.151+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:24:35.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:24:35.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T06:25:05.494+0000] {processor.py:157} INFO - Started process (PID=6632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:25:05.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:25:05.501+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:25:05.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:25:05.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:25:05.556+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:25:05.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:25:05.572+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:25:05.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:25:05.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T06:25:35.902+0000] {processor.py:157} INFO - Started process (PID=6642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:25:35.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:25:35.908+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:25:35.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:25:35.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:25:35.944+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:25:35.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:25:35.975+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:25:35.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:25:35.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T06:26:06.300+0000] {processor.py:157} INFO - Started process (PID=6651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:26:06.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:26:06.305+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:26:06.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:26:06.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:26:06.362+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:26:06.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:26:06.386+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:26:06.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:26:06.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T06:26:36.659+0000] {processor.py:157} INFO - Started process (PID=6662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:26:36.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:26:36.662+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:26:36.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:26:36.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:26:36.701+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:26:36.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:26:36.717+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:26:36.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:26:36.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T06:27:07.060+0000] {processor.py:157} INFO - Started process (PID=6672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:27:07.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:27:07.064+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:27:07.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:27:07.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:27:07.121+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:27:07.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:27:07.138+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:27:07.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:27:07.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T06:27:37.384+0000] {processor.py:157} INFO - Started process (PID=6682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:27:37.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:27:37.389+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:27:37.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:27:37.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:27:37.438+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:27:37.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:27:37.464+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:27:37.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:27:37.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T06:28:07.805+0000] {processor.py:157} INFO - Started process (PID=6692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:28:07.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:28:07.809+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:28:07.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:28:07.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:28:07.853+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:28:07.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:28:07.872+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:28:07.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:28:07.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T06:28:38.206+0000] {processor.py:157} INFO - Started process (PID=6702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:28:38.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:28:38.211+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:28:38.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:28:38.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:28:38.270+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:28:38.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:28:38.287+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:28:38.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:28:38.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T06:29:08.682+0000] {processor.py:157} INFO - Started process (PID=6712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:29:08.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:29:08.688+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:29:08.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:29:08.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:29:08.750+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:29:08.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:29:08.767+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:29:08.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:29:08.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T06:29:39.081+0000] {processor.py:157} INFO - Started process (PID=6722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:29:39.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:29:39.087+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:29:39.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:29:39.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:29:39.141+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:29:39.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:29:39.161+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:29:39.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:29:39.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T06:30:09.532+0000] {processor.py:157} INFO - Started process (PID=6732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:30:09.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:30:09.536+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:30:09.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:30:09.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:30:09.569+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:30:09.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:30:09.584+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:30:09.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:30:09.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T06:30:39.984+0000] {processor.py:157} INFO - Started process (PID=6741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:30:39.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:30:39.996+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:30:39.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:30:40.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:30:40.054+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:30:40.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:30:40.077+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:30:40.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:30:40.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T06:31:10.305+0000] {processor.py:157} INFO - Started process (PID=6752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:31:10.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:31:10.307+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:31:10.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:31:10.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:31:10.347+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:31:10.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:31:10.363+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:31:10.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:31:10.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T06:31:40.726+0000] {processor.py:157} INFO - Started process (PID=6762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:31:40.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:31:40.732+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:31:40.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:31:40.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:31:40.789+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:31:40.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:31:40.815+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:31:40.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:31:40.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T06:32:11.076+0000] {processor.py:157} INFO - Started process (PID=6772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:32:11.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:32:11.080+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:32:11.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:32:11.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:32:11.119+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:32:11.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:32:11.136+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:32:11.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:32:11.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T06:32:41.452+0000] {processor.py:157} INFO - Started process (PID=6782) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:32:41.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:32:41.456+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:32:41.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:32:41.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:32:41.504+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:32:41.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:32:41.523+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:32:41.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:32:41.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T06:33:11.879+0000] {processor.py:157} INFO - Started process (PID=6790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:33:11.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:33:11.887+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:33:11.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:33:11.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:33:11.999+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:33:11.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:33:12.025+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:33:12.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:33:12.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-09-15T06:33:42.243+0000] {processor.py:157} INFO - Started process (PID=6802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:33:42.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:33:42.248+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:33:42.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:33:42.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:33:42.302+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:33:42.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:33:42.328+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:33:42.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:33:42.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T06:34:12.649+0000] {processor.py:157} INFO - Started process (PID=6811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:34:12.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:34:12.652+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:34:12.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:34:12.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:34:12.687+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:34:12.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:34:12.702+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:34:12.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:34:12.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T06:34:43.155+0000] {processor.py:157} INFO - Started process (PID=6821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:34:43.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:34:43.163+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:34:43.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:34:43.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:34:43.225+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:34:43.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:34:43.242+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:34:43.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:34:43.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T06:35:13.503+0000] {processor.py:157} INFO - Started process (PID=6832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:35:13.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:35:13.509+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:35:13.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:35:13.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:35:13.554+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:35:13.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:35:13.570+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:35:13.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:35:13.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T06:35:44.013+0000] {processor.py:157} INFO - Started process (PID=6842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:35:44.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:35:44.017+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:35:44.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:35:44.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:35:44.058+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:35:44.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:35:44.074+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:35:44.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:35:44.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T06:36:14.434+0000] {processor.py:157} INFO - Started process (PID=6852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:36:14.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:36:14.440+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:36:14.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:36:14.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:36:14.485+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:36:14.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:36:14.508+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:36:14.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:36:14.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T06:36:44.825+0000] {processor.py:157} INFO - Started process (PID=6862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:36:44.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:36:44.830+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:36:44.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:36:44.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:36:44.868+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:36:44.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:36:44.893+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:36:44.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:36:44.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T06:37:15.201+0000] {processor.py:157} INFO - Started process (PID=6871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:37:15.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:37:15.213+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:37:15.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:37:15.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:37:15.266+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:37:15.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:37:15.282+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:37:15.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:37:15.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T06:37:45.723+0000] {processor.py:157} INFO - Started process (PID=6882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:37:45.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:37:45.726+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:37:45.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:37:45.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:37:45.765+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:37:45.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:37:45.795+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:37:45.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:37:45.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T06:38:16.268+0000] {processor.py:157} INFO - Started process (PID=6892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:38:16.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:38:16.272+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:38:16.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:38:16.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:38:16.316+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:38:16.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:38:16.333+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:38:16.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:38:16.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T06:38:46.661+0000] {processor.py:157} INFO - Started process (PID=6902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:38:46.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:38:46.666+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:38:46.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:38:46.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:38:46.713+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:38:46.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:38:46.728+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:38:46.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:38:46.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T06:39:17.093+0000] {processor.py:157} INFO - Started process (PID=6912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:39:17.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:39:17.098+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:39:17.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:39:17.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:39:17.156+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:39:17.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:39:17.174+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:39:17.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:39:17.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T06:39:47.512+0000] {processor.py:157} INFO - Started process (PID=6921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:39:47.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:39:47.522+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:39:47.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:39:47.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:39:47.578+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:39:47.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:39:47.594+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:39:47.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:39:47.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T06:40:17.838+0000] {processor.py:157} INFO - Started process (PID=6932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:40:17.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:40:17.841+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:40:17.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:40:17.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:40:17.874+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:40:17.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:40:17.899+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:40:17.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:40:17.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T06:40:48.316+0000] {processor.py:157} INFO - Started process (PID=6942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:40:48.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:40:48.320+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:40:48.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:40:48.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:40:48.388+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:40:48.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:40:48.405+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:40:48.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:40:48.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T06:41:18.738+0000] {processor.py:157} INFO - Started process (PID=6952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:41:18.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:41:18.742+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:41:18.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:41:18.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:41:18.786+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:41:18.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:41:18.802+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:41:18.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:41:18.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T06:41:49.197+0000] {processor.py:157} INFO - Started process (PID=6962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:41:49.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:41:49.200+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:41:49.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:41:49.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:41:49.235+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:41:49.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:41:49.252+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:41:49.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:41:49.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T06:42:19.652+0000] {processor.py:157} INFO - Started process (PID=6971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:42:19.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:42:19.657+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:42:19.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:42:19.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:42:19.725+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:42:19.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:42:19.751+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:42:19.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:42:19.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T06:42:50.028+0000] {processor.py:157} INFO - Started process (PID=6982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:42:50.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:42:50.035+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:42:50.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:42:50.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:42:50.109+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:42:50.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:42:50.127+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:42:50.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:42:50.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T06:43:20.470+0000] {processor.py:157} INFO - Started process (PID=6992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:43:20.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:43:20.476+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:43:20.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:43:20.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:43:20.518+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:43:20.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:43:20.539+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:43:20.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:43:20.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T06:43:50.942+0000] {processor.py:157} INFO - Started process (PID=7002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:43:50.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:43:50.945+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:43:50.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:43:50.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:43:50.977+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:43:50.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:43:50.998+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:43:50.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:43:51.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T06:44:21.364+0000] {processor.py:157} INFO - Started process (PID=7012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:44:21.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:44:21.376+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:44:21.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:44:21.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:44:21.438+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:44:21.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:44:21.464+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:44:21.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:44:21.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T06:44:51.865+0000] {processor.py:157} INFO - Started process (PID=7022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:44:51.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:44:51.869+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:44:51.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:44:51.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:44:51.911+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:44:51.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:44:51.926+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:44:51.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:44:51.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T06:45:22.276+0000] {processor.py:157} INFO - Started process (PID=7031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:45:22.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:45:22.280+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:45:22.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:45:22.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:45:22.335+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:45:22.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:45:22.356+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:45:22.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:45:22.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T06:45:52.651+0000] {processor.py:157} INFO - Started process (PID=7042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:45:52.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:45:52.656+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:45:52.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:45:52.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:45:52.698+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:45:52.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:45:52.726+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:45:52.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:45:52.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T06:46:23.070+0000] {processor.py:157} INFO - Started process (PID=7052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:46:23.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:46:23.074+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:46:23.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:46:23.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:46:23.106+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:46:23.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:46:23.125+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:46:23.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:46:23.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T06:46:53.467+0000] {processor.py:157} INFO - Started process (PID=7062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:46:53.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:46:53.472+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:46:53.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:46:53.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:46:53.532+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:46:53.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:46:53.557+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:46:53.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:46:53.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T06:47:23.812+0000] {processor.py:157} INFO - Started process (PID=7072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:47:23.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:47:23.816+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:47:23.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:47:23.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:47:23.852+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:47:23.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:47:23.872+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:47:23.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:47:23.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-15T06:47:54.274+0000] {processor.py:157} INFO - Started process (PID=7082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:47:54.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:47:54.278+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:47:54.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:47:54.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:47:54.335+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:47:54.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:47:54.365+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:47:54.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:47:54.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T06:48:24.764+0000] {processor.py:157} INFO - Started process (PID=7091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:48:24.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:48:24.779+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:48:24.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:48:24.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:48:24.839+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:48:24.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:48:24.865+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:48:24.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:48:24.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T06:48:55.264+0000] {processor.py:157} INFO - Started process (PID=7102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:48:55.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:48:55.266+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:48:55.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:48:55.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:48:55.294+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:48:55.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:48:55.310+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:48:55.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:48:55.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T06:49:25.724+0000] {processor.py:157} INFO - Started process (PID=7111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:49:25.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:49:25.729+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:49:25.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:49:25.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:49:25.788+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:49:25.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:49:25.805+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:49:25.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:49:25.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T06:49:56.170+0000] {processor.py:157} INFO - Started process (PID=7122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:49:56.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:49:56.176+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:49:56.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:49:56.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:49:56.221+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:49:56.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:49:56.240+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:49:56.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:49:56.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T06:50:26.647+0000] {processor.py:157} INFO - Started process (PID=7131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:50:26.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:50:26.653+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:50:26.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:50:26.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:50:26.720+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:50:26.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:50:26.737+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:50:26.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:50:26.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T06:50:57.168+0000] {processor.py:157} INFO - Started process (PID=7142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:50:57.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:50:57.175+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:50:57.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:50:57.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:50:57.205+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:50:57.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:50:57.219+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:50:57.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:50:57.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T06:51:27.610+0000] {processor.py:157} INFO - Started process (PID=7152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:51:27.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:51:27.614+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:51:27.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:51:27.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:51:27.672+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:51:27.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:51:27.693+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:51:27.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:51:27.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T06:51:57.944+0000] {processor.py:157} INFO - Started process (PID=7162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:51:57.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:51:57.947+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:51:57.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:51:57.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:51:57.986+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:51:57.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:51:57.999+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:51:57.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:51:58.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T06:52:28.359+0000] {processor.py:157} INFO - Started process (PID=7171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:52:28.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:52:28.366+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:52:28.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:52:28.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:52:28.435+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:52:28.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:52:28.467+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:52:28.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:52:28.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T06:52:58.655+0000] {processor.py:157} INFO - Started process (PID=7182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:52:58.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:52:58.658+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:52:58.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:52:58.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:52:58.692+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:52:58.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:52:58.709+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:52:58.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:52:58.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T06:53:29.146+0000] {processor.py:157} INFO - Started process (PID=7191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:53:29.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:53:29.156+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:53:29.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:53:29.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:53:29.203+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:53:29.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:53:29.219+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:53:29.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:53:29.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T06:53:59.494+0000] {processor.py:157} INFO - Started process (PID=7202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:53:59.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:53:59.499+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:53:59.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:53:59.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:53:59.539+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:53:59.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:53:59.554+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:53:59.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:53:59.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T06:54:29.847+0000] {processor.py:157} INFO - Started process (PID=7212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:54:29.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:54:29.851+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:54:29.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:54:29.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:54:29.878+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:54:29.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:54:29.893+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:54:29.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:54:29.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T06:55:00.297+0000] {processor.py:157} INFO - Started process (PID=7221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:55:00.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:55:00.302+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:55:00.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:55:00.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:55:00.359+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:55:00.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:55:00.385+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:55:00.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:55:00.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T06:55:30.687+0000] {processor.py:157} INFO - Started process (PID=7232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:55:30.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:55:30.697+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:55:30.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:55:30.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:55:30.738+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:55:30.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:55:30.756+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:55:30.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:55:30.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T06:56:01.133+0000] {processor.py:157} INFO - Started process (PID=7242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:56:01.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:56:01.138+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:56:01.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:56:01.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:56:01.167+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:56:01.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:56:01.180+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:56:01.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:56:01.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T06:56:31.572+0000] {processor.py:157} INFO - Started process (PID=7251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:56:31.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:56:31.579+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:56:31.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:56:31.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:56:31.632+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:56:31.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:56:31.646+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:56:31.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:56:31.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T06:57:01.855+0000] {processor.py:157} INFO - Started process (PID=7262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:57:01.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:57:01.859+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:57:01.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:57:01.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:57:01.890+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:57:01.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:57:01.902+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:57:01.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:57:01.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T06:57:32.266+0000] {processor.py:157} INFO - Started process (PID=7271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:57:32.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:57:32.277+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:57:32.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:57:32.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:57:32.334+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:57:32.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:57:32.365+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:57:32.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:57:32.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T06:58:02.811+0000] {processor.py:157} INFO - Started process (PID=7282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:58:02.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T06:58:02.824+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:58:02.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:58:02.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T06:58:02.899+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:58:02.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T06:58:02.918+0000] {logging_mixin.py:151} INFO - [2024-09-15T06:58:02.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T06:58:02.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-15T07:14:26.306+0000] {processor.py:157} INFO - Started process (PID=7293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:14:26.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:14:26.324+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:14:26.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:14:26.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:14:26.392+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:14:26.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:14:26.406+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:14:26.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:14:26.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-15T07:30:12.712+0000] {processor.py:157} INFO - Started process (PID=7306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:30:12.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:30:12.721+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:30:12.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:30:12.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:30:12.805+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:30:12.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:30:12.824+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:30:12.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:30:12.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-15T07:30:43.049+0000] {processor.py:157} INFO - Started process (PID=7315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:30:43.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:30:43.056+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:30:43.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:30:43.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:30:43.133+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:30:43.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:30:43.150+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:30:43.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:30:43.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T07:31:13.413+0000] {processor.py:157} INFO - Started process (PID=7326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:31:13.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:31:13.427+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:31:13.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:31:13.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:31:13.487+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:31:13.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:31:13.510+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:31:13.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:31:13.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T07:31:43.759+0000] {processor.py:157} INFO - Started process (PID=7336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:31:43.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:31:43.762+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:31:43.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:31:43.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:31:43.792+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:31:43.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:31:43.802+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:31:43.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:31:43.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-15T07:32:14.192+0000] {processor.py:157} INFO - Started process (PID=7346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:32:14.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:32:14.198+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:32:14.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:32:14.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:32:14.236+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:32:14.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:32:14.255+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:32:14.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:32:14.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T07:32:44.650+0000] {processor.py:157} INFO - Started process (PID=7356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:32:44.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:32:44.660+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:32:44.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:32:44.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:32:44.738+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:32:44.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:32:44.762+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:32:44.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:32:44.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-15T07:33:15.027+0000] {processor.py:157} INFO - Started process (PID=7365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:33:15.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:33:15.033+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:33:15.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:33:15.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:33:15.102+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:33:15.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:33:15.138+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:33:15.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:33:15.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-15T07:33:45.393+0000] {processor.py:157} INFO - Started process (PID=7376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:33:45.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:33:45.396+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:33:45.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:33:45.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:33:45.426+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:33:45.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:33:45.436+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:33:45.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:33:45.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T07:34:15.858+0000] {processor.py:157} INFO - Started process (PID=7386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:34:15.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:34:15.867+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:34:15.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:34:15.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:34:15.919+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:34:15.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:34:15.948+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:34:15.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:34:15.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T07:34:46.152+0000] {processor.py:157} INFO - Started process (PID=7396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:34:46.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:34:46.154+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:34:46.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:34:46.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:34:46.184+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:34:46.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:34:46.194+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:34:46.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:34:46.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T07:35:16.575+0000] {processor.py:157} INFO - Started process (PID=7405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:35:16.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:35:16.607+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:35:16.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:35:16.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:35:16.654+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:35:16.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:35:16.682+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:35:16.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:35:16.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T07:35:46.881+0000] {processor.py:157} INFO - Started process (PID=7416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:35:46.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:35:46.886+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:35:46.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:35:46.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:35:46.941+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:35:46.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:35:46.958+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:35:46.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:35:46.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T07:36:17.347+0000] {processor.py:157} INFO - Started process (PID=7425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:36:17.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:36:17.352+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:36:17.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:36:17.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:36:17.401+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:36:17.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:36:17.423+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:36:17.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:36:17.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T07:36:47.700+0000] {processor.py:157} INFO - Started process (PID=7436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:36:47.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:36:47.715+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:36:47.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:36:47.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:36:47.769+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:36:47.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:36:47.798+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:36:47.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:36:47.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T07:37:18.009+0000] {processor.py:157} INFO - Started process (PID=7446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:37:18.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:37:18.013+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:37:18.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:37:18.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:37:18.042+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:37:18.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:37:18.055+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:37:18.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:37:18.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T07:37:48.474+0000] {processor.py:157} INFO - Started process (PID=7455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:37:48.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:37:48.486+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:37:48.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:37:48.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:37:48.538+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:37:48.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:37:48.566+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:37:48.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:37:48.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T07:38:18.833+0000] {processor.py:157} INFO - Started process (PID=7466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:38:18.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:38:18.837+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:38:18.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:38:18.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:38:18.866+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:38:18.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:38:18.878+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:38:18.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:38:18.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T07:38:49.256+0000] {processor.py:157} INFO - Started process (PID=7475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:38:49.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:38:49.262+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:38:49.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:38:49.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:38:49.324+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:38:49.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:38:49.341+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:38:49.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:38:49.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T07:39:19.579+0000] {processor.py:157} INFO - Started process (PID=7486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:39:19.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:39:19.583+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:39:19.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:39:19.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:39:19.636+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:39:19.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:39:19.650+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:39:19.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:39:19.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T07:39:50.079+0000] {processor.py:157} INFO - Started process (PID=7496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:39:50.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:39:50.083+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:39:50.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:39:50.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:39:50.117+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:39:50.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:39:50.130+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:39:50.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:39:50.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T07:40:20.501+0000] {processor.py:157} INFO - Started process (PID=7505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:40:20.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:40:20.514+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:40:20.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:40:20.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:40:20.558+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:40:20.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:40:20.571+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:40:20.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:40:20.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T07:40:50.858+0000] {processor.py:157} INFO - Started process (PID=7516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:40:50.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:40:50.860+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:40:50.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:40:50.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:40:50.899+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:40:50.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:40:50.922+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:40:50.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:40:50.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T07:41:21.218+0000] {processor.py:157} INFO - Started process (PID=7526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:41:21.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:41:21.226+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:41:21.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:41:21.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:41:21.280+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:41:21.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:41:21.295+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:41:21.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:41:21.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T07:41:51.608+0000] {processor.py:157} INFO - Started process (PID=7536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:41:51.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:41:51.616+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:41:51.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:41:51.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:41:51.660+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:41:51.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:41:51.675+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:41:51.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:41:51.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T07:42:22.034+0000] {processor.py:157} INFO - Started process (PID=7546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:42:22.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:42:22.039+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:42:22.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:42:22.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:42:22.111+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:42:22.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:42:22.127+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:42:22.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:42:22.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T07:42:52.507+0000] {processor.py:157} INFO - Started process (PID=7556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:42:52.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:42:52.513+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:42:52.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:42:52.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:42:52.574+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:42:52.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:42:52.590+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:42:52.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:42:52.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T07:43:22.898+0000] {processor.py:157} INFO - Started process (PID=7566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:43:22.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:43:22.905+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:43:22.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:43:22.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:43:22.941+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:43:22.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:43:22.952+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:43:22.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:43:22.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T07:43:53.315+0000] {processor.py:157} INFO - Started process (PID=7576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:43:53.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:43:53.324+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:43:53.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:43:53.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:43:53.369+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:43:53.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:43:53.400+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:43:53.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:43:53.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T07:44:23.832+0000] {processor.py:157} INFO - Started process (PID=7585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:44:23.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:44:23.838+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:44:23.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:44:23.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:44:23.900+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:44:23.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:44:23.919+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:44:23.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:44:23.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T07:44:54.210+0000] {processor.py:157} INFO - Started process (PID=7596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:44:54.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:44:54.214+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:44:54.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:44:54.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:44:54.253+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:44:54.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:44:54.267+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:44:54.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:44:54.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-15T07:45:24.629+0000] {processor.py:157} INFO - Started process (PID=7606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:45:24.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:45:24.641+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:45:24.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:45:24.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:45:24.757+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:45:24.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:45:24.782+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:45:24.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:45:24.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-15T07:45:55.013+0000] {processor.py:157} INFO - Started process (PID=7616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:45:55.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:45:55.023+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:45:55.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:45:55.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:45:55.091+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:45:55.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:45:55.108+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:45:55.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:45:55.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T07:46:25.331+0000] {processor.py:157} INFO - Started process (PID=7626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:46:25.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:46:25.337+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:46:25.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:46:25.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:46:25.377+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:46:25.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:46:25.391+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:46:25.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:46:25.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T07:46:55.703+0000] {processor.py:157} INFO - Started process (PID=7634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:46:55.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:46:55.708+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:46:55.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:46:55.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:46:55.741+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:46:55.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:46:55.752+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:46:55.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:46:55.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T07:47:26.147+0000] {processor.py:157} INFO - Started process (PID=7646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:47:26.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:47:26.154+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:47:26.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:47:26.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:47:26.190+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:47:26.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:47:26.207+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:47:26.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:47:26.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T07:47:56.589+0000] {processor.py:157} INFO - Started process (PID=7655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:47:56.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:47:56.611+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:47:56.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:47:56.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:47:56.654+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:47:56.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:47:56.665+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:47:56.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:47:56.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T07:48:27.029+0000] {processor.py:157} INFO - Started process (PID=7666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:48:27.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:48:27.032+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:48:27.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:48:27.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:48:27.063+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:48:27.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:48:27.075+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:48:27.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:48:27.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T07:48:57.460+0000] {processor.py:157} INFO - Started process (PID=7676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:48:57.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:48:57.465+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:48:57.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:48:57.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:48:57.499+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:48:57.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:48:57.512+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:48:57.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:48:57.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T07:49:27.810+0000] {processor.py:157} INFO - Started process (PID=7686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:49:27.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:49:27.815+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:49:27.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:49:27.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:49:27.848+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:49:27.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:49:27.858+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:49:27.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:49:27.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T07:49:58.161+0000] {processor.py:157} INFO - Started process (PID=7696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:49:58.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:49:58.166+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:49:58.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:49:58.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:49:58.201+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:49:58.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:49:58.216+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:49:58.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:49:58.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-15T07:50:28.611+0000] {processor.py:157} INFO - Started process (PID=7706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:50:28.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:50:28.615+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:50:28.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:50:28.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:50:28.652+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:50:28.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:50:28.682+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:50:28.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:50:28.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T07:50:59.050+0000] {processor.py:157} INFO - Started process (PID=7716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:50:59.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:50:59.059+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:50:59.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:50:59.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:50:59.100+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:50:59.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:50:59.116+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:50:59.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:50:59.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T07:51:29.450+0000] {processor.py:157} INFO - Started process (PID=7726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:51:29.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:51:29.456+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:51:29.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:51:29.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:51:29.499+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:51:29.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:51:29.510+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:51:29.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:51:29.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T07:51:59.822+0000] {processor.py:157} INFO - Started process (PID=7736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:51:59.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:51:59.833+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:51:59.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:51:59.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:51:59.878+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:51:59.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:51:59.900+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:51:59.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:51:59.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T07:52:30.151+0000] {processor.py:157} INFO - Started process (PID=7746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:52:30.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:52:30.155+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:52:30.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:52:30.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:52:30.190+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:52:30.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:52:30.202+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:52:30.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:52:30.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T07:53:00.589+0000] {processor.py:157} INFO - Started process (PID=7755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:53:00.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:53:00.605+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:53:00.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:53:00.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:53:00.653+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:53:00.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:53:00.669+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:53:00.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:53:00.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T07:53:31.027+0000] {processor.py:157} INFO - Started process (PID=7766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:53:31.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:53:31.032+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:53:31.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:53:31.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:53:31.091+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:53:31.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:53:31.103+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:53:31.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:53:31.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T07:54:01.470+0000] {processor.py:157} INFO - Started process (PID=7776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:54:01.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:54:01.477+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:54:01.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:54:01.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:54:01.537+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:54:01.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:54:01.551+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:54:01.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:54:01.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-15T07:54:31.834+0000] {processor.py:157} INFO - Started process (PID=7786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:54:31.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:54:31.841+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:54:31.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:54:31.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:54:31.884+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:54:31.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:54:31.896+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:54:31.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:54:31.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T07:55:02.307+0000] {processor.py:157} INFO - Started process (PID=7796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:55:02.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:55:02.316+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:55:02.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:55:02.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:55:02.364+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:55:02.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:55:02.390+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:55:02.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:55:02.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T07:55:32.664+0000] {processor.py:157} INFO - Started process (PID=7806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:55:32.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:55:32.667+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:55:32.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:55:32.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:55:32.701+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:55:32.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:55:32.712+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:55:32.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:55:32.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T07:56:03.106+0000] {processor.py:157} INFO - Started process (PID=7816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:56:03.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:56:03.118+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:56:03.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:56:03.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:56:03.162+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:56:03.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:56:03.193+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:56:03.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:56:03.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T07:56:33.459+0000] {processor.py:157} INFO - Started process (PID=7826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:56:33.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:56:33.464+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:56:33.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:56:33.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:56:33.523+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:56:33.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:56:33.535+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:56:33.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:56:33.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T07:57:03.975+0000] {processor.py:157} INFO - Started process (PID=7836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:57:03.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:57:03.985+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:57:03.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:57:04.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:57:04.041+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:57:04.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:57:04.058+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:57:04.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:57:04.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T07:57:34.379+0000] {processor.py:157} INFO - Started process (PID=7846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:57:34.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:57:34.386+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:57:34.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:57:34.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:57:34.425+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:57:34.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:57:34.440+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:57:34.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:57:34.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T07:58:04.807+0000] {processor.py:157} INFO - Started process (PID=7856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:58:04.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:58:04.810+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:58:04.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:58:04.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:58:04.839+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:58:04.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:58:04.849+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:58:04.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:58:04.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-15T07:58:35.329+0000] {processor.py:157} INFO - Started process (PID=7865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:58:35.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:58:35.336+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:58:35.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:58:35.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:58:35.402+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:58:35.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:58:35.421+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:58:35.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:58:35.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T07:59:05.655+0000] {processor.py:157} INFO - Started process (PID=7876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:59:05.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:59:05.659+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:59:05.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:59:05.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:59:05.690+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:59:05.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:59:05.702+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:59:05.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:59:05.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T07:59:36.128+0000] {processor.py:157} INFO - Started process (PID=7885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:59:36.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T07:59:36.136+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:59:36.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:59:36.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T07:59:36.197+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:59:36.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T07:59:36.213+0000] {logging_mixin.py:151} INFO - [2024-09-15T07:59:36.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T07:59:36.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T08:00:06.386+0000] {processor.py:157} INFO - Started process (PID=7896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:00:06.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:00:06.389+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:00:06.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:00:06.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:00:06.419+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:00:06.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:00:06.430+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:00:06.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:00:06.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-15T08:00:36.800+0000] {processor.py:157} INFO - Started process (PID=7905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:00:36.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:00:36.805+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:00:36.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:00:36.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:00:36.869+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:00:36.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:00:36.883+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:00:36.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:00:36.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T08:01:07.243+0000] {processor.py:157} INFO - Started process (PID=7916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:01:07.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:01:07.247+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:01:07.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:01:07.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:01:07.278+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:01:07.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:01:07.293+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:01:07.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:01:07.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T08:01:37.552+0000] {processor.py:157} INFO - Started process (PID=7925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:01:37.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:01:37.566+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:01:37.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:01:37.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:01:37.611+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:01:37.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:01:37.639+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:01:37.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:01:37.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T08:02:08.033+0000] {processor.py:157} INFO - Started process (PID=7936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:02:08.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:02:08.037+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:02:08.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:02:08.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:02:08.072+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:02:08.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:02:08.085+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:02:08.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:02:08.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T08:02:38.387+0000] {processor.py:157} INFO - Started process (PID=7946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:02:38.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:02:38.392+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:02:38.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:02:38.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:02:38.449+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:02:38.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:02:38.464+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:02:38.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:02:38.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T08:03:08.858+0000] {processor.py:157} INFO - Started process (PID=7955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:03:08.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:03:08.863+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:03:08.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:03:08.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:03:08.903+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:03:08.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:03:08.917+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:03:08.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:03:08.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T08:03:39.221+0000] {processor.py:157} INFO - Started process (PID=7966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:03:39.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:03:39.224+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:03:39.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:03:39.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:03:39.262+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:03:39.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:03:39.284+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:03:39.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:03:39.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T08:04:09.552+0000] {processor.py:157} INFO - Started process (PID=7975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:04:09.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:04:09.557+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:04:09.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:04:09.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:04:09.590+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:04:09.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:04:09.604+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:04:09.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:04:09.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T08:04:39.965+0000] {processor.py:157} INFO - Started process (PID=7986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:04:39.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:04:39.973+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:04:39.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:04:40.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:04:40.032+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:04:40.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:04:40.045+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:04:40.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:04:40.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T08:05:10.323+0000] {processor.py:157} INFO - Started process (PID=7995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:05:10.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:05:10.328+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:05:10.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:05:10.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:05:10.377+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:05:10.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:05:10.401+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:05:10.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:05:10.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T08:05:40.637+0000] {processor.py:157} INFO - Started process (PID=8006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:05:40.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:05:40.642+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:05:40.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:05:40.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:05:40.701+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:05:40.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:05:40.714+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:05:40.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:05:40.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T08:06:11.077+0000] {processor.py:157} INFO - Started process (PID=8016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:06:11.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:06:11.083+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:06:11.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:06:11.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:06:11.147+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:06:11.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:06:11.172+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:06:11.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:06:11.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T08:06:41.411+0000] {processor.py:157} INFO - Started process (PID=8026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:06:41.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:06:41.416+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:06:41.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:06:41.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:06:41.444+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:06:41.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:06:41.457+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:06:41.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:06:41.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T08:07:11.837+0000] {processor.py:157} INFO - Started process (PID=8034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:07:11.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:07:11.857+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:07:11.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:07:11.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:07:11.914+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:07:11.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:07:11.945+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:07:11.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:07:11.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T08:07:42.234+0000] {processor.py:157} INFO - Started process (PID=8046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:07:42.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:07:42.237+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:07:42.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:07:42.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:07:42.270+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:07:42.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:07:42.281+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:07:42.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:07:42.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T08:08:12.622+0000] {processor.py:157} INFO - Started process (PID=8055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:08:12.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:08:12.629+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:08:12.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:08:12.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:08:12.689+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:08:12.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:08:12.705+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:08:12.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:08:12.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T08:08:43.083+0000] {processor.py:157} INFO - Started process (PID=8066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:08:43.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:08:43.088+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:08:43.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:08:43.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:08:43.119+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:08:43.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:08:43.132+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:08:43.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:08:43.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T08:09:13.452+0000] {processor.py:157} INFO - Started process (PID=8076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:09:13.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:09:13.463+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:09:13.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:09:13.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:09:13.516+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:09:13.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:09:13.530+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:09:13.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:09:13.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T08:09:43.731+0000] {processor.py:157} INFO - Started process (PID=8086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:09:43.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:09:43.734+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:09:43.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:09:43.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:09:43.778+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:09:43.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:09:43.794+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:09:43.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:09:43.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T08:10:14.150+0000] {processor.py:157} INFO - Started process (PID=8095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:10:14.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:10:14.155+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:10:14.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:10:14.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:10:14.212+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:10:14.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:10:14.227+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:10:14.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:10:14.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T08:10:44.516+0000] {processor.py:157} INFO - Started process (PID=8106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:10:44.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:10:44.521+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:10:44.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:10:44.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:10:44.574+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:10:44.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:10:44.587+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:10:44.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:10:44.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T08:11:14.972+0000] {processor.py:157} INFO - Started process (PID=8116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:11:14.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:11:14.976+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:11:14.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:11:14.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:11:15.019+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:11:15.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:11:15.034+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:11:15.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:11:15.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T08:11:45.338+0000] {processor.py:157} INFO - Started process (PID=8126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:11:45.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:11:45.342+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:11:45.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:11:45.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:11:45.383+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:11:45.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:11:45.402+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:11:45.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:11:45.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T08:12:15.817+0000] {processor.py:157} INFO - Started process (PID=8136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:12:15.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:12:15.824+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:12:15.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:12:15.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:12:15.900+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:12:15.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:12:15.920+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:12:15.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:12:15.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-15T08:12:46.174+0000] {processor.py:157} INFO - Started process (PID=8146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:12:46.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:12:46.176+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:12:46.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:12:46.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:12:46.208+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:12:46.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:12:46.220+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:12:46.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:12:46.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T08:13:16.618+0000] {processor.py:157} INFO - Started process (PID=8155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:13:16.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:13:16.624+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:13:16.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:13:16.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:13:16.688+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:13:16.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:13:16.702+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:13:16.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:13:16.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T08:13:47.070+0000] {processor.py:157} INFO - Started process (PID=8165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:13:47.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:13:47.076+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:13:47.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:13:47.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:13:47.150+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:13:47.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:13:47.166+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:13:47.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:13:47.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T08:14:17.520+0000] {processor.py:157} INFO - Started process (PID=8174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:14:17.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:14:17.525+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:14:17.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:14:17.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:14:17.594+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:14:17.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:14:17.612+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:14:17.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:14:17.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T08:14:47.891+0000] {processor.py:157} INFO - Started process (PID=8186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:14:47.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:14:47.896+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:14:47.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:14:47.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:14:47.935+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:14:47.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:14:47.948+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:14:47.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:14:47.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T08:15:18.381+0000] {processor.py:157} INFO - Started process (PID=8196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:15:18.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:15:18.385+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:15:18.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:15:18.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:15:18.437+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:15:18.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:15:18.452+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:15:18.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:15:18.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T08:15:48.762+0000] {processor.py:157} INFO - Started process (PID=8206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:15:48.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:15:48.779+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:15:48.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:15:48.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:15:48.841+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:15:48.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:15:48.858+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:15:48.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:15:48.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T08:16:19.069+0000] {processor.py:157} INFO - Started process (PID=8216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:16:19.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:16:19.072+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:16:19.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:16:19.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:16:19.101+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:16:19.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:16:19.112+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:16:19.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:16:19.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-15T08:16:49.497+0000] {processor.py:157} INFO - Started process (PID=8225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:16:49.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:16:49.505+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:16:49.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:16:49.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:16:49.550+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:16:49.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:16:49.565+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:16:49.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:16:49.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T08:17:19.832+0000] {processor.py:157} INFO - Started process (PID=8236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:17:19.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:17:19.836+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:17:19.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:17:19.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:17:19.865+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:17:19.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:17:19.877+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:17:19.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:17:19.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T08:17:50.275+0000] {processor.py:157} INFO - Started process (PID=8246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:17:50.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:17:50.282+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:17:50.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:17:50.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:17:50.316+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:17:50.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:17:50.329+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:17:50.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:17:50.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T08:18:20.626+0000] {processor.py:157} INFO - Started process (PID=8256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:18:20.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:18:20.631+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:18:20.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:18:20.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:18:20.666+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:18:20.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:18:20.679+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:18:20.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:18:20.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T08:18:51.029+0000] {processor.py:157} INFO - Started process (PID=8265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:18:51.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:18:51.036+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:18:51.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:18:51.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:18:51.098+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:18:51.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:18:51.113+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:18:51.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:18:51.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T08:19:21.487+0000] {processor.py:157} INFO - Started process (PID=8276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:19:21.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:19:21.494+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:19:21.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:19:21.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:19:21.534+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:19:21.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:19:21.547+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:19:21.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:19:21.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T08:19:51.828+0000] {processor.py:157} INFO - Started process (PID=8286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:19:51.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:19:51.832+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:19:51.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:19:51.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:19:51.866+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:19:51.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:19:51.880+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:19:51.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:19:51.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-15T08:20:22.368+0000] {processor.py:157} INFO - Started process (PID=8294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:20:22.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:20:22.373+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:20:22.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:20:22.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:20:22.422+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:20:22.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:20:22.435+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:20:22.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:20:22.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T08:20:52.726+0000] {processor.py:157} INFO - Started process (PID=8306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:20:52.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:20:52.728+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:20:52.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:20:52.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:20:52.770+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:20:52.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:20:52.783+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:20:52.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:20:52.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T08:21:23.166+0000] {processor.py:157} INFO - Started process (PID=8316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:21:23.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:21:23.171+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:21:23.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:21:23.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:21:23.222+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:21:23.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:21:23.238+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:21:23.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:21:23.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T08:21:53.524+0000] {processor.py:157} INFO - Started process (PID=8326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:21:53.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:21:53.526+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:21:53.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:21:53.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:21:53.563+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:21:53.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:21:53.588+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:21:53.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:21:53.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T08:22:23.894+0000] {processor.py:157} INFO - Started process (PID=8336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:22:23.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:22:23.903+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:22:23.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:22:23.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:22:23.947+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:22:23.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:22:23.965+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:22:23.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:22:23.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T08:22:54.308+0000] {processor.py:157} INFO - Started process (PID=8346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:22:54.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:22:54.312+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:22:54.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:22:54.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:22:54.346+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:22:54.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:22:54.359+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:22:54.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:22:54.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T08:23:24.711+0000] {processor.py:157} INFO - Started process (PID=8356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:23:24.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:23:24.714+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:23:24.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:23:24.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:23:24.742+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:23:24.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:23:24.756+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:23:24.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:23:24.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-15T08:23:55.148+0000] {processor.py:157} INFO - Started process (PID=8366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:23:55.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:23:55.155+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:23:55.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:23:55.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:23:55.229+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:23:55.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:23:55.244+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:23:55.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:23:55.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T08:24:25.620+0000] {processor.py:157} INFO - Started process (PID=8376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:24:25.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:24:25.628+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:24:25.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:24:25.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:24:25.693+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:24:25.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:24:25.707+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:24:25.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:24:25.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T08:24:55.941+0000] {processor.py:157} INFO - Started process (PID=8386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:24:55.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:24:55.944+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:24:55.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:24:55.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:24:55.976+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:24:55.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:24:55.989+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:24:55.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:24:56.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-15T08:25:26.433+0000] {processor.py:157} INFO - Started process (PID=8396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:25:26.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:25:26.439+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:25:26.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:25:26.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:25:26.508+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:25:26.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:25:26.524+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:25:26.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:25:26.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T08:25:56.892+0000] {processor.py:157} INFO - Started process (PID=8406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:25:56.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:25:56.895+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:25:56.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:25:56.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:25:56.935+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:25:56.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:25:56.947+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:25:56.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:25:56.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T08:26:27.361+0000] {processor.py:157} INFO - Started process (PID=8416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:26:27.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:26:27.369+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:26:27.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:26:27.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:26:27.414+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:26:27.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:26:27.428+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:26:27.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:26:27.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T08:26:57.695+0000] {processor.py:157} INFO - Started process (PID=8426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:26:57.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:26:57.700+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:26:57.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:26:57.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:26:57.750+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:26:57.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:26:57.764+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:26:57.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:26:57.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T08:27:28.044+0000] {processor.py:157} INFO - Started process (PID=8436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:27:28.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:27:28.065+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:27:28.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:27:28.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:27:28.118+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:27:28.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:27:28.149+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:27:28.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:27:28.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T08:27:58.510+0000] {processor.py:157} INFO - Started process (PID=8446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:27:58.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:27:58.514+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:27:58.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:27:58.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:27:58.570+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:27:58.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:27:58.585+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:27:58.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:27:58.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T08:28:28.833+0000] {processor.py:157} INFO - Started process (PID=8456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:28:28.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:28:28.845+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:28:28.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:28:28.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:28:28.886+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:28:28.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:28:28.914+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:28:28.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:28:28.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T08:28:59.287+0000] {processor.py:157} INFO - Started process (PID=8466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:28:59.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:28:59.291+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:28:59.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:28:59.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:28:59.324+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:28:59.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:28:59.337+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:28:59.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:28:59.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T08:29:29.736+0000] {processor.py:157} INFO - Started process (PID=8474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:29:29.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:29:29.741+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:29:29.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:29:29.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:29:29.797+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:29:29.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:29:29.811+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:29:29.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:29:29.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T08:30:00.094+0000] {processor.py:157} INFO - Started process (PID=8486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:30:00.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:30:00.102+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:30:00.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:30:00.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:30:00.154+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:30:00.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:30:00.169+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:30:00.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:30:00.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T08:30:30.565+0000] {processor.py:157} INFO - Started process (PID=8496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:30:30.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:30:30.571+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:30:30.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:30:30.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:30:30.630+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:30:30.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:30:30.646+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:30:30.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:30:30.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T08:31:01.046+0000] {processor.py:157} INFO - Started process (PID=8506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:31:01.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:31:01.049+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:31:01.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:31:01.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:31:01.079+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:31:01.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:31:01.095+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:31:01.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:31:01.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T08:31:31.436+0000] {processor.py:157} INFO - Started process (PID=8515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:31:31.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:31:31.448+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:31:31.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:31:31.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:31:31.495+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:31:31.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:31:31.516+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:31:31.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:31:31.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T08:47:07.896+0000] {processor.py:157} INFO - Started process (PID=8526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:47:07.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:47:07.935+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:47:07.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:47:07.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:47:08.032+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:47:08.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:47:08.059+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:47:08.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:47:08.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.201 seconds
[2024-09-15T08:47:38.194+0000] {processor.py:157} INFO - Started process (PID=8538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:47:38.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:47:38.201+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:47:38.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:47:38.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:47:38.270+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:47:38.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:47:38.289+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:47:38.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:47:38.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T08:48:08.522+0000] {processor.py:157} INFO - Started process (PID=8548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:48:08.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:48:08.531+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:48:08.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:48:08.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:48:08.598+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:48:08.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:48:08.627+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:48:08.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:48:08.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T08:48:38.832+0000] {processor.py:157} INFO - Started process (PID=8558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:48:38.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T08:48:38.837+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:48:38.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:48:38.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T08:48:38.879+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:48:38.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T08:48:38.895+0000] {logging_mixin.py:151} INFO - [2024-09-15T08:48:38.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T08:48:38.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T09:04:39.582+0000] {processor.py:157} INFO - Started process (PID=8568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:04:39.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:04:39.589+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:04:39.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:04:39.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:04:39.651+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:04:39.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:04:39.665+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:04:39.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:04:39.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T09:05:10.098+0000] {processor.py:157} INFO - Started process (PID=8580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:05:10.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:05:10.103+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:05:10.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:05:10.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:05:10.185+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:05:10.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:05:10.209+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:05:10.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:05:10.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-15T09:21:58.216+0000] {processor.py:157} INFO - Started process (PID=8589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:21:58.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:21:58.222+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:21:58.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:21:58.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:21:58.280+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:21:58.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:21:58.304+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:21:58.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:21:58.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T09:22:28.596+0000] {processor.py:157} INFO - Started process (PID=8602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:22:28.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:22:28.605+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:22:28.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:22:28.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:22:28.678+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:22:28.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:22:28.695+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:22:28.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:22:28.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T09:22:58.959+0000] {processor.py:157} INFO - Started process (PID=8612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:22:58.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:22:58.964+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:22:58.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:22:58.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:22:59.022+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:22:59.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:22:59.042+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:22:59.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:22:59.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T09:23:29.315+0000] {processor.py:157} INFO - Started process (PID=8622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:23:29.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:23:29.322+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:23:29.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:23:29.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:23:29.362+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:23:29.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:23:29.375+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:23:29.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:23:29.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T09:23:59.725+0000] {processor.py:157} INFO - Started process (PID=8632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:23:59.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:23:59.728+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:23:59.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:23:59.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:23:59.776+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:23:59.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:23:59.790+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:23:59.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:23:59.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T09:24:30.108+0000] {processor.py:157} INFO - Started process (PID=8642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:24:30.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:24:30.114+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:24:30.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:24:30.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:24:30.152+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:24:30.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:24:30.165+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:24:30.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:24:30.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T09:25:00.432+0000] {processor.py:157} INFO - Started process (PID=8652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:25:00.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:25:00.435+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:25:00.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:25:00.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:25:00.473+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:25:00.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:25:00.487+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:25:00.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:25:00.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T09:41:17.116+0000] {processor.py:157} INFO - Started process (PID=8661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:41:17.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:41:17.123+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:41:17.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:41:17.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:41:17.191+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:41:17.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:41:17.212+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:41:17.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:41:17.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T09:41:47.455+0000] {processor.py:157} INFO - Started process (PID=8672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:41:47.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:41:47.461+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:41:47.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:41:47.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:41:47.517+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:41:47.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:41:47.536+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:41:47.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:41:47.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T09:42:17.802+0000] {processor.py:157} INFO - Started process (PID=8682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:42:17.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:42:17.807+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:42:17.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:42:17.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:42:17.837+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:42:17.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:42:17.864+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:42:17.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:42:17.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T09:42:48.232+0000] {processor.py:157} INFO - Started process (PID=8691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:42:48.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:42:48.238+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:42:48.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:42:48.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:42:48.275+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:42:48.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:42:48.289+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:42:48.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:42:48.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T09:43:18.521+0000] {processor.py:157} INFO - Started process (PID=8702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:43:18.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:43:18.526+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:43:18.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:43:18.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:43:18.553+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:43:18.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:43:18.564+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:43:18.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:43:18.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-15T09:51:19.380+0000] {processor.py:157} INFO - Started process (PID=8713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:51:19.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:51:19.398+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:51:19.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:51:19.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:51:19.472+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:51:19.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:51:19.509+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:51:19.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:51:19.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-15T09:51:49.893+0000] {processor.py:157} INFO - Started process (PID=8723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:51:49.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T09:51:49.898+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:51:49.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:51:49.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T09:51:49.953+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:51:49.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T09:51:49.970+0000] {logging_mixin.py:151} INFO - [2024-09-15T09:51:49.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T09:51:49.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T10:07:31.338+0000] {processor.py:157} INFO - Started process (PID=8736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:07:31.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:07:31.343+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:07:31.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:07:31.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:07:31.390+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:07:31.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:07:31.414+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:07:31.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:07:31.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T10:23:03.699+0000] {processor.py:157} INFO - Started process (PID=8745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:23:03.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:23:03.702+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:23:03.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:23:03.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:23:03.759+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:23:03.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:23:03.778+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:23:03.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:23:03.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T10:23:34.075+0000] {processor.py:157} INFO - Started process (PID=8754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:23:34.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:23:34.080+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:23:34.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:23:34.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:23:34.137+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:23:34.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:23:34.162+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:23:34.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:23:34.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T10:24:04.460+0000] {processor.py:157} INFO - Started process (PID=8766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:24:04.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:24:04.463+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:24:04.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:24:04.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:24:04.494+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:24:04.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:24:04.509+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:24:04.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:24:04.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T10:24:34.880+0000] {processor.py:157} INFO - Started process (PID=8775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:24:34.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:24:34.888+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:24:34.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:24:34.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:24:34.953+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:24:34.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:24:34.970+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:24:34.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:24:34.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T10:25:05.297+0000] {processor.py:157} INFO - Started process (PID=8785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:25:05.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:25:05.306+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:25:05.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:25:05.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:25:05.374+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:25:05.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:25:05.391+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:25:05.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:25:05.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T10:25:35.619+0000] {processor.py:157} INFO - Started process (PID=8796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:25:35.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:25:35.624+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:25:35.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:25:35.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:25:35.667+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:25:35.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:25:35.681+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:25:35.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:25:35.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T10:26:06.025+0000] {processor.py:157} INFO - Started process (PID=8806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:26:06.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:26:06.029+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:26:06.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:26:06.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:26:06.075+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:26:06.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:26:06.088+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:26:06.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:26:06.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T10:26:36.448+0000] {processor.py:157} INFO - Started process (PID=8815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:26:36.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:26:36.458+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:26:36.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:26:36.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:26:36.515+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:26:36.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:26:36.529+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:26:36.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:26:36.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T10:27:06.797+0000] {processor.py:157} INFO - Started process (PID=8826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:27:06.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:27:06.804+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:27:06.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:27:06.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:27:06.844+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:27:06.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:27:06.856+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:27:06.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:27:06.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T10:27:37.277+0000] {processor.py:157} INFO - Started process (PID=8836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:27:37.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:27:37.281+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:27:37.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:27:37.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:27:37.318+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:27:37.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:27:37.334+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:27:37.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:27:37.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T10:28:07.664+0000] {processor.py:157} INFO - Started process (PID=8846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:28:07.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:28:07.669+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:28:07.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:28:07.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:28:07.706+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:28:07.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:28:07.722+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:28:07.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:28:07.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T10:28:38.012+0000] {processor.py:157} INFO - Started process (PID=8856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:28:38.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:28:38.021+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:28:38.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:28:38.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:28:38.076+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:28:38.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:28:38.093+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:28:38.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:28:38.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T10:29:08.383+0000] {processor.py:157} INFO - Started process (PID=8866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:29:08.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:29:08.387+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:29:08.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:29:08.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:29:08.415+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:29:08.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:29:08.427+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:29:08.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:29:08.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T10:29:38.706+0000] {processor.py:157} INFO - Started process (PID=8876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:29:38.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:29:38.711+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:29:38.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:29:38.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:29:38.752+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:29:38.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:29:38.768+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:29:38.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:29:38.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T10:30:09.145+0000] {processor.py:157} INFO - Started process (PID=8886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:30:09.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:30:09.147+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:30:09.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:30:09.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:30:09.178+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:30:09.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:30:09.188+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:30:09.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:30:09.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-15T10:30:39.604+0000] {processor.py:157} INFO - Started process (PID=8894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:30:39.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:30:39.609+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:30:39.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:30:39.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:30:39.674+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:30:39.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:30:39.690+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:30:39.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:30:39.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T10:31:10.054+0000] {processor.py:157} INFO - Started process (PID=8906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:31:10.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:31:10.057+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:31:10.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:31:10.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:31:10.086+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:31:10.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:31:10.098+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:31:10.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:31:10.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-15T10:31:40.497+0000] {processor.py:157} INFO - Started process (PID=8915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:31:40.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:31:40.506+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:31:40.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:31:40.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:31:40.560+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:31:40.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:31:40.577+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:31:40.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:31:40.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T10:32:10.801+0000] {processor.py:157} INFO - Started process (PID=8926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:32:10.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:32:10.805+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:32:10.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:32:10.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:32:10.836+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:32:10.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:32:10.847+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:32:10.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:32:10.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T10:32:41.193+0000] {processor.py:157} INFO - Started process (PID=8936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:32:41.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:32:41.205+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:32:41.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:32:41.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:32:41.254+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:32:41.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:32:41.280+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:32:41.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:32:41.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T10:33:11.744+0000] {processor.py:157} INFO - Started process (PID=8945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:33:11.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:33:11.753+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:33:11.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:33:11.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:33:11.841+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:33:11.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:33:11.878+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:33:11.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:33:11.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-15T10:33:42.072+0000] {processor.py:157} INFO - Started process (PID=8956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:33:42.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:33:42.075+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:33:42.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:33:42.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:33:42.108+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:33:42.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:33:42.121+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:33:42.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:33:42.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T10:34:12.505+0000] {processor.py:157} INFO - Started process (PID=8966) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:34:12.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:34:12.512+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:34:12.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:34:12.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:34:12.550+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:34:12.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:34:12.564+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:34:12.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:34:12.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T10:34:42.894+0000] {processor.py:157} INFO - Started process (PID=8976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:34:42.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:34:42.897+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:34:42.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:34:42.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:34:42.932+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:34:42.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:34:42.943+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:34:42.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:34:42.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T10:35:13.314+0000] {processor.py:157} INFO - Started process (PID=8984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:35:13.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:35:13.324+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:35:13.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:35:13.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:35:13.389+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:35:13.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:35:13.404+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:35:13.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:35:13.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T10:35:43.635+0000] {processor.py:157} INFO - Started process (PID=8996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:35:43.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:35:43.638+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:35:43.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:35:43.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:35:43.670+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:35:43.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:35:43.683+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:35:43.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:35:43.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T10:36:14.029+0000] {processor.py:157} INFO - Started process (PID=9006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:36:14.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:36:14.035+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:36:14.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:36:14.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:36:14.075+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:36:14.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:36:14.090+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:36:14.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:36:14.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T10:36:44.370+0000] {processor.py:157} INFO - Started process (PID=9016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:36:44.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:36:44.375+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:36:44.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:36:44.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:36:44.417+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:36:44.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:36:44.434+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:36:44.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:36:44.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T10:37:14.816+0000] {processor.py:157} INFO - Started process (PID=9025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:37:14.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:37:14.822+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:37:14.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:37:14.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:37:14.873+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:37:14.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:37:14.888+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:37:14.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:37:14.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T10:37:45.112+0000] {processor.py:157} INFO - Started process (PID=9036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:37:45.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:37:45.116+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:37:45.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:37:45.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:37:45.148+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:37:45.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:37:45.160+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:37:45.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:37:45.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T10:38:15.634+0000] {processor.py:157} INFO - Started process (PID=9046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:38:15.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:38:15.640+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:38:15.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:38:15.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:38:15.677+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:38:15.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:38:15.691+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:38:15.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:38:15.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T10:38:46.001+0000] {processor.py:157} INFO - Started process (PID=9056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:38:46.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:38:46.012+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:38:46.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:38:46.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:38:46.041+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:38:46.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:38:46.053+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:38:46.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:38:46.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T10:39:16.410+0000] {processor.py:157} INFO - Started process (PID=9065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:39:16.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:39:16.419+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:39:16.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:39:16.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:39:16.480+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:39:16.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:39:16.493+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:39:16.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:39:16.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T10:39:46.866+0000] {processor.py:157} INFO - Started process (PID=9076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:39:46.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:39:46.869+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:39:46.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:39:46.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:39:46.918+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:39:46.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:39:46.933+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:39:46.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:39:46.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T10:40:17.274+0000] {processor.py:157} INFO - Started process (PID=9085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:40:17.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:40:17.280+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:40:17.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:40:17.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:40:17.342+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:40:17.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:40:17.356+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:40:17.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:40:17.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T10:40:47.701+0000] {processor.py:157} INFO - Started process (PID=9096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:40:47.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:40:47.704+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:40:47.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:40:47.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:40:47.739+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:40:47.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:40:47.751+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:40:47.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:40:47.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T10:41:18.110+0000] {processor.py:157} INFO - Started process (PID=9105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:41:18.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:41:18.127+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:41:18.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:41:18.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:41:18.165+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:41:18.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:41:18.178+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:41:18.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:41:18.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T10:41:48.548+0000] {processor.py:157} INFO - Started process (PID=9116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:41:48.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:41:48.552+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:41:48.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:41:48.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:41:48.607+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:41:48.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:41:48.620+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:41:48.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:41:48.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T10:42:19.019+0000] {processor.py:157} INFO - Started process (PID=9125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:42:19.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:42:19.023+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:42:19.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:42:19.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:42:19.092+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:42:19.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:42:19.106+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:42:19.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:42:19.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T10:42:49.331+0000] {processor.py:157} INFO - Started process (PID=9136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:42:49.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:42:49.335+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:42:49.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:42:49.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:42:49.398+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:42:49.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:42:49.412+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:42:49.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:42:49.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T10:43:19.858+0000] {processor.py:157} INFO - Started process (PID=9145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:43:19.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:43:19.863+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:43:19.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:43:19.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:43:19.909+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:43:19.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:43:19.925+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:43:19.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:43:19.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T10:43:50.204+0000] {processor.py:157} INFO - Started process (PID=9156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:43:50.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:43:50.207+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:43:50.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:43:50.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:43:50.264+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:43:50.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:43:50.276+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:43:50.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:43:50.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T10:44:20.535+0000] {processor.py:157} INFO - Started process (PID=9166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:44:20.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:44:20.557+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:44:20.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:44:20.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:44:20.596+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:44:20.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:44:20.626+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:44:20.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:44:20.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T10:44:51.006+0000] {processor.py:157} INFO - Started process (PID=9176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:44:51.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:44:51.012+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:44:51.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:44:51.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:44:51.075+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:44:51.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:44:51.088+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:44:51.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:44:51.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T10:45:21.352+0000] {processor.py:157} INFO - Started process (PID=9185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:45:21.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:45:21.361+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:45:21.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:45:21.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:45:21.418+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:45:21.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:45:21.433+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:45:21.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:45:21.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T10:45:51.777+0000] {processor.py:157} INFO - Started process (PID=9196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:45:51.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:45:51.780+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:45:51.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:45:51.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:45:51.815+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:45:51.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:45:51.826+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:45:51.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:45:51.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T10:46:22.182+0000] {processor.py:157} INFO - Started process (PID=9206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:46:22.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:46:22.192+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:46:22.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:46:22.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:46:22.233+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:46:22.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:46:22.247+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:46:22.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:46:22.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T10:46:52.643+0000] {processor.py:157} INFO - Started process (PID=9216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:46:52.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:46:52.650+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:46:52.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:46:52.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:46:52.688+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:46:52.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:46:52.700+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:46:52.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:46:52.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T10:47:23.110+0000] {processor.py:157} INFO - Started process (PID=9225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:47:23.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:47:23.125+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:47:23.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:47:23.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:47:23.181+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:47:23.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:47:23.194+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:47:23.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:47:23.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T10:47:53.469+0000] {processor.py:157} INFO - Started process (PID=9236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:47:53.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:47:53.475+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:47:53.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:47:53.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:47:53.510+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:47:53.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:47:53.523+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:47:53.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:47:53.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T10:48:23.872+0000] {processor.py:157} INFO - Started process (PID=9246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:48:23.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:48:23.881+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:48:23.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:48:23.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:48:23.938+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:48:23.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:48:23.951+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:48:23.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:48:23.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T10:48:54.236+0000] {processor.py:157} INFO - Started process (PID=9256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:48:54.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:48:54.239+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:48:54.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:48:54.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:48:54.277+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:48:54.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:48:54.292+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:48:54.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:48:54.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T10:49:24.669+0000] {processor.py:157} INFO - Started process (PID=9264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:49:24.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:49:24.672+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:49:24.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:49:24.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:49:24.708+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:49:24.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:49:24.723+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:49:24.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:49:24.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T10:49:55.035+0000] {processor.py:157} INFO - Started process (PID=9276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:49:55.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:49:55.039+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:49:55.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:49:55.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:49:55.084+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:49:55.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:49:55.103+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:49:55.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:49:55.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T10:50:25.338+0000] {processor.py:157} INFO - Started process (PID=9286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:50:25.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:50:25.349+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:50:25.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:50:25.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:50:25.396+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:50:25.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:50:25.410+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:50:25.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:50:25.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T10:50:55.765+0000] {processor.py:157} INFO - Started process (PID=9296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:50:55.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:50:55.769+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:50:55.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:50:55.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:50:55.805+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:50:55.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:50:55.834+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:50:55.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:50:55.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T10:51:26.201+0000] {processor.py:157} INFO - Started process (PID=9306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:51:26.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:51:26.206+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:51:26.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:51:26.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:51:26.265+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:51:26.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:51:26.279+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:51:26.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:51:26.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T10:51:56.559+0000] {processor.py:157} INFO - Started process (PID=9315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:51:56.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:51:56.564+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:51:56.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:51:56.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:51:56.608+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:51:56.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:51:56.624+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:51:56.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:51:56.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T10:52:26.904+0000] {processor.py:157} INFO - Started process (PID=9326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:52:26.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:52:26.906+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:52:26.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:52:26.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:52:26.936+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:52:26.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:52:26.947+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:52:26.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:52:26.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-15T10:52:57.354+0000] {processor.py:157} INFO - Started process (PID=9336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:52:57.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:52:57.365+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:52:57.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:52:57.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:52:57.437+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:52:57.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:52:57.453+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:52:57.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:52:57.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T10:53:27.795+0000] {processor.py:157} INFO - Started process (PID=9346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:53:27.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:53:27.806+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:53:27.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:53:27.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:53:27.930+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:53:27.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:53:27.974+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:53:27.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:53:27.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.199 seconds
[2024-09-15T10:53:58.112+0000] {processor.py:157} INFO - Started process (PID=9356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:53:58.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:53:58.117+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:53:58.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:53:58.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:53:58.155+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:53:58.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:53:58.169+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:53:58.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:53:58.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T10:54:28.451+0000] {processor.py:157} INFO - Started process (PID=9366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:54:28.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:54:28.458+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:54:28.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:54:28.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:54:28.526+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:54:28.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:54:28.548+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:54:28.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:54:28.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T10:54:58.820+0000] {processor.py:157} INFO - Started process (PID=9375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:54:58.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:54:58.827+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:54:58.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:54:58.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:54:58.889+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:54:58.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:54:58.913+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:54:58.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:54:58.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T10:55:29.189+0000] {processor.py:157} INFO - Started process (PID=9385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:55:29.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:55:29.195+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:55:29.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:55:29.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:55:29.260+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:55:29.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:55:29.276+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:55:29.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:55:29.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T10:55:59.649+0000] {processor.py:157} INFO - Started process (PID=9396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:55:59.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:55:59.652+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:55:59.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:55:59.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:55:59.680+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:55:59.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:55:59.690+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:55:59.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:55:59.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-15T10:56:30.086+0000] {processor.py:157} INFO - Started process (PID=9406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:56:30.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:56:30.096+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:56:30.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:56:30.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:56:30.148+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:56:30.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:56:30.182+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:56:30.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:56:30.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T10:57:00.401+0000] {processor.py:157} INFO - Started process (PID=9416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:57:00.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:57:00.406+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:57:00.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:57:00.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:57:00.440+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:57:00.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:57:00.456+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:57:00.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:57:00.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T10:57:30.794+0000] {processor.py:157} INFO - Started process (PID=9426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:57:30.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:57:30.800+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:57:30.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:57:30.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:57:30.876+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:57:30.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:57:30.891+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:57:30.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:57:30.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T10:58:01.147+0000] {processor.py:157} INFO - Started process (PID=9435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:58:01.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:58:01.168+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:58:01.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:58:01.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:58:01.215+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:58:01.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:58:01.231+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:58:01.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:58:01.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T10:58:31.573+0000] {processor.py:157} INFO - Started process (PID=9446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:58:31.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:58:31.576+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:58:31.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:58:31.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:58:31.610+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:58:31.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:58:31.623+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:58:31.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:58:31.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T10:59:02.048+0000] {processor.py:157} INFO - Started process (PID=9456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:59:02.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:59:02.060+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:59:02.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:59:02.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:59:02.102+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:59:02.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:59:02.117+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:59:02.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:59:02.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T10:59:32.393+0000] {processor.py:157} INFO - Started process (PID=9466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:59:32.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T10:59:32.397+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:59:32.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:59:32.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T10:59:32.429+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:59:32.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T10:59:32.441+0000] {logging_mixin.py:151} INFO - [2024-09-15T10:59:32.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T10:59:32.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T11:00:02.865+0000] {processor.py:157} INFO - Started process (PID=9476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:00:02.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:00:02.876+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:00:02.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:00:02.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:00:02.944+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:00:02.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:00:02.961+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:00:02.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:00:02.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T11:00:33.198+0000] {processor.py:157} INFO - Started process (PID=9486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:00:33.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:00:33.200+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:00:33.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:00:33.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:00:33.230+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:00:33.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:00:33.244+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:00:33.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:00:33.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T11:01:03.584+0000] {processor.py:157} INFO - Started process (PID=9496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:01:03.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:01:03.597+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:01:03.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:01:03.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:01:03.650+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:01:03.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:01:03.681+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:01:03.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:01:03.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T11:01:34.060+0000] {processor.py:157} INFO - Started process (PID=9506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:01:34.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:01:34.064+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:01:34.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:01:34.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:01:34.097+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:01:34.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:01:34.108+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:01:34.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:01:34.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T11:02:04.443+0000] {processor.py:157} INFO - Started process (PID=9515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:02:04.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:02:04.452+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:02:04.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:02:04.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:02:04.503+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:02:04.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:02:04.533+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:02:04.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:02:04.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T11:02:34.747+0000] {processor.py:157} INFO - Started process (PID=9526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:02:34.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:02:34.755+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:02:34.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:02:34.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:02:34.790+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:02:34.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:02:34.803+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:02:34.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:02:34.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T11:03:05.121+0000] {processor.py:157} INFO - Started process (PID=9536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:03:05.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:03:05.128+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:03:05.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:03:05.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:03:05.184+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:03:05.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:03:05.205+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:03:05.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:03:05.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T11:03:35.562+0000] {processor.py:157} INFO - Started process (PID=9546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:03:35.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:03:35.565+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:03:35.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:03:35.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:03:35.611+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:03:35.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:03:35.627+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:03:35.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:03:35.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T11:04:06.011+0000] {processor.py:157} INFO - Started process (PID=9554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:04:06.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:04:06.016+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:04:06.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:04:06.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:04:06.071+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:04:06.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:04:06.083+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:04:06.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:04:06.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T11:04:36.367+0000] {processor.py:157} INFO - Started process (PID=9566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:04:36.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:04:36.388+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:04:36.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:04:36.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:04:36.426+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:04:36.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:04:36.441+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:04:36.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:04:36.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T11:05:06.693+0000] {processor.py:157} INFO - Started process (PID=9576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:05:06.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:05:06.705+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:05:06.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:05:06.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:05:06.764+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:05:06.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:05:06.780+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:05:06.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:05:06.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T11:05:37.082+0000] {processor.py:157} INFO - Started process (PID=9586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:05:37.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:05:37.088+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:05:37.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:05:37.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:05:37.160+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:05:37.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:05:37.177+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:05:37.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:05:37.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T11:06:07.423+0000] {processor.py:157} INFO - Started process (PID=9596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:06:07.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:06:07.429+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:06:07.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:06:07.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:06:07.462+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:06:07.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:06:07.475+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:06:07.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:06:07.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T11:06:37.853+0000] {processor.py:157} INFO - Started process (PID=9606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:06:37.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:06:37.866+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:06:37.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:06:37.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:06:37.906+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:06:37.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:06:37.922+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:06:37.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:06:37.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T11:07:08.170+0000] {processor.py:157} INFO - Started process (PID=9616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:07:08.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:07:08.174+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:07:08.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:07:08.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:07:08.205+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:07:08.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:07:08.224+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:07:08.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:07:08.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-15T11:07:38.663+0000] {processor.py:157} INFO - Started process (PID=9625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:07:38.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:07:38.670+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:07:38.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:07:38.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:07:38.757+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:07:38.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:07:38.774+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:07:38.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:07:38.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-15T11:08:09.015+0000] {processor.py:157} INFO - Started process (PID=9636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:08:09.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:08:09.018+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:08:09.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:08:09.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:08:09.046+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:08:09.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:08:09.056+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:08:09.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:08:09.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T11:08:39.486+0000] {processor.py:157} INFO - Started process (PID=9644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:08:39.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:08:39.491+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:08:39.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:08:39.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:08:39.546+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:08:39.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:08:39.561+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:08:39.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:08:39.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T11:09:09.818+0000] {processor.py:157} INFO - Started process (PID=9656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:09:09.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:09:09.823+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:09:09.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:09:09.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:09:09.854+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:09:09.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:09:09.865+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:09:09.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:09:09.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-15T11:09:40.248+0000] {processor.py:157} INFO - Started process (PID=9665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:09:40.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:09:40.253+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:09:40.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:09:40.271+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:09:40.299+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:09:40.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:09:40.314+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:09:40.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:09:40.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T11:10:10.609+0000] {processor.py:157} INFO - Started process (PID=9676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:10:10.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:10:10.615+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:10:10.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:10:10.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:10:10.661+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:10:10.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:10:10.674+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:10:10.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:10:10.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T11:10:40.913+0000] {processor.py:157} INFO - Started process (PID=9685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:10:40.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:10:40.918+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:10:40.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:10:40.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:10:40.982+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:10:40.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:10:40.997+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:10:40.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:10:41.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T11:11:11.227+0000] {processor.py:157} INFO - Started process (PID=9696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:11:11.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:11:11.230+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:11:11.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:11:11.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:11:11.266+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:11:11.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:11:11.282+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:11:11.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:11:11.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T11:11:41.694+0000] {processor.py:157} INFO - Started process (PID=9706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:11:41.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:11:41.703+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:11:41.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:11:41.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:11:41.748+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:11:41.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:11:41.763+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:11:41.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:11:41.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T11:12:12.059+0000] {processor.py:157} INFO - Started process (PID=9716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:12:12.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:12:12.063+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:12:12.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:12:12.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:12:12.113+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:12:12.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:12:12.127+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:12:12.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:12:12.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T11:12:42.528+0000] {processor.py:157} INFO - Started process (PID=9725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:12:42.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:12:42.534+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:12:42.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:12:42.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:12:42.576+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:12:42.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:12:42.594+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:12:42.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:12:42.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T11:13:12.899+0000] {processor.py:157} INFO - Started process (PID=9736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:13:12.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:13:12.903+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:13:12.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:13:12.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:13:12.964+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:13:12.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:13:12.977+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:13:12.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:13:12.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T11:13:43.356+0000] {processor.py:157} INFO - Started process (PID=9745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:13:43.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:13:43.361+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:13:43.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:13:43.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:13:43.408+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:13:43.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:13:43.423+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:13:43.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:13:43.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T11:14:13.734+0000] {processor.py:157} INFO - Started process (PID=9756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:14:13.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:14:13.738+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:14:13.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:14:13.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:14:13.780+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:14:13.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:14:13.794+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:14:13.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:14:13.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T11:14:44.127+0000] {processor.py:157} INFO - Started process (PID=9765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:14:44.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:14:44.134+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:14:44.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:14:44.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:14:44.205+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:14:44.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:14:44.221+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:14:44.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:14:44.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T11:15:14.438+0000] {processor.py:157} INFO - Started process (PID=9776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:15:14.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:15:14.442+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:15:14.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:15:14.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:15:14.474+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:15:14.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:15:14.493+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:15:14.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:15:14.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T11:15:44.831+0000] {processor.py:157} INFO - Started process (PID=9786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:15:44.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:15:44.837+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:15:44.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:15:44.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:15:44.905+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:15:44.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:15:44.920+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:15:44.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:15:44.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T11:16:15.162+0000] {processor.py:157} INFO - Started process (PID=9796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:16:15.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:16:15.166+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:16:15.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:16:15.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:16:15.194+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:16:15.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:16:15.204+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:16:15.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:16:15.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-15T11:16:45.618+0000] {processor.py:157} INFO - Started process (PID=9806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:16:45.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:16:45.624+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:16:45.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:16:45.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:16:45.670+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:16:45.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:16:45.693+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:16:45.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:16:45.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T11:17:15.951+0000] {processor.py:157} INFO - Started process (PID=9816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:17:15.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:17:15.956+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:17:15.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:17:15.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:17:15.987+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:17:15.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:17:16.000+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:17:16.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:17:16.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T11:17:46.363+0000] {processor.py:157} INFO - Started process (PID=9826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:17:46.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:17:46.381+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:17:46.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:17:46.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:17:46.429+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:17:46.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:17:46.444+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:17:46.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:17:46.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T11:18:16.815+0000] {processor.py:157} INFO - Started process (PID=9836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:18:16.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:18:16.821+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:18:16.821+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:18:16.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:18:16.878+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:18:16.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:18:16.894+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:18:16.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:18:16.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T11:18:47.227+0000] {processor.py:157} INFO - Started process (PID=9846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:18:47.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:18:47.230+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:18:47.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:18:47.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:18:47.260+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:18:47.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:18:47.279+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:18:47.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:18:47.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T11:19:17.664+0000] {processor.py:157} INFO - Started process (PID=9856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:19:17.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:19:17.673+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:19:17.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:19:17.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:19:17.735+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:19:17.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:19:17.750+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:19:17.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:19:17.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T11:19:48.113+0000] {processor.py:157} INFO - Started process (PID=9866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:19:48.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:19:48.115+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:19:48.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:19:48.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:19:48.147+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:19:48.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:19:48.159+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:19:48.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:19:48.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T11:20:18.529+0000] {processor.py:157} INFO - Started process (PID=9876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:20:18.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:20:18.539+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:20:18.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:20:18.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:20:18.597+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:20:18.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:20:18.615+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:20:18.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:20:18.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T11:20:48.881+0000] {processor.py:157} INFO - Started process (PID=9886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:20:48.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:20:48.884+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:20:48.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:20:48.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:20:48.915+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:20:48.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:20:48.932+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:20:48.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:20:48.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T11:21:19.324+0000] {processor.py:157} INFO - Started process (PID=9895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:21:19.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:21:19.337+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:21:19.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:21:19.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:21:19.382+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:21:19.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:21:19.398+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:21:19.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:21:19.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T11:21:49.656+0000] {processor.py:157} INFO - Started process (PID=9906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:21:49.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:21:49.662+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:21:49.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:21:49.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:21:49.705+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:21:49.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:21:49.718+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:21:49.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:21:49.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T11:22:20.091+0000] {processor.py:157} INFO - Started process (PID=9915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:22:20.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:22:20.108+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:22:20.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:22:20.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:22:20.168+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:22:20.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:22:20.193+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:22:20.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:22:20.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-15T11:22:50.450+0000] {processor.py:157} INFO - Started process (PID=9926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:22:50.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:22:50.456+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:22:50.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:22:50.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:22:50.530+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:22:50.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:22:50.548+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:22:50.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:22:50.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-15T11:23:20.849+0000] {processor.py:157} INFO - Started process (PID=9936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:23:20.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:23:20.854+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:23:20.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:23:20.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:23:20.911+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:23:20.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:23:20.929+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:23:20.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:23:20.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T11:23:51.238+0000] {processor.py:157} INFO - Started process (PID=9946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:23:51.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:23:51.244+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:23:51.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:23:51.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:23:51.292+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:23:51.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:23:51.323+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:23:51.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:23:51.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T11:39:43.791+0000] {processor.py:157} INFO - Started process (PID=9958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:39:43.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:39:43.802+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:39:43.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:39:43.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:39:43.922+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:39:43.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:39:43.957+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:39:43.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:39:43.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-09-15T11:40:14.141+0000] {processor.py:157} INFO - Started process (PID=9967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:40:14.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:40:14.172+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:40:14.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:40:14.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:40:14.232+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:40:14.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:40:14.250+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:40:14.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:40:14.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-15T11:40:44.562+0000] {processor.py:157} INFO - Started process (PID=9978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:40:44.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:40:44.569+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:40:44.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:40:44.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:40:44.616+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:40:44.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:40:44.632+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:40:44.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:40:44.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T11:41:15.046+0000] {processor.py:157} INFO - Started process (PID=9988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:41:15.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:41:15.049+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:41:15.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:41:15.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:41:15.079+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:41:15.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:41:15.092+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:41:15.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:41:15.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T11:41:45.514+0000] {processor.py:157} INFO - Started process (PID=9998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:41:45.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:41:45.521+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:41:45.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:41:45.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:41:45.571+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:41:45.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:41:45.590+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:41:45.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:41:45.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T11:42:15.947+0000] {processor.py:157} INFO - Started process (PID=10008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:42:15.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:42:15.952+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:42:15.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:42:15.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:42:15.978+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:42:15.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:42:16.004+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:42:16.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:42:16.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T11:42:46.355+0000] {processor.py:157} INFO - Started process (PID=10018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:42:46.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:42:46.363+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:42:46.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:42:46.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:42:46.388+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:42:46.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:42:46.398+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:42:46.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:42:46.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T11:43:16.788+0000] {processor.py:157} INFO - Started process (PID=10028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:43:16.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:43:16.792+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:43:16.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:43:16.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:43:16.833+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:43:16.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:43:16.847+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:43:16.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:43:16.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T11:43:47.180+0000] {processor.py:157} INFO - Started process (PID=10038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:43:47.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:43:47.189+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:43:47.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:43:47.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:43:47.212+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:43:47.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:43:47.226+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:43:47.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:43:47.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-15T11:44:17.612+0000] {processor.py:157} INFO - Started process (PID=10048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:44:17.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:44:17.615+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:44:17.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:44:17.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:44:17.644+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:44:17.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:44:17.657+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:44:17.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:44:17.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T11:44:47.998+0000] {processor.py:157} INFO - Started process (PID=10058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:44:47.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:44:48.004+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:44:48.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:44:48.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:44:48.025+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:44:48.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:44:48.038+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:44:48.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:44:48.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-15T11:45:18.359+0000] {processor.py:157} INFO - Started process (PID=10068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:45:18.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:45:18.371+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:45:18.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:45:18.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:45:18.405+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:45:18.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:45:18.419+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:45:18.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:45:18.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T11:45:48.807+0000] {processor.py:157} INFO - Started process (PID=10078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:45:48.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:45:48.816+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:45:48.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:45:48.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:45:48.839+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:45:48.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:45:48.849+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:45:48.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:45:48.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-15T11:46:19.292+0000] {processor.py:157} INFO - Started process (PID=10088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:46:19.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:46:19.295+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:46:19.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:46:19.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:46:19.337+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:46:19.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:46:19.349+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:46:19.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:46:19.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T11:46:49.742+0000] {processor.py:157} INFO - Started process (PID=10098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:46:49.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:46:49.745+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:46:49.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:46:49.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:46:49.777+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:46:49.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:46:49.790+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:46:49.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:46:49.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T11:47:20.208+0000] {processor.py:157} INFO - Started process (PID=10108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:47:20.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:47:20.212+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:47:20.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:47:20.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:47:20.243+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:47:20.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:47:20.257+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:47:20.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:47:20.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T11:47:50.603+0000] {processor.py:157} INFO - Started process (PID=10118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:47:50.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:47:50.608+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:47:50.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:47:50.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:47:50.633+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:47:50.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:47:50.648+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:47:50.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:47:50.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T11:48:21.070+0000] {processor.py:157} INFO - Started process (PID=10128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:48:21.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:48:21.074+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:48:21.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:48:21.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:48:21.105+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:48:21.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:48:21.117+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:48:21.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:48:21.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T11:48:51.465+0000] {processor.py:157} INFO - Started process (PID=10138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:48:51.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:48:51.468+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:48:51.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:48:51.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:48:51.502+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:48:51.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:48:51.515+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:48:51.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:48:51.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T11:49:21.792+0000] {processor.py:157} INFO - Started process (PID=10148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:49:21.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:49:21.797+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:49:21.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:49:21.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:49:21.827+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:49:21.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:49:21.839+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:49:21.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:49:21.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T11:49:52.147+0000] {processor.py:157} INFO - Started process (PID=10158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:49:52.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:49:52.151+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:49:52.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:49:52.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:49:52.178+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:49:52.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:49:52.188+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:49:52.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:49:52.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-15T11:50:22.630+0000] {processor.py:157} INFO - Started process (PID=10168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:50:22.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:50:22.635+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:50:22.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:50:22.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:50:22.664+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:50:22.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:50:22.680+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:50:22.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:50:22.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T11:50:53.016+0000] {processor.py:157} INFO - Started process (PID=10178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:50:53.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:50:53.019+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:50:53.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:50:53.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:50:53.056+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:50:53.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:50:53.070+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:50:53.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:50:53.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T11:51:23.546+0000] {processor.py:157} INFO - Started process (PID=10188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:51:23.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:51:23.550+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:51:23.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:51:23.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:51:23.577+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:51:23.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:51:23.591+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:51:23.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:51:23.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T11:51:54.063+0000] {processor.py:157} INFO - Started process (PID=10198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:51:54.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:51:54.067+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:51:54.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:51:54.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:51:54.106+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:51:54.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:51:54.121+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:51:54.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:51:54.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T11:52:24.552+0000] {processor.py:157} INFO - Started process (PID=10208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:52:24.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:52:24.558+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:52:24.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:52:24.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:52:24.585+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:52:24.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:52:24.595+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:52:24.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:52:24.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-15T11:52:55.071+0000] {processor.py:157} INFO - Started process (PID=10218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:52:55.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:52:55.075+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:52:55.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:52:55.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:52:55.112+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:52:55.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:52:55.126+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:52:55.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:52:55.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T11:53:25.477+0000] {processor.py:157} INFO - Started process (PID=10228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:53:25.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:53:25.479+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:53:25.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:53:25.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:53:25.508+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:53:25.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:53:25.521+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:53:25.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:53:25.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T11:53:55.978+0000] {processor.py:157} INFO - Started process (PID=10238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:53:55.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:53:55.981+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:53:55.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:53:55.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:53:56.010+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:53:56.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:53:56.025+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:53:56.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:53:56.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T11:54:26.398+0000] {processor.py:157} INFO - Started process (PID=10248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:54:26.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:54:26.402+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:54:26.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:54:26.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:54:26.441+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:54:26.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:54:26.456+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:54:26.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:54:26.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T11:54:56.873+0000] {processor.py:157} INFO - Started process (PID=10258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:54:56.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:54:56.876+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:54:56.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:54:56.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:54:56.907+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:54:56.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:54:56.920+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:54:56.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:54:56.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T11:55:27.309+0000] {processor.py:157} INFO - Started process (PID=10268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:55:27.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:55:27.312+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:55:27.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:55:27.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:55:27.343+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:55:27.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:55:27.356+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:55:27.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:55:27.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T11:55:57.647+0000] {processor.py:157} INFO - Started process (PID=10278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:55:57.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:55:57.655+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:55:57.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:55:57.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:55:57.677+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:55:57.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:55:57.690+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:55:57.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:55:57.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-15T11:56:28.026+0000] {processor.py:157} INFO - Started process (PID=10288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:56:28.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:56:28.030+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:56:28.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:56:28.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:56:28.070+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:56:28.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:56:28.084+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:56:28.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:56:28.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T11:56:58.415+0000] {processor.py:157} INFO - Started process (PID=10298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:56:58.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:56:58.421+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:56:58.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:56:58.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:56:58.452+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:56:58.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:56:58.467+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:56:58.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:56:58.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T11:57:28.823+0000] {processor.py:157} INFO - Started process (PID=10308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:57:28.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:57:28.828+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:57:28.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:57:28.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:57:28.870+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:57:28.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:57:28.884+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:57:28.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:57:28.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T11:57:59.166+0000] {processor.py:157} INFO - Started process (PID=10318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:57:59.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:57:59.169+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:57:59.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:57:59.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:57:59.196+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:57:59.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:57:59.213+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:57:59.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:57:59.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T11:58:29.579+0000] {processor.py:157} INFO - Started process (PID=10328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:58:29.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:58:29.583+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:58:29.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:58:29.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:58:29.615+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:58:29.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:58:29.630+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:58:29.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:58:29.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T11:58:59.989+0000] {processor.py:157} INFO - Started process (PID=10338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:58:59.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:58:59.993+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:58:59.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:59:00.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:59:00.023+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:59:00.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:59:00.034+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:59:00.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:59:00.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T11:59:30.447+0000] {processor.py:157} INFO - Started process (PID=10348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:59:30.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T11:59:30.450+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:59:30.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:59:30.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T11:59:30.485+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:59:30.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T11:59:30.499+0000] {logging_mixin.py:151} INFO - [2024-09-15T11:59:30.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T11:59:30.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T12:00:00.828+0000] {processor.py:157} INFO - Started process (PID=10358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:00:00.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:00:00.831+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:00:00.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:00:00.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:00:00.870+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:00:00.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:00:00.883+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:00:00.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:00:00.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T12:00:31.314+0000] {processor.py:157} INFO - Started process (PID=10368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:00:31.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:00:31.319+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:00:31.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:00:31.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:00:31.378+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:00:31.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:00:31.393+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:00:31.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:00:31.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T12:01:01.856+0000] {processor.py:157} INFO - Started process (PID=10378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:01:01.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:01:01.859+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:01:01.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:01:01.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:01:01.889+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:01:01.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:01:01.907+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:01:01.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:01:01.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-15T12:01:32.325+0000] {processor.py:157} INFO - Started process (PID=10387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:01:32.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:01:32.333+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:01:32.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:01:32.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:01:32.417+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:01:32.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:01:32.437+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:01:32.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:01:32.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-15T12:02:02.712+0000] {processor.py:157} INFO - Started process (PID=10398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:02:02.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:02:02.723+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:02:02.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:02:02.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:02:02.798+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:02:02.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:02:02.821+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:02:02.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:02:02.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-15T12:02:33.112+0000] {processor.py:157} INFO - Started process (PID=10408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:02:33.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:02:33.117+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:02:33.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:02:33.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:02:33.163+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:02:33.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:02:33.178+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:02:33.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:02:33.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T12:03:03.516+0000] {processor.py:157} INFO - Started process (PID=10418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:03:03.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:03:03.518+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:03:03.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:03:03.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:03:03.547+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:03:03.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:03:03.562+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:03:03.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:03:03.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-15T12:03:33.870+0000] {processor.py:157} INFO - Started process (PID=10428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:03:33.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:03:33.873+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:03:33.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:03:33.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:03:33.902+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:03:33.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:03:33.915+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:03:33.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:03:33.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T12:04:04.263+0000] {processor.py:157} INFO - Started process (PID=10438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:04:04.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:04:04.266+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:04:04.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:04:04.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:04:04.300+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:04:04.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:04:04.317+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:04:04.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:04:04.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T12:04:34.677+0000] {processor.py:157} INFO - Started process (PID=10448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:04:34.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:04:34.685+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:04:34.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:04:34.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:04:34.707+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:04:34.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:04:34.720+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:04:34.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:04:34.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T12:05:05.084+0000] {processor.py:157} INFO - Started process (PID=10458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:05:05.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:05:05.087+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:05:05.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:05:05.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:05:05.116+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:05:05.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:05:05.129+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:05:05.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:05:05.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T12:05:35.575+0000] {processor.py:157} INFO - Started process (PID=10468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:05:35.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:05:35.581+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:05:35.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:05:35.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:05:35.618+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:05:35.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:05:35.633+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:05:35.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:05:35.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T12:06:05.898+0000] {processor.py:157} INFO - Started process (PID=10478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:06:05.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:06:05.903+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:06:05.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:06:05.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:06:05.935+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:06:05.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:06:05.948+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:06:05.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:06:05.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T12:06:36.339+0000] {processor.py:157} INFO - Started process (PID=10488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:06:36.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:06:36.342+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:06:36.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:06:36.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:06:36.370+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:06:36.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:06:36.384+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:06:36.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:06:36.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T12:07:06.759+0000] {processor.py:157} INFO - Started process (PID=10498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:07:06.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:07:06.767+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:07:06.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:07:06.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:07:06.800+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:07:06.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:07:06.813+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:07:06.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:07:06.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-15T12:07:37.163+0000] {processor.py:157} INFO - Started process (PID=10508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:07:37.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:07:37.169+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:07:37.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:07:37.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:07:37.234+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:07:37.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:07:37.249+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:07:37.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:07:37.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T12:08:07.604+0000] {processor.py:157} INFO - Started process (PID=10518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:08:07.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:08:07.607+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:08:07.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:08:07.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:08:07.635+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:08:07.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:08:07.649+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:08:07.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:08:07.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T12:08:38.018+0000] {processor.py:157} INFO - Started process (PID=10528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:08:38.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:08:38.022+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:08:38.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:08:38.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:08:38.060+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:08:38.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:08:38.074+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:08:38.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:08:38.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-15T12:09:08.427+0000] {processor.py:157} INFO - Started process (PID=10538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:09:08.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:09:08.430+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:09:08.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:09:08.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:09:08.462+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:09:08.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:09:08.485+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:09:08.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:09:08.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T12:09:38.891+0000] {processor.py:157} INFO - Started process (PID=10548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:09:38.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:09:38.896+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:09:38.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:09:38.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:09:38.926+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:09:38.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:09:38.937+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:09:38.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:09:38.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T12:10:09.292+0000] {processor.py:157} INFO - Started process (PID=10558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:10:09.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:10:09.295+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:10:09.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:10:09.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:10:09.340+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:10:09.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:10:09.365+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:10:09.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:10:09.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T12:10:39.661+0000] {processor.py:157} INFO - Started process (PID=10568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:10:39.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:10:39.669+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:10:39.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:10:39.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:10:39.696+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:10:39.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:10:39.709+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:10:39.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:10:39.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T12:11:10.123+0000] {processor.py:157} INFO - Started process (PID=10578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:11:10.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:11:10.128+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:11:10.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:11:10.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:11:10.196+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:11:10.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:11:10.210+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:11:10.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:11:10.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T12:11:40.599+0000] {processor.py:157} INFO - Started process (PID=10588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:11:40.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:11:40.603+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:11:40.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:11:40.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:11:40.635+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:11:40.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:11:40.653+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:11:40.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:11:40.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T12:12:11.009+0000] {processor.py:157} INFO - Started process (PID=10598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:12:11.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:12:11.017+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:12:11.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:12:11.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:12:11.043+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:12:11.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:12:11.057+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:12:11.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:12:11.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T12:12:41.409+0000] {processor.py:157} INFO - Started process (PID=10608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:12:41.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:12:41.411+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:12:41.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:12:41.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:12:41.444+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:12:41.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:12:41.460+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:12:41.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:12:41.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T12:13:11.739+0000] {processor.py:157} INFO - Started process (PID=10618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:13:11.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:13:11.741+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:13:11.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:13:11.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:13:11.769+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:13:11.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:13:11.782+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:13:11.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:13:11.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-15T12:13:42.071+0000] {processor.py:157} INFO - Started process (PID=10628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:13:42.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:13:42.073+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:13:42.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:13:42.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:13:42.101+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:13:42.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:13:42.110+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:13:42.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:13:42.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-15T12:14:12.543+0000] {processor.py:157} INFO - Started process (PID=10638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:14:12.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:14:12.546+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:14:12.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:14:12.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:14:12.608+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:14:12.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:14:12.624+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:14:12.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:14:12.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T12:14:42.854+0000] {processor.py:157} INFO - Started process (PID=10648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:14:42.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:14:42.859+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:14:42.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:14:42.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:14:42.897+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:14:42.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:14:42.912+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:14:42.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:14:42.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T12:15:13.180+0000] {processor.py:157} INFO - Started process (PID=10658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:15:13.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:15:13.184+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:15:13.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:15:13.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:15:13.210+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:15:13.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:15:13.224+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:15:13.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:15:13.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T12:15:43.555+0000] {processor.py:157} INFO - Started process (PID=10668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:15:43.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:15:43.559+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:15:43.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:15:43.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:15:43.590+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:15:43.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:15:43.603+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:15:43.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:15:43.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T12:16:13.986+0000] {processor.py:157} INFO - Started process (PID=10678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:16:13.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:16:13.992+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:16:13.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:16:14.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:16:14.024+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:16:14.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:16:14.037+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:16:14.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:16:14.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T12:16:44.352+0000] {processor.py:157} INFO - Started process (PID=10688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:16:44.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:16:44.357+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:16:44.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:16:44.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:16:44.393+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:16:44.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:16:44.406+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:16:44.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:16:44.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T12:17:14.847+0000] {processor.py:157} INFO - Started process (PID=10698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:17:14.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:17:14.857+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:17:14.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:17:14.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:17:14.883+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:17:14.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:17:14.898+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:17:14.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:17:14.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T12:17:45.307+0000] {processor.py:157} INFO - Started process (PID=10708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:17:45.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:17:45.317+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:17:45.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:17:45.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:17:45.342+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:17:45.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:17:45.357+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:17:45.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:17:45.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T12:18:15.762+0000] {processor.py:157} INFO - Started process (PID=10718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:18:15.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:18:15.765+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:18:15.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:18:15.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:18:15.792+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:18:15.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:18:15.804+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:18:15.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:18:15.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-15T12:18:46.290+0000] {processor.py:157} INFO - Started process (PID=10728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:18:46.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:18:46.295+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:18:46.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:18:46.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:18:46.327+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:18:46.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:18:46.342+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:18:46.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:18:46.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T12:19:16.810+0000] {processor.py:157} INFO - Started process (PID=10738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:19:16.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:19:16.814+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:19:16.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:19:16.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:19:16.849+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:19:16.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:19:16.862+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:19:16.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:19:16.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-15T12:19:47.241+0000] {processor.py:157} INFO - Started process (PID=10748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:19:47.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:19:47.248+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:19:47.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:19:47.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:19:47.274+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:19:47.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:19:47.291+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:19:47.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:19:47.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T12:20:17.619+0000] {processor.py:157} INFO - Started process (PID=10758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:20:17.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:20:17.625+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:20:17.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:20:17.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:20:17.654+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:20:17.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:20:17.669+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:20:17.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:20:17.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T12:20:48.109+0000] {processor.py:157} INFO - Started process (PID=10768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:20:48.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:20:48.117+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:20:48.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:20:48.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:20:48.137+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:20:48.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:20:48.149+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:20:48.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:20:48.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-15T12:21:18.567+0000] {processor.py:157} INFO - Started process (PID=10778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:21:18.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:21:18.571+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:21:18.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:21:18.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:21:18.610+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:21:18.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:21:18.621+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:21:18.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:21:18.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-15T12:21:49.035+0000] {processor.py:157} INFO - Started process (PID=10788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:21:49.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:21:49.038+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:21:49.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:21:49.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:21:49.068+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:21:49.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:21:49.081+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:21:49.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:21:49.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T12:22:19.468+0000] {processor.py:157} INFO - Started process (PID=10798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:22:19.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:22:19.477+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:22:19.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:22:19.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:22:19.502+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:22:19.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:22:19.517+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:22:19.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:22:19.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T12:22:49.943+0000] {processor.py:157} INFO - Started process (PID=10808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:22:49.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:22:49.949+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:22:49.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:22:49.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:22:49.988+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:22:49.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:22:49.999+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:22:49.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:22:50.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-15T12:23:20.338+0000] {processor.py:157} INFO - Started process (PID=10818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:23:20.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:23:20.350+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:23:20.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:23:20.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:23:20.376+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:23:20.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:23:20.390+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:23:20.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:23:20.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T12:23:50.617+0000] {processor.py:157} INFO - Started process (PID=10828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:23:50.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:23:50.625+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:23:50.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:23:50.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:23:50.647+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:23:50.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:23:50.661+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:23:50.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:23:50.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T12:24:20.995+0000] {processor.py:157} INFO - Started process (PID=10838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:24:20.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:24:20.999+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:24:20.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:24:21.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:24:21.027+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:24:21.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:24:21.039+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:24:21.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:24:21.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T12:24:51.432+0000] {processor.py:157} INFO - Started process (PID=10848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:24:51.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:24:51.441+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:24:51.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:24:51.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:24:51.470+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:24:51.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:24:51.485+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:24:51.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:24:51.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T12:25:21.807+0000] {processor.py:157} INFO - Started process (PID=10858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:25:21.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:25:21.810+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:25:21.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:25:21.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:25:21.839+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:25:21.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:25:21.852+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:25:21.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:25:21.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T12:25:52.189+0000] {processor.py:157} INFO - Started process (PID=10868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:25:52.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:25:52.192+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:25:52.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:25:52.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:25:52.221+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:25:52.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:25:52.235+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:25:52.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:25:52.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T12:26:22.601+0000] {processor.py:157} INFO - Started process (PID=10878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:26:22.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:26:22.605+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:26:22.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:26:22.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:26:22.640+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:26:22.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:26:22.656+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:26:22.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:26:22.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T12:26:53.083+0000] {processor.py:157} INFO - Started process (PID=10888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:26:53.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:26:53.092+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:26:53.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:26:53.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:26:53.121+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:26:53.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:26:53.136+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:26:53.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:26:53.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T12:27:23.408+0000] {processor.py:157} INFO - Started process (PID=10898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:27:23.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:27:23.410+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:27:23.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:27:23.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:27:23.438+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:27:23.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:27:23.450+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:27:23.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:27:23.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T12:27:53.777+0000] {processor.py:157} INFO - Started process (PID=10908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:27:53.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:27:53.785+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:27:53.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:27:53.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:27:53.806+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:27:53.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:27:53.820+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:27:53.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:27:53.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T12:28:24.124+0000] {processor.py:157} INFO - Started process (PID=10918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:28:24.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:28:24.128+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:28:24.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:28:24.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:28:24.157+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:28:24.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:28:24.171+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:28:24.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:28:24.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T12:28:54.549+0000] {processor.py:157} INFO - Started process (PID=10928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:28:54.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:28:54.553+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:28:54.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:28:54.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:28:54.588+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:28:54.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:28:54.606+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:28:54.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:28:54.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T12:29:24.872+0000] {processor.py:157} INFO - Started process (PID=10938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:29:24.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:29:24.877+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:29:24.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:29:24.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:29:24.907+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:29:24.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:29:24.926+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:29:24.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:29:24.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T12:29:55.407+0000] {processor.py:157} INFO - Started process (PID=10948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:29:55.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:29:55.419+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:29:55.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:29:55.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:29:55.447+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:29:55.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:29:55.460+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:29:55.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:29:55.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-15T12:30:25.908+0000] {processor.py:157} INFO - Started process (PID=10958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:30:25.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:30:25.913+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:30:25.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:30:25.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:30:25.982+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:30:25.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:30:25.998+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:30:25.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:30:26.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T12:30:56.304+0000] {processor.py:157} INFO - Started process (PID=10968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:30:56.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:30:56.312+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:30:56.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:30:56.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:30:56.358+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:30:56.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:30:56.373+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:30:56.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:30:56.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T12:31:26.718+0000] {processor.py:157} INFO - Started process (PID=10978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:31:26.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:31:26.722+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:31:26.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:31:26.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:31:26.779+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:31:26.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:31:26.796+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:31:26.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:31:26.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T12:31:57.199+0000] {processor.py:157} INFO - Started process (PID=10988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:31:57.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:31:57.203+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:31:57.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:31:57.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:31:57.235+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:31:57.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:31:57.252+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:31:57.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:31:57.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T12:32:27.606+0000] {processor.py:157} INFO - Started process (PID=10998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:32:27.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:32:27.610+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:32:27.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:32:27.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:32:27.664+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:32:27.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:32:27.681+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:32:27.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:32:27.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T12:32:58.004+0000] {processor.py:157} INFO - Started process (PID=11008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:32:58.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:32:58.009+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:32:58.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:32:58.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:32:58.046+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:32:58.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:32:58.061+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:32:58.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:32:58.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T12:33:28.510+0000] {processor.py:157} INFO - Started process (PID=11018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:33:28.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:33:28.513+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:33:28.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:33:28.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:33:28.540+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:33:28.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:33:28.558+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:33:28.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:33:28.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T12:33:59.013+0000] {processor.py:157} INFO - Started process (PID=11028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:33:59.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:33:59.017+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:33:59.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:33:59.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:33:59.102+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:33:59.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:33:59.123+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:33:59.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:33:59.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T12:34:29.607+0000] {processor.py:157} INFO - Started process (PID=11038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:34:29.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:34:29.612+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:34:29.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:34:29.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:34:29.656+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:34:29.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:34:29.672+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:34:29.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:34:29.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T12:35:00.092+0000] {processor.py:157} INFO - Started process (PID=11048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:35:00.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:35:00.095+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:35:00.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:35:00.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:35:00.123+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:35:00.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:35:00.141+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:35:00.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:35:00.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T12:35:30.646+0000] {processor.py:157} INFO - Started process (PID=11058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:35:30.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:35:30.648+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:35:30.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:35:30.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:35:30.680+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:35:30.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:35:30.696+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:35:30.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:35:30.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-15T12:36:01.050+0000] {processor.py:157} INFO - Started process (PID=11068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:36:01.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:36:01.056+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:36:01.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:36:01.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:36:01.136+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:36:01.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:36:01.152+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:36:01.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:36:01.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T12:36:31.432+0000] {processor.py:157} INFO - Started process (PID=11078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:36:31.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:36:31.436+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:36:31.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:36:31.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:36:31.468+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:36:31.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:36:31.482+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:36:31.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:36:31.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T12:37:01.950+0000] {processor.py:157} INFO - Started process (PID=11086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:37:01.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:37:01.955+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:37:01.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:37:01.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:37:02.022+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:37:02.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:37:02.038+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:37:02.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:37:02.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T12:37:32.341+0000] {processor.py:157} INFO - Started process (PID=11098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:37:32.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:37:32.351+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:37:32.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:37:32.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:37:32.376+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:37:32.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:37:32.393+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:37:32.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:37:32.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T12:38:02.811+0000] {processor.py:157} INFO - Started process (PID=11108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:38:02.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:38:02.815+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:38:02.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:38:02.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:38:02.853+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:38:02.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:38:02.867+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:38:02.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:38:02.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T12:38:33.233+0000] {processor.py:157} INFO - Started process (PID=11118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:38:33.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:38:33.240+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:38:33.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:38:33.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:38:33.281+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:38:33.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:38:33.296+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:38:33.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:38:33.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T12:39:03.524+0000] {processor.py:157} INFO - Started process (PID=11128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:39:03.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:39:03.529+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:39:03.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:39:03.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:39:03.563+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:39:03.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:39:03.578+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:39:03.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:39:03.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T12:39:33.985+0000] {processor.py:157} INFO - Started process (PID=11137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:39:33.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:39:33.993+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:39:33.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:39:34.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:39:34.034+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:39:34.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:39:34.047+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:39:34.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:39:34.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T12:40:04.435+0000] {processor.py:157} INFO - Started process (PID=11148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:40:04.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:40:04.439+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:40:04.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:40:04.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:40:04.473+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:40:04.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:40:04.486+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:40:04.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:40:04.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-15T12:40:34.816+0000] {processor.py:157} INFO - Started process (PID=11158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:40:34.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:40:34.825+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:40:34.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:40:34.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:40:34.889+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:40:34.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:40:34.905+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:40:34.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:40:34.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T12:52:02.162+0000] {processor.py:157} INFO - Started process (PID=11167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:52:02.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:52:02.176+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:52:02.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:52:02.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:52:02.287+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:52:02.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:52:02.335+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:52:02.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:52:02.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.232 seconds
[2024-09-15T12:52:32.615+0000] {processor.py:157} INFO - Started process (PID=11179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:52:32.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T12:52:32.627+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:52:32.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:52:32.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T12:52:32.690+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:52:32.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T12:52:32.707+0000] {logging_mixin.py:151} INFO - [2024-09-15T12:52:32.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T12:52:32.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T13:00:18.047+0000] {processor.py:157} INFO - Started process (PID=11192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:00:18.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:00:18.055+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:00:18.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:00:18.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:00:18.123+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:00:18.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:00:18.152+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:00:18.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:00:18.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-15T13:00:48.565+0000] {processor.py:157} INFO - Started process (PID=11201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:00:48.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:00:48.571+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:00:48.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:00:48.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:00:48.632+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:00:48.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:00:48.662+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:00:48.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:00:48.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T13:01:18.912+0000] {processor.py:157} INFO - Started process (PID=11212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:01:18.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:01:18.920+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:01:18.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:01:18.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:01:18.969+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:01:18.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:01:18.986+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:01:18.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:01:18.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T13:01:49.271+0000] {processor.py:157} INFO - Started process (PID=11222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:01:49.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:01:49.276+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:01:49.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:01:49.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:01:49.309+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:01:49.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:01:49.321+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:01:49.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:01:49.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T13:02:19.656+0000] {processor.py:157} INFO - Started process (PID=11231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:02:19.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:02:19.663+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:02:19.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:02:19.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:02:19.716+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:02:19.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:02:19.739+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:02:19.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:02:19.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T13:02:49.965+0000] {processor.py:157} INFO - Started process (PID=11242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:02:49.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:02:49.968+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:02:49.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:02:49.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:02:50.001+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:02:50.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:02:50.015+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:02:50.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:02:50.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T13:03:20.461+0000] {processor.py:157} INFO - Started process (PID=11251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:03:20.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:03:20.467+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:03:20.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:03:20.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:03:20.525+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:03:20.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:03:20.541+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:03:20.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:03:20.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T13:03:50.802+0000] {processor.py:157} INFO - Started process (PID=11262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:03:50.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:03:50.805+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:03:50.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:03:50.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:03:50.833+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:03:50.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:03:50.851+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:03:50.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:03:50.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T13:04:21.229+0000] {processor.py:157} INFO - Started process (PID=11271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:04:21.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:04:21.234+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:04:21.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:04:21.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:04:21.294+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:04:21.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:04:21.312+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:04:21.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:04:21.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T13:04:51.744+0000] {processor.py:157} INFO - Started process (PID=11282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:04:51.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:04:51.753+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:04:51.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:04:51.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:04:51.798+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:04:51.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:04:51.816+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:04:51.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:04:51.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T13:21:24.031+0000] {processor.py:157} INFO - Started process (PID=11294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:21:24.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:21:24.035+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:21:24.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:21:24.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:21:24.076+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:21:24.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:21:24.091+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:21:24.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:21:24.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T13:21:54.490+0000] {processor.py:157} INFO - Started process (PID=11304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:21:54.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:21:54.498+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:21:54.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:21:54.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:21:54.578+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:21:54.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:21:54.596+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:21:54.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:21:54.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T13:22:24.916+0000] {processor.py:157} INFO - Started process (PID=11314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:22:24.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:22:24.920+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:22:24.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:22:24.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:22:24.951+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:22:24.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:22:24.966+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:22:24.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:22:24.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T13:22:55.313+0000] {processor.py:157} INFO - Started process (PID=11324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:22:55.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:22:55.317+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:22:55.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:22:55.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:22:55.359+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:22:55.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:22:55.375+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:22:55.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:22:55.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T13:39:50.111+0000] {processor.py:157} INFO - Started process (PID=11336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:39:50.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:39:50.120+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:39:50.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:39:50.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:39:50.181+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:39:50.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:39:50.210+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:39:50.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:39:50.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-15T13:40:20.511+0000] {processor.py:157} INFO - Started process (PID=11345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:40:20.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:40:20.519+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:40:20.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:40:20.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:40:20.569+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:40:20.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:40:20.586+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:40:20.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:40:20.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T13:40:50.989+0000] {processor.py:157} INFO - Started process (PID=11356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:40:50.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:40:50.993+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:40:50.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:40:51.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:40:51.027+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:40:51.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:40:51.044+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:40:51.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:40:51.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T13:41:21.462+0000] {processor.py:157} INFO - Started process (PID=11366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:41:21.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:41:21.465+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:41:21.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:41:21.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:41:21.500+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:41:21.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:41:21.526+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:41:21.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:41:21.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T13:41:51.894+0000] {processor.py:157} INFO - Started process (PID=11376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:41:51.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:41:51.897+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:41:51.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:41:51.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:41:51.925+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:41:51.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:41:51.960+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:41:51.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:41:51.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T13:42:22.362+0000] {processor.py:157} INFO - Started process (PID=11386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:42:22.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:42:22.367+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:42:22.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:42:22.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:42:22.409+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:42:22.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:42:22.426+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:42:22.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:42:22.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T13:42:52.721+0000] {processor.py:157} INFO - Started process (PID=11396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:42:52.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:42:52.724+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:42:52.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:42:52.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:42:52.754+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:42:52.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:42:52.769+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:42:52.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:42:52.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T13:43:23.085+0000] {processor.py:157} INFO - Started process (PID=11406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:43:23.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:43:23.088+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:43:23.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:43:23.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:43:23.120+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:43:23.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:43:23.135+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:43:23.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:43:23.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-15T13:43:53.529+0000] {processor.py:157} INFO - Started process (PID=11415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:43:53.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:43:53.533+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:43:53.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:43:53.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:43:53.574+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:43:53.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:43:53.590+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:43:53.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:43:53.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T13:44:23.968+0000] {processor.py:157} INFO - Started process (PID=11426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:44:23.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:44:23.971+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:44:23.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:44:23.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:44:24.005+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:44:24.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:44:24.024+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:44:24.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:44:24.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T13:44:54.451+0000] {processor.py:157} INFO - Started process (PID=11436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:44:54.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:44:54.454+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:44:54.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:44:54.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:44:54.497+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:44:54.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:44:54.510+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:44:54.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:44:54.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T13:45:24.930+0000] {processor.py:157} INFO - Started process (PID=11446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:45:24.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:45:24.936+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:45:24.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:45:24.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:45:24.987+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:45:24.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:45:25.007+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:45:25.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:45:25.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T13:45:55.419+0000] {processor.py:157} INFO - Started process (PID=11456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:45:55.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:45:55.423+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:45:55.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:45:55.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:45:55.452+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:45:55.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:45:55.466+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:45:55.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:45:55.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T13:46:25.709+0000] {processor.py:157} INFO - Started process (PID=11466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:46:25.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:46:25.713+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:46:25.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:46:25.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:46:25.743+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:46:25.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:46:25.758+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:46:25.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:46:25.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T13:46:56.155+0000] {processor.py:157} INFO - Started process (PID=11476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:46:56.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:46:56.163+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:46:56.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:46:56.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:46:56.202+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:46:56.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:46:56.219+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:46:56.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:46:56.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T13:47:26.574+0000] {processor.py:157} INFO - Started process (PID=11486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:47:26.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:47:26.577+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:47:26.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:47:26.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:47:26.612+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:47:26.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:47:26.625+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:47:26.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:47:26.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T13:47:56.965+0000] {processor.py:157} INFO - Started process (PID=11496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:47:56.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:47:56.968+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:47:56.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:47:56.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:47:57.003+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:47:57.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:47:57.018+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:47:57.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:47:57.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T13:48:27.316+0000] {processor.py:157} INFO - Started process (PID=11506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:48:27.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:48:27.321+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:48:27.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:48:27.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:48:27.362+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:48:27.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:48:27.380+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:48:27.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:48:27.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T13:48:57.686+0000] {processor.py:157} INFO - Started process (PID=11516) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:48:57.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:48:57.688+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:48:57.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:48:57.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:48:57.718+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:48:57.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:48:57.733+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:48:57.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:48:57.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T13:49:28.032+0000] {processor.py:157} INFO - Started process (PID=11526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:49:28.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:49:28.035+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:49:28.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:49:28.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:49:28.087+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:49:28.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:49:28.105+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:49:28.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:49:28.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T13:49:58.394+0000] {processor.py:157} INFO - Started process (PID=11535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:49:58.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:49:58.419+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:49:58.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:49:58.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:49:58.469+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:49:58.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:49:58.489+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:49:58.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:49:58.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T13:50:28.790+0000] {processor.py:157} INFO - Started process (PID=11546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:50:28.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:50:28.793+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:50:28.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:50:28.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:50:28.826+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:50:28.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:50:28.841+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:50:28.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:50:28.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T13:50:59.207+0000] {processor.py:157} INFO - Started process (PID=11556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:50:59.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:50:59.212+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:50:59.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:50:59.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:50:59.244+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:50:59.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:50:59.256+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:50:59.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:50:59.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T13:51:29.614+0000] {processor.py:157} INFO - Started process (PID=11566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:51:29.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:51:29.617+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:51:29.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:51:29.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:51:29.655+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:51:29.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:51:29.671+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:51:29.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:51:29.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T13:52:00.021+0000] {processor.py:157} INFO - Started process (PID=11576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:52:00.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:52:00.025+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:52:00.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:52:00.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:52:00.063+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:52:00.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:52:00.076+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:52:00.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:52:00.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T13:52:30.324+0000] {processor.py:157} INFO - Started process (PID=11586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:52:30.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:52:30.327+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:52:30.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:52:30.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:52:30.357+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:52:30.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:52:30.388+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:52:30.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:52:30.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T13:53:00.741+0000] {processor.py:157} INFO - Started process (PID=11596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:53:00.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:53:00.744+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:53:00.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:53:00.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:53:00.779+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:53:00.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:53:00.809+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:53:00.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:53:00.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T13:53:31.091+0000] {processor.py:157} INFO - Started process (PID=11606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:53:31.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:53:31.094+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:53:31.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:53:31.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:53:31.124+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:53:31.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:53:31.138+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:53:31.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:53:31.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T13:54:01.401+0000] {processor.py:157} INFO - Started process (PID=11616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:54:01.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:54:01.406+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:54:01.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:54:01.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:54:01.447+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:54:01.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:54:01.461+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:54:01.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:54:01.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T13:54:31.763+0000] {processor.py:157} INFO - Started process (PID=11626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:54:31.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:54:31.767+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:54:31.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:54:31.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:54:31.800+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:54:31.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:54:31.816+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:54:31.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:54:31.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-15T13:55:02.146+0000] {processor.py:157} INFO - Started process (PID=11636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:55:02.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:55:02.153+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:55:02.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:55:02.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:55:02.195+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:55:02.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:55:02.226+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:55:02.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:55:02.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T13:55:32.566+0000] {processor.py:157} INFO - Started process (PID=11646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:55:32.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:55:32.571+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:55:32.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:55:32.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:55:32.601+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:55:32.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:55:32.619+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:55:32.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:55:32.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T13:56:02.978+0000] {processor.py:157} INFO - Started process (PID=11656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:56:02.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:56:02.982+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:56:02.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:56:02.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:56:03.015+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:56:03.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:56:03.033+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:56:03.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:56:03.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T13:56:33.502+0000] {processor.py:157} INFO - Started process (PID=11666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:56:33.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:56:33.520+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:56:33.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:56:33.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:56:33.560+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:56:33.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:56:33.581+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:56:33.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:56:33.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T13:57:03.898+0000] {processor.py:157} INFO - Started process (PID=11676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:57:03.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:57:03.902+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:57:03.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:57:03.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:57:03.935+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:57:03.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:57:03.968+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:57:03.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:57:03.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T13:57:34.275+0000] {processor.py:157} INFO - Started process (PID=11686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:57:34.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:57:34.279+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:57:34.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:57:34.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:57:34.319+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:57:34.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:57:34.335+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:57:34.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:57:34.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T13:58:04.666+0000] {processor.py:157} INFO - Started process (PID=11696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:58:04.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:58:04.669+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:58:04.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:58:04.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:58:04.707+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:58:04.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:58:04.739+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:58:04.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:58:04.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T13:58:35.038+0000] {processor.py:157} INFO - Started process (PID=11706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:58:35.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:58:35.042+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:58:35.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:58:35.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:58:35.082+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:58:35.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:58:35.096+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:58:35.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:58:35.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T13:59:05.457+0000] {processor.py:157} INFO - Started process (PID=11716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:59:05.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:59:05.461+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:59:05.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:59:05.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:59:05.497+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:59:05.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:59:05.514+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:59:05.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:59:05.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-15T13:59:35.845+0000] {processor.py:157} INFO - Started process (PID=11725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:59:35.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T13:59:35.851+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:59:35.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:59:35.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T13:59:35.920+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:59:35.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T13:59:35.938+0000] {logging_mixin.py:151} INFO - [2024-09-15T13:59:35.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T13:59:35.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T14:00:06.201+0000] {processor.py:157} INFO - Started process (PID=11736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:00:06.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:00:06.206+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:00:06.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:00:06.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:00:06.246+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:00:06.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:00:06.279+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:00:06.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:00:06.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T14:00:36.660+0000] {processor.py:157} INFO - Started process (PID=11746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:00:36.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:00:36.663+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:00:36.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:00:36.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:00:36.723+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:00:36.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:00:36.747+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:00:36.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:00:36.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T14:01:07.038+0000] {processor.py:157} INFO - Started process (PID=11755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:01:07.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:01:07.055+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:01:07.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:01:07.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:01:07.109+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:01:07.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:01:07.142+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:01:07.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:01:07.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T14:01:37.535+0000] {processor.py:157} INFO - Started process (PID=11766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:01:37.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:01:37.540+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:01:37.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:01:37.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:01:37.579+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:01:37.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:01:37.595+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:01:37.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:01:37.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-15T14:02:07.986+0000] {processor.py:157} INFO - Started process (PID=11776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:02:07.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:02:07.991+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:02:07.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:02:08.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:02:08.031+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:02:08.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:02:08.047+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:02:08.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:02:08.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T14:02:38.391+0000] {processor.py:157} INFO - Started process (PID=11786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:02:38.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:02:38.396+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:02:38.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:02:38.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:02:38.427+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:02:38.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:02:38.442+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:02:38.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:02:38.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T14:03:08.782+0000] {processor.py:157} INFO - Started process (PID=11796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:03:08.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:03:08.786+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:03:08.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:03:08.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:03:08.815+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:03:08.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:03:08.835+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:03:08.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:03:08.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-15T14:03:39.252+0000] {processor.py:157} INFO - Started process (PID=11806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:03:39.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:03:39.259+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:03:39.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:03:39.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:03:39.300+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:03:39.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:03:39.331+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:03:39.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:03:39.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T14:04:09.651+0000] {processor.py:157} INFO - Started process (PID=11816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:04:09.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:04:09.656+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:04:09.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:04:09.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:04:09.691+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:04:09.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:04:09.724+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:04:09.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:04:09.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T14:04:40.121+0000] {processor.py:157} INFO - Started process (PID=11826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:04:40.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:04:40.127+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:04:40.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:04:40.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:04:40.165+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:04:40.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:04:40.183+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:04:40.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:04:40.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T14:05:10.438+0000] {processor.py:157} INFO - Started process (PID=11836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:05:10.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:05:10.440+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:05:10.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:05:10.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:05:10.472+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:05:10.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:05:10.488+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:05:10.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:05:10.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T14:05:40.853+0000] {processor.py:157} INFO - Started process (PID=11846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:05:40.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:05:40.861+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:05:40.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:05:40.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:05:40.897+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:05:40.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:05:40.916+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:05:40.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:05:40.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T14:06:11.234+0000] {processor.py:157} INFO - Started process (PID=11856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:06:11.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:06:11.237+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:06:11.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:06:11.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:06:11.268+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:06:11.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:06:11.280+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:06:11.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:06:11.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-15T14:06:41.699+0000] {processor.py:157} INFO - Started process (PID=11866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:06:41.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:06:41.703+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:06:41.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:06:41.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:06:41.740+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:06:41.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:06:41.756+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:06:41.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:06:41.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T14:07:12.163+0000] {processor.py:157} INFO - Started process (PID=11876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:07:12.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:07:12.165+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:07:12.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:07:12.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:07:12.197+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:07:12.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:07:12.212+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:07:12.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:07:12.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T14:07:42.551+0000] {processor.py:157} INFO - Started process (PID=11886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:07:42.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:07:42.557+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:07:42.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:07:42.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:07:42.600+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:07:42.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:07:42.617+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:07:42.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:07:42.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T14:08:12.886+0000] {processor.py:157} INFO - Started process (PID=11896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:08:12.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:08:12.890+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:08:12.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:08:12.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:08:12.932+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:08:12.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:08:12.946+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:08:12.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:08:12.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T14:08:43.258+0000] {processor.py:157} INFO - Started process (PID=11906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:08:43.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:08:43.264+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:08:43.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:08:43.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:08:43.308+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:08:43.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:08:43.324+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:08:43.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:08:43.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T14:09:13.600+0000] {processor.py:157} INFO - Started process (PID=11916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:09:13.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:09:13.605+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:09:13.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:09:13.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:09:13.644+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:09:13.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:09:13.672+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:09:13.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:09:13.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T14:09:43.881+0000] {processor.py:157} INFO - Started process (PID=11926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:09:43.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:09:43.885+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:09:43.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:09:43.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:09:43.918+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:09:43.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:09:43.935+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:09:43.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:09:43.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-15T14:10:14.341+0000] {processor.py:157} INFO - Started process (PID=11936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:10:14.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:10:14.345+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:10:14.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:10:14.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:10:14.383+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:10:14.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:10:14.399+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:10:14.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:10:14.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T14:10:44.689+0000] {processor.py:157} INFO - Started process (PID=11946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:10:44.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:10:44.695+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:10:44.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:10:44.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:10:44.756+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:10:44.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:10:44.773+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:10:44.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:10:44.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T14:11:15.022+0000] {processor.py:157} INFO - Started process (PID=11956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:11:15.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:11:15.025+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:11:15.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:11:15.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:11:15.057+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:11:15.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:11:15.074+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:11:15.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:11:15.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T14:11:45.492+0000] {processor.py:157} INFO - Started process (PID=11965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:11:45.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:11:45.498+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:11:45.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:11:45.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:11:45.545+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:11:45.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:11:45.571+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:11:45.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:11:45.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T14:12:15.938+0000] {processor.py:157} INFO - Started process (PID=11976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:12:15.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:12:15.944+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:12:15.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:12:15.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:12:15.975+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:12:15.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:12:15.991+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:12:15.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:12:16.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T14:12:46.363+0000] {processor.py:157} INFO - Started process (PID=11986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:12:46.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:12:46.367+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:12:46.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:12:46.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:12:46.405+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:12:46.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:12:46.422+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:12:46.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:12:46.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T14:13:16.811+0000] {processor.py:157} INFO - Started process (PID=11996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:13:16.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:13:16.814+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:13:16.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:13:16.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:13:16.861+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:13:16.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:13:16.877+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:13:16.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:13:16.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T14:13:47.156+0000] {processor.py:157} INFO - Started process (PID=12006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:13:47.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:13:47.180+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:13:47.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:13:47.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:13:47.234+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:13:47.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:13:47.267+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:13:47.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:13:47.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-15T14:14:17.507+0000] {processor.py:157} INFO - Started process (PID=12016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:14:17.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:14:17.511+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:14:17.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:14:17.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:14:17.545+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:14:17.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:14:17.560+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:14:17.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:14:17.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T14:14:47.917+0000] {processor.py:157} INFO - Started process (PID=12026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:14:47.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:14:47.924+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:14:47.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:14:47.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:14:47.962+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:14:47.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:14:47.978+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:14:47.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:14:47.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-15T14:15:18.245+0000] {processor.py:157} INFO - Started process (PID=12036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:15:18.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:15:18.248+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:15:18.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:15:18.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:15:18.277+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:15:18.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:15:18.292+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:15:18.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:15:18.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T14:15:48.709+0000] {processor.py:157} INFO - Started process (PID=12046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:15:48.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:15:48.714+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:15:48.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:15:48.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:15:48.755+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:15:48.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:15:48.773+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:15:48.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:15:48.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T14:16:19.191+0000] {processor.py:157} INFO - Started process (PID=12056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:16:19.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:16:19.194+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:16:19.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:16:19.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:16:19.224+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:16:19.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:16:19.239+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:16:19.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:16:19.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T14:16:49.633+0000] {processor.py:157} INFO - Started process (PID=12066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:16:49.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:16:49.636+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:16:49.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:16:49.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:16:49.666+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:16:49.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:16:49.681+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:16:49.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:16:49.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T14:17:20.045+0000] {processor.py:157} INFO - Started process (PID=12076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:17:20.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:17:20.048+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:17:20.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:17:20.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:17:20.078+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:17:20.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:17:20.100+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:17:20.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:17:20.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-15T14:17:50.432+0000] {processor.py:157} INFO - Started process (PID=12086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:17:50.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:17:50.435+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:17:50.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:17:50.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:17:50.489+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:17:50.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:17:50.520+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:17:50.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:17:50.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T14:18:20.897+0000] {processor.py:157} INFO - Started process (PID=12096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:18:20.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:18:20.904+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:18:20.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:18:20.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:18:20.945+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:18:20.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:18:20.965+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:18:20.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:18:20.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T14:18:51.290+0000] {processor.py:157} INFO - Started process (PID=12106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:18:51.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:18:51.294+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:18:51.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:18:51.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:18:51.355+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:18:51.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:18:51.372+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:18:51.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:18:51.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T14:19:21.820+0000] {processor.py:157} INFO - Started process (PID=12116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:19:21.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:19:21.825+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:19:21.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:19:21.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:19:21.861+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:19:21.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:19:21.878+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:19:21.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:19:21.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T14:19:52.219+0000] {processor.py:157} INFO - Started process (PID=12126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:19:52.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:19:52.229+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:19:52.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:19:52.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:19:52.299+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:19:52.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:19:52.317+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:19:52.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:19:52.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T14:20:22.527+0000] {processor.py:157} INFO - Started process (PID=12135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:20:22.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:20:22.535+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:20:22.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:20:22.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:20:22.591+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:20:22.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:20:22.608+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:20:22.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:20:22.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T14:20:52.854+0000] {processor.py:157} INFO - Started process (PID=12146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:20:52.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:20:52.858+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:20:52.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:20:52.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:20:52.892+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:20:52.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:20:52.906+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:20:52.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:20:52.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T14:21:23.313+0000] {processor.py:157} INFO - Started process (PID=12156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:21:23.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:21:23.319+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:21:23.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:21:23.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:21:23.380+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:21:23.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:21:23.399+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:21:23.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:21:23.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T14:21:53.718+0000] {processor.py:157} INFO - Started process (PID=12166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:21:53.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:21:53.722+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:21:53.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:21:53.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:21:53.757+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:21:53.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:21:53.774+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:21:53.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:21:53.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T14:22:24.193+0000] {processor.py:157} INFO - Started process (PID=12176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:22:24.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:22:24.199+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:22:24.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:22:24.217+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:22:24.247+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:22:24.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:22:24.274+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:22:24.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:22:24.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T14:22:54.674+0000] {processor.py:157} INFO - Started process (PID=12186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:22:54.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:22:54.679+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:22:54.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:22:54.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:22:54.720+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:22:54.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:22:54.736+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:22:54.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:22:54.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T14:23:25.031+0000] {processor.py:157} INFO - Started process (PID=12195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:23:25.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:23:25.043+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:23:25.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:23:25.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:23:25.119+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:23:25.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:23:25.136+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:23:25.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:23:25.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T14:23:55.326+0000] {processor.py:157} INFO - Started process (PID=12206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:23:55.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:23:55.331+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:23:55.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:23:55.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:23:55.367+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:23:55.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:23:55.382+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:23:55.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:23:55.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T14:24:25.697+0000] {processor.py:157} INFO - Started process (PID=12215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:24:25.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:24:25.703+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:24:25.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:24:25.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:24:25.771+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:24:25.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:24:25.788+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:24:25.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:24:25.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T14:24:56.067+0000] {processor.py:157} INFO - Started process (PID=12226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:24:56.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:24:56.071+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:24:56.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:24:56.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:24:56.104+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:24:56.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:24:56.144+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:24:56.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:24:56.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T14:25:26.552+0000] {processor.py:157} INFO - Started process (PID=12234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:25:26.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:25:26.558+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:25:26.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:25:26.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:25:26.606+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:25:26.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:25:26.634+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:25:26.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:25:26.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T14:25:56.958+0000] {processor.py:157} INFO - Started process (PID=12246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:25:56.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:25:56.961+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:25:56.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:25:56.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:25:56.998+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:25:56.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:25:57.019+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:25:57.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:25:57.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T14:26:27.449+0000] {processor.py:157} INFO - Started process (PID=12256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:26:27.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:26:27.462+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:26:27.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:26:27.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:26:27.525+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:26:27.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:26:27.541+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:26:27.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:26:27.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T14:26:57.813+0000] {processor.py:157} INFO - Started process (PID=12266) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:26:57.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:26:57.816+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:26:57.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:26:57.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:26:57.851+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:26:57.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:26:57.865+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:26:57.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:26:57.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T14:27:28.152+0000] {processor.py:157} INFO - Started process (PID=12275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:27:28.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:27:28.171+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:27:28.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:27:28.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:27:28.219+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:27:28.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:27:28.252+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:27:28.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:27:28.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T14:27:58.438+0000] {processor.py:157} INFO - Started process (PID=12286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:27:58.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:27:58.441+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:27:58.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:27:58.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:27:58.476+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:27:58.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:27:58.507+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:27:58.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:27:58.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T14:28:28.897+0000] {processor.py:157} INFO - Started process (PID=12295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:28:28.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:28:28.901+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:28:28.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:28:28.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:28:28.951+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:28:28.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:28:28.968+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:28:28.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:28:28.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T14:28:59.290+0000] {processor.py:157} INFO - Started process (PID=12304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:28:59.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:28:59.297+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:28:59.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:28:59.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:28:59.328+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:28:59.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:28:59.343+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:28:59.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:28:59.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T14:29:29.844+0000] {processor.py:157} INFO - Started process (PID=12314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:29:29.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:29:29.849+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:29:29.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:29:29.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:29:29.894+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:29:29.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:29:29.922+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:29:29.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:29:29.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T14:30:00.264+0000] {processor.py:157} INFO - Started process (PID=12326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:30:00.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:30:00.272+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:30:00.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:30:00.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:30:00.330+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:30:00.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:30:00.348+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:30:00.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:30:00.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T14:30:30.785+0000] {processor.py:157} INFO - Started process (PID=12336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:30:30.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:30:30.792+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:30:30.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:30:30.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:30:30.834+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:30:30.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:30:30.850+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:30:30.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:30:30.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T14:31:01.090+0000] {processor.py:157} INFO - Started process (PID=12346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:31:01.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:31:01.094+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:31:01.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:31:01.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:31:01.136+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:31:01.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:31:01.160+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:31:01.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:31:01.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T14:31:31.716+0000] {processor.py:157} INFO - Started process (PID=12356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:31:31.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:31:31.733+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:31:31.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:31:31.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:31:31.841+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:31:31.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:31:31.872+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:31:31.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:31:31.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-09-15T14:32:02.097+0000] {processor.py:157} INFO - Started process (PID=12366) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:32:02.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:32:02.111+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:32:02.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:32:02.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:32:02.185+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:32:02.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:32:02.220+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:32:02.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:32:02.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-15T14:32:32.646+0000] {processor.py:157} INFO - Started process (PID=12376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:32:32.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:32:32.655+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:32:32.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:32:32.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:32:32.727+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:32:32.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:32:32.755+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:32:32.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:32:32.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T14:33:03.201+0000] {processor.py:157} INFO - Started process (PID=12385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:33:03.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:33:03.211+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:33:03.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:33:03.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:33:03.295+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:33:03.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:33:03.321+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:33:03.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:33:03.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-15T14:33:34.096+0000] {processor.py:157} INFO - Started process (PID=12396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:33:34.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:33:34.115+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:33:34.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:33:34.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:33:34.307+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:33:34.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:33:34.402+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:33:34.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:33:34.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.362 seconds
[2024-09-15T14:34:04.828+0000] {processor.py:157} INFO - Started process (PID=12405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:34:04.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:34:04.841+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:34:04.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:34:04.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:34:04.962+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:34:04.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:34:05.001+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:34:05.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:34:05.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-09-15T14:34:35.317+0000] {processor.py:157} INFO - Started process (PID=12416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:34:35.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:34:35.334+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:34:35.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:34:35.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:34:35.553+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:34:35.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:34:35.597+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:34:35.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:34:35.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.307 seconds
[2024-09-15T14:35:05.967+0000] {processor.py:157} INFO - Started process (PID=12426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:35:05.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:35:05.990+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:35:05.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:35:06.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:35:06.084+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:35:06.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:35:06.111+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:35:06.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:35:06.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-15T14:35:36.340+0000] {processor.py:157} INFO - Started process (PID=12436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:35:36.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:35:36.353+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:35:36.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:35:36.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:35:36.445+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:35:36.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:35:36.479+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:35:36.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:35:36.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-09-15T14:36:06.783+0000] {processor.py:157} INFO - Started process (PID=12446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:36:06.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:36:06.790+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:36:06.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:36:06.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:36:06.884+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:36:06.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:36:06.921+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:36:06.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:36:06.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-15T14:36:37.174+0000] {processor.py:157} INFO - Started process (PID=12456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:36:37.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:36:37.180+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:36:37.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:36:37.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:36:37.244+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:36:37.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:36:37.274+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:36:37.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:36:37.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-15T14:37:07.588+0000] {processor.py:157} INFO - Started process (PID=12466) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:37:07.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:37:07.595+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:37:07.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:37:07.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:37:07.707+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:37:07.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:37:07.744+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:37:07.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:37:07.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.214 seconds
[2024-09-15T14:37:37.916+0000] {processor.py:157} INFO - Started process (PID=12624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:37:37.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:37:37.925+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:37:37.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:37:38.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:37:38.311+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:37:38.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:37:38.434+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:37:38.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:37:38.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.577 seconds
[2024-09-15T14:38:08.823+0000] {processor.py:157} INFO - Started process (PID=12722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:38:08.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:38:08.838+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:38:08.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:38:08.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:38:08.989+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:38:08.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:38:09.025+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:38:09.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:38:09.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.234 seconds
[2024-09-15T14:38:39.163+0000] {processor.py:157} INFO - Started process (PID=12733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:38:39.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:38:39.171+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:38:39.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:38:39.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:38:39.256+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:38:39.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:38:39.280+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:38:39.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:38:39.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-15T14:39:09.665+0000] {processor.py:157} INFO - Started process (PID=12743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:39:09.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:39:09.672+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:39:09.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:39:09.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:39:09.763+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:39:09.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:39:09.782+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:39:09.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:39:09.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-15T14:39:40.294+0000] {processor.py:157} INFO - Started process (PID=12753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:39:40.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:39:40.299+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:39:40.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:39:40.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:39:40.375+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:39:40.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:39:40.401+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:39:40.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:39:40.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-15T14:40:10.759+0000] {processor.py:157} INFO - Started process (PID=12762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:40:10.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:40:10.775+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:40:10.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:40:10.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:40:10.929+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:40:10.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:40:10.955+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:40:10.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:40:10.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.230 seconds
[2024-09-15T14:40:41.093+0000] {processor.py:157} INFO - Started process (PID=12773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:40:41.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:40:41.100+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:40:41.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:40:41.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:40:41.195+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:40:41.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:40:41.218+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:40:41.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:40:41.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-15T14:41:11.581+0000] {processor.py:157} INFO - Started process (PID=12783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:41:11.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:41:11.588+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:41:11.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:41:11.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:41:11.696+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:41:11.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:41:11.723+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:41:11.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:41:11.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-15T14:41:42.009+0000] {processor.py:157} INFO - Started process (PID=12793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:41:42.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:41:42.020+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:41:42.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:41:42.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:41:42.115+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:41:42.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:41:42.148+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:41:42.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:41:42.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-15T14:42:12.411+0000] {processor.py:157} INFO - Started process (PID=12803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:42:12.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:42:12.432+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:42:12.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:42:12.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:42:12.569+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:42:12.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:42:12.596+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:42:12.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:42:12.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.229 seconds
[2024-09-15T14:42:43.023+0000] {processor.py:157} INFO - Started process (PID=12812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:42:43.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:42:43.031+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:42:43.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:42:43.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:42:43.149+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:42:43.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:42:43.176+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:42:43.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:42:43.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-15T14:43:13.350+0000] {processor.py:157} INFO - Started process (PID=12823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:43:13.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:43:13.363+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:43:13.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:43:13.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:43:13.499+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:43:13.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:43:13.526+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:43:13.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:43:13.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-09-15T14:43:43.770+0000] {processor.py:157} INFO - Started process (PID=12833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:43:43.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:43:43.785+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:43:43.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:43:43.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:43:43.888+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:43:43.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:43:43.916+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:43:43.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:43:43.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-09-15T14:44:14.170+0000] {processor.py:157} INFO - Started process (PID=12843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:44:14.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:44:14.192+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:44:14.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:44:14.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:44:14.272+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:44:14.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:44:14.291+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:44:14.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:44:14.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-15T14:44:44.504+0000] {processor.py:157} INFO - Started process (PID=12853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:44:44.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:44:44.514+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:44:44.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:44:44.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:44:44.611+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:44:44.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:44:44.637+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:44:44.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:44:44.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-09-15T14:45:14.911+0000] {processor.py:157} INFO - Started process (PID=12863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:45:14.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:45:14.922+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:45:14.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:45:14.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:45:14.994+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:45:14.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:45:15.046+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:45:15.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:45:15.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-09-15T14:45:45.264+0000] {processor.py:157} INFO - Started process (PID=12873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:45:45.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:45:45.271+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:45:45.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:45:45.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:45:45.335+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:45:45.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:45:45.352+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:45:45.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:45:45.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T14:46:15.596+0000] {processor.py:157} INFO - Started process (PID=12883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:46:15.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:46:15.607+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:46:15.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:46:15.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:46:15.677+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:46:15.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:46:15.733+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:46:15.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:46:15.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-15T14:46:45.939+0000] {processor.py:157} INFO - Started process (PID=12893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:46:45.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:46:45.948+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:46:45.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:46:45.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:46:46.036+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:46:46.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:46:46.059+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:46:46.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:46:46.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-15T14:47:16.400+0000] {processor.py:157} INFO - Started process (PID=12903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:47:16.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:47:16.412+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:47:16.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:47:16.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:47:16.506+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:47:16.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:47:16.526+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:47:16.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:47:16.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-15T14:47:46.773+0000] {processor.py:157} INFO - Started process (PID=12913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:47:46.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:47:46.780+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:47:46.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:47:46.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:47:46.851+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:47:46.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:47:46.868+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:47:46.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:47:46.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T14:48:17.057+0000] {processor.py:157} INFO - Started process (PID=12923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:48:17.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:48:17.071+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:48:17.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:48:17.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:48:17.136+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:48:17.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:48:17.156+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:48:17.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:48:17.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T14:48:47.628+0000] {processor.py:157} INFO - Started process (PID=12933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:48:47.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:48:47.650+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:48:47.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:48:47.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:48:47.719+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:48:47.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:48:47.749+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:48:47.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:48:47.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-15T14:49:18.054+0000] {processor.py:157} INFO - Started process (PID=12943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:49:18.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:49:18.064+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:49:18.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:49:18.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:49:18.160+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:49:18.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:49:18.189+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:49:18.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:49:18.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-15T14:49:48.608+0000] {processor.py:157} INFO - Started process (PID=12953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:49:48.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:49:48.616+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:49:48.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:49:48.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:49:48.683+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:49:48.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:49:48.722+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:49:48.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:49:48.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-15T14:50:19.011+0000] {processor.py:157} INFO - Started process (PID=12963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:50:19.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:50:19.016+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:50:19.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:50:19.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:50:19.123+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:50:19.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:50:19.158+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:50:19.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:50:19.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-09-15T14:50:49.447+0000] {processor.py:157} INFO - Started process (PID=12973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:50:49.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:50:49.452+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:50:49.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:50:49.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:50:49.530+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:50:49.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:50:49.549+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:50:49.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:50:49.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T14:51:19.781+0000] {processor.py:157} INFO - Started process (PID=12983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:51:19.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:51:19.794+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:51:19.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:51:19.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:51:19.877+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:51:19.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:51:19.905+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:51:19.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:51:19.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-15T14:51:50.171+0000] {processor.py:157} INFO - Started process (PID=12992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:51:50.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:51:50.182+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:51:50.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:51:50.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:51:50.267+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:51:50.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:51:50.291+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:51:50.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:51:50.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T14:52:20.611+0000] {processor.py:157} INFO - Started process (PID=13003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:52:20.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:52:20.618+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:52:20.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:52:20.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:52:20.694+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:52:20.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:52:20.712+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:52:20.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:52:20.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-15T14:52:50.993+0000] {processor.py:157} INFO - Started process (PID=13013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:52:50.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:52:51.001+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:52:51.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:52:51.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:52:51.103+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:52:51.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:52:51.144+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:52:51.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:52:51.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-09-15T14:53:21.593+0000] {processor.py:157} INFO - Started process (PID=13023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:53:21.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:53:21.609+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:53:21.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:53:21.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:53:21.698+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:53:21.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:53:21.737+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:53:21.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:53:21.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.275 seconds
[2024-09-15T14:53:52.201+0000] {processor.py:157} INFO - Started process (PID=13033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:53:52.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:53:52.209+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:53:52.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:53:52.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:53:52.297+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:53:52.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:53:52.327+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:53:52.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:53:52.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-15T14:54:22.586+0000] {processor.py:157} INFO - Started process (PID=13042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:54:22.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:54:22.593+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:54:22.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:54:22.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:54:22.656+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:54:22.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:54:22.671+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:54:22.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:54:22.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T14:54:52.853+0000] {processor.py:157} INFO - Started process (PID=13053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:54:52.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:54:52.862+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:54:52.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:54:52.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:54:52.920+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:54:52.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:54:52.935+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:54:52.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:54:52.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T14:55:23.324+0000] {processor.py:157} INFO - Started process (PID=13063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:55:23.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:55:23.340+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:55:23.330+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:55:23.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:55:23.395+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:55:23.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:55:23.409+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:55:23.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:55:23.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T14:55:53.759+0000] {processor.py:157} INFO - Started process (PID=13073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:55:53.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:55:53.767+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:55:53.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:55:53.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:55:53.805+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:55:53.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:55:53.820+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:55:53.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:55:53.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T14:56:24.165+0000] {processor.py:157} INFO - Started process (PID=13083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:56:24.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:56:24.179+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:56:24.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:56:24.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:56:24.226+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:56:24.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:56:24.247+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:56:24.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:56:24.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T14:56:54.497+0000] {processor.py:157} INFO - Started process (PID=13093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:56:54.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:56:54.503+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:56:54.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:56:54.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:56:54.532+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:56:54.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:56:54.544+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:56:54.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:56:54.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-15T14:57:25.007+0000] {processor.py:157} INFO - Started process (PID=13103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:57:25.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:57:25.015+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:57:25.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:57:25.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:57:25.075+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:57:25.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:57:25.095+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:57:25.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:57:25.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T14:57:55.357+0000] {processor.py:157} INFO - Started process (PID=13113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:57:55.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:57:55.364+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:57:55.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:57:55.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:57:55.417+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:57:55.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:57:55.432+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:57:55.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:57:55.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T14:58:25.771+0000] {processor.py:157} INFO - Started process (PID=13123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:58:25.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:58:25.778+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:58:25.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:58:25.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:58:25.843+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:58:25.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:58:25.859+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:58:25.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:58:25.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T14:58:56.128+0000] {processor.py:157} INFO - Started process (PID=13133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:58:56.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:58:56.133+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:58:56.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:58:56.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:58:56.169+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:58:56.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:58:56.187+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:58:56.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:58:56.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T14:59:26.592+0000] {processor.py:157} INFO - Started process (PID=13143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:59:26.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:59:26.596+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:59:26.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:59:26.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:59:26.639+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:59:26.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:59:26.653+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:59:26.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:59:26.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T14:59:56.932+0000] {processor.py:157} INFO - Started process (PID=13153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:59:56.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T14:59:56.936+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:59:56.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:59:56.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T14:59:56.974+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:59:56.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T14:59:56.986+0000] {logging_mixin.py:151} INFO - [2024-09-15T14:59:56.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T14:59:56.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T15:00:27.360+0000] {processor.py:157} INFO - Started process (PID=13163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:00:27.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:00:27.370+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:00:27.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:00:27.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:00:27.404+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:00:27.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:00:27.415+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:00:27.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:00:27.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T15:00:57.721+0000] {processor.py:157} INFO - Started process (PID=13173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:00:57.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:00:57.726+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:00:57.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:00:57.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:00:57.768+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:00:57.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:00:57.783+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:00:57.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:00:57.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T15:01:28.161+0000] {processor.py:157} INFO - Started process (PID=13183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:01:28.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:01:28.168+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:01:28.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:01:28.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:01:28.210+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:01:28.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:01:28.224+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:01:28.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:01:28.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T15:01:58.537+0000] {processor.py:157} INFO - Started process (PID=13193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:01:58.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:01:58.540+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:01:58.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:01:58.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:01:58.571+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:01:58.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:01:58.582+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:01:58.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:01:58.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T15:02:28.904+0000] {processor.py:157} INFO - Started process (PID=13203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:02:28.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:02:28.910+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:02:28.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:02:28.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:02:28.955+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:02:28.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:02:28.969+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:02:28.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:02:28.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T15:02:59.294+0000] {processor.py:157} INFO - Started process (PID=13213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:02:59.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:02:59.300+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:02:59.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:02:59.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:02:59.340+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:02:59.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:02:59.353+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:02:59.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:02:59.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-15T15:03:29.629+0000] {processor.py:157} INFO - Started process (PID=13223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:03:29.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:03:29.635+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:03:29.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:03:29.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:03:29.677+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:03:29.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:03:29.697+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:03:29.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:03:29.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T15:04:00.156+0000] {processor.py:157} INFO - Started process (PID=13233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:04:00.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:04:00.162+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:04:00.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:04:00.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:04:00.208+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:04:00.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:04:00.221+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:04:00.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:04:00.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T15:04:30.549+0000] {processor.py:157} INFO - Started process (PID=13243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:04:30.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:04:30.571+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:04:30.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:04:30.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:04:30.611+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:04:30.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:04:30.625+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:04:30.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:04:30.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T15:05:00.952+0000] {processor.py:157} INFO - Started process (PID=13253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:05:00.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:05:00.959+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:05:00.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:05:00.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:05:00.991+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:05:00.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:05:01.005+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:05:01.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:05:01.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T15:05:31.279+0000] {processor.py:157} INFO - Started process (PID=13263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:05:31.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:05:31.285+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:05:31.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:05:31.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:05:31.328+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:05:31.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:05:31.342+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:05:31.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:05:31.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T15:06:01.631+0000] {processor.py:157} INFO - Started process (PID=13273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:06:01.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:06:01.637+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:06:01.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:06:01.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:06:01.691+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:06:01.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:06:01.707+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:06:01.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:06:01.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T15:06:31.945+0000] {processor.py:157} INFO - Started process (PID=13283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:06:31.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:06:31.949+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:06:31.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:06:31.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:06:31.979+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:06:31.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:06:31.989+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:06:31.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:06:31.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-15T15:07:02.442+0000] {processor.py:157} INFO - Started process (PID=13293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:07:02.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:07:02.456+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:07:02.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:07:02.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:07:02.509+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:07:02.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:07:02.524+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:07:02.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:07:02.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T15:07:32.794+0000] {processor.py:157} INFO - Started process (PID=13303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:07:32.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:07:32.800+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:07:32.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:07:32.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:07:32.836+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:07:32.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:07:32.848+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:07:32.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:07:32.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T15:08:03.276+0000] {processor.py:157} INFO - Started process (PID=13313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:08:03.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:08:03.285+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:08:03.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:08:03.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:08:03.325+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:08:03.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:08:03.339+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:08:03.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:08:03.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T15:08:33.690+0000] {processor.py:157} INFO - Started process (PID=13323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:08:33.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:08:33.695+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:08:33.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:08:33.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:08:33.724+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:08:33.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:08:33.734+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:08:33.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:08:33.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T15:09:04.118+0000] {processor.py:157} INFO - Started process (PID=13333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:09:04.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:09:04.124+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:09:04.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:09:04.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:09:04.169+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:09:04.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:09:04.185+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:09:04.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:09:04.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T15:09:34.425+0000] {processor.py:157} INFO - Started process (PID=13343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:09:34.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:09:34.432+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:09:34.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:09:34.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:09:34.461+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:09:34.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:09:34.471+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:09:34.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:09:34.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-15T15:10:04.861+0000] {processor.py:157} INFO - Started process (PID=13353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:10:04.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:10:04.868+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:10:04.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:10:04.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:10:04.922+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:10:04.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:10:04.938+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:10:04.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:10:04.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T15:10:35.201+0000] {processor.py:157} INFO - Started process (PID=13363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:10:35.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:10:35.207+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:10:35.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:10:35.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:10:35.247+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:10:35.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:10:35.261+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:10:35.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:10:35.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T15:11:05.654+0000] {processor.py:157} INFO - Started process (PID=13373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:11:05.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:11:05.661+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:11:05.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:11:05.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:11:05.701+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:11:05.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:11:05.714+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:11:05.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:11:05.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T15:11:36.016+0000] {processor.py:157} INFO - Started process (PID=13383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:11:36.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:11:36.020+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:11:36.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:11:36.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:11:36.052+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:11:36.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:11:36.062+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:11:36.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:11:36.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T15:12:06.491+0000] {processor.py:157} INFO - Started process (PID=13392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:12:06.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:12:06.496+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:12:06.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:12:06.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:12:06.539+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:12:06.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:12:06.560+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:12:06.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:12:06.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T15:12:36.911+0000] {processor.py:157} INFO - Started process (PID=13403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:12:36.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:12:36.917+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:12:36.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:12:36.929+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:12:36.953+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:12:36.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:12:36.967+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:12:36.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:12:36.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T15:13:07.364+0000] {processor.py:157} INFO - Started process (PID=13413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:13:07.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:13:07.370+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:13:07.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:13:07.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:13:07.414+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:13:07.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:13:07.429+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:13:07.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:13:07.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T15:13:37.672+0000] {processor.py:157} INFO - Started process (PID=13423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:13:37.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:13:37.679+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:13:37.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:13:37.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:13:37.718+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:13:37.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:13:37.730+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:13:37.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:13:37.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T15:14:08.048+0000] {processor.py:157} INFO - Started process (PID=13433) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:14:08.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:14:08.052+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:14:08.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:14:08.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:14:08.091+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:14:08.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:14:08.104+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:14:08.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:14:08.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-15T15:14:38.514+0000] {processor.py:157} INFO - Started process (PID=13443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:14:38.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:14:38.518+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:14:38.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:14:38.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:14:38.547+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:14:38.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:14:38.563+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:14:38.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:14:38.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T15:15:08.964+0000] {processor.py:157} INFO - Started process (PID=13453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:15:08.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:15:08.972+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:15:08.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:15:08.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:15:09.011+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:15:09.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:15:09.023+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:15:09.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:15:09.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T15:15:39.349+0000] {processor.py:157} INFO - Started process (PID=13463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:15:39.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:15:39.354+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:15:39.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:15:39.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:15:39.386+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:15:39.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:15:39.400+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:15:39.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:15:39.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T15:16:09.704+0000] {processor.py:157} INFO - Started process (PID=13473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:16:09.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:16:09.712+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:16:09.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:16:09.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:16:09.768+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:16:09.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:16:09.781+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:16:09.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:16:09.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T15:16:40.120+0000] {processor.py:157} INFO - Started process (PID=13483) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:16:40.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:16:40.127+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:16:40.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:16:40.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:16:40.201+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:16:40.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:16:40.216+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:16:40.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:16:40.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T15:17:10.506+0000] {processor.py:157} INFO - Started process (PID=13493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:17:10.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:17:10.511+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:17:10.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:17:10.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:17:10.554+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:17:10.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:17:10.568+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:17:10.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:17:10.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T15:17:40.928+0000] {processor.py:157} INFO - Started process (PID=13503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:17:40.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:17:40.935+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:17:40.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:17:40.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:17:40.982+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:17:40.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:17:40.996+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:17:40.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:17:41.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T15:18:11.329+0000] {processor.py:157} INFO - Started process (PID=13513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:18:11.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:18:11.334+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:18:11.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:18:11.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:18:11.397+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:18:11.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:18:11.415+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:18:11.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:18:11.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T15:18:41.720+0000] {processor.py:157} INFO - Started process (PID=13523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:18:41.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:18:41.729+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:18:41.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:18:41.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:18:41.777+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:18:41.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:18:41.791+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:18:41.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:18:41.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T15:19:12.049+0000] {processor.py:157} INFO - Started process (PID=13533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:19:12.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:19:12.061+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:19:12.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:19:12.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:19:12.105+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:19:12.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:19:12.120+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:19:12.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:19:12.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T15:19:42.387+0000] {processor.py:157} INFO - Started process (PID=13543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:19:42.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:19:42.393+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:19:42.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:19:42.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:19:42.438+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:19:42.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:19:42.452+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:19:42.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:19:42.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T15:20:12.804+0000] {processor.py:157} INFO - Started process (PID=13553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:20:12.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:20:12.811+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:20:12.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:20:12.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:20:12.852+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:20:12.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:20:12.865+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:20:12.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:20:12.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T15:20:43.285+0000] {processor.py:157} INFO - Started process (PID=13563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:20:43.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:20:43.288+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:20:43.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:20:43.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:20:43.315+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:20:43.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:20:43.324+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:20:43.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:20:43.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-15T15:21:13.689+0000] {processor.py:157} INFO - Started process (PID=13573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:21:13.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:21:13.695+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:21:13.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:21:13.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:21:13.738+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:21:13.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:21:13.755+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:21:13.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:21:13.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T15:21:44.082+0000] {processor.py:157} INFO - Started process (PID=13583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:21:44.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:21:44.089+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:21:44.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:21:44.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:21:44.127+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:21:44.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:21:44.140+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:21:44.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:21:44.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-15T15:22:14.481+0000] {processor.py:157} INFO - Started process (PID=13593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:22:14.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:22:14.483+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:22:14.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:22:14.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:22:14.512+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:22:14.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:22:14.523+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:22:14.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:22:14.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-15T15:22:44.818+0000] {processor.py:157} INFO - Started process (PID=13603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:22:44.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:22:44.823+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:22:44.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:22:44.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:22:44.873+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:22:44.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:22:44.887+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:22:44.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:22:44.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T15:23:15.269+0000] {processor.py:157} INFO - Started process (PID=13612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:23:15.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:23:15.274+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:23:15.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:23:15.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:23:15.330+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:23:15.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:23:15.349+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:23:15.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:23:15.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T15:23:45.742+0000] {processor.py:157} INFO - Started process (PID=13623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:23:45.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:23:45.748+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:23:45.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:23:45.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:23:45.805+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:23:45.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:23:45.819+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:23:45.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:23:45.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T15:24:16.153+0000] {processor.py:157} INFO - Started process (PID=13633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:24:16.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:24:16.169+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:24:16.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:24:16.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:24:16.216+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:24:16.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:24:16.242+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:24:16.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:24:16.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T15:24:46.572+0000] {processor.py:157} INFO - Started process (PID=13643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:24:46.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:24:46.577+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:24:46.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:24:46.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:24:46.616+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:24:46.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:24:46.629+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:24:46.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:24:46.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T15:25:17.030+0000] {processor.py:157} INFO - Started process (PID=13652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:25:17.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:25:17.036+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:25:17.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:25:17.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:25:17.098+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:25:17.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:25:17.111+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:25:17.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:25:17.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T15:25:47.367+0000] {processor.py:157} INFO - Started process (PID=13663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:25:47.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:25:47.370+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:25:47.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:25:47.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:25:47.445+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:25:47.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:25:47.461+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:25:47.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:25:47.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T15:26:17.769+0000] {processor.py:157} INFO - Started process (PID=13672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:26:17.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:26:17.776+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:26:17.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:26:17.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:26:17.826+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:26:17.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:26:17.841+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:26:17.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:26:17.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T15:26:48.233+0000] {processor.py:157} INFO - Started process (PID=13683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:26:48.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:26:48.240+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:26:48.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:26:48.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:26:48.294+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:26:48.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:26:48.308+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:26:48.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:26:48.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T15:27:18.716+0000] {processor.py:157} INFO - Started process (PID=13693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:27:18.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:27:18.732+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:27:18.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:27:18.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:27:18.787+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:27:18.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:27:18.810+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:27:18.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:27:18.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T15:27:49.228+0000] {processor.py:157} INFO - Started process (PID=13703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:27:49.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:27:49.236+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:27:49.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:27:49.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:27:49.282+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:27:49.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:27:49.295+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:27:49.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:27:49.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T15:28:19.625+0000] {processor.py:157} INFO - Started process (PID=13713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:28:19.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:28:19.629+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:28:19.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:28:19.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:28:19.669+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:28:19.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:28:19.682+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:28:19.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:28:19.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T15:28:50.008+0000] {processor.py:157} INFO - Started process (PID=13723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:28:50.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:28:50.011+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:28:50.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:28:50.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:28:50.037+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:28:50.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:28:50.046+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:28:50.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:28:50.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-15T15:29:20.406+0000] {processor.py:157} INFO - Started process (PID=13733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:29:20.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:29:20.413+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:29:20.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:29:20.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:29:20.476+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:29:20.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:29:20.491+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:29:20.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:29:20.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T15:29:50.859+0000] {processor.py:157} INFO - Started process (PID=13743) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:29:50.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:29:50.868+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:29:50.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:29:50.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:29:50.916+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:29:50.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:29:50.943+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:29:50.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:29:50.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T15:30:21.346+0000] {processor.py:157} INFO - Started process (PID=13753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:30:21.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:30:21.351+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:30:21.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:30:21.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:30:21.399+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:30:21.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:30:21.420+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:30:21.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:30:21.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T15:30:51.915+0000] {processor.py:157} INFO - Started process (PID=13763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:30:51.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:30:51.951+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:30:51.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:30:51.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:30:51.995+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:30:51.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:30:52.008+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:30:52.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:30:52.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T15:31:22.493+0000] {processor.py:157} INFO - Started process (PID=13773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:31:22.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:31:22.499+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:31:22.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:31:22.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:31:22.557+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:31:22.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:31:22.574+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:31:22.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:31:22.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T15:31:52.933+0000] {processor.py:157} INFO - Started process (PID=13783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:31:52.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:31:52.939+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:31:52.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:31:52.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:31:52.996+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:31:52.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:31:53.009+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:31:53.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:31:53.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T15:32:23.356+0000] {processor.py:157} INFO - Started process (PID=13793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:32:23.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:32:23.363+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:32:23.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:32:23.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:32:23.423+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:32:23.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:32:23.436+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:32:23.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:32:23.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-15T15:32:53.821+0000] {processor.py:157} INFO - Started process (PID=13803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:32:53.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:32:53.825+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:32:53.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:32:53.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:32:53.864+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:32:53.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:32:53.876+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:32:53.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:32:53.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T15:33:24.252+0000] {processor.py:157} INFO - Started process (PID=13813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:33:24.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:33:24.256+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:33:24.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:33:24.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:33:24.292+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:33:24.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:33:24.304+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:33:24.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:33:24.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T15:33:54.737+0000] {processor.py:157} INFO - Started process (PID=13823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:33:54.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:33:54.741+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:33:54.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:33:54.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:33:54.788+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:33:54.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:33:54.803+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:33:54.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:33:54.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T15:34:25.070+0000] {processor.py:157} INFO - Started process (PID=13833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:34:25.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:34:25.077+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:34:25.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:34:25.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:34:25.138+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:34:25.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:34:25.153+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:34:25.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:34:25.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T15:34:55.624+0000] {processor.py:157} INFO - Started process (PID=13843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:34:55.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:34:55.627+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:34:55.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:34:55.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:34:55.654+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:34:55.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:34:55.663+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:34:55.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:34:55.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-15T15:35:26.061+0000] {processor.py:157} INFO - Started process (PID=13853) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:35:26.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:35:26.066+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:35:26.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:35:26.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:35:26.125+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:35:26.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:35:26.141+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:35:26.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:35:26.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T15:35:56.425+0000] {processor.py:157} INFO - Started process (PID=13863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:35:56.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:35:56.432+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:35:56.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:35:56.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:35:56.476+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:35:56.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:35:56.489+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:35:56.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:35:56.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T15:36:26.771+0000] {processor.py:157} INFO - Started process (PID=13873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:36:26.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:36:26.778+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:36:26.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:36:26.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:36:26.822+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:36:26.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:36:26.836+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:36:26.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:36:26.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T15:36:57.143+0000] {processor.py:157} INFO - Started process (PID=13883) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:36:57.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:36:57.150+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:36:57.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:36:57.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:36:57.200+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:36:57.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:36:57.213+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:36:57.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:36:57.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T15:37:27.623+0000] {processor.py:157} INFO - Started process (PID=13893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:37:27.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:37:27.629+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:37:27.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:37:27.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:37:27.690+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:37:27.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:37:27.709+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:37:27.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:37:27.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T15:37:57.969+0000] {processor.py:157} INFO - Started process (PID=13903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:37:57.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:37:57.978+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:37:57.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:37:57.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:37:58.043+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:37:58.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:37:58.058+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:37:58.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:37:58.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T15:38:28.390+0000] {processor.py:157} INFO - Started process (PID=13913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:38:28.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:38:28.397+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:38:28.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:38:28.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:38:28.450+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:38:28.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:38:28.463+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:38:28.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:38:28.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T15:38:58.812+0000] {processor.py:157} INFO - Started process (PID=13923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:38:58.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:38:58.815+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:38:58.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:38:58.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:38:58.840+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:38:58.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:38:58.851+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:38:58.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:38:58.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-15T15:39:29.322+0000] {processor.py:157} INFO - Started process (PID=13933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:39:29.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:39:29.329+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:39:29.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:39:29.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:39:29.384+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:39:29.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:39:29.400+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:39:29.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:39:29.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-15T15:39:59.715+0000] {processor.py:157} INFO - Started process (PID=13943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:39:59.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:39:59.720+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:39:59.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:39:59.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:39:59.759+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:39:59.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:39:59.774+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:39:59.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:39:59.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-15T15:40:30.102+0000] {processor.py:157} INFO - Started process (PID=13953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:40:30.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:40:30.110+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:40:30.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:40:30.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:40:30.167+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:40:30.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:40:30.183+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:40:30.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:40:30.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T15:41:00.515+0000] {processor.py:157} INFO - Started process (PID=13963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:41:00.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:41:00.519+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:41:00.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:41:00.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:41:00.547+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:41:00.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:41:00.555+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:41:00.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:41:00.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-15T15:41:30.911+0000] {processor.py:157} INFO - Started process (PID=13973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:41:30.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:41:30.917+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:41:30.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:41:30.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:41:30.971+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:41:30.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:41:30.986+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:41:30.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:41:30.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T15:42:01.259+0000] {processor.py:157} INFO - Started process (PID=13981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:42:01.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:42:01.265+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:42:01.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:42:01.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:42:01.306+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:42:01.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:42:01.319+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:42:01.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:42:01.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T15:42:31.645+0000] {processor.py:157} INFO - Started process (PID=13993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:42:31.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:42:31.650+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:42:31.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:42:31.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:42:31.702+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:42:31.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:42:31.716+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:42:31.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:42:31.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T15:43:02.076+0000] {processor.py:157} INFO - Started process (PID=14003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:43:02.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:43:02.081+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:43:02.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:43:02.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:43:02.122+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:43:02.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:43:02.153+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:43:02.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:43:02.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T15:43:32.509+0000] {processor.py:157} INFO - Started process (PID=14013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:43:32.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:43:32.513+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:43:32.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:43:32.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:43:32.546+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:43:32.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:43:32.560+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:43:32.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:43:32.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T15:44:02.858+0000] {processor.py:157} INFO - Started process (PID=14023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:44:02.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:44:02.880+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:44:02.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:44:02.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:44:02.946+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:44:02.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:44:02.964+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:44:02.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:44:02.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-15T15:44:33.339+0000] {processor.py:157} INFO - Started process (PID=14033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:44:33.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:44:33.343+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:44:33.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:44:33.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:44:33.381+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:44:33.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:44:33.394+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:44:33.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:44:33.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-15T15:45:03.803+0000] {processor.py:157} INFO - Started process (PID=14042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:45:03.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:45:03.810+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:45:03.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:45:03.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:45:03.856+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:45:03.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:45:03.870+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:45:03.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:45:03.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T15:45:34.181+0000] {processor.py:157} INFO - Started process (PID=14052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:45:34.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:45:34.199+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:45:34.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:45:34.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:45:34.265+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:45:34.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:45:34.288+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:45:34.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:45:34.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-15T15:46:04.670+0000] {processor.py:157} INFO - Started process (PID=14063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:46:04.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:46:04.676+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:46:04.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:46:04.696+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:46:04.736+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:46:04.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:46:04.748+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:46:04.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:46:04.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T15:46:35.089+0000] {processor.py:157} INFO - Started process (PID=14073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:46:35.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:46:35.093+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:46:35.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:46:35.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:46:35.121+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:46:35.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:46:35.130+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:46:35.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:46:35.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-15T15:47:05.514+0000] {processor.py:157} INFO - Started process (PID=14083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:47:05.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:47:05.533+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:47:05.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:47:05.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:47:05.584+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:47:05.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:47:05.606+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:47:05.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:47:05.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T15:47:35.912+0000] {processor.py:157} INFO - Started process (PID=14092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:47:35.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:47:35.918+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:47:35.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:47:35.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:47:35.983+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:47:35.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:47:35.996+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:47:35.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:47:36.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T15:48:06.263+0000] {processor.py:157} INFO - Started process (PID=14103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:48:06.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:48:06.268+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:48:06.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:48:06.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:48:06.313+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:48:06.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:48:06.326+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:48:06.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:48:06.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T15:48:36.665+0000] {processor.py:157} INFO - Started process (PID=14113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:48:36.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:48:36.668+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:48:36.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:48:36.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:48:36.716+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:48:36.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:48:36.730+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:48:36.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:48:36.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T15:49:07.140+0000] {processor.py:157} INFO - Started process (PID=14122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:49:07.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:49:07.146+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:49:07.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:49:07.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:49:07.192+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:49:07.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:49:07.205+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:49:07.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:49:07.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T15:49:37.468+0000] {processor.py:157} INFO - Started process (PID=14133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:49:37.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:49:37.474+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:49:37.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:49:37.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:49:37.502+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:49:37.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:49:37.513+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:49:37.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:49:37.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-15T15:50:08.047+0000] {processor.py:157} INFO - Started process (PID=14143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:50:08.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:50:08.053+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:50:08.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:50:08.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:50:08.105+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:50:08.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:50:08.118+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:50:08.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:50:08.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T15:50:38.447+0000] {processor.py:157} INFO - Started process (PID=14153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:50:38.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:50:38.450+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:50:38.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:50:38.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:50:38.484+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:50:38.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:50:38.493+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:50:38.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:50:38.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T15:51:08.941+0000] {processor.py:157} INFO - Started process (PID=14163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:51:08.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:51:08.958+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:51:08.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:51:08.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:51:09.010+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:51:09.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:51:09.036+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:51:09.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:51:09.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T15:51:39.418+0000] {processor.py:157} INFO - Started process (PID=14173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:51:39.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:51:39.422+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:51:39.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:51:39.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:51:39.466+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:51:39.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:51:39.481+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:51:39.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:51:39.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T15:52:09.855+0000] {processor.py:157} INFO - Started process (PID=14183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:52:09.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:52:09.861+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:52:09.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:52:09.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:52:09.902+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:52:09.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:52:09.915+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:52:09.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:52:09.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-15T15:52:40.264+0000] {processor.py:157} INFO - Started process (PID=14193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:52:40.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:52:40.272+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:52:40.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:52:40.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:52:40.405+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:52:40.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:52:40.419+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:52:40.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:52:40.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-09-15T15:53:10.835+0000] {processor.py:157} INFO - Started process (PID=14202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:53:10.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:53:10.841+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:53:10.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:53:10.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:53:10.906+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:53:10.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:53:10.934+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:53:10.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:53:10.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T15:53:41.348+0000] {processor.py:157} INFO - Started process (PID=14213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:53:41.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:53:41.358+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:53:41.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:53:41.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:53:41.436+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:53:41.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:53:41.457+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:53:41.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:53:41.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-15T15:54:11.852+0000] {processor.py:157} INFO - Started process (PID=14223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:54:11.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:54:11.857+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:54:11.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:54:11.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:54:11.910+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:54:11.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:54:11.924+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:54:11.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:54:11.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T15:54:42.317+0000] {processor.py:157} INFO - Started process (PID=14233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:54:42.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:54:42.323+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:54:42.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:54:42.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:54:42.389+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:54:42.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:54:42.403+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:54:42.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:54:42.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T15:55:12.638+0000] {processor.py:157} INFO - Started process (PID=14243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:55:12.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:55:12.646+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:55:12.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:55:12.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:55:12.700+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:55:12.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:55:12.716+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:55:12.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:55:12.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T15:55:43.137+0000] {processor.py:157} INFO - Started process (PID=14253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:55:43.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:55:43.145+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:55:43.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:55:43.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:55:43.197+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:55:43.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:55:43.211+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:55:43.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:55:43.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T15:56:13.534+0000] {processor.py:157} INFO - Started process (PID=14263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:56:13.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:56:13.546+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:56:13.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:56:13.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:56:13.605+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:56:13.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:56:13.627+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:56:13.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:56:13.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T15:56:43.918+0000] {processor.py:157} INFO - Started process (PID=14272) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:56:43.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:56:43.924+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:56:43.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:56:43.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:56:43.975+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:56:43.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:56:43.996+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:56:43.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:56:44.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T15:57:14.471+0000] {processor.py:157} INFO - Started process (PID=14283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:57:14.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:57:14.478+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:57:14.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:57:14.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:57:14.529+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:57:14.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:57:14.549+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:57:14.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:57:14.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T15:57:44.975+0000] {processor.py:157} INFO - Started process (PID=14292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:57:44.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:57:44.983+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:57:44.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:57:45.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:57:45.031+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:57:45.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:57:45.045+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:57:45.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:57:45.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T15:58:15.298+0000] {processor.py:157} INFO - Started process (PID=14303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:58:15.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:58:15.302+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:58:15.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:58:15.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:58:15.333+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:58:15.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:58:15.342+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:58:15.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:58:15.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-15T15:58:45.774+0000] {processor.py:157} INFO - Started process (PID=14313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:58:45.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:58:45.780+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:58:45.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:58:45.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:58:45.831+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:58:45.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:58:45.845+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:58:45.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:58:45.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T15:59:16.198+0000] {processor.py:157} INFO - Started process (PID=14323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:59:16.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:59:16.206+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:59:16.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:59:16.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:59:16.246+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:59:16.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:59:16.260+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:59:16.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:59:16.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-15T15:59:46.529+0000] {processor.py:157} INFO - Started process (PID=14333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:59:46.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T15:59:46.534+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:59:46.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:59:46.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T15:59:46.563+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:59:46.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T15:59:46.574+0000] {logging_mixin.py:151} INFO - [2024-09-15T15:59:46.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T15:59:46.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T16:00:16.987+0000] {processor.py:157} INFO - Started process (PID=14343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:00:16.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:00:16.996+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:00:16.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:00:17.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:00:17.050+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:00:17.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:00:17.064+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:00:17.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:00:17.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T16:00:47.834+0000] {processor.py:157} INFO - Started process (PID=14353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:00:47.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:00:47.847+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:00:47.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:00:47.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:00:47.924+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:00:47.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:00:47.941+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:00:47.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:00:47.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T16:12:08.681+0000] {processor.py:157} INFO - Started process (PID=14363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:12:08.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:12:08.705+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:12:08.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:12:08.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:12:08.860+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:12:08.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:12:08.929+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:12:08.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:12:08.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.284 seconds
[2024-09-15T16:12:39.188+0000] {processor.py:157} INFO - Started process (PID=14375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:12:39.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:12:39.200+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:12:39.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:12:39.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:12:39.405+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:12:39.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:12:39.437+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:12:39.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:12:39.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.328 seconds
[2024-09-15T16:13:09.793+0000] {processor.py:157} INFO - Started process (PID=14385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:13:09.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:13:09.801+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:13:09.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:13:09.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:13:09.890+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:13:09.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:13:09.937+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:13:09.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:13:09.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-15T16:13:40.150+0000] {processor.py:157} INFO - Started process (PID=14395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:13:40.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:13:40.160+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:13:40.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:13:40.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:13:40.231+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:13:40.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:13:40.252+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:13:40.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:13:40.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T16:14:10.660+0000] {processor.py:157} INFO - Started process (PID=14405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:14:10.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:14:10.668+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:14:10.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:14:10.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:14:10.739+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:14:10.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:14:10.758+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:14:10.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:14:10.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T16:14:41.123+0000] {processor.py:157} INFO - Started process (PID=14415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:14:41.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:14:41.131+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:14:41.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:14:41.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:14:41.194+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:14:41.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:14:41.214+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:14:41.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:14:41.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T16:15:11.614+0000] {processor.py:157} INFO - Started process (PID=14425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:15:11.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:15:11.623+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:15:11.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:15:11.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:15:11.736+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:15:11.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:15:11.771+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:15:11.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:15:11.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-09-15T16:15:41.878+0000] {processor.py:157} INFO - Started process (PID=14435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:15:41.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:15:41.886+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:15:41.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:15:41.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:15:41.948+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:15:41.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:15:41.976+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:15:41.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:15:41.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T16:16:12.195+0000] {processor.py:157} INFO - Started process (PID=14445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:16:12.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:16:12.203+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:16:12.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:16:12.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:16:12.259+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:16:12.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:16:12.284+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:16:12.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:16:12.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T16:16:42.679+0000] {processor.py:157} INFO - Started process (PID=14455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:16:42.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:16:42.687+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:16:42.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:16:42.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:16:42.742+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:16:42.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:16:42.761+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:16:42.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:16:42.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T16:17:13.133+0000] {processor.py:157} INFO - Started process (PID=14465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:17:13.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:17:13.137+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:17:13.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:17:13.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:17:13.167+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:17:13.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:17:13.178+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:17:13.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:17:13.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T16:17:43.516+0000] {processor.py:157} INFO - Started process (PID=14474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:17:43.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:17:43.521+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:17:43.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:17:43.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:17:43.590+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:17:43.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:17:43.606+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:17:43.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:17:43.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T16:18:13.815+0000] {processor.py:157} INFO - Started process (PID=14485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:18:13.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:18:13.818+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:18:13.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:18:13.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:18:13.848+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:18:13.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:18:13.858+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:18:13.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:18:13.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T16:18:44.226+0000] {processor.py:157} INFO - Started process (PID=14495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:18:44.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:18:44.242+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:18:44.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:18:44.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:18:44.315+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:18:44.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:18:44.334+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:18:44.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:18:44.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T16:19:14.783+0000] {processor.py:157} INFO - Started process (PID=14505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:19:14.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:19:14.789+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:19:14.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:19:14.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:19:14.847+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:19:14.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:19:14.862+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:19:14.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:19:14.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T16:19:45.214+0000] {processor.py:157} INFO - Started process (PID=14515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:19:45.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:19:45.216+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:19:45.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:19:45.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:19:45.247+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:19:45.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:19:45.259+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:19:45.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:19:45.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T16:20:15.686+0000] {processor.py:157} INFO - Started process (PID=14525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:20:15.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:20:15.704+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:20:15.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:20:15.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:20:15.756+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:20:15.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:20:15.796+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:20:15.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:20:15.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-15T16:20:46.008+0000] {processor.py:157} INFO - Started process (PID=14535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:20:46.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:20:46.013+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:20:46.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:20:46.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:20:46.059+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:20:46.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:20:46.075+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:20:46.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:20:46.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T16:21:16.504+0000] {processor.py:157} INFO - Started process (PID=14545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:21:16.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:21:16.512+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:21:16.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:21:16.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:21:16.561+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:21:16.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:21:16.582+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:21:16.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:21:16.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T16:21:46.915+0000] {processor.py:157} INFO - Started process (PID=14554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:21:46.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:21:46.921+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:21:46.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:21:46.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:21:46.995+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:21:46.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:21:47.021+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:21:47.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:21:47.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-15T16:22:17.229+0000] {processor.py:157} INFO - Started process (PID=14565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:22:17.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:22:17.237+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:22:17.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:22:17.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:22:17.325+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:22:17.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:22:17.346+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:22:17.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:22:17.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-15T16:22:47.642+0000] {processor.py:157} INFO - Started process (PID=14573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:22:47.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:22:47.649+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:22:47.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:22:47.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:22:47.711+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:22:47.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:22:47.726+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:22:47.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:22:47.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T16:23:18.035+0000] {processor.py:157} INFO - Started process (PID=14584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:23:18.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:23:18.042+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:23:18.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:23:18.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:23:18.096+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:23:18.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:23:18.114+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:23:18.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:23:18.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T16:23:48.381+0000] {processor.py:157} INFO - Started process (PID=14594) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:23:48.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:23:48.389+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:23:48.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:23:48.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:23:48.430+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:23:48.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:23:48.444+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:23:48.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:23:48.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T16:24:18.817+0000] {processor.py:157} INFO - Started process (PID=14605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:24:18.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:24:18.832+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:24:18.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:24:18.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:24:18.883+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:24:18.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:24:18.910+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:24:18.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:24:18.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T16:24:49.279+0000] {processor.py:157} INFO - Started process (PID=14615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:24:49.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:24:49.287+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:24:49.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:24:49.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:24:49.355+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:24:49.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:24:49.373+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:24:49.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:24:49.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T16:25:19.694+0000] {processor.py:157} INFO - Started process (PID=14625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:25:19.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:25:19.724+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:25:19.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:25:19.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:25:19.788+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:25:19.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:25:19.804+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:25:19.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:25:19.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-15T16:25:50.075+0000] {processor.py:157} INFO - Started process (PID=14635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:25:50.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:25:50.084+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:25:50.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:25:50.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:25:50.149+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:25:50.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:25:50.176+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:25:50.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:25:50.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T16:26:20.692+0000] {processor.py:157} INFO - Started process (PID=14645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:26:20.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:26:20.699+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:26:20.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:26:20.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:26:20.765+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:26:20.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:26:20.781+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:26:20.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:26:20.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T16:26:51.035+0000] {processor.py:157} INFO - Started process (PID=14655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:26:51.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:26:51.043+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:26:51.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:26:51.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:26:51.137+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:26:51.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:26:51.289+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:26:51.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:26:51.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.279 seconds
[2024-09-15T16:27:21.597+0000] {processor.py:157} INFO - Started process (PID=14665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:27:21.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:27:21.624+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:27:21.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:27:21.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:27:21.690+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:27:21.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:27:21.707+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:27:21.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:27:21.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T16:27:51.980+0000] {processor.py:157} INFO - Started process (PID=14675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:27:51.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:27:51.985+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:27:51.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:27:52.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:27:52.045+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:27:52.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:27:52.062+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:27:52.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:27:52.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T16:28:22.390+0000] {processor.py:157} INFO - Started process (PID=14685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:28:22.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:28:22.397+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:28:22.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:28:22.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:28:22.471+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:28:22.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:28:22.499+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:28:22.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:28:22.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-15T16:28:52.819+0000] {processor.py:157} INFO - Started process (PID=14695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:28:52.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:28:52.828+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:28:52.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:28:52.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:28:52.910+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:28:52.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:28:52.944+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:28:52.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:28:52.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-15T16:29:23.180+0000] {processor.py:157} INFO - Started process (PID=14705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:29:23.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:29:23.193+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:29:23.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:29:23.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:29:23.263+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:29:23.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:29:23.278+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:29:23.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:29:23.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T16:29:53.500+0000] {processor.py:157} INFO - Started process (PID=14715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:29:53.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:29:53.503+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:29:53.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:29:53.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:29:53.535+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:29:53.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:29:53.547+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:29:53.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:29:53.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T16:30:23.950+0000] {processor.py:157} INFO - Started process (PID=14725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:30:23.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:30:23.956+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:30:23.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:30:23.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:30:24.018+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:30:24.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:30:24.042+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:30:24.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:30:24.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T16:30:54.274+0000] {processor.py:157} INFO - Started process (PID=14735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:30:54.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:30:54.279+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:30:54.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:30:54.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:30:54.342+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:30:54.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:30:54.357+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:30:54.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:30:54.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T16:31:24.711+0000] {processor.py:157} INFO - Started process (PID=14745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:31:24.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:31:24.738+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:31:24.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:31:24.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:31:24.795+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:31:24.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:31:24.824+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:31:24.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:31:24.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T16:31:55.042+0000] {processor.py:157} INFO - Started process (PID=14755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:31:55.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:31:55.047+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:31:55.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:31:55.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:31:55.113+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:31:55.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:31:55.136+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:31:55.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:31:55.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T16:32:25.482+0000] {processor.py:157} INFO - Started process (PID=14764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:32:25.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:32:25.489+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:32:25.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:32:25.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:32:25.551+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:32:25.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:32:25.568+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:32:25.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:32:25.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T16:32:55.982+0000] {processor.py:157} INFO - Started process (PID=14775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:32:55.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:32:55.988+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:32:55.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:32:56.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:32:56.069+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:32:56.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:32:56.085+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:32:56.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:32:56.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T16:33:26.383+0000] {processor.py:157} INFO - Started process (PID=14785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:33:26.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:33:26.390+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:33:26.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:33:26.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:33:26.464+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:33:26.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:33:26.491+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:33:26.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:33:26.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T16:33:57.208+0000] {processor.py:157} INFO - Started process (PID=14795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:33:57.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:33:57.222+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:33:57.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:33:57.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:33:57.301+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:33:57.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:33:57.337+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:33:57.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:33:57.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-15T16:34:27.859+0000] {processor.py:157} INFO - Started process (PID=14805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:34:27.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:34:27.869+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:34:27.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:34:27.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:34:27.971+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:34:27.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:34:27.993+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:34:27.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:34:28.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-15T16:34:58.385+0000] {processor.py:157} INFO - Started process (PID=14815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:34:58.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:34:58.405+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:34:58.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:34:58.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:34:58.531+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:34:58.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:34:58.565+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:34:58.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:34:58.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.202 seconds
[2024-09-15T16:35:28.717+0000] {processor.py:157} INFO - Started process (PID=14825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:35:28.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:35:28.729+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:35:28.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:35:28.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:35:28.796+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:35:28.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:35:28.816+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:35:28.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:35:28.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-15T16:35:59.167+0000] {processor.py:157} INFO - Started process (PID=14835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:35:59.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:35:59.177+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:35:59.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:35:59.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:35:59.227+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:35:59.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:35:59.244+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:35:59.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:35:59.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T16:36:29.625+0000] {processor.py:157} INFO - Started process (PID=14845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:36:29.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:36:29.630+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:36:29.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:36:29.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:36:29.687+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:36:29.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:36:29.702+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:36:29.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:36:29.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T16:37:00.070+0000] {processor.py:157} INFO - Started process (PID=14854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:37:00.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:37:00.076+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:37:00.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:37:00.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:37:00.129+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:37:00.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:37:00.151+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:37:00.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:37:00.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T16:37:30.529+0000] {processor.py:157} INFO - Started process (PID=14865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:37:30.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:37:30.536+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:37:30.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:37:30.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:37:30.588+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:37:30.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:37:30.606+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:37:30.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:37:30.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T16:38:00.989+0000] {processor.py:157} INFO - Started process (PID=14874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:38:00.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:38:00.995+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:38:00.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:38:01.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:38:01.046+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:38:01.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:38:01.072+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:38:01.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:38:01.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T16:38:31.361+0000] {processor.py:157} INFO - Started process (PID=14885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:38:31.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:38:31.369+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:38:31.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:38:31.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:38:31.417+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:38:31.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:38:31.440+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:38:31.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:38:31.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T16:39:01.778+0000] {processor.py:157} INFO - Started process (PID=14895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:39:01.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:39:01.784+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:39:01.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:39:01.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:39:01.852+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:39:01.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:39:01.874+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:39:01.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:39:01.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T16:39:32.154+0000] {processor.py:157} INFO - Started process (PID=14905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:39:32.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:39:32.161+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:39:32.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:39:32.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:39:32.214+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:39:32.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:39:32.241+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:39:32.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:39:32.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T16:40:02.557+0000] {processor.py:157} INFO - Started process (PID=14915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:40:02.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:40:02.564+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:40:02.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:40:02.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:40:02.636+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:40:02.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:40:02.652+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:40:02.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:40:02.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T16:40:33.045+0000] {processor.py:157} INFO - Started process (PID=14925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:40:33.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:40:33.050+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:40:33.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:40:33.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:40:33.107+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:40:33.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:40:33.123+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:40:33.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:40:33.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T16:41:03.397+0000] {processor.py:157} INFO - Started process (PID=14935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:41:03.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:41:03.405+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:41:03.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:41:03.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:41:03.466+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:41:03.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:41:03.482+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:41:03.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:41:03.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T16:41:33.740+0000] {processor.py:157} INFO - Started process (PID=14945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:41:33.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:41:33.745+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:41:33.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:41:33.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:41:33.812+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:41:33.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:41:33.828+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:41:33.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:41:33.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T16:42:04.097+0000] {processor.py:157} INFO - Started process (PID=14955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:42:04.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:42:04.103+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:42:04.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:42:04.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:42:04.162+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:42:04.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:42:04.179+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:42:04.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:42:04.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T16:42:34.489+0000] {processor.py:157} INFO - Started process (PID=14965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:42:34.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:42:34.497+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:42:34.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:42:34.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:42:34.552+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:42:34.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:42:34.567+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:42:34.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:42:34.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T16:43:04.878+0000] {processor.py:157} INFO - Started process (PID=14974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:43:04.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:43:04.884+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:43:04.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:43:04.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:43:04.943+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:43:04.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:43:04.958+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:43:04.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:43:04.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T16:43:35.218+0000] {processor.py:157} INFO - Started process (PID=14985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:43:35.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:43:35.222+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:43:35.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:43:35.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:43:35.262+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:43:35.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:43:35.278+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:43:35.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:43:35.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T16:44:05.616+0000] {processor.py:157} INFO - Started process (PID=14995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:44:05.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:44:05.622+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:44:05.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:44:05.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:44:05.688+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:44:05.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:44:05.707+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:44:05.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:44:05.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T16:44:36.110+0000] {processor.py:157} INFO - Started process (PID=15003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:44:36.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:44:36.118+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:44:36.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:44:36.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:44:36.182+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:44:36.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:44:36.198+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:44:36.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:44:36.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T16:45:06.531+0000] {processor.py:157} INFO - Started process (PID=15015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:45:06.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:45:06.538+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:45:06.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:45:06.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:45:06.597+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:45:06.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:45:06.612+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:45:06.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:45:06.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T16:45:36.884+0000] {processor.py:157} INFO - Started process (PID=15025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:45:36.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:45:36.893+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:45:36.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:45:36.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:45:36.959+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:45:36.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:45:36.976+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:45:36.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:45:36.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T16:46:07.300+0000] {processor.py:157} INFO - Started process (PID=15035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:46:07.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:46:07.309+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:46:07.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:46:07.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:46:07.378+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:46:07.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:46:07.402+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:46:07.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:46:07.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T16:46:37.790+0000] {processor.py:157} INFO - Started process (PID=15045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:46:37.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:46:37.796+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:46:37.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:46:37.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:46:37.890+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:46:37.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:46:37.907+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:46:37.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:46:37.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-15T16:47:08.183+0000] {processor.py:157} INFO - Started process (PID=15055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:47:08.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:47:08.198+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:47:08.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:47:08.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:47:08.284+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:47:08.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:47:08.305+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:47:08.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:47:08.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-15T16:47:38.533+0000] {processor.py:157} INFO - Started process (PID=15065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:47:38.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:47:38.538+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:47:38.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:47:38.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:47:38.622+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:47:38.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:47:38.644+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:47:38.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:47:38.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-15T16:48:09.040+0000] {processor.py:157} INFO - Started process (PID=15075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:48:09.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:48:09.048+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:48:09.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:48:09.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:48:09.123+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:48:09.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:48:09.144+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:48:09.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:48:09.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T16:48:39.594+0000] {processor.py:157} INFO - Started process (PID=15084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:48:39.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:48:39.603+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:48:39.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:48:39.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:48:39.696+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:48:39.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:48:39.718+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:48:39.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:48:39.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-15T16:49:10.047+0000] {processor.py:157} INFO - Started process (PID=15095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:49:10.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:49:10.053+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:49:10.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:49:10.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:49:10.120+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:49:10.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:49:10.137+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:49:10.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:49:10.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T16:49:40.369+0000] {processor.py:157} INFO - Started process (PID=15105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:49:40.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:49:40.373+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:49:40.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:49:40.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:49:40.421+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:49:40.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:49:40.437+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:49:40.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:49:40.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T16:50:10.846+0000] {processor.py:157} INFO - Started process (PID=15115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:50:10.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:50:10.858+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:50:10.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:50:10.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:50:10.928+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:50:10.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:50:10.950+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:50:10.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:50:10.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T16:50:41.178+0000] {processor.py:157} INFO - Started process (PID=15125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:50:41.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:50:41.184+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:50:41.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:50:41.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:50:41.261+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:50:41.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:50:41.278+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:50:41.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:50:41.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-15T16:51:11.506+0000] {processor.py:157} INFO - Started process (PID=15135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:51:11.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:51:11.511+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:51:11.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:51:11.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:51:11.558+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:51:11.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:51:11.573+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:51:11.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:51:11.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T16:51:41.945+0000] {processor.py:157} INFO - Started process (PID=15145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:51:41.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:51:41.950+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:51:41.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:51:41.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:51:41.998+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:51:41.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:51:42.029+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:51:42.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:51:42.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T16:52:12.225+0000] {processor.py:157} INFO - Started process (PID=15155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:52:12.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:52:12.231+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:52:12.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:52:12.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:52:12.345+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:52:12.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:52:12.482+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:52:12.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:52:12.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.302 seconds
[2024-09-15T16:52:42.974+0000] {processor.py:157} INFO - Started process (PID=15165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:52:42.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:52:42.979+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:52:42.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:52:42.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:52:43.027+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:52:43.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:52:43.041+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:52:43.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:52:43.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T16:53:13.412+0000] {processor.py:157} INFO - Started process (PID=15175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:53:13.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:53:13.416+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:53:13.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:53:13.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:53:13.451+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:53:13.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:53:13.463+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:53:13.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:53:13.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T16:53:43.824+0000] {processor.py:157} INFO - Started process (PID=15185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:53:43.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:53:43.829+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:53:43.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:53:43.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:53:43.891+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:53:43.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:53:43.907+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:53:43.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:53:43.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T16:54:14.255+0000] {processor.py:157} INFO - Started process (PID=15195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:54:14.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:54:14.260+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:54:14.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:54:14.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:54:14.332+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:54:14.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:54:14.348+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:54:14.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:54:14.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T16:54:44.595+0000] {processor.py:157} INFO - Started process (PID=15205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:54:44.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:54:44.602+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:54:44.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:54:44.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:54:44.645+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:54:44.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:54:44.662+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:54:44.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:54:44.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T16:55:15.075+0000] {processor.py:157} INFO - Started process (PID=15215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:55:15.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:55:15.082+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:55:15.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:55:15.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:55:15.149+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:55:15.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:55:15.164+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:55:15.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:55:15.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T16:55:45.409+0000] {processor.py:157} INFO - Started process (PID=15225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:55:45.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:55:45.414+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:55:45.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:55:45.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:55:45.487+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:55:45.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:55:45.503+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:55:45.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:55:45.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T16:56:15.827+0000] {processor.py:157} INFO - Started process (PID=15235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:56:15.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:56:15.835+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:56:15.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:56:15.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:56:15.894+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:56:15.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:56:15.909+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:56:15.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:56:15.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T16:56:46.259+0000] {processor.py:157} INFO - Started process (PID=15245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:56:46.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:56:46.264+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:56:46.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:56:46.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:56:46.313+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:56:46.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:56:46.329+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:56:46.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:56:46.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T16:57:16.700+0000] {processor.py:157} INFO - Started process (PID=15255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:57:16.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:57:16.710+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:57:16.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:57:16.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:57:16.737+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:57:16.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:57:16.749+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:57:16.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:57:16.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T16:57:47.067+0000] {processor.py:157} INFO - Started process (PID=15265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:57:47.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:57:47.074+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:57:47.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:57:47.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:57:47.148+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:57:47.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:57:47.162+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:57:47.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:57:47.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T16:58:17.432+0000] {processor.py:157} INFO - Started process (PID=15274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:58:17.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:58:17.438+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:58:17.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:58:17.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:58:17.478+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:58:17.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:58:17.492+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:58:17.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:58:17.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T16:58:47.823+0000] {processor.py:157} INFO - Started process (PID=15285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:58:47.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:58:47.827+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:58:47.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:58:47.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:58:47.879+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:58:47.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:58:47.892+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:58:47.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:58:47.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T16:59:18.247+0000] {processor.py:157} INFO - Started process (PID=15295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:59:18.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:59:18.253+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:59:18.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:59:18.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:59:18.300+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:59:18.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:59:18.317+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:59:18.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:59:18.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T16:59:48.606+0000] {processor.py:157} INFO - Started process (PID=15304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:59:48.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T16:59:48.611+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:59:48.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:59:48.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T16:59:48.670+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:59:48.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T16:59:48.687+0000] {logging_mixin.py:151} INFO - [2024-09-15T16:59:48.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T16:59:48.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T17:00:19.090+0000] {processor.py:157} INFO - Started process (PID=15314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:00:19.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:00:19.095+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:00:19.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:00:19.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:00:19.178+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:00:19.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:00:19.194+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:00:19.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:00:19.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T17:00:49.385+0000] {processor.py:157} INFO - Started process (PID=15325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:00:49.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:00:49.393+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:00:49.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:00:49.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:00:49.465+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:00:49.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:00:49.495+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:00:49.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:00:49.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T17:01:19.756+0000] {processor.py:157} INFO - Started process (PID=15334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:01:19.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:01:19.779+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:01:19.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:01:19.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:01:19.839+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:01:19.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:01:19.864+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:01:19.864+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:01:19.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-15T17:01:50.155+0000] {processor.py:157} INFO - Started process (PID=15344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:01:50.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:01:50.161+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:01:50.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:01:50.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:01:50.240+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:01:50.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:01:50.258+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:01:50.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:01:50.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T17:02:20.688+0000] {processor.py:157} INFO - Started process (PID=15355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:02:20.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:02:20.694+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:02:20.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:02:20.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:02:20.756+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:02:20.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:02:20.788+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:02:20.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:02:20.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-15T17:02:51.163+0000] {processor.py:157} INFO - Started process (PID=15365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:02:51.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:02:51.167+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:02:51.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:02:51.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:02:51.209+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:02:51.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:02:51.223+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:02:51.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:02:51.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T17:03:21.590+0000] {processor.py:157} INFO - Started process (PID=15375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:03:21.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:03:21.597+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:03:21.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:03:21.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:03:21.665+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:03:21.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:03:21.681+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:03:21.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:03:21.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T17:03:51.922+0000] {processor.py:157} INFO - Started process (PID=15385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:03:51.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:03:51.926+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:03:51.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:03:51.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:03:51.967+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:03:51.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:03:51.981+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:03:51.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:03:52.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T17:04:22.210+0000] {processor.py:157} INFO - Started process (PID=15395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:04:22.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:04:22.213+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:04:22.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:04:22.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:04:22.245+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:04:22.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:04:22.256+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:04:22.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:04:22.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T17:04:52.574+0000] {processor.py:157} INFO - Started process (PID=15404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:04:52.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:04:52.581+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:04:52.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:04:52.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:04:52.639+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:04:52.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:04:52.672+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:04:52.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:04:52.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-15T17:05:23.118+0000] {processor.py:157} INFO - Started process (PID=15414) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:05:23.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:05:23.125+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:05:23.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:05:23.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:05:23.195+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:05:23.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:05:23.210+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:05:23.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:05:23.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T17:05:53.551+0000] {processor.py:157} INFO - Started process (PID=15425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:05:53.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:05:53.555+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:05:53.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:05:53.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:05:53.587+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:05:53.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:05:53.602+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:05:53.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:05:53.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T17:06:23.981+0000] {processor.py:157} INFO - Started process (PID=15435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:06:23.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:06:23.989+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:06:23.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:06:24.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:06:24.045+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:06:24.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:06:24.063+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:06:24.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:06:24.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T17:06:54.465+0000] {processor.py:157} INFO - Started process (PID=15445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:06:54.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:06:54.487+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:06:54.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:06:54.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:06:54.552+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:06:54.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:06:54.568+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:06:54.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:06:54.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T17:07:24.842+0000] {processor.py:157} INFO - Started process (PID=15454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:07:24.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:07:24.853+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:07:24.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:07:24.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:07:24.914+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:07:24.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:07:24.931+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:07:24.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:07:24.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-15T17:07:55.229+0000] {processor.py:157} INFO - Started process (PID=15465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:07:55.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:07:55.235+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:07:55.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:07:55.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:07:55.285+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:07:55.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:07:55.305+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:07:55.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:07:55.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T17:08:25.639+0000] {processor.py:157} INFO - Started process (PID=15475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:08:25.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:08:25.641+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:08:25.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:08:25.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:08:25.669+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:08:25.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:08:25.680+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:08:25.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:08:25.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-15T17:08:56.073+0000] {processor.py:157} INFO - Started process (PID=15484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:08:56.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:08:56.085+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:08:56.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:08:56.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:08:56.134+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:08:56.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:08:56.167+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:08:56.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:08:56.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T17:09:26.394+0000] {processor.py:157} INFO - Started process (PID=15495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:09:26.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:09:26.400+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:09:26.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:09:26.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:09:26.443+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:09:26.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:09:26.459+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:09:26.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:09:26.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T17:09:56.764+0000] {processor.py:157} INFO - Started process (PID=15505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:09:56.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:09:56.768+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:09:56.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:09:56.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:09:56.804+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:09:56.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:09:56.822+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:09:56.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:09:56.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T17:10:27.171+0000] {processor.py:157} INFO - Started process (PID=15514) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:10:27.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:10:27.183+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:10:27.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:10:27.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:10:27.245+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:10:27.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:10:27.260+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:10:27.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:10:27.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T17:10:57.521+0000] {processor.py:157} INFO - Started process (PID=15525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:10:57.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:10:57.524+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:10:57.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:10:57.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:10:57.558+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:10:57.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:10:57.569+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:10:57.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:10:57.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T17:11:27.898+0000] {processor.py:157} INFO - Started process (PID=15535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:11:27.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:11:27.904+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:11:27.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:11:27.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:11:27.967+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:11:27.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:11:27.993+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:11:27.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:11:28.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T17:11:58.248+0000] {processor.py:157} INFO - Started process (PID=15545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:11:58.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:11:58.264+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:11:58.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:11:58.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:11:58.339+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:11:58.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:11:58.355+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:11:58.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:11:58.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T17:12:28.741+0000] {processor.py:157} INFO - Started process (PID=15554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:12:28.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:12:28.748+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:12:28.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:12:28.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:12:28.807+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:12:28.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:12:28.823+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:12:28.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:12:28.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T17:12:59.170+0000] {processor.py:157} INFO - Started process (PID=15565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:12:59.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:12:59.180+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:12:59.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:12:59.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:12:59.236+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:12:59.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:12:59.265+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:12:59.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:12:59.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T17:13:29.564+0000] {processor.py:157} INFO - Started process (PID=15575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:13:29.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:13:29.569+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:13:29.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:13:29.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:13:29.616+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:13:29.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:13:29.630+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:13:29.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:13:29.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T17:13:59.821+0000] {processor.py:157} INFO - Started process (PID=15585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:13:59.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:13:59.826+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:13:59.826+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:13:59.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:13:59.855+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:13:59.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:13:59.870+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:13:59.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:13:59.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T17:14:30.226+0000] {processor.py:157} INFO - Started process (PID=15595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:14:30.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:14:30.240+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:14:30.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:14:30.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:14:30.292+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:14:30.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:14:30.320+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:14:30.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:14:30.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T17:15:00.575+0000] {processor.py:157} INFO - Started process (PID=15605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:15:00.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:15:00.580+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:15:00.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:15:00.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:15:00.623+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:15:00.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:15:00.645+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:15:00.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:15:00.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T17:15:30.943+0000] {processor.py:157} INFO - Started process (PID=15615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:15:30.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:15:30.953+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:15:30.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:15:30.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:15:31.015+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:15:31.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:15:31.032+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:15:31.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:15:31.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T17:16:01.294+0000] {processor.py:157} INFO - Started process (PID=15625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:16:01.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:16:01.309+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:16:01.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:16:01.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:16:01.374+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:16:01.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:16:01.399+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:16:01.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:16:01.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-15T17:16:31.696+0000] {processor.py:157} INFO - Started process (PID=15635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:16:31.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:16:31.712+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:16:31.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:16:31.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:16:31.786+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:16:31.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:16:31.807+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:16:31.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:16:31.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-15T17:17:02.034+0000] {processor.py:157} INFO - Started process (PID=15645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:17:02.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:17:02.045+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:17:02.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:17:02.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:17:02.114+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:17:02.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:17:02.131+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:17:02.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:17:02.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T17:17:32.438+0000] {processor.py:157} INFO - Started process (PID=15654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:17:32.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:17:32.444+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:17:32.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:17:32.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:17:32.507+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:17:32.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:17:32.524+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:17:32.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:17:32.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T17:18:02.830+0000] {processor.py:157} INFO - Started process (PID=15665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:18:02.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:18:02.836+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:18:02.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:18:02.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:18:02.907+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:18:02.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:18:02.923+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:18:02.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:18:02.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T17:18:33.328+0000] {processor.py:157} INFO - Started process (PID=15675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:18:33.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:18:33.338+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:18:33.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:18:33.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:18:33.415+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:18:33.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:18:33.432+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:18:33.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:18:33.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-15T17:19:03.728+0000] {processor.py:157} INFO - Started process (PID=15685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:19:03.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:19:03.737+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:19:03.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:19:03.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:19:03.805+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:19:03.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:19:03.832+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:19:03.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:19:03.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T17:19:34.037+0000] {processor.py:157} INFO - Started process (PID=15695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:19:34.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:19:34.051+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:19:34.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:19:34.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:19:34.116+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:19:34.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:19:34.132+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:19:34.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:19:34.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T17:20:04.367+0000] {processor.py:157} INFO - Started process (PID=15705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:20:04.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:20:04.373+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:20:04.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:20:04.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:20:04.428+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:20:04.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:20:04.444+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:20:04.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:20:04.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-15T17:20:34.700+0000] {processor.py:157} INFO - Started process (PID=15715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:20:34.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:20:34.705+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:20:34.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:20:34.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:20:34.748+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:20:34.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:20:34.762+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:20:34.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:20:34.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T17:21:05.006+0000] {processor.py:157} INFO - Started process (PID=15725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:21:05.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:21:05.010+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:21:05.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:21:05.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:21:05.039+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:21:05.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:21:05.063+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:21:05.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:21:05.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T17:21:35.434+0000] {processor.py:157} INFO - Started process (PID=15735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:21:35.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:21:35.455+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:21:35.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:21:35.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:21:35.517+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:21:35.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:21:35.532+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:21:35.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:21:35.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T17:22:05.726+0000] {processor.py:157} INFO - Started process (PID=15745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:22:05.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:22:05.736+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:22:05.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:22:05.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:22:05.847+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:22:05.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:22:05.883+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:22:05.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:22:05.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-09-15T17:22:36.061+0000] {processor.py:157} INFO - Started process (PID=15755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:22:36.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:22:36.068+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:22:36.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:22:36.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:22:36.126+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:22:36.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:22:36.147+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:22:36.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:22:36.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T17:23:06.557+0000] {processor.py:157} INFO - Started process (PID=15765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:23:06.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:23:06.567+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:23:06.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:23:06.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:23:06.612+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:23:06.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:23:06.628+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:23:06.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:23:06.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T17:23:37.045+0000] {processor.py:157} INFO - Started process (PID=15775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:23:37.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:23:37.051+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:23:37.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:23:37.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:23:37.114+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:23:37.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:23:37.129+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:23:37.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:23:37.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T17:24:07.452+0000] {processor.py:157} INFO - Started process (PID=15785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:24:07.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:24:07.461+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:24:07.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:24:07.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:24:07.539+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:24:07.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:24:07.556+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:24:07.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:24:07.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T17:24:37.806+0000] {processor.py:157} INFO - Started process (PID=15795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:24:37.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:24:37.815+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:24:37.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:24:37.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:24:37.879+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:24:37.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:24:37.910+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:24:37.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:24:37.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-15T17:25:08.191+0000] {processor.py:157} INFO - Started process (PID=15805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:25:08.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:25:08.200+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:25:08.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:25:08.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:25:08.265+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:25:08.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:25:08.280+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:25:08.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:25:08.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T17:25:38.575+0000] {processor.py:157} INFO - Started process (PID=15815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:25:38.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:25:38.578+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:25:38.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:25:38.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:25:38.603+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:25:38.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:25:38.616+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:25:38.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:25:38.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-15T17:26:08.951+0000] {processor.py:157} INFO - Started process (PID=15825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:26:08.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:26:08.957+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:26:08.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:26:08.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:26:08.998+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:26:08.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:26:09.013+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:26:09.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:26:09.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T17:26:39.289+0000] {processor.py:157} INFO - Started process (PID=15835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:26:39.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:26:39.293+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:26:39.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:26:39.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:26:39.346+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:26:39.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:26:39.361+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:26:39.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:26:39.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T17:27:09.636+0000] {processor.py:157} INFO - Started process (PID=15845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:27:09.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:27:09.641+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:27:09.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:27:09.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:27:09.675+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:27:09.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:27:09.689+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:27:09.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:27:09.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T17:27:40.021+0000] {processor.py:157} INFO - Started process (PID=15855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:27:40.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:27:40.027+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:27:40.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:27:40.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:27:40.061+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:27:40.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:27:40.073+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:27:40.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:27:40.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-15T17:28:10.359+0000] {processor.py:157} INFO - Started process (PID=15865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:28:10.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:28:10.363+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:28:10.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:28:10.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:28:10.402+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:28:10.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:28:10.420+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:28:10.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:28:10.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T17:28:40.793+0000] {processor.py:157} INFO - Started process (PID=15875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:28:40.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:28:40.797+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:28:40.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:28:40.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:28:40.826+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:28:40.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:28:40.840+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:28:40.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:28:40.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T17:29:11.156+0000] {processor.py:157} INFO - Started process (PID=15885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:29:11.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:29:11.159+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:29:11.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:29:11.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:29:11.194+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:29:11.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:29:11.206+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:29:11.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:29:11.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T17:29:41.460+0000] {processor.py:157} INFO - Started process (PID=15895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:29:41.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:29:41.466+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:29:41.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:29:41.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:29:41.507+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:29:41.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:29:41.520+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:29:41.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:29:41.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T17:30:11.796+0000] {processor.py:157} INFO - Started process (PID=15905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:30:11.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:30:11.799+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:30:11.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:30:11.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:30:11.828+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:30:11.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:30:11.842+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:30:11.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:30:11.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T17:30:42.132+0000] {processor.py:157} INFO - Started process (PID=15915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:30:42.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:30:42.137+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:30:42.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:30:42.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:30:42.169+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:30:42.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:30:42.181+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:30:42.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:30:42.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T17:31:12.509+0000] {processor.py:157} INFO - Started process (PID=15925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:31:12.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:31:12.513+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:31:12.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:31:12.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:31:12.546+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:31:12.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:31:12.557+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:31:12.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:31:12.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-15T17:31:42.908+0000] {processor.py:157} INFO - Started process (PID=15935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:31:42.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:31:42.912+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:31:42.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:31:42.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:31:42.949+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:31:42.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:31:42.966+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:31:42.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:31:42.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T17:32:13.210+0000] {processor.py:157} INFO - Started process (PID=15945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:32:13.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:32:13.213+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:32:13.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:32:13.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:32:13.246+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:32:13.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:32:13.259+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:32:13.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:32:13.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T17:32:43.584+0000] {processor.py:157} INFO - Started process (PID=15955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:32:43.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:32:43.588+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:32:43.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:32:43.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:32:43.632+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:32:43.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:32:43.646+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:32:43.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:32:43.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T17:33:14.009+0000] {processor.py:157} INFO - Started process (PID=15965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:33:14.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:33:14.013+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:33:14.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:33:14.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:33:14.047+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:33:14.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:33:14.061+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:33:14.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:33:14.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T17:33:44.495+0000] {processor.py:157} INFO - Started process (PID=15975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:33:44.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:33:44.514+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:33:44.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:33:44.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:33:44.580+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:33:44.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:33:44.597+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:33:44.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:33:44.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T17:34:14.771+0000] {processor.py:157} INFO - Started process (PID=15985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:34:14.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:34:14.773+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:34:14.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:34:14.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:34:14.806+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:34:14.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:34:14.822+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:34:14.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:34:14.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T17:34:45.139+0000] {processor.py:157} INFO - Started process (PID=15994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:34:45.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:34:45.145+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:34:45.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:34:45.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:34:45.206+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:34:45.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:34:45.224+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:34:45.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:34:45.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T17:35:15.466+0000] {processor.py:157} INFO - Started process (PID=16005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:35:15.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:35:15.474+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:35:15.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:35:15.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:35:15.526+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:35:15.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:35:15.542+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:35:15.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:35:15.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T17:35:45.827+0000] {processor.py:157} INFO - Started process (PID=16015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:35:45.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:35:45.836+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:35:45.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:35:45.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:35:45.898+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:35:45.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:35:45.913+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:35:45.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:35:45.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T17:36:16.173+0000] {processor.py:157} INFO - Started process (PID=16025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:36:16.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:36:16.178+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:36:16.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:36:16.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:36:16.211+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:36:16.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:36:16.227+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:36:16.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:36:16.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T17:36:46.549+0000] {processor.py:157} INFO - Started process (PID=16035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:36:46.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:36:46.554+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:36:46.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:36:46.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:36:46.623+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:36:46.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:36:46.639+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:36:46.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:36:46.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T17:37:16.874+0000] {processor.py:157} INFO - Started process (PID=16045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:37:16.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:37:16.877+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:37:16.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:37:16.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:37:16.911+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:37:16.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:37:16.933+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:37:16.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:37:16.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T17:37:47.169+0000] {processor.py:157} INFO - Started process (PID=16055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:37:47.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:37:47.183+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:37:47.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:37:47.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:37:47.244+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:37:47.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:37:47.283+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:37:47.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:37:47.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T17:38:17.538+0000] {processor.py:157} INFO - Started process (PID=16064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:38:17.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:38:17.561+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:38:17.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:38:17.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:38:17.624+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:38:17.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:38:17.644+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:38:17.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:38:17.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T17:38:48.010+0000] {processor.py:157} INFO - Started process (PID=16075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:38:48.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:38:48.017+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:38:48.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:38:48.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:38:48.099+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:38:48.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:38:48.115+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:38:48.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:38:48.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-15T17:39:18.454+0000] {processor.py:157} INFO - Started process (PID=16085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:39:18.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:39:18.458+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:39:18.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:39:18.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:39:18.486+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:39:18.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:39:18.503+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:39:18.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:39:18.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T17:39:48.882+0000] {processor.py:157} INFO - Started process (PID=16095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:39:48.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:39:48.890+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:39:48.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:39:48.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:39:48.980+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:39:48.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:39:49.002+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:39:49.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:39:49.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-15T17:40:19.365+0000] {processor.py:157} INFO - Started process (PID=16104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:40:19.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:40:19.369+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:40:19.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:40:19.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:40:19.408+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:40:19.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:40:19.426+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:40:19.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:40:19.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T17:40:49.760+0000] {processor.py:157} INFO - Started process (PID=16115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:40:49.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:40:49.764+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:40:49.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:40:49.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:40:49.809+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:40:49.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:40:49.830+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:40:49.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:40:49.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T17:41:20.111+0000] {processor.py:157} INFO - Started process (PID=16124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:41:20.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:41:20.120+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:41:20.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:41:20.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:41:20.181+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:41:20.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:41:20.197+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:41:20.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:41:20.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T17:41:50.576+0000] {processor.py:157} INFO - Started process (PID=16135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:41:50.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:41:50.586+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:41:50.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:41:50.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:41:50.651+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:41:50.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:41:50.672+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:41:50.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:41:50.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T17:42:21.118+0000] {processor.py:157} INFO - Started process (PID=16145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:42:21.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:42:21.131+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:42:21.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:42:21.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:42:21.182+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:42:21.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:42:21.201+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:42:21.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:42:21.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T17:42:51.723+0000] {processor.py:157} INFO - Started process (PID=16155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:42:51.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:42:51.739+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:42:51.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:42:51.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:42:51.870+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:42:51.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:42:51.904+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:42:51.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:42:51.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.214 seconds
[2024-09-15T17:43:22.070+0000] {processor.py:157} INFO - Started process (PID=16165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:43:22.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:43:22.078+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:43:22.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:43:22.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:43:22.144+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:43:22.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:43:22.170+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:43:22.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:43:22.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T17:43:52.500+0000] {processor.py:157} INFO - Started process (PID=16175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:43:52.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:43:52.507+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:43:52.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:43:52.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:43:52.563+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:43:52.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:43:52.579+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:43:52.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:43:52.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T17:44:22.820+0000] {processor.py:157} INFO - Started process (PID=16185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:44:22.821+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:44:22.823+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:44:22.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:44:22.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:44:22.853+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:44:22.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:44:22.867+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:44:22.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:44:22.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T17:44:53.114+0000] {processor.py:157} INFO - Started process (PID=16195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:44:53.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:44:53.126+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:44:53.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:44:53.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:44:53.191+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:44:53.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:44:53.214+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:44:53.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:44:53.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T17:45:23.572+0000] {processor.py:157} INFO - Started process (PID=16205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:45:23.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:45:23.577+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:45:23.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:45:23.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:45:23.618+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:45:23.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:45:23.633+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:45:23.633+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:45:23.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T17:45:54.026+0000] {processor.py:157} INFO - Started process (PID=16214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:45:54.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:45:54.033+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:45:54.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:45:54.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:45:54.105+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:45:54.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:45:54.120+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:45:54.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:45:54.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T17:46:24.362+0000] {processor.py:157} INFO - Started process (PID=16224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:46:24.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:46:24.377+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:46:24.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:46:24.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:46:24.421+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:46:24.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:46:24.442+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:46:24.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:46:24.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T17:46:54.748+0000] {processor.py:157} INFO - Started process (PID=16235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:46:54.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:46:54.755+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:46:54.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:46:54.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:46:54.825+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:46:54.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:46:54.841+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:46:54.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:46:54.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T17:47:25.098+0000] {processor.py:157} INFO - Started process (PID=16245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:47:25.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:47:25.106+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:47:25.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:47:25.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:47:25.163+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:47:25.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:47:25.179+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:47:25.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:47:25.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T17:47:55.562+0000] {processor.py:157} INFO - Started process (PID=16255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:47:55.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:47:55.569+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:47:55.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:47:55.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:47:55.628+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:47:55.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:47:55.645+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:47:55.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:47:55.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T17:48:25.886+0000] {processor.py:157} INFO - Started process (PID=16265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:48:25.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:48:25.892+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:48:25.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:48:25.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:48:25.952+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:48:25.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:48:25.968+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:48:25.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:48:25.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T17:48:56.338+0000] {processor.py:157} INFO - Started process (PID=16273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:48:56.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:48:56.343+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:48:56.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:48:56.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:48:56.403+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:48:56.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:48:56.420+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:48:56.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:48:56.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T17:49:26.764+0000] {processor.py:157} INFO - Started process (PID=16285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:49:26.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:49:26.768+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:49:26.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:49:26.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:49:26.806+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:49:26.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:49:26.819+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:49:26.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:49:26.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T17:49:57.062+0000] {processor.py:157} INFO - Started process (PID=16294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:49:57.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:49:57.067+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:49:57.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:49:57.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:49:57.126+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:49:57.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:49:57.143+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:49:57.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:49:57.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T17:50:27.494+0000] {processor.py:157} INFO - Started process (PID=16305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:50:27.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:50:27.501+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:50:27.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:50:27.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:50:27.535+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:50:27.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:50:27.560+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:50:27.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:50:27.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T17:50:57.969+0000] {processor.py:157} INFO - Started process (PID=16314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:50:57.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:50:57.974+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:50:57.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:50:58.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:50:58.035+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:50:58.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:50:58.053+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:50:58.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:50:58.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T17:51:28.275+0000] {processor.py:157} INFO - Started process (PID=16325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:51:28.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:51:28.280+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:51:28.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:51:28.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:51:28.311+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:51:28.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:51:28.330+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:51:28.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:51:28.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T17:51:58.588+0000] {processor.py:157} INFO - Started process (PID=16334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:51:58.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:51:58.593+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:51:58.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:51:58.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:51:58.646+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:51:58.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:51:58.663+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:51:58.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:51:58.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T17:52:28.920+0000] {processor.py:157} INFO - Started process (PID=16345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:52:28.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:52:28.924+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:52:28.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:52:28.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:52:28.954+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:52:28.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:52:28.970+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:52:28.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:52:28.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T17:52:59.328+0000] {processor.py:157} INFO - Started process (PID=16355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:52:59.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:52:59.335+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:52:59.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:52:59.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:52:59.374+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:52:59.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:52:59.389+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:52:59.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:52:59.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T17:53:29.648+0000] {processor.py:157} INFO - Started process (PID=16365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:53:29.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:53:29.652+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:53:29.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:53:29.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:53:29.682+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:53:29.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:53:29.695+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:53:29.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:53:29.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T17:53:59.974+0000] {processor.py:157} INFO - Started process (PID=16375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:53:59.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:53:59.981+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:53:59.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:53:59.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:54:00.020+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:54:00.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:54:00.031+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:54:00.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:54:00.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T17:54:30.350+0000] {processor.py:157} INFO - Started process (PID=16385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:54:30.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:54:30.354+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:54:30.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:54:30.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:54:30.386+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:54:30.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:54:30.421+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:54:30.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:54:30.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T17:55:00.787+0000] {processor.py:157} INFO - Started process (PID=16394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:55:00.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:55:00.809+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:55:00.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:55:00.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:55:00.854+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:55:00.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:55:00.872+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:55:00.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:55:00.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T17:55:31.140+0000] {processor.py:157} INFO - Started process (PID=16405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:55:31.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:55:31.153+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:55:31.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:55:31.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:55:31.194+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:55:31.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:55:31.210+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:55:31.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:55:31.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T17:56:01.453+0000] {processor.py:157} INFO - Started process (PID=16415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:56:01.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:56:01.457+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:56:01.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:56:01.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:56:01.489+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:56:01.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:56:01.502+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:56:01.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:56:01.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T17:56:31.839+0000] {processor.py:157} INFO - Started process (PID=16425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:56:31.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:56:31.845+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:56:31.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:56:31.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:56:31.881+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:56:31.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:56:31.894+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:56:31.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:56:31.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T17:57:02.222+0000] {processor.py:157} INFO - Started process (PID=16435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:57:02.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:57:02.230+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:57:02.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:57:02.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:57:02.269+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:57:02.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:57:02.298+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:57:02.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:57:02.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T17:57:32.694+0000] {processor.py:157} INFO - Started process (PID=16445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:57:32.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:57:32.697+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:57:32.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:57:32.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:57:32.728+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:57:32.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:57:32.741+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:57:32.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:57:32.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T17:58:03.161+0000] {processor.py:157} INFO - Started process (PID=16454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:58:03.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:58:03.166+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:58:03.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:58:03.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:58:03.229+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:58:03.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:58:03.245+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:58:03.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:58:03.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T17:58:33.436+0000] {processor.py:157} INFO - Started process (PID=16465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:58:33.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:58:33.444+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:58:33.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:58:33.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:58:33.474+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:58:33.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:58:33.486+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:58:33.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:58:33.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T17:59:03.928+0000] {processor.py:157} INFO - Started process (PID=16474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:59:03.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:59:03.935+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:59:03.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:59:03.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:59:04.004+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:59:04.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:59:04.029+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:59:04.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:59:04.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-15T17:59:34.275+0000] {processor.py:157} INFO - Started process (PID=16485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:59:34.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T17:59:34.280+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:59:34.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:59:34.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T17:59:34.323+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:59:34.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T17:59:34.338+0000] {logging_mixin.py:151} INFO - [2024-09-15T17:59:34.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T17:59:34.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T18:00:04.718+0000] {processor.py:157} INFO - Started process (PID=16495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:00:04.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:00:04.730+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:00:04.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:00:04.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:00:04.775+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:00:04.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:00:04.791+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:00:04.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:00:04.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T18:00:35.118+0000] {processor.py:157} INFO - Started process (PID=16505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:00:35.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:00:35.122+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:00:35.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:00:35.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:00:35.147+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:00:35.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:00:35.162+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:00:35.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:00:35.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T18:01:05.466+0000] {processor.py:157} INFO - Started process (PID=16515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:01:05.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:01:05.475+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:01:05.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:01:05.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:01:05.533+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:01:05.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:01:05.550+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:01:05.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:01:05.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T18:01:35.795+0000] {processor.py:157} INFO - Started process (PID=16525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:01:35.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:01:35.799+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:01:35.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:01:35.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:01:35.827+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:01:35.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:01:35.841+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:01:35.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:01:35.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T18:02:06.190+0000] {processor.py:157} INFO - Started process (PID=16535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:02:06.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:02:06.212+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:02:06.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:02:06.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:02:06.263+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:02:06.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:02:06.297+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:02:06.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:02:06.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T18:02:36.516+0000] {processor.py:157} INFO - Started process (PID=16545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:02:36.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:02:36.520+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:02:36.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:02:36.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:02:36.550+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:02:36.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:02:36.567+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:02:36.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:02:36.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T18:03:06.919+0000] {processor.py:157} INFO - Started process (PID=16555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:03:06.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:03:06.927+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:03:06.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:03:06.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:03:06.965+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:03:06.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:03:06.979+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:03:06.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:03:06.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T18:03:37.242+0000] {processor.py:157} INFO - Started process (PID=16565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:03:37.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:03:37.247+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:03:37.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:03:37.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:03:37.279+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:03:37.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:03:37.312+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:03:37.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:03:37.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T18:04:07.605+0000] {processor.py:157} INFO - Started process (PID=16575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:04:07.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:04:07.611+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:04:07.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:04:07.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:04:07.674+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:04:07.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:04:07.706+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:04:07.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:04:07.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T18:04:37.955+0000] {processor.py:157} INFO - Started process (PID=16585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:04:37.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:04:37.963+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:04:37.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:04:37.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:04:38.021+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:04:38.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:04:38.037+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:04:38.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:04:38.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T18:05:08.281+0000] {processor.py:157} INFO - Started process (PID=16595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:05:08.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:05:08.288+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:05:08.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:05:08.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:05:08.336+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:05:08.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:05:08.361+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:05:08.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:05:08.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T18:05:38.742+0000] {processor.py:157} INFO - Started process (PID=16605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:05:38.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:05:38.749+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:05:38.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:05:38.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:05:38.824+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:05:38.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:05:38.842+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:05:38.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:05:38.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-15T18:06:09.184+0000] {processor.py:157} INFO - Started process (PID=16615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:06:09.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:06:09.190+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:06:09.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:06:09.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:06:09.229+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:06:09.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:06:09.253+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:06:09.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:06:09.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T18:06:39.579+0000] {processor.py:157} INFO - Started process (PID=16625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:06:39.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:06:39.597+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:06:39.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:06:39.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:06:39.672+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:06:39.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:06:39.690+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:06:39.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:06:39.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-15T18:07:09.933+0000] {processor.py:157} INFO - Started process (PID=16635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:07:09.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:07:09.939+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:07:09.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:07:09.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:07:09.983+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:07:09.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:07:10.008+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:07:10.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:07:10.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T18:07:40.417+0000] {processor.py:157} INFO - Started process (PID=16645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:07:40.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:07:40.424+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:07:40.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:07:40.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:07:40.495+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:07:40.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:07:40.513+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:07:40.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:07:40.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T18:08:10.725+0000] {processor.py:157} INFO - Started process (PID=16655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:08:10.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:08:10.731+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:08:10.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:08:10.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:08:10.772+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:08:10.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:08:10.791+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:08:10.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:08:10.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T18:08:41.042+0000] {processor.py:157} INFO - Started process (PID=16665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:08:41.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:08:41.048+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:08:41.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:08:41.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:08:41.105+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:08:41.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:08:41.121+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:08:41.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:08:41.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T18:09:11.377+0000] {processor.py:157} INFO - Started process (PID=16674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:09:11.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:09:11.383+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:09:11.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:09:11.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:09:11.453+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:09:11.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:09:11.471+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:09:11.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:09:11.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T18:09:41.798+0000] {processor.py:157} INFO - Started process (PID=16685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:09:41.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:09:41.805+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:09:41.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:09:41.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:09:41.866+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:09:41.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:09:41.883+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:09:41.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:09:41.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T18:10:12.167+0000] {processor.py:157} INFO - Started process (PID=16695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:10:12.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:10:12.174+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:10:12.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:10:12.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:10:12.246+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:10:12.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:10:12.263+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:10:12.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:10:12.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T18:10:42.551+0000] {processor.py:157} INFO - Started process (PID=16705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:10:42.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:10:42.558+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:10:42.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:10:42.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:10:42.624+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:10:42.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:10:42.641+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:10:42.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:10:42.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T18:11:12.873+0000] {processor.py:157} INFO - Started process (PID=16715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:11:12.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:11:12.879+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:11:12.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:11:12.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:11:12.916+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:11:12.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:11:12.929+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:11:12.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:11:12.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T18:11:43.292+0000] {processor.py:157} INFO - Started process (PID=16725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:11:43.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:11:43.299+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:11:43.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:11:43.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:11:43.351+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:11:43.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:11:43.374+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:11:43.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:11:43.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T18:12:13.711+0000] {processor.py:157} INFO - Started process (PID=16735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:12:13.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:12:13.716+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:12:13.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:12:13.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:12:13.778+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:12:13.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:12:13.794+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:12:13.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:12:13.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T18:12:43.955+0000] {processor.py:157} INFO - Started process (PID=16745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:12:43.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:12:43.959+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:12:43.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:12:43.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:12:44.010+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:12:44.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:12:44.031+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:12:44.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:12:44.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T18:13:14.325+0000] {processor.py:157} INFO - Started process (PID=16755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:13:14.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:13:14.335+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:13:14.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:13:14.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:13:14.397+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:13:14.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:13:14.413+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:13:14.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:13:14.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T18:13:44.696+0000] {processor.py:157} INFO - Started process (PID=16765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:13:44.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:13:44.714+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:13:44.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:13:44.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:13:44.881+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:13:44.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:13:44.908+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:13:44.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:13:44.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.278 seconds
[2024-09-15T18:14:15.114+0000] {processor.py:157} INFO - Started process (PID=16775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:14:15.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:14:15.124+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:14:15.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:14:15.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:14:15.199+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:14:15.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:14:15.224+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:14:15.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:14:15.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-15T18:14:45.660+0000] {processor.py:157} INFO - Started process (PID=16785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:14:45.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:14:45.669+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:14:45.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:14:45.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:14:45.733+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:14:45.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:14:45.751+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:14:45.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:14:45.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T18:15:16.049+0000] {processor.py:157} INFO - Started process (PID=16795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:15:16.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:15:16.056+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:15:16.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:15:16.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:15:16.138+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:15:16.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:15:16.176+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:15:16.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:15:16.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-15T18:15:46.601+0000] {processor.py:157} INFO - Started process (PID=16805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:15:46.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:15:46.608+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:15:46.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:15:46.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:15:46.676+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:15:46.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:15:46.705+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:15:46.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:15:46.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T18:16:16.949+0000] {processor.py:157} INFO - Started process (PID=16815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:16:16.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:16:16.956+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:16:16.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:16:16.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:16:17.025+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:16:17.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:16:17.045+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:16:17.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:16:17.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T18:16:47.334+0000] {processor.py:157} INFO - Started process (PID=16825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:16:47.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:16:47.340+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:16:47.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:16:47.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:16:47.407+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:16:47.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:16:47.429+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:16:47.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:16:47.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T18:17:17.725+0000] {processor.py:157} INFO - Started process (PID=16835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:17:17.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:17:17.730+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:17:17.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:17:17.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:17:17.773+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:17:17.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:17:17.811+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:17:17.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:17:17.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T18:17:48.046+0000] {processor.py:157} INFO - Started process (PID=16845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:17:48.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:17:48.054+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:17:48.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:17:48.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:17:48.137+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:17:48.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:17:48.157+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:17:48.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:17:48.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-15T18:18:18.427+0000] {processor.py:157} INFO - Started process (PID=16855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:18:18.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:18:18.435+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:18:18.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:18:18.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:18:18.477+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:18:18.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:18:18.492+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:18:18.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:18:18.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T18:18:48.859+0000] {processor.py:157} INFO - Started process (PID=16864) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:18:48.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:18:48.867+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:18:48.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:18:48.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:18:48.931+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:18:48.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:18:48.957+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:18:48.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:18:48.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T18:19:19.190+0000] {processor.py:157} INFO - Started process (PID=16875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:19:19.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:19:19.196+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:19:19.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:19:19.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:19:19.239+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:19:19.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:19:19.258+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:19:19.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:19:19.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T18:19:49.668+0000] {processor.py:157} INFO - Started process (PID=16885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:19:49.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:19:49.688+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:19:49.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:19:49.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:19:49.759+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:19:49.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:19:49.775+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:19:49.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:19:49.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T18:20:20.138+0000] {processor.py:157} INFO - Started process (PID=16894) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:20:20.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:20:20.148+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:20:20.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:20:20.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:20:20.218+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:20:20.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:20:20.249+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:20:20.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:20:20.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-15T18:20:50.537+0000] {processor.py:157} INFO - Started process (PID=16905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:20:50.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:20:50.542+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:20:50.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:20:50.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:20:50.608+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:20:50.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:20:50.625+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:20:50.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:20:50.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T18:21:20.985+0000] {processor.py:157} INFO - Started process (PID=16915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:21:20.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:21:20.990+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:21:20.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:21:21.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:21:21.042+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:21:21.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:21:21.061+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:21:21.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:21:21.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T18:21:51.322+0000] {processor.py:157} INFO - Started process (PID=16925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:21:51.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:21:51.330+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:21:51.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:21:51.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:21:51.403+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:21:51.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:21:51.421+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:21:51.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:21:51.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T18:22:21.778+0000] {processor.py:157} INFO - Started process (PID=16935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:22:21.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:22:21.787+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:22:21.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:22:21.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:22:21.844+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:22:21.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:22:21.871+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:22:21.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:22:21.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T18:22:52.127+0000] {processor.py:157} INFO - Started process (PID=16945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:22:52.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:22:52.134+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:22:52.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:22:52.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:22:52.192+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:22:52.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:22:52.209+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:22:52.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:22:52.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T18:23:22.464+0000] {processor.py:157} INFO - Started process (PID=16955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:23:22.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:23:22.470+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:23:22.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:23:22.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:23:22.519+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:23:22.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:23:22.536+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:23:22.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:23:22.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T18:23:52.908+0000] {processor.py:157} INFO - Started process (PID=16965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:23:52.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:23:52.916+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:23:52.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:23:52.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:23:52.972+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:23:52.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:23:52.997+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:23:52.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:23:53.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T18:24:23.229+0000] {processor.py:157} INFO - Started process (PID=16975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:24:23.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:24:23.234+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:24:23.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:24:23.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:24:23.287+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:24:23.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:24:23.303+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:24:23.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:24:23.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T18:24:53.710+0000] {processor.py:157} INFO - Started process (PID=16985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:24:53.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:24:53.726+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:24:53.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:24:53.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:24:53.782+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:24:53.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:24:53.804+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:24:53.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:24:53.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T18:25:24.018+0000] {processor.py:157} INFO - Started process (PID=16995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:25:24.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:25:24.023+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:25:24.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:25:24.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:25:24.067+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:25:24.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:25:24.083+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:25:24.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:25:24.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T18:25:54.405+0000] {processor.py:157} INFO - Started process (PID=17003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:25:54.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:25:54.412+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:25:54.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:25:54.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:25:54.485+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:25:54.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:25:54.503+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:25:54.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:25:54.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T18:26:25.071+0000] {processor.py:157} INFO - Started process (PID=17015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:26:25.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:26:25.084+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:26:25.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:26:25.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:26:25.178+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:26:25.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:26:25.257+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:26:25.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:26:25.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.308 seconds
[2024-09-15T18:26:55.617+0000] {processor.py:157} INFO - Started process (PID=17025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:26:55.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:26:55.623+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:26:55.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:26:55.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:26:55.684+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:26:55.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:26:55.711+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:26:55.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:26:55.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T18:27:26.188+0000] {processor.py:157} INFO - Started process (PID=17035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:27:26.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:27:26.209+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:27:26.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:27:26.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:27:26.277+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:27:26.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:27:26.309+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:27:26.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:27:26.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-15T18:27:56.507+0000] {processor.py:157} INFO - Started process (PID=17045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:27:56.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:27:56.515+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:27:56.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:27:56.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:27:56.600+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:27:56.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:27:56.642+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:27:56.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:27:56.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-15T18:28:27.312+0000] {processor.py:157} INFO - Started process (PID=17055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:28:27.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:28:27.335+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:28:27.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:28:27.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:28:27.417+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:28:27.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:28:27.440+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:28:27.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:28:27.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-15T18:28:57.609+0000] {processor.py:157} INFO - Started process (PID=17065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:28:57.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:28:57.619+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:28:57.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:28:57.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:28:57.683+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:28:57.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:28:57.726+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:28:57.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:28:57.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-15T18:29:28.019+0000] {processor.py:157} INFO - Started process (PID=17075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:29:28.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:29:28.029+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:29:28.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:29:28.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:29:28.088+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:29:28.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:29:28.141+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:29:28.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:29:28.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-15T18:29:58.457+0000] {processor.py:157} INFO - Started process (PID=17085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:29:58.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:29:58.464+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:29:58.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:29:58.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:29:58.521+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:29:58.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:29:58.541+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:29:58.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:29:58.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T18:30:28.813+0000] {processor.py:157} INFO - Started process (PID=17095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:30:28.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:30:28.825+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:30:28.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:30:28.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:30:28.888+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:30:28.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:30:28.921+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:30:28.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:30:28.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T18:30:59.134+0000] {processor.py:157} INFO - Started process (PID=17105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:30:59.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:30:59.139+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:30:59.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:30:59.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:30:59.183+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:30:59.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:30:59.204+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:30:59.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:30:59.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T18:31:29.488+0000] {processor.py:157} INFO - Started process (PID=17115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:31:29.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:31:29.494+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:31:29.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:31:29.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:31:29.537+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:31:29.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:31:29.554+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:31:29.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:31:29.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T18:31:59.933+0000] {processor.py:157} INFO - Started process (PID=17125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:31:59.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:31:59.944+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:31:59.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:31:59.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:32:00.007+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:32:00.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:32:00.026+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:32:00.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:32:00.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T18:32:30.300+0000] {processor.py:157} INFO - Started process (PID=17135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:32:30.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:32:30.313+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:32:30.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:32:30.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:32:30.392+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:32:30.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:32:30.408+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:32:30.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:32:30.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T18:33:00.626+0000] {processor.py:157} INFO - Started process (PID=17145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:33:00.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:33:00.633+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:33:00.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:33:00.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:33:00.726+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:33:00.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:33:00.753+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:33:00.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:33:00.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-15T18:33:31.021+0000] {processor.py:157} INFO - Started process (PID=17155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:33:31.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:33:31.026+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:33:31.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:33:31.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:33:31.102+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:33:31.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:33:31.119+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:33:31.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:33:31.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T18:34:01.440+0000] {processor.py:157} INFO - Started process (PID=17165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:34:01.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:34:01.451+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:34:01.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:34:01.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:34:01.548+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:34:01.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:34:01.578+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:34:01.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:34:01.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-15T18:34:31.807+0000] {processor.py:157} INFO - Started process (PID=17175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:34:31.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:34:31.814+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:34:31.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:34:31.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:34:31.898+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:34:31.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:34:31.918+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:34:31.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:34:31.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T18:35:02.223+0000] {processor.py:157} INFO - Started process (PID=17185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:35:02.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:35:02.232+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:35:02.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:35:02.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:35:02.307+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:35:02.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:35:02.338+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:35:02.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:35:02.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-15T18:35:32.614+0000] {processor.py:157} INFO - Started process (PID=17195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:35:32.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:35:32.627+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:35:32.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:35:32.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:35:32.696+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:35:32.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:35:32.713+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:35:32.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:35:32.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T18:36:03.001+0000] {processor.py:157} INFO - Started process (PID=17205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:36:03.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:36:03.007+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:36:03.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:36:03.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:36:03.068+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:36:03.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:36:03.084+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:36:03.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:36:03.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T18:36:33.354+0000] {processor.py:157} INFO - Started process (PID=17215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:36:33.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:36:33.368+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:36:33.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:36:33.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:36:33.421+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:36:33.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:36:33.448+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:36:33.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:36:33.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T18:37:03.816+0000] {processor.py:157} INFO - Started process (PID=17225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:37:03.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:37:03.823+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:37:03.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:37:03.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:37:03.883+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:37:03.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:37:03.900+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:37:03.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:37:03.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T18:37:34.280+0000] {processor.py:157} INFO - Started process (PID=17235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:37:34.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:37:34.285+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:37:34.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:37:34.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:37:34.329+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:37:34.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:37:34.357+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:37:34.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:37:34.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T18:38:04.693+0000] {processor.py:157} INFO - Started process (PID=17245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:38:04.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:38:04.698+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:38:04.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:38:04.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:38:04.753+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:38:04.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:38:04.771+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:38:04.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:38:04.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-15T18:38:35.291+0000] {processor.py:157} INFO - Started process (PID=17255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:38:35.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:38:35.308+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:38:35.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:38:35.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:38:35.385+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:38:35.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:38:35.403+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:38:35.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:38:35.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-15T18:39:05.656+0000] {processor.py:157} INFO - Started process (PID=17265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:39:05.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:39:05.663+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:39:05.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:39:05.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:39:05.725+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:39:05.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:39:05.744+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:39:05.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:39:05.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T18:39:36.362+0000] {processor.py:157} INFO - Started process (PID=17275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:39:36.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:39:36.380+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:39:36.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:39:36.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:39:36.679+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:39:36.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:39:36.764+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:39:36.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:39:36.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.437 seconds
[2024-09-15T18:40:07.111+0000] {processor.py:157} INFO - Started process (PID=17285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:40:07.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:40:07.125+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:40:07.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:40:07.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:40:07.208+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:40:07.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:40:07.226+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:40:07.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:40:07.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-15T18:40:37.511+0000] {processor.py:157} INFO - Started process (PID=17295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:40:37.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:40:37.518+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:40:37.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:40:37.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:40:37.583+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:40:37.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:40:37.604+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:40:37.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:40:37.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T18:41:07.855+0000] {processor.py:157} INFO - Started process (PID=17305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:41:07.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:41:07.863+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:41:07.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:41:07.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:41:07.916+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:41:07.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:41:07.939+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:41:07.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:41:07.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T18:41:38.108+0000] {processor.py:157} INFO - Started process (PID=17315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:41:38.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:41:38.112+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:41:38.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:41:38.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:41:38.142+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:41:38.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:41:38.160+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:41:38.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:41:38.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T18:42:08.479+0000] {processor.py:157} INFO - Started process (PID=17325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:42:08.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:42:08.487+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:42:08.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:42:08.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:42:08.535+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:42:08.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:42:08.553+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:42:08.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:42:08.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T18:42:38.811+0000] {processor.py:157} INFO - Started process (PID=17335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:42:38.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:42:38.816+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:42:38.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:42:38.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:42:38.843+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:42:38.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:42:38.857+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:42:38.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:42:38.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T18:43:09.214+0000] {processor.py:157} INFO - Started process (PID=17345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:43:09.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:43:09.220+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:43:09.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:43:09.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:43:09.271+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:43:09.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:43:09.290+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:43:09.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:43:09.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T18:43:39.649+0000] {processor.py:157} INFO - Started process (PID=17355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:43:39.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:43:39.655+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:43:39.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:43:39.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:43:39.728+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:43:39.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:43:39.758+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:43:39.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:43:39.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-15T18:44:09.966+0000] {processor.py:157} INFO - Started process (PID=17364) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:44:09.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:44:09.984+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:44:09.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:44:10.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:44:10.057+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:44:10.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:44:10.077+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:44:10.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:44:10.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T18:44:40.344+0000] {processor.py:157} INFO - Started process (PID=17375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:44:40.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:44:40.348+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:44:40.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:44:40.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:44:40.426+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:44:40.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:44:40.442+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:44:40.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:44:40.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T18:45:10.752+0000] {processor.py:157} INFO - Started process (PID=17385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:45:10.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:45:10.763+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:45:10.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:45:10.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:45:10.828+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:45:10.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:45:10.858+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:45:10.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:45:10.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T18:45:41.091+0000] {processor.py:157} INFO - Started process (PID=17395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:45:41.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:45:41.095+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:45:41.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:45:41.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:45:41.137+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:45:41.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:45:41.156+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:45:41.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:45:41.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T18:46:11.467+0000] {processor.py:157} INFO - Started process (PID=17405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:46:11.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:46:11.472+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:46:11.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:46:11.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:46:11.510+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:46:11.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:46:11.525+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:46:11.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:46:11.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T18:46:41.809+0000] {processor.py:157} INFO - Started process (PID=17415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:46:41.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:46:41.812+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:46:41.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:46:41.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:46:41.883+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:46:41.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:46:41.897+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:46:41.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:46:41.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T18:47:12.157+0000] {processor.py:157} INFO - Started process (PID=17425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:47:12.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:47:12.163+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:47:12.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:47:12.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:47:12.220+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:47:12.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:47:12.240+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:47:12.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:47:12.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T18:47:42.522+0000] {processor.py:157} INFO - Started process (PID=17435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:47:42.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:47:42.529+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:47:42.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:47:42.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:47:42.580+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:47:42.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:47:42.605+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:47:42.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:47:42.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T18:48:12.881+0000] {processor.py:157} INFO - Started process (PID=17445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:48:12.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:48:12.898+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:48:12.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:48:12.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:48:12.962+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:48:12.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:48:12.979+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:48:12.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:48:12.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T18:48:43.229+0000] {processor.py:157} INFO - Started process (PID=17455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:48:43.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:48:43.235+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:48:43.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:48:43.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:48:43.294+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:48:43.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:48:43.310+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:48:43.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:48:43.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T18:49:13.654+0000] {processor.py:157} INFO - Started process (PID=17465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:49:13.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:49:13.656+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:49:13.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:49:13.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:49:13.686+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:49:13.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:49:13.700+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:49:13.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:49:13.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-15T18:49:44.103+0000] {processor.py:157} INFO - Started process (PID=17475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:49:44.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:49:44.116+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:49:44.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:49:44.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:49:44.184+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:49:44.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:49:44.200+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:49:44.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:49:44.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T18:50:14.515+0000] {processor.py:157} INFO - Started process (PID=17485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:50:14.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:50:14.520+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:50:14.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:50:14.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:50:14.561+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:50:14.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:50:14.574+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:50:14.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:50:14.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T18:50:44.914+0000] {processor.py:157} INFO - Started process (PID=17495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:50:44.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:50:44.926+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:50:44.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:50:44.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:50:44.975+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:50:44.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:50:44.991+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:50:44.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:50:45.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T18:51:15.264+0000] {processor.py:157} INFO - Started process (PID=17505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:51:15.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:51:15.286+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:51:15.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:51:15.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:51:15.385+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:51:15.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:51:15.407+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:51:15.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:51:15.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-09-15T18:51:45.623+0000] {processor.py:157} INFO - Started process (PID=17515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:51:45.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:51:45.630+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:51:45.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:51:45.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:51:45.679+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:51:45.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:51:45.701+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:51:45.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:51:45.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T18:52:15.992+0000] {processor.py:157} INFO - Started process (PID=17525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:52:15.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:52:16.007+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:52:16.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:52:16.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:52:16.078+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:52:16.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:52:16.095+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:52:16.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:52:16.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-15T18:52:46.346+0000] {processor.py:157} INFO - Started process (PID=17535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:52:46.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:52:46.363+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:52:46.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:52:46.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:52:46.441+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:52:46.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:52:46.457+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:52:46.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:52:46.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T18:53:16.655+0000] {processor.py:157} INFO - Started process (PID=17545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:53:16.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:53:16.661+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:53:16.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:53:16.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:53:16.700+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:53:16.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:53:16.712+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:53:16.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:53:16.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T18:53:47.076+0000] {processor.py:157} INFO - Started process (PID=17555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:53:47.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:53:47.083+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:53:47.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:53:47.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:53:47.113+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:53:47.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:53:47.125+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:53:47.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:53:47.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T18:54:17.368+0000] {processor.py:157} INFO - Started process (PID=17565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:54:17.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:54:17.379+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:54:17.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:54:17.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:54:17.473+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:54:17.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:54:17.491+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:54:17.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:54:17.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-15T18:54:47.644+0000] {processor.py:157} INFO - Started process (PID=17575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:54:47.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:54:47.651+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:54:47.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:54:47.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:54:47.694+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:54:47.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:54:47.712+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:54:47.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:54:47.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T18:55:18.178+0000] {processor.py:157} INFO - Started process (PID=17585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:55:18.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:55:18.186+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:55:18.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:55:18.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:55:18.246+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:55:18.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:55:18.262+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:55:18.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:55:18.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T18:55:48.472+0000] {processor.py:157} INFO - Started process (PID=17595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:55:48.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:55:48.478+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:55:48.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:55:48.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:55:48.506+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:55:48.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:55:48.516+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:55:48.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:55:48.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T18:56:18.852+0000] {processor.py:157} INFO - Started process (PID=17605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:56:18.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:56:18.855+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:56:18.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:56:18.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:56:18.928+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:56:18.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:56:18.964+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:56:18.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:56:18.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T18:56:49.242+0000] {processor.py:157} INFO - Started process (PID=17615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:56:49.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:56:49.248+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:56:49.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:56:49.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:56:49.313+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:56:49.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:56:49.328+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:56:49.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:56:49.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T18:57:19.624+0000] {processor.py:157} INFO - Started process (PID=17625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:57:19.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:57:19.638+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:57:19.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:57:19.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:57:19.704+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:57:19.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:57:19.722+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:57:19.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:57:19.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T18:57:50.024+0000] {processor.py:157} INFO - Started process (PID=17635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:57:50.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:57:50.030+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:57:50.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:57:50.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:57:50.109+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:57:50.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:57:50.125+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:57:50.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:57:50.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T18:58:20.365+0000] {processor.py:157} INFO - Started process (PID=17645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:58:20.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:58:20.371+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:58:20.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:58:20.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:58:20.428+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:58:20.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:58:20.450+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:58:20.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:58:20.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T18:58:50.731+0000] {processor.py:157} INFO - Started process (PID=17654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:58:50.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:58:50.738+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:58:50.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:58:50.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:58:50.836+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:58:50.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:58:50.851+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:58:50.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:58:50.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-15T18:59:21.071+0000] {processor.py:157} INFO - Started process (PID=17665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:59:21.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:59:21.077+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:59:21.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:59:21.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:59:21.125+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:59:21.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:59:21.147+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:59:21.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:59:21.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T18:59:51.474+0000] {processor.py:157} INFO - Started process (PID=17675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:59:51.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T18:59:51.482+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:59:51.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:59:51.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T18:59:51.531+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:59:51.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T18:59:51.547+0000] {logging_mixin.py:151} INFO - [2024-09-15T18:59:51.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T18:59:51.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T19:00:21.937+0000] {processor.py:157} INFO - Started process (PID=17685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:00:21.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:00:21.950+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:00:21.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:00:21.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:00:22.025+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:00:22.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:00:22.046+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:00:22.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:00:22.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T19:00:52.356+0000] {processor.py:157} INFO - Started process (PID=17694) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:00:52.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:00:52.365+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:00:52.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:00:52.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:00:52.479+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:00:52.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:00:52.498+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:00:52.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:00:52.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-15T19:01:22.687+0000] {processor.py:157} INFO - Started process (PID=17705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:01:22.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:01:22.695+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:01:22.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:01:22.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:01:22.754+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:01:22.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:01:22.769+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:01:22.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:01:22.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T19:01:53.173+0000] {processor.py:157} INFO - Started process (PID=17714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:01:53.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:01:53.179+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:01:53.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:01:53.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:01:53.224+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:01:53.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:01:53.238+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:01:53.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:01:53.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T19:02:23.615+0000] {processor.py:157} INFO - Started process (PID=17725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:02:23.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:02:23.634+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:02:23.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:02:23.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:02:23.725+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:02:23.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:02:23.756+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:02:23.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:02:23.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-15T19:02:54.139+0000] {processor.py:157} INFO - Started process (PID=17735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:02:54.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:02:54.147+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:02:54.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:02:54.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:02:54.223+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:02:54.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:02:54.251+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:02:54.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:02:54.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T19:03:24.493+0000] {processor.py:157} INFO - Started process (PID=17744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:03:24.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:03:24.499+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:03:24.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:03:24.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:03:24.553+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:03:24.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:03:24.571+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:03:24.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:03:24.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T19:03:54.958+0000] {processor.py:157} INFO - Started process (PID=17754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:03:54.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:03:54.970+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:03:54.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:03:54.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:03:55.033+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:03:55.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:03:55.054+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:03:55.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:03:55.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-15T19:04:25.281+0000] {processor.py:157} INFO - Started process (PID=17765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:04:25.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:04:25.285+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:04:25.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:04:25.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:04:25.327+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:04:25.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:04:25.342+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:04:25.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:04:25.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T19:04:55.729+0000] {processor.py:157} INFO - Started process (PID=17775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:04:55.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:04:55.736+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:04:55.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:04:55.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:04:55.803+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:04:55.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:04:55.818+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:04:55.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:04:55.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T19:05:26.427+0000] {processor.py:157} INFO - Started process (PID=17785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:05:26.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:05:26.441+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:05:26.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:05:26.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:05:26.611+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:05:26.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:05:26.644+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:05:26.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:05:26.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.266 seconds
[2024-09-15T19:05:57.149+0000] {processor.py:157} INFO - Started process (PID=17795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:05:57.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:05:57.158+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:05:57.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:05:57.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:05:57.232+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:05:57.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:05:57.251+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:05:57.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:05:57.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T19:06:27.539+0000] {processor.py:157} INFO - Started process (PID=17805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:06:27.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:06:27.559+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:06:27.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:06:27.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:06:27.627+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:06:27.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:06:27.643+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:06:27.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:06:27.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T19:06:57.918+0000] {processor.py:157} INFO - Started process (PID=17815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:06:57.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:06:57.928+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:06:57.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:06:57.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:06:57.996+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:06:57.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:06:58.015+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:06:58.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:06:58.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-15T19:07:28.402+0000] {processor.py:157} INFO - Started process (PID=17825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:07:28.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:07:28.425+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:07:28.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:07:28.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:07:28.554+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:07:28.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:07:28.586+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:07:28.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:07:28.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.236 seconds
[2024-09-15T19:07:58.760+0000] {processor.py:157} INFO - Started process (PID=17835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:07:58.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:07:58.767+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:07:58.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:07:58.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:07:58.839+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:07:58.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:07:58.856+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:07:58.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:07:58.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T19:08:29.203+0000] {processor.py:157} INFO - Started process (PID=17845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:08:29.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:08:29.211+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:08:29.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:08:29.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:08:29.282+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:08:29.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:08:29.300+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:08:29.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:08:29.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T19:08:59.700+0000] {processor.py:157} INFO - Started process (PID=17855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:08:59.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:08:59.706+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:08:59.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:08:59.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:08:59.784+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:08:59.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:08:59.801+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:08:59.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:08:59.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T19:09:30.089+0000] {processor.py:157} INFO - Started process (PID=17865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:09:30.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:09:30.096+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:09:30.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:09:30.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:09:30.164+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:09:30.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:09:30.179+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:09:30.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:09:30.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T19:10:00.498+0000] {processor.py:157} INFO - Started process (PID=17875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:10:00.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:10:00.504+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:10:00.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:10:00.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:10:00.570+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:10:00.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:10:00.585+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:10:00.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:10:00.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T19:10:30.861+0000] {processor.py:157} INFO - Started process (PID=17885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:10:30.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:10:30.876+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:10:30.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:10:30.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:10:30.950+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:10:30.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:10:30.967+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:10:30.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:10:30.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-15T19:11:01.207+0000] {processor.py:157} INFO - Started process (PID=17895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:11:01.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:11:01.213+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:11:01.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:11:01.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:11:01.255+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:11:01.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:11:01.269+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:11:01.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:11:01.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T19:11:31.553+0000] {processor.py:157} INFO - Started process (PID=17905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:11:31.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:11:31.556+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:11:31.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:11:31.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:11:31.585+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:11:31.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:11:31.598+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:11:31.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:11:31.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-15T19:12:01.963+0000] {processor.py:157} INFO - Started process (PID=17915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:12:01.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:12:01.969+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:12:01.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:12:01.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:12:02.041+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:12:02.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:12:02.064+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:12:02.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:12:02.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T19:12:32.340+0000] {processor.py:157} INFO - Started process (PID=17925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:12:32.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:12:32.348+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:12:32.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:12:32.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:12:32.401+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:12:32.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:12:32.423+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:12:32.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:12:32.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T19:13:02.808+0000] {processor.py:157} INFO - Started process (PID=17935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:13:02.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:13:02.816+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:13:02.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:13:02.840+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:13:02.888+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:13:02.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:13:02.904+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:13:02.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:13:02.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T19:13:33.278+0000] {processor.py:157} INFO - Started process (PID=17945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:13:33.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:13:33.284+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:13:33.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:13:33.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:13:33.347+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:13:33.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:13:33.363+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:13:33.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:13:33.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T19:14:03.659+0000] {processor.py:157} INFO - Started process (PID=17955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:14:03.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:14:03.665+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:14:03.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:14:03.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:14:03.721+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:14:03.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:14:03.752+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:14:03.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:14:03.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T19:14:34.022+0000] {processor.py:157} INFO - Started process (PID=17965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:14:34.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:14:34.029+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:14:34.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:14:34.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:14:34.097+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:14:34.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:14:34.114+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:14:34.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:14:34.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T19:15:04.459+0000] {processor.py:157} INFO - Started process (PID=17975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:15:04.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:15:04.470+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:15:04.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:15:04.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:15:04.525+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:15:04.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:15:04.540+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:15:04.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:15:04.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-15T19:15:34.892+0000] {processor.py:157} INFO - Started process (PID=17985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:15:34.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:15:34.898+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:15:34.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:15:34.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:15:34.940+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:15:34.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:15:34.954+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:15:34.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:15:34.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T19:16:05.198+0000] {processor.py:157} INFO - Started process (PID=17995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:16:05.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:16:05.208+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:16:05.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:16:05.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:16:05.278+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:16:05.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:16:05.295+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:16:05.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:16:05.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T19:16:35.528+0000] {processor.py:157} INFO - Started process (PID=18005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:16:35.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:16:35.535+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:16:35.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:16:35.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:16:35.576+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:16:35.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:16:35.594+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:16:35.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:16:35.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T19:17:05.994+0000] {processor.py:157} INFO - Started process (PID=18014) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:17:05.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:17:06.002+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:17:06.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:17:06.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:17:06.087+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:17:06.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:17:06.113+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:17:06.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:17:06.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-15T19:17:36.332+0000] {processor.py:157} INFO - Started process (PID=18024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:17:36.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:17:36.339+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:17:36.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:17:36.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:17:36.400+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:17:36.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:17:36.416+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:17:36.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:17:36.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T19:18:06.762+0000] {processor.py:157} INFO - Started process (PID=18035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:18:06.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:18:06.772+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:18:06.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:18:06.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:18:06.852+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:18:06.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:18:06.872+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:18:06.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:18:06.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T19:18:37.210+0000] {processor.py:157} INFO - Started process (PID=18045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:18:37.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:18:37.220+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:18:37.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:18:37.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:18:37.321+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:18:37.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:18:37.372+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:18:37.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:18:37.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-09-15T19:19:07.519+0000] {processor.py:157} INFO - Started process (PID=18055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:19:07.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:19:07.526+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:19:07.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:19:07.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:19:07.586+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:19:07.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:19:07.602+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:19:07.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:19:07.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T19:19:37.811+0000] {processor.py:157} INFO - Started process (PID=18065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:19:37.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:19:37.815+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:19:37.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:19:37.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:19:37.845+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:19:37.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:19:37.855+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:19:37.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:19:37.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-15T19:20:08.221+0000] {processor.py:157} INFO - Started process (PID=18075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:20:08.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:20:08.232+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:20:08.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:20:08.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:20:08.296+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:20:08.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:20:08.322+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:20:08.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:20:08.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-15T19:20:38.606+0000] {processor.py:157} INFO - Started process (PID=18085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:20:38.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:20:38.612+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:20:38.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:20:38.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:20:38.690+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:20:38.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:20:38.708+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:20:38.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:20:38.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-15T19:21:09.071+0000] {processor.py:157} INFO - Started process (PID=18094) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:21:09.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:21:09.077+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:21:09.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:21:09.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:21:09.144+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:21:09.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:21:09.160+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:21:09.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:21:09.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T19:21:39.342+0000] {processor.py:157} INFO - Started process (PID=18105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:21:39.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:21:39.347+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:21:39.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:21:39.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:21:39.389+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:21:39.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:21:39.404+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:21:39.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:21:39.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T19:22:09.744+0000] {processor.py:157} INFO - Started process (PID=18115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:22:09.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:22:09.761+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:22:09.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:22:09.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:22:09.813+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:22:09.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:22:09.831+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:22:09.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:22:09.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T19:22:40.217+0000] {processor.py:157} INFO - Started process (PID=18125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:22:40.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:22:40.224+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:22:40.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:22:40.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:22:40.288+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:22:40.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:22:40.313+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:22:40.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:22:40.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T19:23:10.540+0000] {processor.py:157} INFO - Started process (PID=18135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:23:10.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:23:10.546+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:23:10.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:23:10.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:23:10.597+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:23:10.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:23:10.612+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:23:10.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:23:10.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T19:23:41.059+0000] {processor.py:157} INFO - Started process (PID=18145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:23:41.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:23:41.065+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:23:41.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:23:41.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:23:41.123+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:23:41.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:23:41.141+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:23:41.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:23:41.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T19:24:11.498+0000] {processor.py:157} INFO - Started process (PID=18155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:24:11.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:24:11.505+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:24:11.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:24:11.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:24:11.563+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:24:11.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:24:11.580+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:24:11.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:24:11.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T19:24:41.899+0000] {processor.py:157} INFO - Started process (PID=18165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:24:41.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:24:41.910+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:24:41.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:24:41.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:24:41.996+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:24:41.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:24:42.016+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:24:42.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:24:42.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-15T19:25:12.243+0000] {processor.py:157} INFO - Started process (PID=18175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:25:12.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:25:12.253+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:25:12.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:25:12.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:25:12.343+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:25:12.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:25:12.360+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:25:12.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:25:12.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-15T19:25:42.532+0000] {processor.py:157} INFO - Started process (PID=18185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:25:42.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:25:42.540+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:25:42.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:25:42.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:25:42.591+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:25:42.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:25:42.607+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:25:42.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:25:42.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T19:26:12.931+0000] {processor.py:157} INFO - Started process (PID=18195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:26:12.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:26:12.939+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:26:12.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:26:12.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:26:13.036+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:26:13.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:26:13.055+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:26:13.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:26:13.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-15T19:26:43.458+0000] {processor.py:157} INFO - Started process (PID=18205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:26:43.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:26:43.462+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:26:43.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:26:43.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:26:43.533+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:26:43.532+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:26:43.552+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:26:43.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:26:43.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T19:27:13.818+0000] {processor.py:157} INFO - Started process (PID=18215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:27:13.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:27:13.823+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:27:13.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:27:13.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:27:13.887+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:27:13.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:27:13.904+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:27:13.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:27:13.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T19:27:44.173+0000] {processor.py:157} INFO - Started process (PID=18225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:27:44.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:27:44.182+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:27:44.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:27:44.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:27:44.314+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:27:44.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:27:44.333+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:27:44.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:27:44.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-09-15T19:28:14.581+0000] {processor.py:157} INFO - Started process (PID=18235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:28:14.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:28:14.590+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:28:14.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:28:14.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:28:14.656+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:28:14.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:28:14.672+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:28:14.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:28:14.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T19:28:45.008+0000] {processor.py:157} INFO - Started process (PID=18245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:28:45.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:28:45.013+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:28:45.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:28:45.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:28:45.066+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:28:45.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:28:45.080+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:28:45.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:28:45.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T19:29:15.337+0000] {processor.py:157} INFO - Started process (PID=18255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:29:15.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:29:15.342+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:29:15.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:29:15.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:29:15.427+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:29:15.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:29:15.454+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:29:15.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:29:15.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-15T19:29:45.708+0000] {processor.py:157} INFO - Started process (PID=18265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:29:45.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:29:45.716+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:29:45.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:29:45.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:29:45.779+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:29:45.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:29:45.795+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:29:45.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:29:45.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T19:30:16.070+0000] {processor.py:157} INFO - Started process (PID=18275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:30:16.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:30:16.074+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:30:16.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:30:16.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:30:16.114+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:30:16.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:30:16.129+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:30:16.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:30:16.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T19:30:46.553+0000] {processor.py:157} INFO - Started process (PID=18285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:30:46.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:30:46.559+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:30:46.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:30:46.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:30:46.631+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:30:46.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:30:46.647+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:30:46.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:30:46.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T19:31:16.912+0000] {processor.py:157} INFO - Started process (PID=18295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:31:16.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:31:16.920+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:31:16.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:31:16.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:31:16.987+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:31:16.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:31:17.002+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:31:17.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:31:17.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T19:31:47.439+0000] {processor.py:157} INFO - Started process (PID=18305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:31:47.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:31:47.450+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:31:47.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:31:47.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:31:47.519+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:31:47.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:31:47.536+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:31:47.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:31:47.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T19:32:18.254+0000] {processor.py:157} INFO - Started process (PID=18314) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:32:18.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:32:18.261+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:32:18.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:32:18.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:32:18.315+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:32:18.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:32:18.333+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:32:18.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:32:18.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T19:32:48.652+0000] {processor.py:157} INFO - Started process (PID=18325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:32:48.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:32:48.654+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:32:48.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:32:48.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:32:48.678+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:32:48.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:32:48.690+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:32:48.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:32:48.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T19:33:19.136+0000] {processor.py:157} INFO - Started process (PID=18335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:33:19.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:33:19.144+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:33:19.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:33:19.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:33:19.228+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:33:19.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:33:19.252+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:33:19.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:33:19.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-15T19:33:49.672+0000] {processor.py:157} INFO - Started process (PID=18345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:33:49.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:33:49.684+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:33:49.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:33:49.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:33:49.763+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:33:49.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:33:49.781+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:33:49.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:33:49.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T19:34:20.072+0000] {processor.py:157} INFO - Started process (PID=18355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:34:20.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:34:20.078+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:34:20.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:34:20.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:34:20.142+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:34:20.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:34:20.161+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:34:20.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:34:20.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-15T19:34:50.419+0000] {processor.py:157} INFO - Started process (PID=18363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:34:50.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:34:50.427+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:34:50.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:34:50.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:34:50.489+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:34:50.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:34:50.506+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:34:50.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:34:50.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T19:35:20.787+0000] {processor.py:157} INFO - Started process (PID=18375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:35:20.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:35:20.793+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:35:20.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:35:20.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:35:20.855+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:35:20.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:35:20.874+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:35:20.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:35:20.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-15T19:35:51.316+0000] {processor.py:157} INFO - Started process (PID=18384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:35:51.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:35:51.325+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:35:51.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:35:51.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:35:51.407+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:35:51.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:35:51.432+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:35:51.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:35:51.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T19:36:21.695+0000] {processor.py:157} INFO - Started process (PID=18394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:36:21.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:36:21.701+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:36:21.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:36:21.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:36:21.766+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:36:21.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:36:21.785+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:36:21.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:36:21.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T19:36:52.043+0000] {processor.py:157} INFO - Started process (PID=18405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:36:52.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:36:52.050+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:36:52.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:36:52.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:36:52.117+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:36:52.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:36:52.134+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:36:52.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:36:52.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T19:37:22.415+0000] {processor.py:157} INFO - Started process (PID=18415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:37:22.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:37:22.421+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:37:22.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:37:22.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:37:22.479+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:37:22.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:37:22.494+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:37:22.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:37:22.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T19:37:52.838+0000] {processor.py:157} INFO - Started process (PID=18425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:37:52.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:37:52.843+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:37:52.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:37:52.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:37:52.894+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:37:52.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:37:52.909+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:37:52.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:37:52.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T19:38:23.302+0000] {processor.py:157} INFO - Started process (PID=18435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:38:23.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:38:23.307+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:38:23.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:38:23.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:38:23.349+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:38:23.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:38:23.363+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:38:23.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:38:23.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T19:38:53.733+0000] {processor.py:157} INFO - Started process (PID=18445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:38:53.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:38:53.741+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:38:53.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:38:53.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:38:53.801+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:38:53.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:38:53.816+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:38:53.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:38:53.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T19:39:24.089+0000] {processor.py:157} INFO - Started process (PID=18455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:39:24.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:39:24.097+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:39:24.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:39:24.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:39:24.170+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:39:24.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:39:24.196+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:39:24.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:39:24.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T19:39:54.505+0000] {processor.py:157} INFO - Started process (PID=18465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:39:54.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:39:54.509+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:39:54.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:39:54.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:39:54.575+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:39:54.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:39:54.590+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:39:54.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:39:54.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T19:40:24.881+0000] {processor.py:157} INFO - Started process (PID=18474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:40:24.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:40:24.887+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:40:24.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:40:24.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:40:24.966+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:40:24.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:40:24.982+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:40:24.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:40:24.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T19:40:55.215+0000] {processor.py:157} INFO - Started process (PID=18485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:40:55.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:40:55.221+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:40:55.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:40:55.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:40:55.290+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:40:55.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:40:55.306+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:40:55.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:40:55.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T19:41:25.714+0000] {processor.py:157} INFO - Started process (PID=18495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:41:25.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:41:25.719+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:41:25.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:41:25.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:41:25.785+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:41:25.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:41:25.800+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:41:25.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:41:25.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T19:41:56.215+0000] {processor.py:157} INFO - Started process (PID=18505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:41:56.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:41:56.222+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:41:56.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:41:56.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:41:56.301+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:41:56.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:41:56.318+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:41:56.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:41:56.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T19:42:26.578+0000] {processor.py:157} INFO - Started process (PID=18515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:42:26.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:42:26.587+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:42:26.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:42:26.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:42:26.647+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:42:26.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:42:26.662+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:42:26.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:42:26.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T19:42:56.964+0000] {processor.py:157} INFO - Started process (PID=18524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:42:56.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:42:56.971+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:42:56.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:42:57.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:42:57.052+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:42:57.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:42:57.069+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:42:57.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:42:57.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T19:43:27.426+0000] {processor.py:157} INFO - Started process (PID=18535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:43:27.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:43:27.433+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:43:27.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:43:27.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:43:27.482+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:43:27.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:43:27.499+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:43:27.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:43:27.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T19:43:57.809+0000] {processor.py:157} INFO - Started process (PID=18543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:43:57.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:43:57.828+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:43:57.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:43:57.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:43:57.899+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:43:57.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:43:57.919+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:43:57.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:43:57.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-15T19:44:28.104+0000] {processor.py:157} INFO - Started process (PID=18555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:44:28.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:44:28.111+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:44:28.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:44:28.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:44:28.172+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:44:28.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:44:28.189+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:44:28.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:44:28.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T19:44:58.512+0000] {processor.py:157} INFO - Started process (PID=18565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:44:58.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:44:58.518+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:44:58.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:44:58.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:44:58.593+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:44:58.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:44:58.609+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:44:58.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:44:58.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-15T19:45:28.882+0000] {processor.py:157} INFO - Started process (PID=18575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:45:28.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:45:28.888+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:45:28.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:45:28.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:45:28.945+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:45:28.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:45:28.961+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:45:28.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:45:28.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T19:45:59.317+0000] {processor.py:157} INFO - Started process (PID=18585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:45:59.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:45:59.327+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:45:59.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:45:59.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:45:59.385+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:45:59.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:45:59.401+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:45:59.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:45:59.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T19:46:29.649+0000] {processor.py:157} INFO - Started process (PID=18595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:46:29.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:46:29.653+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:46:29.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:46:29.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:46:29.683+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:46:29.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:46:29.693+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:46:29.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:46:29.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T19:47:00.091+0000] {processor.py:157} INFO - Started process (PID=18605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:47:00.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:47:00.100+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:47:00.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:47:00.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:47:00.175+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:47:00.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:47:00.192+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:47:00.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:47:00.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T19:47:30.461+0000] {processor.py:157} INFO - Started process (PID=18615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:47:30.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:47:30.469+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:47:30.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:47:30.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:47:30.531+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:47:30.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:47:30.549+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:47:30.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:47:30.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T19:48:00.911+0000] {processor.py:157} INFO - Started process (PID=18625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:48:00.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:48:00.926+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:48:00.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:48:00.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:48:00.994+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:48:00.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:48:01.011+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:48:01.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:48:01.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-15T19:48:31.183+0000] {processor.py:157} INFO - Started process (PID=18635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:48:31.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:48:31.199+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:48:31.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:48:31.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:48:31.278+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:48:31.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:48:31.299+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:48:31.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:48:31.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-15T19:49:01.592+0000] {processor.py:157} INFO - Started process (PID=18645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:49:01.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:49:01.599+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:49:01.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:49:01.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:49:01.662+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:49:01.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:49:01.680+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:49:01.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:49:01.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T19:49:32.085+0000] {processor.py:157} INFO - Started process (PID=18655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:49:32.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:49:32.091+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:49:32.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:49:32.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:49:32.162+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:49:32.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:49:32.178+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:49:32.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:49:32.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T19:50:02.411+0000] {processor.py:157} INFO - Started process (PID=18665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:50:02.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:50:02.416+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:50:02.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:50:02.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:50:02.467+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:50:02.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:50:02.481+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:50:02.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:50:02.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T19:50:32.816+0000] {processor.py:157} INFO - Started process (PID=18675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:50:32.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:50:32.821+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:50:32.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:50:32.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:50:32.886+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:50:32.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:50:32.913+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:50:32.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:50:32.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-15T19:51:03.351+0000] {processor.py:157} INFO - Started process (PID=18685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:51:03.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:51:03.359+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:51:03.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:51:03.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:51:03.422+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:51:03.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:51:03.442+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:51:03.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:51:03.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-15T19:51:33.665+0000] {processor.py:157} INFO - Started process (PID=18695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:51:33.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:51:33.672+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:51:33.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:51:33.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:51:33.744+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:51:33.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:51:33.760+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:51:33.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:51:33.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T19:52:04.101+0000] {processor.py:157} INFO - Started process (PID=18705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:52:04.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:52:04.107+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:52:04.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:52:04.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:52:04.159+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:52:04.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:52:04.183+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:52:04.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:52:04.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T19:52:34.423+0000] {processor.py:157} INFO - Started process (PID=18715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:52:34.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:52:34.434+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:52:34.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:52:34.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:52:34.500+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:52:34.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:52:34.516+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:52:34.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:52:34.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T19:53:04.795+0000] {processor.py:157} INFO - Started process (PID=18723) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:53:04.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:53:04.801+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:53:04.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:53:04.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:53:04.865+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:53:04.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:53:04.881+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:53:04.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:53:04.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T19:53:35.170+0000] {processor.py:157} INFO - Started process (PID=18735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:53:35.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:53:35.174+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:53:35.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:53:35.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:53:35.235+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:53:35.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:53:35.253+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:53:35.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:53:35.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T19:54:05.626+0000] {processor.py:157} INFO - Started process (PID=18745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:54:05.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:54:05.631+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:54:05.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:54:05.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:54:05.674+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:54:05.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:54:05.689+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:54:05.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:54:05.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T19:54:35.993+0000] {processor.py:157} INFO - Started process (PID=18755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:54:35.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:54:35.997+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:54:35.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:54:36.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:54:36.032+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:54:36.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:54:36.048+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:54:36.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:54:36.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-15T19:55:06.318+0000] {processor.py:157} INFO - Started process (PID=18765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:55:06.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:55:06.325+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:55:06.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:55:06.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:55:06.392+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:55:06.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:55:06.406+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:55:06.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:55:06.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T19:55:36.837+0000] {processor.py:157} INFO - Started process (PID=18775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:55:36.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:55:36.841+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:55:36.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:55:36.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:55:36.873+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:55:36.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:55:36.884+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:55:36.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:55:36.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T19:56:07.262+0000] {processor.py:157} INFO - Started process (PID=18785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:56:07.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:56:07.275+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:56:07.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:56:07.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:56:07.344+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:56:07.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:56:07.362+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:56:07.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:56:07.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T19:56:37.677+0000] {processor.py:157} INFO - Started process (PID=18795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:56:37.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:56:37.680+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:56:37.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:56:37.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:56:37.719+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:56:37.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:56:37.730+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:56:37.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:56:37.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T19:57:08.123+0000] {processor.py:157} INFO - Started process (PID=18805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:57:08.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:57:08.150+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:57:08.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:57:08.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:57:08.206+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:57:08.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:57:08.223+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:57:08.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:57:08.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T19:57:38.597+0000] {processor.py:157} INFO - Started process (PID=18815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:57:38.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:57:38.603+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:57:38.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:57:38.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:57:38.672+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:57:38.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:57:38.689+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:57:38.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:57:38.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T19:58:08.950+0000] {processor.py:157} INFO - Started process (PID=18825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:58:08.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:58:08.954+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:58:08.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:58:08.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:58:08.999+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:58:08.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:58:09.014+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:58:09.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:58:09.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T19:58:39.479+0000] {processor.py:157} INFO - Started process (PID=18835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:58:39.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:58:39.483+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:58:39.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:58:39.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:58:39.554+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:58:39.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:58:39.570+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:58:39.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:58:39.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T19:59:09.991+0000] {processor.py:157} INFO - Started process (PID=18845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:59:09.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:59:09.997+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:59:09.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:59:10.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:59:10.038+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:59:10.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:59:10.053+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:59:10.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:59:10.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T19:59:40.413+0000] {processor.py:157} INFO - Started process (PID=18855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:59:40.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T19:59:40.418+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:59:40.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:59:40.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T19:59:40.479+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:59:40.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T19:59:40.497+0000] {logging_mixin.py:151} INFO - [2024-09-15T19:59:40.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T19:59:40.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T20:00:10.916+0000] {processor.py:157} INFO - Started process (PID=18865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:00:10.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:00:10.920+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:00:10.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:00:10.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:00:10.950+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:00:10.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:00:10.963+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:00:10.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:00:10.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T20:00:41.314+0000] {processor.py:157} INFO - Started process (PID=18875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:00:41.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:00:41.329+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:00:41.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:00:41.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:00:41.392+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:00:41.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:00:41.407+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:00:41.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:00:41.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T20:01:11.857+0000] {processor.py:157} INFO - Started process (PID=18885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:01:11.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:01:11.864+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:01:11.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:01:11.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:01:11.933+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:01:11.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:01:11.949+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:01:11.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:01:11.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T20:01:42.250+0000] {processor.py:157} INFO - Started process (PID=18895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:01:42.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:01:42.254+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:01:42.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:01:42.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:01:42.297+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:01:42.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:01:42.311+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:01:42.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:01:42.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T20:02:12.637+0000] {processor.py:157} INFO - Started process (PID=18905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:02:12.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:02:12.642+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:02:12.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:02:12.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:02:12.685+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:02:12.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:02:12.710+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:02:12.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:02:12.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T20:02:43.129+0000] {processor.py:157} INFO - Started process (PID=18915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:02:43.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:02:43.142+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:02:43.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:02:43.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:02:43.213+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:02:43.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:02:43.230+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:02:43.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:02:43.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T20:03:13.510+0000] {processor.py:157} INFO - Started process (PID=18925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:03:13.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:03:13.516+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:03:13.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:03:13.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:03:13.582+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:03:13.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:03:13.599+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:03:13.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:03:13.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T20:03:43.923+0000] {processor.py:157} INFO - Started process (PID=18935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:03:43.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:03:43.932+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:03:43.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:03:43.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:03:44.029+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:03:44.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:03:44.048+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:03:44.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:03:44.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-15T20:04:14.285+0000] {processor.py:157} INFO - Started process (PID=18945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:04:14.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:04:14.294+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:04:14.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:04:14.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:04:14.361+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:04:14.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:04:14.388+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:04:14.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:04:14.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T20:04:44.794+0000] {processor.py:157} INFO - Started process (PID=18954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:04:44.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:04:44.801+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:04:44.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:04:44.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:04:44.870+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:04:44.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:04:44.887+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:04:44.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:04:44.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T20:05:15.162+0000] {processor.py:157} INFO - Started process (PID=18965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:05:15.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:05:15.167+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:05:15.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:05:15.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:05:15.211+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:05:15.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:05:15.230+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:05:15.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:05:15.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T20:05:45.636+0000] {processor.py:157} INFO - Started process (PID=18974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:05:45.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:05:45.643+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:05:45.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:05:45.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:05:45.685+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:05:45.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:05:45.702+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:05:45.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:05:45.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T20:06:16.006+0000] {processor.py:157} INFO - Started process (PID=18985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:06:16.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:06:16.012+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:06:16.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:06:16.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:06:16.054+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:06:16.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:06:16.069+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:06:16.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:06:16.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T20:06:46.432+0000] {processor.py:157} INFO - Started process (PID=18994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:06:46.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:06:46.439+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:06:46.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:06:46.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:06:46.507+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:06:46.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:06:46.524+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:06:46.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:06:46.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T20:07:16.753+0000] {processor.py:157} INFO - Started process (PID=19005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:07:16.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:07:16.758+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:07:16.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:07:16.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:07:16.800+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:07:16.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:07:16.815+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:07:16.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:07:16.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T20:07:47.106+0000] {processor.py:157} INFO - Started process (PID=19015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:07:47.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:07:47.115+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:07:47.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:07:47.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:07:47.183+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:07:47.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:07:47.198+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:07:47.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:07:47.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T20:08:17.531+0000] {processor.py:157} INFO - Started process (PID=19023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:08:17.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:08:17.536+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:08:17.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:08:17.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:08:17.596+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:08:17.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:08:17.612+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:08:17.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:08:17.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T20:08:47.919+0000] {processor.py:157} INFO - Started process (PID=19035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:08:47.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:08:47.930+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:08:47.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:08:47.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:08:48.005+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:08:48.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:08:48.021+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:08:48.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:08:48.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T20:09:18.269+0000] {processor.py:157} INFO - Started process (PID=19044) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:09:18.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:09:18.274+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:09:18.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:09:18.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:09:18.316+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:09:18.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:09:18.330+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:09:18.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:09:18.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T20:09:48.713+0000] {processor.py:157} INFO - Started process (PID=19055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:09:48.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:09:48.719+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:09:48.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:09:48.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:09:48.770+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:09:48.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:09:48.791+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:09:48.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:09:48.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T20:10:19.170+0000] {processor.py:157} INFO - Started process (PID=19063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:10:19.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:10:19.176+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:10:19.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:10:19.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:10:19.239+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:10:19.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:10:19.272+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:10:19.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:10:19.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T20:10:49.552+0000] {processor.py:157} INFO - Started process (PID=19073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:10:49.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:10:49.558+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:10:49.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:10:49.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:10:49.639+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:10:49.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:10:49.655+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:10:49.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:10:49.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T20:11:19.960+0000] {processor.py:157} INFO - Started process (PID=19085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:11:19.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:11:19.964+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:11:19.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:11:19.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:11:20.020+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:11:20.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:11:20.034+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:11:20.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:11:20.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T20:11:50.337+0000] {processor.py:157} INFO - Started process (PID=19095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:11:50.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:11:50.342+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:11:50.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:11:50.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:11:50.378+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:11:50.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:11:50.410+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:11:50.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:11:50.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T20:12:20.733+0000] {processor.py:157} INFO - Started process (PID=19104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:12:20.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:12:20.738+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:12:20.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:12:20.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:12:20.800+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:12:20.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:12:20.816+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:12:20.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:12:20.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T20:12:51.181+0000] {processor.py:157} INFO - Started process (PID=19115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:12:51.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:12:51.185+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:12:51.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:12:51.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:12:51.222+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:12:51.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:12:51.236+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:12:51.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:12:51.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T20:13:21.506+0000] {processor.py:157} INFO - Started process (PID=19125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:13:21.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:13:21.510+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:13:21.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:13:21.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:13:21.563+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:13:21.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:13:21.577+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:13:21.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:13:21.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T20:13:51.945+0000] {processor.py:157} INFO - Started process (PID=19135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:13:51.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:13:51.962+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:13:51.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:13:51.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:13:52.017+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:13:52.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:13:52.043+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:13:52.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:13:52.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T20:14:22.283+0000] {processor.py:157} INFO - Started process (PID=19145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:14:22.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:14:22.285+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:14:22.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:14:22.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:14:22.317+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:14:22.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:14:22.328+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:14:22.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:14:22.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T20:14:52.662+0000] {processor.py:157} INFO - Started process (PID=19155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:14:52.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:14:52.676+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:14:52.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:14:52.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:14:52.730+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:14:52.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:14:52.746+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:14:52.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:14:52.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-15T20:15:23.199+0000] {processor.py:157} INFO - Started process (PID=19164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:15:23.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:15:23.211+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:15:23.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:15:23.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:15:23.274+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:15:23.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:15:23.303+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:15:23.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:15:23.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T20:15:53.528+0000] {processor.py:157} INFO - Started process (PID=19175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:15:53.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:15:53.546+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:15:53.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:15:53.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:15:53.597+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:15:53.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:15:53.621+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:15:53.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:15:53.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T20:16:23.955+0000] {processor.py:157} INFO - Started process (PID=19184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:16:23.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:16:23.962+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:16:23.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:16:23.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:16:24.025+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:16:24.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:16:24.041+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:16:24.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:16:24.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T20:16:54.289+0000] {processor.py:157} INFO - Started process (PID=19195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:16:54.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:16:54.295+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:16:54.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:16:54.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:16:54.346+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:16:54.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:16:54.362+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:16:54.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:16:54.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T20:17:24.608+0000] {processor.py:157} INFO - Started process (PID=19204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:17:24.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:17:24.616+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:17:24.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:17:24.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:17:24.677+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:17:24.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:17:24.700+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:17:24.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:17:24.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T20:17:54.948+0000] {processor.py:157} INFO - Started process (PID=19215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:17:54.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:17:54.954+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:17:54.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:17:54.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:17:54.994+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:17:54.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:17:55.010+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:17:55.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:17:55.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T20:18:25.297+0000] {processor.py:157} INFO - Started process (PID=19225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:18:25.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:18:25.303+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:18:25.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:18:25.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:18:25.332+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:18:25.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:18:25.344+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:18:25.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:18:25.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T20:18:55.731+0000] {processor.py:157} INFO - Started process (PID=19233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:18:55.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:18:55.736+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:18:55.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:18:55.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:18:55.808+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:18:55.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:18:55.823+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:18:55.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:18:55.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T20:19:26.049+0000] {processor.py:157} INFO - Started process (PID=19245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:19:26.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:19:26.053+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:19:26.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:19:26.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:19:26.094+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:19:26.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:19:26.107+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:19:26.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:19:26.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T20:19:56.451+0000] {processor.py:157} INFO - Started process (PID=19255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:19:56.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:19:56.456+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:19:56.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:19:56.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:19:56.510+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:19:56.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:19:56.529+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:19:56.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:19:56.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-15T20:20:26.747+0000] {processor.py:157} INFO - Started process (PID=19265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:20:26.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:20:26.750+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:20:26.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:20:26.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:20:26.789+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:20:26.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:20:26.803+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:20:26.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:20:26.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-15T20:20:57.226+0000] {processor.py:157} INFO - Started process (PID=19275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:20:57.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:20:57.245+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:20:57.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:20:57.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:20:57.314+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:20:57.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:20:57.333+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:20:57.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:20:57.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T20:21:27.589+0000] {processor.py:157} INFO - Started process (PID=19285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:21:27.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:21:27.593+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:21:27.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:21:27.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:21:27.661+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:21:27.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:21:27.690+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:21:27.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:21:27.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T20:21:57.943+0000] {processor.py:157} INFO - Started process (PID=19295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:21:57.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:21:57.950+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:21:57.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:21:57.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:21:58.005+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:21:58.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:21:58.023+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:21:58.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:21:58.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T20:22:28.446+0000] {processor.py:157} INFO - Started process (PID=19305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:22:28.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:22:28.452+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:22:28.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:22:28.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:22:28.521+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:22:28.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:22:28.537+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:22:28.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:22:28.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T20:22:58.781+0000] {processor.py:157} INFO - Started process (PID=19315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:22:58.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:22:58.794+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:22:58.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:22:58.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:22:58.868+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:22:58.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:22:58.885+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:22:58.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:22:58.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T20:23:29.085+0000] {processor.py:157} INFO - Started process (PID=19325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:23:29.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:23:29.091+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:23:29.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:23:29.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:23:29.132+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:23:29.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:23:29.149+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:23:29.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:23:29.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T20:23:59.435+0000] {processor.py:157} INFO - Started process (PID=19335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:23:59.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:23:59.440+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:23:59.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:23:59.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:23:59.479+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:23:59.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:23:59.492+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:23:59.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:23:59.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T20:24:29.844+0000] {processor.py:157} INFO - Started process (PID=19345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:24:29.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:24:29.858+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:24:29.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:24:29.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:24:29.923+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:24:29.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:24:29.940+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:24:29.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:24:29.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T20:25:00.232+0000] {processor.py:157} INFO - Started process (PID=19355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:25:00.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:25:00.246+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:25:00.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:25:00.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:25:00.312+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:25:00.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:25:00.327+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:25:00.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:25:00.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T20:25:30.713+0000] {processor.py:157} INFO - Started process (PID=19365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:25:30.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:25:30.720+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:25:30.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:25:30.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:25:30.781+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:25:30.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:25:30.797+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:25:30.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:25:30.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T20:26:01.134+0000] {processor.py:157} INFO - Started process (PID=19375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:26:01.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:26:01.147+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:26:01.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:26:01.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:26:01.218+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:26:01.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:26:01.233+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:26:01.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:26:01.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T20:26:31.635+0000] {processor.py:157} INFO - Started process (PID=19384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:26:31.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:26:31.641+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:26:31.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:26:31.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:26:31.708+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:26:31.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:26:31.724+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:26:31.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:26:31.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T20:27:01.914+0000] {processor.py:157} INFO - Started process (PID=19395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:27:01.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:27:01.927+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:27:01.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:27:01.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:27:02.009+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:27:02.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:27:02.029+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:27:02.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:27:02.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-15T20:27:32.401+0000] {processor.py:157} INFO - Started process (PID=19404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:27:32.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:27:32.409+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:27:32.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:27:32.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:27:32.470+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:27:32.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:27:32.493+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:27:32.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:27:32.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T20:28:02.777+0000] {processor.py:157} INFO - Started process (PID=19415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:28:02.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:28:02.787+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:28:02.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:28:02.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:28:02.853+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:28:02.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:28:02.883+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:28:02.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:28:02.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T20:28:33.160+0000] {processor.py:157} INFO - Started process (PID=19424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:28:33.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:28:33.176+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:28:33.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:28:33.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:28:33.240+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:28:33.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:28:33.256+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:28:33.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:28:33.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T20:29:03.532+0000] {processor.py:157} INFO - Started process (PID=19435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:29:03.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:29:03.540+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:29:03.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:29:03.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:29:03.594+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:29:03.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:29:03.620+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:29:03.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:29:03.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T20:29:33.917+0000] {processor.py:157} INFO - Started process (PID=19445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:29:33.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:29:33.924+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:29:33.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:29:33.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:29:33.990+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:29:33.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:29:34.008+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:29:34.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:29:34.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T20:30:04.265+0000] {processor.py:157} INFO - Started process (PID=19455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:30:04.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:30:04.279+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:30:04.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:30:04.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:30:04.362+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:30:04.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:30:04.383+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:30:04.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:30:04.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-15T20:30:34.601+0000] {processor.py:157} INFO - Started process (PID=19465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:30:34.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:30:34.613+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:30:34.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:30:34.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:30:34.685+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:30:34.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:30:34.704+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:30:34.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:30:34.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-15T20:31:04.931+0000] {processor.py:157} INFO - Started process (PID=19475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:31:04.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:31:04.938+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:31:04.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:31:04.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:31:04.999+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:31:04.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:31:05.014+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:31:05.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:31:05.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T20:31:35.434+0000] {processor.py:157} INFO - Started process (PID=19485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:31:35.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:31:35.441+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:31:35.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:31:35.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:31:35.512+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:31:35.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:31:35.527+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:31:35.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:31:35.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T20:32:05.818+0000] {processor.py:157} INFO - Started process (PID=19495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:32:05.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:32:05.824+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:32:05.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:32:05.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:32:05.881+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:32:05.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:32:05.897+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:32:05.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:32:05.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T20:32:36.187+0000] {processor.py:157} INFO - Started process (PID=19504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:32:36.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:32:36.192+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:32:36.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:32:36.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:32:36.261+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:32:36.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:32:36.278+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:32:36.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:32:36.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T20:33:06.524+0000] {processor.py:157} INFO - Started process (PID=19515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:33:06.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:33:06.529+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:33:06.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:33:06.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:33:06.594+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:33:06.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:33:06.625+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:33:06.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:33:06.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T20:33:37.060+0000] {processor.py:157} INFO - Started process (PID=19525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:33:37.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:33:37.069+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:33:37.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:33:37.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:33:37.189+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:33:37.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:33:37.207+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:33:37.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:33:37.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-15T20:34:07.454+0000] {processor.py:157} INFO - Started process (PID=19535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:34:07.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:34:07.484+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:34:07.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:34:07.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:34:07.597+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:34:07.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:34:07.620+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:34:07.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:34:07.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-09-15T20:34:38.058+0000] {processor.py:157} INFO - Started process (PID=19545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:34:38.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:34:38.065+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:34:38.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:34:38.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:34:38.130+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:34:38.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:34:38.149+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:34:38.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:34:38.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T20:35:08.515+0000] {processor.py:157} INFO - Started process (PID=19555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:35:08.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:35:08.536+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:35:08.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:35:08.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:35:08.588+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:35:08.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:35:08.623+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:35:08.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:35:08.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-15T20:35:38.993+0000] {processor.py:157} INFO - Started process (PID=19565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:35:38.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:35:39.000+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:35:38.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:35:39.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:35:39.073+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:35:39.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:35:39.104+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:35:39.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:35:39.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T20:36:09.467+0000] {processor.py:157} INFO - Started process (PID=19575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:36:09.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:36:09.474+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:36:09.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:36:09.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:36:09.560+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:36:09.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:36:09.593+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:36:09.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:36:09.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-15T20:36:39.849+0000] {processor.py:157} INFO - Started process (PID=19585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:36:39.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:36:39.857+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:36:39.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:36:39.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:36:39.936+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:36:39.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:36:39.951+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:36:39.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:36:39.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-15T20:37:10.143+0000] {processor.py:157} INFO - Started process (PID=19595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:37:10.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:37:10.151+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:37:10.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:37:10.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:37:10.193+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:37:10.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:37:10.211+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:37:10.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:37:10.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T20:37:40.595+0000] {processor.py:157} INFO - Started process (PID=19605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:37:40.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:37:40.603+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:37:40.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:37:40.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:37:40.642+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:37:40.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:37:40.658+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:37:40.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:37:40.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T20:38:10.990+0000] {processor.py:157} INFO - Started process (PID=19615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:38:10.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:38:10.996+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:38:10.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:38:11.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:38:11.038+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:38:11.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:38:11.054+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:38:11.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:38:11.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T20:38:41.286+0000] {processor.py:157} INFO - Started process (PID=19625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:38:41.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:38:41.295+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:38:41.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:38:41.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:38:41.344+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:38:41.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:38:41.360+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:38:41.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:38:41.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T20:39:11.795+0000] {processor.py:157} INFO - Started process (PID=19635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:39:11.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:39:11.802+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:39:11.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:39:11.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:39:11.877+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:39:11.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:39:11.894+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:39:11.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:39:11.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T20:39:42.152+0000] {processor.py:157} INFO - Started process (PID=19645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:39:42.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:39:42.159+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:39:42.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:39:42.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:39:42.214+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:39:42.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:39:42.251+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:39:42.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:39:42.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T20:40:12.820+0000] {processor.py:157} INFO - Started process (PID=19655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:40:12.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:40:12.850+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:40:12.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:40:12.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:40:13.073+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:40:13.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:40:13.109+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:40:13.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:40:13.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.362 seconds
[2024-09-15T20:40:43.498+0000] {processor.py:157} INFO - Started process (PID=19665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:40:43.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:40:43.524+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:40:43.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:40:43.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:40:43.596+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:40:43.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:40:43.613+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:40:43.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:40:43.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T20:41:13.887+0000] {processor.py:157} INFO - Started process (PID=19675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:41:13.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:41:13.894+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:41:13.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:41:13.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:41:13.982+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:41:13.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:41:14.007+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:41:14.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:41:14.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T20:41:44.278+0000] {processor.py:157} INFO - Started process (PID=19685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:41:44.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:41:44.295+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:41:44.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:41:44.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:41:44.378+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:41:44.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:41:44.405+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:41:44.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:41:44.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.164 seconds
[2024-09-15T20:42:14.785+0000] {processor.py:157} INFO - Started process (PID=19695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:42:14.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:42:14.791+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:42:14.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:42:14.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:42:14.884+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:42:14.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:42:14.901+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:42:14.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:42:14.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-15T20:42:45.202+0000] {processor.py:157} INFO - Started process (PID=19705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:42:45.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:42:45.208+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:42:45.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:42:45.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:42:45.276+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:42:45.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:42:45.292+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:42:45.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:42:45.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T20:43:15.538+0000] {processor.py:157} INFO - Started process (PID=19715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:43:15.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:43:15.549+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:43:15.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:43:15.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:43:15.614+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:43:15.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:43:15.629+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:43:15.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:43:15.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T20:43:45.898+0000] {processor.py:157} INFO - Started process (PID=19725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:43:45.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:43:45.912+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:43:45.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:43:45.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:43:45.979+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:43:45.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:43:45.997+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:43:45.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:43:46.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T20:44:16.378+0000] {processor.py:157} INFO - Started process (PID=19734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:44:16.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:44:16.384+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:44:16.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:44:16.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:44:16.444+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:44:16.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:44:16.470+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:44:16.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:44:16.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T20:44:46.770+0000] {processor.py:157} INFO - Started process (PID=19744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:44:46.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:44:46.776+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:44:46.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:44:46.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:44:46.852+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:44:46.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:44:46.867+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:44:46.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:44:46.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T20:45:17.135+0000] {processor.py:157} INFO - Started process (PID=19755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:45:17.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:45:17.146+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:45:17.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:45:17.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:45:17.212+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:45:17.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:45:17.228+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:45:17.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:45:17.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T20:45:47.421+0000] {processor.py:157} INFO - Started process (PID=19765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:45:47.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:45:47.428+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:45:47.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:45:47.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:45:47.483+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:45:47.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:45:47.499+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:45:47.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:45:47.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T20:46:17.952+0000] {processor.py:157} INFO - Started process (PID=19775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:46:17.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:46:17.965+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:46:17.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:46:18.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:46:18.067+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:46:18.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:46:18.085+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:46:18.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:46:18.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-09-15T20:46:48.327+0000] {processor.py:157} INFO - Started process (PID=19784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:46:48.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:46:48.333+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:46:48.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:46:48.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:46:48.420+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:46:48.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:46:48.437+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:46:48.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:46:48.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-15T20:47:18.673+0000] {processor.py:157} INFO - Started process (PID=19793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:47:18.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:47:18.690+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:47:18.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:47:18.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:47:18.763+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:47:18.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:47:18.780+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:47:18.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:47:18.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-15T20:47:49.093+0000] {processor.py:157} INFO - Started process (PID=19805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:47:49.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:47:49.098+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:47:49.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:47:49.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:47:49.177+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:47:49.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:47:49.192+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:47:49.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:47:49.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T20:48:19.465+0000] {processor.py:157} INFO - Started process (PID=19814) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:48:19.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:48:19.471+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:48:19.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:48:19.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:48:19.530+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:48:19.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:48:19.553+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:48:19.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:48:19.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-15T20:48:49.862+0000] {processor.py:157} INFO - Started process (PID=19824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:48:49.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:48:49.869+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:48:49.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:48:49.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:48:49.946+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:48:49.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:48:49.963+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:48:49.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:48:49.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T20:49:20.220+0000] {processor.py:157} INFO - Started process (PID=19835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:49:20.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:49:20.234+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:49:20.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:49:20.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:49:20.298+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:49:20.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:49:20.313+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:49:20.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:49:20.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T20:49:50.600+0000] {processor.py:157} INFO - Started process (PID=19845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:49:50.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:49:50.608+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:49:50.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:49:50.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:49:50.673+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:49:50.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:49:50.688+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:49:50.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:49:50.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T20:50:20.968+0000] {processor.py:157} INFO - Started process (PID=19855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:50:20.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:50:20.981+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:50:20.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:50:20.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:50:21.043+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:50:21.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:50:21.067+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:50:21.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:50:21.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T20:50:51.326+0000] {processor.py:157} INFO - Started process (PID=19865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:50:51.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:50:51.336+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:50:51.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:50:51.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:50:51.409+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:50:51.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:50:51.427+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:50:51.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:50:51.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-15T20:51:21.672+0000] {processor.py:157} INFO - Started process (PID=19874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:51:21.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:51:21.679+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:51:21.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:51:21.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:51:21.750+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:51:21.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:51:21.782+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:51:21.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:51:21.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-15T20:51:52.012+0000] {processor.py:157} INFO - Started process (PID=19885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:51:52.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:51:52.019+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:51:52.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:51:52.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:51:52.085+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:51:52.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:51:52.102+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:51:52.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:51:52.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T20:52:22.429+0000] {processor.py:157} INFO - Started process (PID=19895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:52:22.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:52:22.448+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:52:22.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:52:22.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:52:22.510+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:52:22.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:52:22.525+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:52:22.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:52:22.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T20:52:52.806+0000] {processor.py:157} INFO - Started process (PID=19905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:52:52.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:52:52.819+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:52:52.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:52:52.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:52:52.891+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:52:52.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:52:52.921+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:52:52.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:52:52.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T20:53:23.108+0000] {processor.py:157} INFO - Started process (PID=19915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:53:23.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:53:23.115+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:53:23.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:53:23.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:53:23.165+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:53:23.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:53:23.184+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:53:23.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:53:23.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T20:53:53.574+0000] {processor.py:157} INFO - Started process (PID=19925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:53:53.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:53:53.580+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:53:53.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:53:53.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:53:53.639+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:53:53.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:53:53.654+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:53:53.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:53:53.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T20:54:23.999+0000] {processor.py:157} INFO - Started process (PID=19935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:54:24.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:54:24.005+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:54:24.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:54:24.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:54:24.066+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:54:24.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:54:24.082+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:54:24.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:54:24.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T20:54:54.334+0000] {processor.py:157} INFO - Started process (PID=19945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:54:54.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:54:54.338+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:54:54.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:54:54.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:54:54.384+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:54:54.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:54:54.395+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:54:54.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:54:54.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T20:55:24.758+0000] {processor.py:157} INFO - Started process (PID=19955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:55:24.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:55:24.776+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:55:24.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:55:24.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:55:24.848+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:55:24.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:55:24.865+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:55:24.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:55:24.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T20:55:55.111+0000] {processor.py:157} INFO - Started process (PID=19965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:55:55.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:55:55.124+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:55:55.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:55:55.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:55:55.194+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:55:55.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:55:55.210+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:55:55.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:55:55.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-15T20:56:25.467+0000] {processor.py:157} INFO - Started process (PID=19975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:56:25.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:56:25.474+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:56:25.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:56:25.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:56:25.521+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:56:25.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:56:25.538+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:56:25.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:56:25.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T20:56:55.833+0000] {processor.py:157} INFO - Started process (PID=19985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:56:55.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:56:55.839+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:56:55.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:56:55.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:56:55.903+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:56:55.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:56:55.920+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:56:55.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:56:55.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T20:57:26.324+0000] {processor.py:157} INFO - Started process (PID=19995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:57:26.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:57:26.331+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:57:26.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:57:26.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:57:26.405+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:57:26.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:57:26.421+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:57:26.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:57:26.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T20:57:56.722+0000] {processor.py:157} INFO - Started process (PID=20005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:57:56.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:57:56.733+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:57:56.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:57:56.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:57:56.842+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:57:56.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:57:56.860+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:57:56.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:57:56.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-15T20:58:27.025+0000] {processor.py:157} INFO - Started process (PID=20015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:58:27.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:58:27.032+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:58:27.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:58:27.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:58:27.110+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:58:27.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:58:27.128+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:58:27.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:58:27.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T20:58:57.510+0000] {processor.py:157} INFO - Started process (PID=20025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:58:57.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:58:57.515+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:58:57.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:58:57.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:58:57.553+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:58:57.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:58:57.567+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:58:57.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:58:57.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T20:59:27.904+0000] {processor.py:157} INFO - Started process (PID=20035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:59:27.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:59:27.919+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:59:27.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:59:27.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:59:27.967+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:59:27.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:59:27.984+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:59:27.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:59:27.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T20:59:58.308+0000] {processor.py:157} INFO - Started process (PID=20045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:59:58.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T20:59:58.314+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:59:58.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:59:58.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T20:59:58.381+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:59:58.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T20:59:58.397+0000] {logging_mixin.py:151} INFO - [2024-09-15T20:59:58.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T20:59:58.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T21:00:28.643+0000] {processor.py:157} INFO - Started process (PID=20055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:00:28.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:00:28.652+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:00:28.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:00:28.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:00:28.715+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:00:28.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:00:28.744+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:00:28.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:00:28.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T21:00:59.116+0000] {processor.py:157} INFO - Started process (PID=20064) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:00:59.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:00:59.123+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:00:59.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:00:59.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:00:59.196+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:00:59.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:00:59.211+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:00:59.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:00:59.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T21:01:29.506+0000] {processor.py:157} INFO - Started process (PID=20073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:01:29.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:01:29.518+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:01:29.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:01:29.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:01:29.591+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:01:29.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:01:29.609+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:01:29.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:01:29.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T21:01:59.889+0000] {processor.py:157} INFO - Started process (PID=20084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:01:59.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:01:59.896+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:01:59.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:01:59.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:01:59.960+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:01:59.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:01:59.979+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:01:59.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:01:59.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T21:02:30.211+0000] {processor.py:157} INFO - Started process (PID=20095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:02:30.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:02:30.222+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:02:30.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:02:30.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:02:30.289+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:02:30.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:02:30.305+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:02:30.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:02:30.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T21:03:00.565+0000] {processor.py:157} INFO - Started process (PID=20104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:03:00.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:03:00.579+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:03:00.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:03:00.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:03:00.648+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:03:00.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:03:00.666+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:03:00.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:03:00.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T21:03:31.040+0000] {processor.py:157} INFO - Started process (PID=20114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:03:31.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:03:31.046+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:03:31.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:03:31.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:03:31.109+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:03:31.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:03:31.134+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:03:31.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:03:31.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T21:04:01.477+0000] {processor.py:157} INFO - Started process (PID=20125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:04:01.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:04:01.483+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:04:01.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:04:01.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:04:01.523+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:04:01.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:04:01.537+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:04:01.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:04:01.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T21:04:31.779+0000] {processor.py:157} INFO - Started process (PID=20135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:04:31.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:04:31.782+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:04:31.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:04:31.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:04:31.818+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:04:31.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:04:31.845+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:04:31.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:04:31.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T21:05:02.126+0000] {processor.py:157} INFO - Started process (PID=20144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:05:02.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:05:02.131+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:05:02.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:05:02.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:05:02.196+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:05:02.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:05:02.210+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:05:02.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:05:02.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T21:05:32.589+0000] {processor.py:157} INFO - Started process (PID=20155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:05:32.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:05:32.596+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:05:32.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:05:32.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:05:32.647+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:05:32.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:05:32.666+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:05:32.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:05:32.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T21:06:02.957+0000] {processor.py:157} INFO - Started process (PID=20165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:06:02.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:06:02.963+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:06:02.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:06:02.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:06:03.035+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:06:03.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:06:03.054+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:06:03.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:06:03.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T21:06:33.255+0000] {processor.py:157} INFO - Started process (PID=20175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:06:33.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:06:33.262+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:06:33.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:06:33.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:06:33.312+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:06:33.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:06:33.327+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:06:33.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:06:33.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T21:07:03.614+0000] {processor.py:157} INFO - Started process (PID=20185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:07:03.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:07:03.621+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:07:03.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:07:03.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:07:03.674+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:07:03.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:07:03.689+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:07:03.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:07:03.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T21:07:33.986+0000] {processor.py:157} INFO - Started process (PID=20194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:07:33.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:07:33.994+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:07:33.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:07:34.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:07:34.059+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:07:34.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:07:34.084+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:07:34.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:07:34.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T21:08:04.320+0000] {processor.py:157} INFO - Started process (PID=20205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:08:04.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:08:04.326+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:08:04.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:08:04.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:08:04.367+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:08:04.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:08:04.381+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:08:04.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:08:04.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T21:08:34.695+0000] {processor.py:157} INFO - Started process (PID=20215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:08:34.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:08:34.698+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:08:34.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:08:34.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:08:34.725+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:08:34.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:08:34.738+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:08:34.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:08:34.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T21:09:05.124+0000] {processor.py:157} INFO - Started process (PID=20225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:09:05.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:09:05.138+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:09:05.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:09:05.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:09:05.195+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:09:05.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:09:05.230+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:09:05.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:09:05.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T21:09:35.475+0000] {processor.py:157} INFO - Started process (PID=20235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:09:35.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:09:35.482+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:09:35.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:09:35.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:09:35.545+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:09:35.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:09:35.561+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:09:35.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:09:35.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T21:10:05.855+0000] {processor.py:157} INFO - Started process (PID=20245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:10:05.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:10:05.862+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:10:05.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:10:05.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:10:05.910+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:10:05.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:10:05.925+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:10:05.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:10:05.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T21:10:36.290+0000] {processor.py:157} INFO - Started process (PID=20255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:10:36.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:10:36.296+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:10:36.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:10:36.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:10:36.371+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:10:36.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:10:36.390+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:10:36.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:10:36.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T21:11:06.815+0000] {processor.py:157} INFO - Started process (PID=20264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:11:06.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:11:06.831+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:11:06.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:11:06.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:11:06.890+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:11:06.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:11:06.918+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:11:06.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:11:06.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T21:11:37.317+0000] {processor.py:157} INFO - Started process (PID=20275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:11:37.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:11:37.325+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:11:37.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:11:37.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:11:37.404+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:11:37.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:11:37.429+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:11:37.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:11:37.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-15T21:12:07.713+0000] {processor.py:157} INFO - Started process (PID=20285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:12:07.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:12:07.721+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:12:07.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:12:07.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:12:07.788+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:12:07.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:12:07.806+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:12:07.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:12:07.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T21:12:38.249+0000] {processor.py:157} INFO - Started process (PID=20295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:12:38.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:12:38.255+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:12:38.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:12:38.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:12:38.313+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:12:38.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:12:38.328+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:12:38.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:12:38.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T21:13:08.771+0000] {processor.py:157} INFO - Started process (PID=20305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:13:08.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:13:08.777+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:13:08.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:13:08.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:13:08.855+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:13:08.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:13:08.876+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:13:08.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:13:08.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T21:13:39.331+0000] {processor.py:157} INFO - Started process (PID=20315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:13:39.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:13:39.337+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:13:39.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:13:39.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:13:39.428+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:13:39.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:13:39.447+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:13:39.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:13:39.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-15T21:29:36.705+0000] {processor.py:157} INFO - Started process (PID=20326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:29:36.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:29:36.709+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:29:36.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:29:36.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:29:36.775+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:29:36.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:29:36.821+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:29:36.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:29:36.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-15T21:30:07.218+0000] {processor.py:157} INFO - Started process (PID=20337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:30:07.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:30:07.241+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:30:07.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:30:07.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:30:07.331+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:30:07.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:30:07.361+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:30:07.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:30:07.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-15T21:30:37.605+0000] {processor.py:157} INFO - Started process (PID=20346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:30:37.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:30:37.611+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:30:37.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:30:37.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:30:37.683+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:30:37.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:30:37.705+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:30:37.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:30:37.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T21:31:07.997+0000] {processor.py:157} INFO - Started process (PID=20357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:31:07.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:31:08.001+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:31:08.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:31:08.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:31:08.046+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:31:08.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:31:08.064+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:31:08.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:31:08.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T21:31:38.446+0000] {processor.py:157} INFO - Started process (PID=20367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:31:38.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:31:38.451+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:31:38.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:31:38.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:31:38.489+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:31:38.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:31:38.508+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:31:38.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:31:38.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T21:32:08.847+0000] {processor.py:157} INFO - Started process (PID=20376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:32:08.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:32:08.852+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:32:08.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:32:08.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:32:08.915+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:32:08.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:32:08.931+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:32:08.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:32:08.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T21:32:39.180+0000] {processor.py:157} INFO - Started process (PID=20387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:32:39.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:32:39.186+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:32:39.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:32:39.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:32:39.247+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:32:39.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:32:39.275+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:32:39.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:32:39.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T21:33:09.734+0000] {processor.py:157} INFO - Started process (PID=20397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:33:09.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:33:09.757+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:33:09.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:33:09.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:33:09.866+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:33:09.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:33:09.911+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:33:09.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:33:09.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-09-15T21:33:40.034+0000] {processor.py:157} INFO - Started process (PID=20407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:33:40.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:33:40.040+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:33:40.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:33:40.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:33:40.080+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:33:40.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:33:40.098+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:33:40.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:33:40.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T21:34:10.509+0000] {processor.py:157} INFO - Started process (PID=20417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:34:10.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:34:10.513+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:34:10.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:34:10.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:34:10.548+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:34:10.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:34:10.560+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:34:10.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:34:10.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-15T21:34:41.015+0000] {processor.py:157} INFO - Started process (PID=20427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:34:41.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:34:41.019+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:34:41.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:34:41.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:34:41.064+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:34:41.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:34:41.090+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:34:41.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:34:41.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T21:35:11.328+0000] {processor.py:157} INFO - Started process (PID=20437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:35:11.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:35:11.334+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:35:11.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:35:11.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:35:11.379+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:35:11.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:35:11.404+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:35:11.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:35:11.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T21:35:41.662+0000] {processor.py:157} INFO - Started process (PID=20447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:35:41.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:35:41.665+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:35:41.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:35:41.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:35:41.700+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:35:41.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:35:41.726+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:35:41.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:35:41.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T21:36:11.997+0000] {processor.py:157} INFO - Started process (PID=20457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:36:12.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:36:12.013+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:36:12.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:36:12.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:36:12.059+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:36:12.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:36:12.075+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:36:12.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:36:12.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T21:36:42.535+0000] {processor.py:157} INFO - Started process (PID=20467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:36:42.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:36:42.540+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:36:42.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:36:42.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:36:42.599+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:36:42.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:36:42.617+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:36:42.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:36:42.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T21:37:12.975+0000] {processor.py:157} INFO - Started process (PID=20477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:37:12.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:37:12.980+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:37:12.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:37:12.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:37:13.019+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:37:13.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:37:13.032+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:37:13.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:37:13.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T21:37:43.444+0000] {processor.py:157} INFO - Started process (PID=20487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:37:43.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:37:43.449+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:37:43.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:37:43.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:37:43.496+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:37:43.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:37:43.516+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:37:43.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:37:43.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T21:38:13.925+0000] {processor.py:157} INFO - Started process (PID=20496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:38:13.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:38:13.928+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:38:13.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:38:13.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:38:13.985+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:38:13.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:38:13.999+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:38:13.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:38:14.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T21:38:44.244+0000] {processor.py:157} INFO - Started process (PID=20507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:38:44.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:38:44.249+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:38:44.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:38:44.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:38:44.306+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:38:44.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:38:44.325+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:38:44.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:38:44.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T21:39:14.593+0000] {processor.py:157} INFO - Started process (PID=20517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:39:14.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:39:14.598+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:39:14.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:39:14.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:39:14.634+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:39:14.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:39:14.664+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:39:14.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:39:14.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T21:39:45.012+0000] {processor.py:157} INFO - Started process (PID=20527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:39:45.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:39:45.017+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:39:45.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:39:45.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:39:45.072+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:39:45.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:39:45.089+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:39:45.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:39:45.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T21:40:15.415+0000] {processor.py:157} INFO - Started process (PID=20537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:40:15.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:40:15.417+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:40:15.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:40:15.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:40:15.445+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:40:15.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:40:15.457+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:40:15.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:40:15.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T21:40:45.942+0000] {processor.py:157} INFO - Started process (PID=20547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:40:45.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:40:45.950+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:40:45.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:40:45.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:40:46.006+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:40:46.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:40:46.022+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:40:46.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:40:46.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T21:41:16.252+0000] {processor.py:157} INFO - Started process (PID=20557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:41:16.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:41:16.255+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:41:16.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:41:16.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:41:16.286+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:41:16.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:41:16.298+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:41:16.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:41:16.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-15T21:41:46.767+0000] {processor.py:157} INFO - Started process (PID=20566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:41:46.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:41:46.774+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:41:46.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:41:46.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:41:46.843+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:41:46.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:41:46.858+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:41:46.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:41:46.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T21:42:17.229+0000] {processor.py:157} INFO - Started process (PID=20577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:42:17.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:42:17.239+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:42:17.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:42:17.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:42:17.301+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:42:17.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:42:17.317+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:42:17.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:42:17.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T21:42:47.518+0000] {processor.py:157} INFO - Started process (PID=20587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:42:47.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:42:47.524+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:42:47.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:42:47.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:42:47.567+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:42:47.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:42:47.593+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:42:47.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:42:47.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T21:43:17.886+0000] {processor.py:157} INFO - Started process (PID=20597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:43:17.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:43:17.890+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:43:17.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:43:17.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:43:17.930+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:43:17.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:43:17.947+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:43:17.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:43:17.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T21:43:48.330+0000] {processor.py:157} INFO - Started process (PID=20607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:43:48.331+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:43:48.338+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:43:48.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:43:48.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:43:48.397+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:43:48.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:43:48.414+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:43:48.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:43:48.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T21:44:18.778+0000] {processor.py:157} INFO - Started process (PID=20617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:44:18.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:44:18.782+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:44:18.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:44:18.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:44:18.821+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:44:18.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:44:18.841+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:44:18.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:44:18.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T21:44:49.247+0000] {processor.py:157} INFO - Started process (PID=20627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:44:49.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:44:49.260+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:44:49.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:44:49.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:44:49.326+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:44:49.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:44:49.344+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:44:49.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:44:49.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T21:45:19.567+0000] {processor.py:157} INFO - Started process (PID=20637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:45:19.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:45:19.572+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:45:19.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:45:19.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:45:19.611+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:45:19.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:45:19.639+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:45:19.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:45:19.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T21:45:49.990+0000] {processor.py:157} INFO - Started process (PID=20647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:45:49.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:45:49.994+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:45:49.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:45:50.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:45:50.025+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:45:50.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:45:50.039+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:45:50.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:45:50.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T21:46:20.330+0000] {processor.py:157} INFO - Started process (PID=20657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:46:20.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:46:20.336+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:46:20.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:46:20.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:46:20.375+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:46:20.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:46:20.389+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:46:20.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:46:20.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T21:46:50.712+0000] {processor.py:157} INFO - Started process (PID=20667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:46:50.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:46:50.715+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:46:50.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:46:50.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:46:50.748+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:46:50.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:46:50.761+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:46:50.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:46:50.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T21:47:21.155+0000] {processor.py:157} INFO - Started process (PID=20677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:47:21.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:47:21.162+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:47:21.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:47:21.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:47:21.221+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:47:21.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:47:21.247+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:47:21.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:47:21.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T21:47:51.473+0000] {processor.py:157} INFO - Started process (PID=20687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:47:51.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:47:51.476+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:47:51.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:47:51.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:47:51.520+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:47:51.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:47:51.538+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:47:51.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:47:51.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T21:48:21.841+0000] {processor.py:157} INFO - Started process (PID=20697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:48:21.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:48:21.848+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:48:21.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:48:21.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:48:21.914+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:48:21.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:48:21.929+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:48:21.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:48:21.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T21:48:52.273+0000] {processor.py:157} INFO - Started process (PID=20707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:48:52.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:48:52.277+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:48:52.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:48:52.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:48:52.322+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:48:52.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:48:52.338+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:48:52.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:48:52.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T21:49:22.624+0000] {processor.py:157} INFO - Started process (PID=20717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:49:22.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:49:22.630+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:49:22.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:49:22.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:49:22.689+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:49:22.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:49:22.722+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:49:22.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:49:22.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T21:49:52.988+0000] {processor.py:157} INFO - Started process (PID=20727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:49:52.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:49:53.004+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:49:53.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:49:53.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:49:53.068+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:49:53.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:49:53.093+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:49:53.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:49:53.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T21:50:23.323+0000] {processor.py:157} INFO - Started process (PID=20737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:50:23.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:50:23.325+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:50:23.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:50:23.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:50:23.354+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:50:23.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:50:23.367+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:50:23.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:50:23.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T21:50:53.810+0000] {processor.py:157} INFO - Started process (PID=20747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:50:53.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:50:53.819+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:50:53.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:50:53.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:50:53.890+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:50:53.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:50:53.907+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:50:53.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:50:53.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T21:51:24.134+0000] {processor.py:157} INFO - Started process (PID=20757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:51:24.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:51:24.141+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:51:24.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:51:24.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:51:24.172+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:51:24.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:51:24.187+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:51:24.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:51:24.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T21:51:54.586+0000] {processor.py:157} INFO - Started process (PID=20766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:51:54.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:51:54.591+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:51:54.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:51:54.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:51:54.647+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:51:54.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:51:54.677+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:51:54.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:51:54.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T21:52:24.978+0000] {processor.py:157} INFO - Started process (PID=20777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:52:24.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:52:24.982+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:52:24.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:52:24.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:52:25.013+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:52:25.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:52:25.025+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:52:25.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:52:25.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-15T21:52:55.454+0000] {processor.py:157} INFO - Started process (PID=20786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:52:55.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:52:55.467+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:52:55.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:52:55.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:52:55.525+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:52:55.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:52:55.541+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:52:55.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:52:55.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T21:53:25.833+0000] {processor.py:157} INFO - Started process (PID=20796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:53:25.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:53:25.838+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:53:25.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:53:25.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:53:25.886+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:53:25.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:53:25.901+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:53:25.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:53:25.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-15T21:53:56.286+0000] {processor.py:157} INFO - Started process (PID=20806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:53:56.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:53:56.293+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:53:56.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:53:56.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:53:56.357+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:53:56.357+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:53:56.375+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:53:56.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:53:56.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T21:54:26.606+0000] {processor.py:157} INFO - Started process (PID=20817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:54:26.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:54:26.612+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:54:26.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:54:26.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:54:26.640+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:54:26.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:54:26.665+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:54:26.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:54:26.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-15T21:54:57.063+0000] {processor.py:157} INFO - Started process (PID=20827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:54:57.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:54:57.069+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:54:57.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:54:57.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:54:57.133+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:54:57.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:54:57.149+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:54:57.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:54:57.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T21:55:27.490+0000] {processor.py:157} INFO - Started process (PID=20837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:55:27.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:55:27.494+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:55:27.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:55:27.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:55:27.538+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:55:27.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:55:27.553+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:55:27.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:55:27.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T21:55:57.822+0000] {processor.py:157} INFO - Started process (PID=20846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:55:57.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:55:57.829+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:55:57.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:55:57.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:55:57.886+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:55:57.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:55:57.901+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:55:57.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:55:57.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T21:56:28.183+0000] {processor.py:157} INFO - Started process (PID=20857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:56:28.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:56:28.191+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:56:28.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:56:28.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:56:28.247+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:56:28.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:56:28.262+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:56:28.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:56:28.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T21:56:58.525+0000] {processor.py:157} INFO - Started process (PID=20865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:56:58.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:56:58.541+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:56:58.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:56:58.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:56:58.605+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:56:58.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:56:58.625+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:56:58.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:56:58.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T21:57:28.968+0000] {processor.py:157} INFO - Started process (PID=20876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:57:28.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:57:28.976+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:57:28.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:57:28.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:57:29.042+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:57:29.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:57:29.059+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:57:29.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:57:29.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T21:57:59.326+0000] {processor.py:157} INFO - Started process (PID=20886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:57:59.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:57:59.333+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:57:59.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:57:59.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:57:59.398+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:57:59.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:57:59.413+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:57:59.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:57:59.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T21:58:29.787+0000] {processor.py:157} INFO - Started process (PID=20897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:58:29.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:58:29.791+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:58:29.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:58:29.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:58:29.851+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:58:29.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:58:29.868+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:58:29.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:58:29.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T21:59:00.153+0000] {processor.py:157} INFO - Started process (PID=20907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:59:00.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:59:00.155+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:59:00.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:59:00.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:59:00.185+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:59:00.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:59:00.196+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:59:00.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:59:00.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-15T21:59:30.637+0000] {processor.py:157} INFO - Started process (PID=20916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:59:30.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T21:59:30.643+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:59:30.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:59:30.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T21:59:30.687+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:59:30.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T21:59:30.707+0000] {logging_mixin.py:151} INFO - [2024-09-15T21:59:30.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T21:59:30.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T22:00:00.974+0000] {processor.py:157} INFO - Started process (PID=20927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:00:00.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:00:00.984+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:00:00.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:00:01.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:00:01.020+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:00:01.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:00:01.039+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:00:01.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:00:01.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T22:00:31.402+0000] {processor.py:157} INFO - Started process (PID=20936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:00:31.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:00:31.408+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:00:31.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:00:31.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:00:31.468+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:00:31.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:00:31.489+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:00:31.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:00:31.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T22:01:01.872+0000] {processor.py:157} INFO - Started process (PID=20947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:01:01.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:01:01.875+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:01:01.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:01:01.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:01:01.905+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:01:01.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:01:01.923+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:01:01.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:01:01.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T22:01:32.312+0000] {processor.py:157} INFO - Started process (PID=20957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:01:32.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:01:32.336+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:01:32.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:01:32.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:01:32.404+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:01:32.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:01:32.422+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:01:32.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:01:32.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-15T22:02:02.670+0000] {processor.py:157} INFO - Started process (PID=20967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:02:02.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:02:02.673+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:02:02.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:02:02.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:02:02.725+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:02:02.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:02:02.757+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:02:02.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:02:02.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T22:02:33.115+0000] {processor.py:157} INFO - Started process (PID=20977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:02:33.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:02:33.127+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:02:33.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:02:33.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:02:33.167+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:02:33.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:02:33.180+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:02:33.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:02:33.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T22:03:03.461+0000] {processor.py:157} INFO - Started process (PID=20987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:03:03.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:03:03.488+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:03:03.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:03:03.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:03:03.551+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:03:03.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:03:03.566+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:03:03.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:03:03.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T22:03:33.996+0000] {processor.py:157} INFO - Started process (PID=20997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:03:33.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:03:34.002+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:03:34.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:03:34.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:03:34.043+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:03:34.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:03:34.059+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:03:34.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:03:34.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T22:04:04.367+0000] {processor.py:157} INFO - Started process (PID=21007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:04:04.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:04:04.384+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:04:04.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:04:04.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:04:04.416+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:04:04.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:04:04.431+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:04:04.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:04:04.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T22:04:34.879+0000] {processor.py:157} INFO - Started process (PID=21016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:04:34.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:04:34.885+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:04:34.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:04:34.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:04:34.947+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:04:34.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:04:34.974+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:04:34.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:04:34.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T22:05:05.234+0000] {processor.py:157} INFO - Started process (PID=21027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:05:05.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:05:05.240+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:05:05.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:05:05.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:05:05.289+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:05:05.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:05:05.306+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:05:05.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:05:05.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T22:05:35.575+0000] {processor.py:157} INFO - Started process (PID=21037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:05:35.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:05:35.583+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:05:35.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:05:35.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:05:35.626+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:05:35.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:05:35.646+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:05:35.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:05:35.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T22:06:06.081+0000] {processor.py:157} INFO - Started process (PID=21047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:06:06.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:06:06.086+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:06:06.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:06:06.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:06:06.119+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:06:06.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:06:06.144+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:06:06.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:06:06.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T22:06:36.423+0000] {processor.py:157} INFO - Started process (PID=21057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:06:36.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:06:36.442+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:06:36.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:06:36.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:06:36.492+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:06:36.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:06:36.520+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:06:36.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:06:36.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T22:07:06.780+0000] {processor.py:157} INFO - Started process (PID=21067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:07:06.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:07:06.787+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:07:06.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:07:06.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:07:06.849+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:07:06.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:07:06.870+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:07:06.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:07:06.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T22:07:37.086+0000] {processor.py:157} INFO - Started process (PID=21077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:07:37.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:07:37.088+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:07:37.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:07:37.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:07:37.116+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:07:37.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:07:37.131+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:07:37.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:07:37.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-15T22:08:07.391+0000] {processor.py:157} INFO - Started process (PID=21086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:08:07.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:08:07.409+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:08:07.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:08:07.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:08:07.479+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:08:07.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:08:07.497+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:08:07.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:08:07.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-15T22:08:37.631+0000] {processor.py:157} INFO - Started process (PID=21097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:08:37.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:08:37.635+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:08:37.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:08:37.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:08:37.669+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:08:37.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:08:37.683+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:08:37.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:08:37.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-15T22:09:07.996+0000] {processor.py:157} INFO - Started process (PID=21106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:09:07.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:09:08.005+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:09:08.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:09:08.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:09:08.067+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:09:08.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:09:08.083+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:09:08.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:09:08.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T22:09:38.378+0000] {processor.py:157} INFO - Started process (PID=21117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:09:38.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:09:38.382+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:09:38.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:09:38.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:09:38.426+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:09:38.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:09:38.440+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:09:38.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:09:38.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T22:10:08.744+0000] {processor.py:157} INFO - Started process (PID=21127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:10:08.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:10:08.755+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:10:08.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:10:08.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:10:08.806+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:10:08.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:10:08.821+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:10:08.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:10:08.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T22:10:39.198+0000] {processor.py:157} INFO - Started process (PID=21137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:10:39.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:10:39.202+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:10:39.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:10:39.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:10:39.254+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:10:39.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:10:39.268+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:10:39.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:10:39.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T22:11:09.570+0000] {processor.py:157} INFO - Started process (PID=21147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:11:09.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:11:09.575+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:11:09.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:11:09.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:11:09.632+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:11:09.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:11:09.648+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:11:09.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:11:09.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T22:11:39.896+0000] {processor.py:157} INFO - Started process (PID=21157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:11:39.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:11:39.908+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:11:39.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:11:39.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:11:39.952+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:11:39.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:11:39.968+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:11:39.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:11:39.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T22:12:10.398+0000] {processor.py:157} INFO - Started process (PID=21166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:12:10.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:12:10.405+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:12:10.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:12:10.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:12:10.457+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:12:10.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:12:10.478+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:12:10.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:12:10.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T22:12:40.732+0000] {processor.py:157} INFO - Started process (PID=21177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:12:40.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:12:40.738+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:12:40.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:12:40.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:12:40.781+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:12:40.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:12:40.799+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:12:40.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:12:40.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T22:13:11.206+0000] {processor.py:157} INFO - Started process (PID=21187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:13:11.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:13:11.210+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:13:11.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:13:11.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:13:11.236+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:13:11.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:13:11.250+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:13:11.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:13:11.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T22:13:41.638+0000] {processor.py:157} INFO - Started process (PID=21197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:13:41.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:13:41.648+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:13:41.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:13:41.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:13:41.717+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:13:41.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:13:41.733+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:13:41.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:13:41.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T22:14:11.946+0000] {processor.py:157} INFO - Started process (PID=21207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:14:11.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:14:11.950+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:14:11.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:14:11.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:14:11.981+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:14:11.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:14:12.000+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:14:12.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:14:12.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T22:14:42.382+0000] {processor.py:157} INFO - Started process (PID=21216) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:14:42.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:14:42.390+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:14:42.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:14:42.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:14:42.442+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:14:42.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:14:42.458+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:14:42.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:14:42.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T22:15:12.731+0000] {processor.py:157} INFO - Started process (PID=21227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:15:12.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:15:12.737+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:15:12.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:15:12.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:15:12.780+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:15:12.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:15:12.798+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:15:12.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:15:12.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T22:15:43.066+0000] {processor.py:157} INFO - Started process (PID=21237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:15:43.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:15:43.074+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:15:43.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:15:43.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:15:43.121+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:15:43.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:15:43.135+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:15:43.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:15:43.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T22:16:13.452+0000] {processor.py:157} INFO - Started process (PID=21247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:16:13.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:16:13.458+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:16:13.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:16:13.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:16:13.494+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:16:13.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:16:13.528+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:16:13.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:16:13.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T22:16:43.875+0000] {processor.py:157} INFO - Started process (PID=21257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:16:43.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:16:43.884+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:16:43.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:16:43.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:16:43.945+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:16:43.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:16:43.972+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:16:43.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:16:43.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T22:17:14.158+0000] {processor.py:157} INFO - Started process (PID=21267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:17:14.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:17:14.164+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:17:14.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:17:14.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:17:14.209+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:17:14.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:17:14.224+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:17:14.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:17:14.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T22:17:44.505+0000] {processor.py:157} INFO - Started process (PID=21277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:17:44.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:17:44.508+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:17:44.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:17:44.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:17:44.538+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:17:44.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:17:44.553+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:17:44.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:17:44.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-15T22:18:14.880+0000] {processor.py:157} INFO - Started process (PID=21287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:18:14.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:18:14.889+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:18:14.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:18:14.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:18:14.961+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:18:14.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:18:14.993+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:18:14.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:18:15.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-15T22:18:45.190+0000] {processor.py:157} INFO - Started process (PID=21297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:18:45.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:18:45.199+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:18:45.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:18:45.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:18:45.260+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:18:45.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:18:45.274+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:18:45.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:18:45.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-15T22:19:15.624+0000] {processor.py:157} INFO - Started process (PID=21307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:19:15.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:19:15.628+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:19:15.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:19:15.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:19:15.654+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:19:15.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:19:15.668+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:19:15.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:19:15.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T22:19:46.057+0000] {processor.py:157} INFO - Started process (PID=21317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:19:46.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:19:46.071+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:19:46.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:19:46.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:19:46.138+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:19:46.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:19:46.156+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:19:46.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:19:46.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-15T22:20:16.396+0000] {processor.py:157} INFO - Started process (PID=21327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:20:16.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:20:16.398+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:20:16.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:20:16.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:20:16.428+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:20:16.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:20:16.441+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:20:16.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:20:16.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-15T22:20:46.830+0000] {processor.py:157} INFO - Started process (PID=21337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:20:46.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:20:46.835+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:20:46.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:20:46.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:20:46.902+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:20:46.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:20:46.919+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:20:46.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:20:46.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T22:21:17.178+0000] {processor.py:157} INFO - Started process (PID=21347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:21:17.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:21:17.181+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:21:17.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:21:17.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:21:17.211+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:21:17.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:21:17.235+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:21:17.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:21:17.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-15T22:21:47.631+0000] {processor.py:157} INFO - Started process (PID=21357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:21:47.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:21:47.644+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:21:47.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:21:47.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:21:47.703+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:21:47.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:21:47.735+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:21:47.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:21:47.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-15T22:22:18.097+0000] {processor.py:157} INFO - Started process (PID=21367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:22:18.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:22:18.104+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:22:18.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:22:18.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:22:18.159+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:22:18.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:22:18.179+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:22:18.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:22:18.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T22:22:48.550+0000] {processor.py:157} INFO - Started process (PID=21377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:22:48.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:22:48.555+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:22:48.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:22:48.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:22:48.586+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:22:48.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:22:48.611+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:22:48.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:22:48.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T22:23:19.015+0000] {processor.py:157} INFO - Started process (PID=21386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:23:19.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:23:19.024+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:23:19.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:23:19.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:23:19.091+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:23:19.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:23:19.109+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:23:19.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:23:19.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T22:23:49.354+0000] {processor.py:157} INFO - Started process (PID=21397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:23:49.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:23:49.357+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:23:49.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:23:49.372+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:23:49.404+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:23:49.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:23:49.420+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:23:49.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:23:49.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T22:24:19.759+0000] {processor.py:157} INFO - Started process (PID=21407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:24:19.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:24:19.763+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:24:19.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:24:19.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:24:19.818+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:24:19.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:24:19.844+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:24:19.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:24:19.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T22:24:50.204+0000] {processor.py:157} INFO - Started process (PID=21416) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:24:50.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:24:50.211+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:24:50.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:24:50.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:24:50.253+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:24:50.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:24:50.266+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:24:50.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:24:50.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T22:25:20.503+0000] {processor.py:157} INFO - Started process (PID=21427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:25:20.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:25:20.516+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:25:20.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:25:20.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:25:20.577+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:25:20.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:25:20.603+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:25:20.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:25:20.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T22:25:50.830+0000] {processor.py:157} INFO - Started process (PID=21437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:25:50.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:25:50.834+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:25:50.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:25:50.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:25:50.868+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:25:50.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:25:50.887+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:25:50.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:25:50.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T22:26:21.308+0000] {processor.py:157} INFO - Started process (PID=21447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:26:21.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:26:21.314+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:26:21.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:26:21.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:26:21.375+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:26:21.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:26:21.396+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:26:21.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:26:21.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T22:26:51.639+0000] {processor.py:157} INFO - Started process (PID=21457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:26:51.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:26:51.646+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:26:51.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:26:51.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:26:51.687+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:26:51.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:26:51.703+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:26:51.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:26:51.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T22:27:22.054+0000] {processor.py:157} INFO - Started process (PID=21467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:27:22.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:27:22.064+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:27:22.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:27:22.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:27:22.113+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:27:22.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:27:22.131+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:27:22.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:27:22.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T22:27:52.499+0000] {processor.py:157} INFO - Started process (PID=21476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:27:52.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:27:52.507+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:27:52.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:27:52.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:27:52.583+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:27:52.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:27:52.601+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:27:52.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:27:52.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T22:28:22.977+0000] {processor.py:157} INFO - Started process (PID=21487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:28:22.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:28:22.981+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:28:22.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:28:22.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:28:23.019+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:28:23.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:28:23.038+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:28:23.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:28:23.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T22:28:53.415+0000] {processor.py:157} INFO - Started process (PID=21497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:28:53.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:28:53.420+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:28:53.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:28:53.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:28:53.455+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:28:53.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:28:53.472+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:28:53.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:28:53.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-15T22:29:23.747+0000] {processor.py:157} INFO - Started process (PID=21507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:29:23.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:29:23.756+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:29:23.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:29:23.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:29:23.811+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:29:23.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:29:23.824+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:29:23.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:29:23.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T22:29:54.283+0000] {processor.py:157} INFO - Started process (PID=21517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:29:54.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:29:54.287+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:29:54.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:29:54.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:29:54.325+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:29:54.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:29:54.357+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:29:54.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:29:54.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T22:30:24.627+0000] {processor.py:157} INFO - Started process (PID=21527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:30:24.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:30:24.633+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:30:24.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:30:24.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:30:24.693+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:30:24.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:30:24.707+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:30:24.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:30:24.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T22:30:55.096+0000] {processor.py:157} INFO - Started process (PID=21536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:30:55.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:30:55.111+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:30:55.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:30:55.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:30:55.206+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:30:55.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:30:55.230+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:30:55.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:30:55.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-15T22:39:56.551+0000] {processor.py:157} INFO - Started process (PID=21549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:39:56.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:39:56.560+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:39:56.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:39:56.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:39:56.634+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:39:56.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:39:56.657+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:39:56.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:39:56.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-15T22:40:26.851+0000] {processor.py:157} INFO - Started process (PID=21559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:40:26.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:40:26.857+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:40:26.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:40:26.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:40:26.918+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:40:26.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:40:26.946+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:40:26.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:40:26.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T22:40:57.166+0000] {processor.py:157} INFO - Started process (PID=21569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:40:57.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:40:57.169+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:40:57.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:40:57.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:40:57.212+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:40:57.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:40:57.227+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:40:57.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:40:57.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T22:41:27.586+0000] {processor.py:157} INFO - Started process (PID=21579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:41:27.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:41:27.591+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:41:27.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:41:27.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:41:27.656+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:41:27.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:41:27.672+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:41:27.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:41:27.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T22:41:57.978+0000] {processor.py:157} INFO - Started process (PID=21589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:41:57.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:41:57.983+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:41:57.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:41:57.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:41:58.014+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:41:58.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:41:58.057+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:41:58.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:41:58.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-15T22:42:28.322+0000] {processor.py:157} INFO - Started process (PID=21598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:42:28.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:42:28.328+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:42:28.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:42:28.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:42:28.404+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:42:28.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:42:28.419+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:42:28.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:42:28.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T22:42:58.668+0000] {processor.py:157} INFO - Started process (PID=21609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:42:58.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:42:58.673+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:42:58.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:42:58.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:42:58.734+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:42:58.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:42:58.750+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:42:58.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:42:58.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T22:43:29.068+0000] {processor.py:157} INFO - Started process (PID=21619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:43:29.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:43:29.072+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:43:29.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:43:29.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:43:29.106+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:43:29.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:43:29.121+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:43:29.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:43:29.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T22:43:59.412+0000] {processor.py:157} INFO - Started process (PID=21629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:43:59.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:43:59.417+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:43:59.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:43:59.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:43:59.465+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:43:59.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:43:59.480+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:43:59.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:44:00.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.897 seconds
[2024-09-15T22:44:30.657+0000] {processor.py:157} INFO - Started process (PID=21637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:44:30.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:44:30.664+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:44:30.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:44:30.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:44:30.730+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:44:30.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:44:30.747+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:44:30.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:44:30.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-15T22:45:01.012+0000] {processor.py:157} INFO - Started process (PID=21648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:45:01.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:45:01.020+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:45:01.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:45:01.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:45:01.078+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:45:01.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:45:01.093+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:45:01.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:45:01.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-15T22:45:31.322+0000] {processor.py:157} INFO - Started process (PID=21658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:45:31.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:45:31.337+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:45:31.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:45:31.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:45:31.389+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:45:31.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:45:31.406+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:45:31.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:45:31.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T22:46:01.705+0000] {processor.py:157} INFO - Started process (PID=21668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:46:01.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:46:01.713+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:46:01.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:46:01.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:46:01.786+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:46:01.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:46:01.803+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:46:01.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:46:01.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T22:46:32.053+0000] {processor.py:157} INFO - Started process (PID=21678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:46:32.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:46:32.063+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:46:32.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:46:32.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:46:32.133+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:46:32.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:46:32.149+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:46:32.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:46:32.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T22:47:02.373+0000] {processor.py:157} INFO - Started process (PID=21688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:47:02.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:47:02.385+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:47:02.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:47:02.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:47:02.436+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:47:02.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:47:02.451+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:47:02.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:47:02.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.224 seconds
[2024-09-15T22:47:32.738+0000] {processor.py:157} INFO - Started process (PID=21699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:47:32.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:47:32.759+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:47:32.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:47:32.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:47:32.829+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:47:32.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:47:32.846+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:47:32.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:47:32.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-15T22:48:03.177+0000] {processor.py:157} INFO - Started process (PID=21709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:48:03.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:48:03.184+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:48:03.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:48:03.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:48:03.213+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:48:03.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:48:03.228+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:48:03.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:48:03.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T22:48:33.629+0000] {processor.py:157} INFO - Started process (PID=21719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:48:33.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:48:33.642+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:48:33.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:48:33.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:48:33.706+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:48:33.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:48:33.728+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:48:33.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:48:33.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-15T22:49:04.000+0000] {processor.py:157} INFO - Started process (PID=21729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:49:04.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:49:04.005+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:49:04.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:49:04.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:49:04.036+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:49:04.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:49:04.051+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:49:04.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:49:04.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T22:49:34.409+0000] {processor.py:157} INFO - Started process (PID=21739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:49:34.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:49:34.414+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:49:34.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:49:34.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:49:34.463+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:49:34.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:49:34.496+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:49:34.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:49:34.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T22:50:04.769+0000] {processor.py:157} INFO - Started process (PID=21749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:50:04.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:50:04.783+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:50:04.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:50:04.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:50:04.830+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:50:04.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:50:04.845+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:50:04.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:50:05.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.285 seconds
[2024-09-15T22:50:35.365+0000] {processor.py:157} INFO - Started process (PID=21759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:50:35.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:50:35.371+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:50:35.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:50:35.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:50:35.449+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:50:35.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:50:35.467+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:50:35.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:50:35.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T22:51:05.707+0000] {processor.py:157} INFO - Started process (PID=21769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:51:05.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:51:05.714+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:51:05.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:51:05.744+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:51:05.775+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:51:05.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:51:05.806+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:51:05.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:51:05.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T22:51:36.111+0000] {processor.py:157} INFO - Started process (PID=21778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:51:36.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:51:36.116+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:51:36.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:51:36.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:51:36.175+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:51:36.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:51:36.200+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:51:36.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:51:36.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T22:52:06.449+0000] {processor.py:157} INFO - Started process (PID=21789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:52:06.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:52:06.453+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:52:06.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:52:06.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:52:06.497+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:52:06.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:52:06.513+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:52:06.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:52:06.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T22:52:36.839+0000] {processor.py:157} INFO - Started process (PID=21799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:52:36.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:52:36.842+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:52:36.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:52:36.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:52:36.876+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:52:36.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:52:36.902+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:52:36.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:52:36.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T22:53:07.204+0000] {processor.py:157} INFO - Started process (PID=21809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:53:07.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:53:07.210+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:53:07.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:53:07.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:53:07.283+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:53:07.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:53:07.306+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:53:07.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:53:07.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.290 seconds
[2024-09-15T22:53:37.781+0000] {processor.py:157} INFO - Started process (PID=21819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:53:37.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:53:37.785+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:53:37.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:53:37.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:53:37.827+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:53:37.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:53:37.842+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:53:37.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:53:37.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T22:54:08.065+0000] {processor.py:157} INFO - Started process (PID=21829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:54:08.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:54:08.069+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:54:08.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:54:08.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:54:08.110+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:54:08.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:54:08.152+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:54:08.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:54:08.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T22:54:38.476+0000] {processor.py:157} INFO - Started process (PID=21839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:54:38.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:54:38.481+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:54:38.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:54:38.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:54:38.520+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:54:38.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:54:38.538+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:54:38.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:54:38.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T22:55:08.961+0000] {processor.py:157} INFO - Started process (PID=21849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:55:08.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:55:08.966+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:55:08.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:55:08.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:55:09.009+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:55:09.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:55:09.040+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:55:09.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:55:09.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T22:55:39.308+0000] {processor.py:157} INFO - Started process (PID=21859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:55:39.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:55:39.323+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:55:39.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:55:39.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:55:39.375+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:55:39.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:55:39.390+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:55:39.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:55:39.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-15T22:56:09.589+0000] {processor.py:157} INFO - Started process (PID=21869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:56:09.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:56:09.594+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:56:09.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:56:09.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:56:09.623+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:56:09.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:56:09.640+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:56:09.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:56:09.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.260 seconds
[2024-09-15T22:56:39.970+0000] {processor.py:157} INFO - Started process (PID=21878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:56:39.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:56:39.979+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:56:39.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:56:39.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:56:40.047+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:56:40.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:56:40.064+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:56:40.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:56:40.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T22:57:10.429+0000] {processor.py:157} INFO - Started process (PID=21889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:57:10.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:57:10.434+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:57:10.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:57:10.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:57:10.509+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:57:10.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:57:10.539+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:57:10.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:57:10.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T22:57:40.750+0000] {processor.py:157} INFO - Started process (PID=21898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:57:40.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:57:40.756+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:57:40.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:57:40.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:57:40.827+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:57:40.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:57:40.852+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:57:40.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:57:40.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T22:58:11.079+0000] {processor.py:157} INFO - Started process (PID=21909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:58:11.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:58:11.083+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:58:11.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:58:11.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:58:11.124+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:58:11.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:58:11.139+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:58:11.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:58:11.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-15T22:58:41.458+0000] {processor.py:157} INFO - Started process (PID=21919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:58:41.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:58:41.466+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:58:41.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:58:41.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:58:41.547+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:58:41.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:58:41.583+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:58:41.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:58:41.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-15T22:59:11.768+0000] {processor.py:157} INFO - Started process (PID=21929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:59:11.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:59:11.776+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:59:11.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:59:11.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:59:11.845+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:59:11.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:59:12.042+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:59:12.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:59:12.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.303 seconds
[2024-09-15T22:59:42.192+0000] {processor.py:157} INFO - Started process (PID=21939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:59:42.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T22:59:42.203+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:59:42.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:59:42.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T22:59:42.267+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:59:42.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T22:59:42.286+0000] {logging_mixin.py:151} INFO - [2024-09-15T22:59:42.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T22:59:42.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-15T23:00:12.635+0000] {processor.py:157} INFO - Started process (PID=21949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:00:12.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:00:12.649+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:00:12.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:00:12.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:00:12.715+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:00:12.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:00:12.731+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:00:12.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:00:12.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-15T23:00:42.973+0000] {processor.py:157} INFO - Started process (PID=21959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:00:42.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:00:42.979+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:00:42.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:00:43.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:00:43.044+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:00:43.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:00:43.073+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:00:43.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:00:43.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T23:01:13.474+0000] {processor.py:157} INFO - Started process (PID=21969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:01:13.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:01:13.480+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:01:13.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:01:13.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:01:13.550+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:01:13.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:01:13.570+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:01:13.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:01:13.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-15T23:01:43.773+0000] {processor.py:157} INFO - Started process (PID=21979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:01:43.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:01:43.780+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:01:43.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:01:43.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:01:43.855+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:01:43.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:01:43.873+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:01:43.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:01:43.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-15T23:02:14.300+0000] {processor.py:157} INFO - Started process (PID=21988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:02:14.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:02:14.305+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:02:14.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:02:14.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:02:14.377+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:02:14.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:02:14.399+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:02:14.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:02:14.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T23:02:44.651+0000] {processor.py:157} INFO - Started process (PID=21999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:02:44.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:02:44.659+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:02:44.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:02:44.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:02:44.746+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:02:44.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:02:44.772+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:02:44.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:02:44.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-15T23:03:15.136+0000] {processor.py:157} INFO - Started process (PID=22009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:03:15.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:03:15.142+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:03:15.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:03:15.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:03:15.193+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:03:15.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:03:15.217+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:03:15.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:03:15.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T23:03:45.499+0000] {processor.py:157} INFO - Started process (PID=22019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:03:45.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:03:45.510+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:03:45.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:03:45.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:03:45.586+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:03:45.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:03:45.603+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:03:45.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:03:45.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-15T23:04:15.878+0000] {processor.py:157} INFO - Started process (PID=22029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:04:15.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:04:15.884+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:04:15.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:04:15.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:04:15.945+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:04:15.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:04:15.962+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:04:15.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:04:15.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T23:04:46.170+0000] {processor.py:157} INFO - Started process (PID=22039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:04:46.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:04:46.174+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:04:46.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:04:46.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:04:46.207+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:04:46.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:04:46.241+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:04:46.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:04:46.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T23:05:16.580+0000] {processor.py:157} INFO - Started process (PID=22049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:05:16.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:05:16.588+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:05:16.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:05:16.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:05:16.613+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:05:16.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:05:16.782+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:05:16.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:05:16.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.210 seconds
[2024-09-15T23:05:46.977+0000] {processor.py:157} INFO - Started process (PID=22059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:05:46.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:05:46.982+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:05:46.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:05:46.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:05:47.032+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:05:47.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:05:47.047+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:05:47.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:05:47.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-15T23:06:17.382+0000] {processor.py:157} INFO - Started process (PID=22069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:06:17.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:06:17.390+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:06:17.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:06:17.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:06:17.449+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:06:17.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:06:17.480+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:06:17.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:06:17.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-15T23:06:47.734+0000] {processor.py:157} INFO - Started process (PID=22079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:06:47.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:06:47.740+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:06:47.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:06:47.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:06:47.793+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:06:47.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:06:47.819+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:06:47.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:06:47.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-15T23:07:18.021+0000] {processor.py:157} INFO - Started process (PID=22089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:07:18.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:07:18.026+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:07:18.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:07:18.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:07:18.057+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:07:18.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:07:18.085+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:07:18.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:07:18.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-15T23:07:48.381+0000] {processor.py:157} INFO - Started process (PID=22099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:07:48.382+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:07:48.388+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:07:48.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:07:48.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:07:48.434+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:07:48.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:07:48.455+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:07:48.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:07:48.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.239 seconds
[2024-09-15T23:08:18.866+0000] {processor.py:157} INFO - Started process (PID=22109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:08:18.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:08:18.870+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:08:18.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:08:18.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:08:18.899+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:08:18.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:08:18.981+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:08:18.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:08:18.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T23:08:49.300+0000] {processor.py:157} INFO - Started process (PID=22119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:08:49.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:08:49.305+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:08:49.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:08:49.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:08:49.342+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:08:49.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:08:49.356+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:08:49.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:08:49.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T23:09:19.609+0000] {processor.py:157} INFO - Started process (PID=22129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:09:19.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:09:19.617+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:09:19.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:09:19.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:09:19.660+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:09:19.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:09:19.697+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:09:19.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:09:19.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-15T23:09:49.874+0000] {processor.py:157} INFO - Started process (PID=22139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:09:49.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:09:49.877+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:09:49.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:09:49.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:09:49.906+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:09:49.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:09:49.921+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:09:49.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:09:49.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-15T23:10:20.324+0000] {processor.py:157} INFO - Started process (PID=22149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:10:20.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:10:20.333+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:10:20.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:10:20.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:10:20.373+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:10:20.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:10:20.407+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:10:20.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:10:20.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T23:10:50.634+0000] {processor.py:157} INFO - Started process (PID=22159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:10:50.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:10:50.636+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:10:50.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:10:50.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:10:50.669+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:10:50.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:10:50.692+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:10:50.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:10:50.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.237 seconds
[2024-09-15T23:11:20.998+0000] {processor.py:157} INFO - Started process (PID=22169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:11:21.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:11:21.014+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:11:21.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:11:21.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:11:21.071+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:11:21.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:11:21.088+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:11:21.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:11:21.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-15T23:11:51.443+0000] {processor.py:157} INFO - Started process (PID=22179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:11:51.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:11:51.447+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:11:51.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:11:51.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:11:51.491+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:11:51.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:11:51.506+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:11:51.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:11:51.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-15T23:12:21.828+0000] {processor.py:157} INFO - Started process (PID=22189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:12:21.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:12:21.841+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:12:21.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:12:21.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:12:21.907+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:12:21.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:12:21.924+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:12:21.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:12:21.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-15T23:12:52.145+0000] {processor.py:157} INFO - Started process (PID=22199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:12:52.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:12:52.155+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:12:52.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:12:52.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:12:52.201+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:12:52.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:12:52.217+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:12:52.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:12:52.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-15T23:13:22.458+0000] {processor.py:157} INFO - Started process (PID=22209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:13:22.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:13:22.462+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:13:22.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:13:22.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:13:22.506+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:13:22.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:13:22.520+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:13:22.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:13:22.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T23:13:52.872+0000] {processor.py:157} INFO - Started process (PID=22219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:13:52.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:13:52.879+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:13:52.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:13:52.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:13:52.921+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:13:52.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:13:52.946+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:13:52.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:13:53.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.271 seconds
[2024-09-15T23:14:23.409+0000] {processor.py:157} INFO - Started process (PID=22229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:14:23.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:14:23.414+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:14:23.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:14:23.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:14:23.465+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:14:23.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:14:23.482+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:14:23.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:14:23.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-15T23:14:53.738+0000] {processor.py:157} INFO - Started process (PID=22239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:14:53.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:14:53.741+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:14:53.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:14:53.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:14:53.775+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:14:53.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:14:53.792+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:14:53.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:14:53.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T23:15:24.183+0000] {processor.py:157} INFO - Started process (PID=22249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:15:24.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:15:24.196+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:15:24.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:15:24.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:15:24.250+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:15:24.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:15:24.266+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:15:24.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:15:24.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-15T23:15:54.598+0000] {processor.py:157} INFO - Started process (PID=22259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:15:54.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:15:54.601+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:15:54.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:15:54.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:15:54.634+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:15:54.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:15:54.652+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:15:54.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:15:54.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T23:16:24.956+0000] {processor.py:157} INFO - Started process (PID=22269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:16:24.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:16:24.962+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:16:24.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:16:24.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:16:25.018+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:16:25.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:16:25.035+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:16:25.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:16:25.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T23:16:55.311+0000] {processor.py:157} INFO - Started process (PID=22279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:16:55.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:16:55.315+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:16:55.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:16:55.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:16:55.378+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:16:55.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:16:55.397+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:16:55.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:16:55.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.312 seconds
[2024-09-15T23:17:25.925+0000] {processor.py:157} INFO - Started process (PID=22289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:17:25.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:17:25.933+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:17:25.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:17:25.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:17:25.984+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:17:25.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:17:26.009+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:17:26.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:17:26.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-15T23:17:56.246+0000] {processor.py:157} INFO - Started process (PID=22299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:17:56.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:17:56.249+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:17:56.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:17:56.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:17:56.308+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:17:56.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:17:56.350+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:17:56.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:17:56.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T23:18:26.630+0000] {processor.py:157} INFO - Started process (PID=22309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:18:26.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:18:26.637+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:18:26.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:18:26.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:18:26.715+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:18:26.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:18:26.732+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:18:26.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:18:26.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-15T23:18:57.065+0000] {processor.py:157} INFO - Started process (PID=22319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:18:57.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:18:57.069+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:18:57.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:18:57.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:18:57.105+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:18:57.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:18:57.119+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:18:57.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:18:57.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-15T23:19:27.505+0000] {processor.py:157} INFO - Started process (PID=22329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:19:27.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:19:27.510+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:19:27.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:19:27.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:19:27.569+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:19:27.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:19:27.585+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:19:27.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:19:27.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T23:19:57.841+0000] {processor.py:157} INFO - Started process (PID=22339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:19:57.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:19:57.847+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:19:57.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:19:57.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:19:57.893+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:19:57.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:19:57.913+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:19:57.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:19:58.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.230 seconds
[2024-09-15T23:20:28.171+0000] {processor.py:157} INFO - Started process (PID=22349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:20:28.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:20:28.178+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:20:28.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:20:28.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:20:28.223+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:20:28.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:20:28.239+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:20:28.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:20:28.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T23:20:58.558+0000] {processor.py:157} INFO - Started process (PID=22359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:20:58.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:20:58.564+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:20:58.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:20:58.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:20:58.608+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:20:58.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:20:58.624+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:20:58.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:20:58.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-15T23:21:28.963+0000] {processor.py:157} INFO - Started process (PID=22369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:21:28.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:21:28.968+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:21:28.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:21:29.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:21:29.033+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:21:29.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:21:29.049+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:21:29.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:21:29.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-15T23:21:59.382+0000] {processor.py:157} INFO - Started process (PID=22379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:21:59.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:21:59.385+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:21:59.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:21:59.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:21:59.414+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:21:59.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:21:59.430+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:21:59.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:21:59.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-15T23:22:29.843+0000] {processor.py:157} INFO - Started process (PID=22389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:22:29.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:22:29.849+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:22:29.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:22:29.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:22:29.897+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:22:29.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:22:29.914+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:22:29.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:22:29.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-15T23:23:00.319+0000] {processor.py:157} INFO - Started process (PID=22399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:23:00.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:23:00.326+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:23:00.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:23:00.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:23:00.358+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:23:00.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:23:00.480+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:23:00.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:23:00.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-15T23:23:30.813+0000] {processor.py:157} INFO - Started process (PID=22409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:23:30.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:23:30.818+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:23:30.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:23:30.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:23:30.870+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:23:30.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:23:30.885+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:23:30.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:23:30.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T23:24:01.194+0000] {processor.py:157} INFO - Started process (PID=22419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:24:01.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:24:01.200+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:24:01.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:24:01.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:24:01.262+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:24:01.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:24:01.278+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:24:01.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:24:01.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-15T23:24:31.540+0000] {processor.py:157} INFO - Started process (PID=22429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:24:31.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:24:31.546+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:24:31.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:24:31.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:24:31.599+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:24:31.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:24:31.614+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:24:31.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:24:31.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-15T23:25:01.850+0000] {processor.py:157} INFO - Started process (PID=22439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:25:01.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:25:01.857+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:25:01.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:25:01.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:25:01.888+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:25:01.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:25:01.904+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:25:01.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:25:01.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-15T23:25:32.234+0000] {processor.py:157} INFO - Started process (PID=22449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:25:32.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:25:32.238+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:25:32.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:25:32.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:25:32.282+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:25:32.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:25:32.296+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:25:32.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:25:32.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-09-15T23:26:02.793+0000] {processor.py:157} INFO - Started process (PID=22459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:26:02.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:26:02.798+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:26:02.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:26:02.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:26:02.846+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:26:02.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:26:02.981+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:26:02.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:26:02.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.201 seconds
[2024-09-15T23:26:33.127+0000] {processor.py:157} INFO - Started process (PID=22469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:26:33.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:26:33.131+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:26:33.131+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:26:33.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:26:33.172+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:26:33.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:26:33.187+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:26:33.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:26:33.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T23:27:03.488+0000] {processor.py:157} INFO - Started process (PID=22479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:27:03.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:27:03.495+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:27:03.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:27:03.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:27:03.538+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:27:03.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:27:03.557+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:27:03.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:27:03.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T23:27:33.887+0000] {processor.py:157} INFO - Started process (PID=22489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:27:33.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:27:33.892+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:27:33.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:27:33.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:27:33.948+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:27:33.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:27:33.965+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:27:33.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:27:33.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-15T23:28:04.219+0000] {processor.py:157} INFO - Started process (PID=22499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:28:04.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:28:04.225+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:28:04.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:28:04.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:28:04.271+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:28:04.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:28:04.287+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:28:04.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:28:04.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-15T23:28:34.627+0000] {processor.py:157} INFO - Started process (PID=22509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:28:34.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:28:34.632+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:28:34.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:28:34.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:28:34.664+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:28:34.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:28:34.678+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:28:34.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:28:34.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.232 seconds
[2024-09-15T23:29:05.225+0000] {processor.py:157} INFO - Started process (PID=22519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:29:05.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:29:05.234+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:29:05.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:29:05.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:29:05.285+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:29:05.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:29:05.420+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:29:05.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:29:05.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.208 seconds
[2024-09-15T23:29:35.542+0000] {processor.py:157} INFO - Started process (PID=22529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:29:35.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:29:35.548+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:29:35.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:29:35.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:29:35.588+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:29:35.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:29:35.609+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:29:35.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:29:35.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-15T23:30:05.962+0000] {processor.py:157} INFO - Started process (PID=22539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:30:05.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:30:05.966+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:30:05.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:30:05.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:30:06.010+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:30:06.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:30:06.023+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:30:06.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:30:06.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-15T23:30:36.386+0000] {processor.py:157} INFO - Started process (PID=22549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:30:36.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:30:36.389+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:30:36.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:30:36.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:30:36.420+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:30:36.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:30:36.434+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:30:36.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:30:36.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T23:31:06.829+0000] {processor.py:157} INFO - Started process (PID=22558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:31:06.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:31:06.836+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:31:06.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:31:06.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:31:06.907+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:31:06.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:31:06.928+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:31:06.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:31:06.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T23:31:37.165+0000] {processor.py:157} INFO - Started process (PID=22569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:31:37.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:31:37.171+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:31:37.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:31:37.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:31:37.216+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:31:37.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:31:37.234+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:31:37.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:31:37.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.245 seconds
[2024-09-15T23:32:07.487+0000] {processor.py:157} INFO - Started process (PID=22579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:32:07.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:32:07.491+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:32:07.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:32:07.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:32:07.528+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:32:07.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:32:07.646+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:32:07.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:32:07.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-09-15T23:32:37.966+0000] {processor.py:157} INFO - Started process (PID=22589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:32:37.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:32:37.979+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:32:37.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:32:37.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:32:38.031+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:32:38.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:32:38.052+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:32:38.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:32:38.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T23:33:08.404+0000] {processor.py:157} INFO - Started process (PID=22599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:33:08.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:33:08.410+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:33:08.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:33:08.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:33:08.450+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:33:08.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:33:08.465+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:33:08.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:33:08.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-15T23:33:38.734+0000] {processor.py:157} INFO - Started process (PID=22609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:33:38.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:33:38.738+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:33:38.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:33:38.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:33:38.768+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:33:38.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:33:38.781+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:33:38.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:33:38.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-15T23:34:09.158+0000] {processor.py:157} INFO - Started process (PID=22619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:34:09.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:34:09.163+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:34:09.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:34:09.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:34:09.218+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:34:09.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:34:09.247+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:34:09.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:34:09.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-15T23:34:39.561+0000] {processor.py:157} INFO - Started process (PID=22629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:34:39.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:34:39.567+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:34:39.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:34:39.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:34:39.632+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:34:39.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:34:39.653+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:34:39.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:34:39.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.276 seconds
[2024-09-15T23:35:09.901+0000] {processor.py:157} INFO - Started process (PID=22639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:35:09.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:35:09.918+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:35:09.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:35:09.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:35:09.977+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:35:09.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:35:10.172+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:35:10.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:35:10.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.286 seconds
[2024-09-15T23:35:40.486+0000] {processor.py:157} INFO - Started process (PID=22649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:35:40.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:35:40.493+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:35:40.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:35:40.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:35:40.583+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:35:40.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:35:40.606+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:35:40.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:35:40.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-15T23:36:10.860+0000] {processor.py:157} INFO - Started process (PID=22659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:36:10.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:36:10.867+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:36:10.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:36:10.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:36:10.939+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:36:10.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:36:10.959+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:36:10.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:36:10.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-15T23:36:41.221+0000] {processor.py:157} INFO - Started process (PID=22669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:36:41.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:36:41.231+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:36:41.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:36:41.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:36:41.295+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:36:41.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:36:41.317+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:36:41.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:36:41.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T23:37:11.547+0000] {processor.py:157} INFO - Started process (PID=22679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:37:11.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:37:11.552+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:37:11.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:37:11.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:37:11.605+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:37:11.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:37:11.629+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:37:11.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:37:11.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-15T23:37:41.860+0000] {processor.py:157} INFO - Started process (PID=22689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:37:41.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:37:41.868+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:37:41.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:37:41.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:37:41.897+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:37:41.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:37:41.911+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:37:41.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:37:42.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-09-15T23:38:12.249+0000] {processor.py:157} INFO - Started process (PID=22699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:38:12.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:38:12.257+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:38:12.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:38:12.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:38:12.324+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:38:12.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:38:12.464+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:38:12.464+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:38:12.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.228 seconds
[2024-09-15T23:38:42.629+0000] {processor.py:157} INFO - Started process (PID=22709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:38:42.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:38:42.632+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:38:42.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:38:42.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:38:42.663+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:38:42.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:38:42.673+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:38:42.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:38:42.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-15T23:39:13.015+0000] {processor.py:157} INFO - Started process (PID=22719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:39:13.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:39:13.024+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:39:13.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:39:13.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:39:13.117+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:39:13.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:39:13.140+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:39:13.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:39:13.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-15T23:39:43.397+0000] {processor.py:157} INFO - Started process (PID=22729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:39:43.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:39:43.407+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:39:43.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:39:43.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:39:43.478+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:39:43.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:39:43.494+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:39:43.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:39:43.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-15T23:40:13.763+0000] {processor.py:157} INFO - Started process (PID=22739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:40:13.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:40:13.772+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:40:13.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:40:13.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:40:13.830+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:40:13.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:40:13.846+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:40:13.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:40:13.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-15T23:40:44.256+0000] {processor.py:157} INFO - Started process (PID=22749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:40:44.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:40:44.263+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:40:44.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:40:44.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:40:44.333+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:40:44.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:40:44.539+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:40:44.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:40:44.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.300 seconds
[2024-09-15T23:41:14.858+0000] {processor.py:157} INFO - Started process (PID=22759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:41:14.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:41:14.868+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:41:14.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:41:14.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:41:14.930+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:41:14.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:41:15.088+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:41:15.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:41:15.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.249 seconds
[2024-09-15T23:41:45.217+0000] {processor.py:157} INFO - Started process (PID=22769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:41:45.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:41:45.225+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:41:45.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:41:45.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:41:45.278+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:41:45.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:41:45.296+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:41:45.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:41:45.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-15T23:42:15.523+0000] {processor.py:157} INFO - Started process (PID=22779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:42:15.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:42:15.537+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:42:15.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:42:15.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:42:15.589+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:42:15.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:42:15.617+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:42:15.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:42:15.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T23:42:45.984+0000] {processor.py:157} INFO - Started process (PID=22789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:42:45.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:42:45.987+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:42:45.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:42:46.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:42:46.034+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:42:46.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:42:46.078+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:42:46.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:42:46.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-15T23:43:16.354+0000] {processor.py:157} INFO - Started process (PID=22798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:43:16.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:43:16.360+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:43:16.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:43:16.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:43:16.418+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:43:16.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:43:16.431+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:43:16.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:43:16.442+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-15T23:43:46.678+0000] {processor.py:157} INFO - Started process (PID=22809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:43:46.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:43:46.682+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:43:46.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:43:46.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:43:46.719+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:43:46.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:43:46.908+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:43:46.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:43:46.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.243 seconds
[2024-09-15T23:44:16.993+0000] {processor.py:157} INFO - Started process (PID=22819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:44:16.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:44:16.998+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:44:16.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:44:17.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:44:17.053+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:44:17.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:44:17.175+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:44:17.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:44:17.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-09-15T23:44:47.518+0000] {processor.py:157} INFO - Started process (PID=22829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:44:47.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:44:47.524+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:44:47.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:44:47.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:44:47.582+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:44:47.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:44:47.592+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:44:47.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:44:47.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-15T23:45:17.842+0000] {processor.py:157} INFO - Started process (PID=22839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:45:17.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:45:17.845+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:45:17.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:45:17.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:45:17.903+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:45:17.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:45:17.921+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:45:17.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:45:17.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-15T23:45:48.198+0000] {processor.py:157} INFO - Started process (PID=22849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:45:48.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:45:48.202+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:45:48.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:45:48.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:45:48.255+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:45:48.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:45:48.268+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:45:48.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:45:48.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-15T23:46:18.659+0000] {processor.py:157} INFO - Started process (PID=22859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:46:18.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:46:18.676+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:46:18.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:46:18.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:46:18.735+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:46:18.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:46:18.761+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:46:18.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:46:18.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-15T23:46:48.967+0000] {processor.py:157} INFO - Started process (PID=22869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:46:48.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:46:48.971+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:46:48.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:46:48.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:46:49.021+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:46:49.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:46:49.204+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:46:49.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:46:49.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.250 seconds
[2024-09-15T23:47:19.388+0000] {processor.py:157} INFO - Started process (PID=22879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:47:19.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:47:19.400+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:47:19.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:47:19.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:47:19.461+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:47:19.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:47:19.590+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:47:19.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:47:19.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.216 seconds
[2024-09-15T23:47:49.816+0000] {processor.py:157} INFO - Started process (PID=22889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:47:49.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:47:49.820+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:47:49.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:47:49.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:47:49.863+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:47:49.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:47:49.877+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:47:49.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:47:49.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-15T23:48:20.239+0000] {processor.py:157} INFO - Started process (PID=22899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:48:20.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:48:20.242+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:48:20.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:48:20.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:48:20.273+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:48:20.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:48:20.288+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:48:20.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:48:20.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-15T23:48:50.669+0000] {processor.py:157} INFO - Started process (PID=22909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:48:50.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:48:50.681+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:48:50.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:48:50.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:48:50.741+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:48:50.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:48:50.769+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:48:50.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:48:50.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-15T23:49:20.942+0000] {processor.py:157} INFO - Started process (PID=22919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:49:20.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:49:20.948+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:49:20.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:49:20.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:49:20.998+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:49:20.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:49:21.017+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:49:21.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:49:21.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.235 seconds
[2024-09-15T23:49:51.517+0000] {processor.py:157} INFO - Started process (PID=22929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:49:51.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:49:51.524+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:49:51.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:49:51.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:49:51.559+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:49:51.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:49:51.679+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:49:51.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:49:51.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.175 seconds
[2024-09-15T23:50:21.840+0000] {processor.py:157} INFO - Started process (PID=22939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:50:21.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:50:21.846+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:50:21.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:50:21.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:50:21.897+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:50:21.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:50:22.015+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:50:22.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:50:22.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-09-15T23:50:52.417+0000] {processor.py:157} INFO - Started process (PID=22949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:50:52.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:50:52.424+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:50:52.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:50:52.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:50:52.474+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:50:52.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:50:52.489+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:50:52.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:50:52.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-15T23:51:22.779+0000] {processor.py:157} INFO - Started process (PID=22959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:51:22.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:51:22.786+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:51:22.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:51:22.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:51:22.839+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:51:22.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:51:22.854+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:51:22.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:51:22.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T23:51:53.145+0000] {processor.py:157} INFO - Started process (PID=22969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:51:53.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:51:53.148+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:51:53.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:51:53.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:51:53.185+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:51:53.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:51:53.202+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:51:53.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:51:53.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-15T23:52:23.584+0000] {processor.py:157} INFO - Started process (PID=22979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:52:23.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:52:23.592+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:52:23.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:52:23.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:52:23.653+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:52:23.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:52:23.670+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:52:23.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:52:23.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.277 seconds
[2024-09-15T23:52:53.898+0000] {processor.py:157} INFO - Started process (PID=22989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:52:53.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:52:53.902+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:52:53.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:52:53.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:52:53.935+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:52:53.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:52:54.013+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:52:54.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:52:54.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-15T23:53:24.243+0000] {processor.py:157} INFO - Started process (PID=22999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:53:24.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:53:24.252+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:53:24.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:53:24.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:53:24.318+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:53:24.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:53:24.522+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:53:24.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:53:24.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.293 seconds
[2024-09-15T23:53:54.893+0000] {processor.py:157} INFO - Started process (PID=23009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:53:54.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:53:54.897+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:53:54.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:53:54.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:53:54.931+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:53:54.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:53:54.944+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:53:54.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:53:54.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-15T23:54:25.283+0000] {processor.py:157} INFO - Started process (PID=23019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:54:25.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:54:25.286+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:54:25.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:54:25.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:54:25.325+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:54:25.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:54:25.346+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:54:25.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:54:25.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-15T23:54:55.695+0000] {processor.py:157} INFO - Started process (PID=23029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:54:55.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:54:55.699+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:54:55.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:54:55.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:54:55.737+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:54:55.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:54:55.751+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:54:55.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:54:55.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-15T23:55:26.005+0000] {processor.py:157} INFO - Started process (PID=23039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:55:26.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:55:26.013+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:55:26.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:55:26.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:55:26.080+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:55:26.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:55:26.100+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:55:26.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:55:26.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.282 seconds
[2024-09-15T23:55:56.609+0000] {processor.py:157} INFO - Started process (PID=23049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:55:56.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:55:56.618+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:55:56.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:55:56.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:55:56.704+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:55:56.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:55:56.897+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:55:56.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:55:56.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.304 seconds
[2024-09-15T23:56:27.210+0000] {processor.py:157} INFO - Started process (PID=23059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:56:27.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:56:27.215+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:56:27.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:56:27.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:56:27.260+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:56:27.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:56:27.380+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:56:27.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:56:27.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-09-15T23:56:57.737+0000] {processor.py:157} INFO - Started process (PID=23069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:56:57.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:56:57.740+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:56:57.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:56:57.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:56:57.768+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:56:57.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:56:57.778+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:56:57.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:56:57.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-15T23:57:28.128+0000] {processor.py:157} INFO - Started process (PID=23079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:57:28.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:57:28.133+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:57:28.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:57:28.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:57:28.181+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:57:28.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:57:28.206+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:57:28.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:57:28.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-15T23:57:58.509+0000] {processor.py:157} INFO - Started process (PID=23089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:57:58.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:57:58.521+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:57:58.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:57:58.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:57:58.578+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:57:58.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:57:58.600+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:57:58.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:57:58.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-15T23:58:28.853+0000] {processor.py:157} INFO - Started process (PID=23099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:58:28.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:58:28.858+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:58:28.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:58:28.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:58:28.904+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:58:28.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:58:28.944+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:58:28.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:58:29.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.274 seconds
[2024-09-15T23:58:59.245+0000] {processor.py:157} INFO - Started process (PID=23109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:58:59.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:58:59.250+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:58:59.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:58:59.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:58:59.309+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:58:59.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:58:59.398+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:58:59.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:58:59.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-09-15T23:59:29.742+0000] {processor.py:157} INFO - Started process (PID=23119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:59:29.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-15T23:59:29.745+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:59:29.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:59:29.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-15T23:59:29.777+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:59:29.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-15T23:59:29.923+0000] {logging_mixin.py:151} INFO - [2024-09-15T23:59:29.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-14T01:00:00+00:00, run_after=2024-09-15T01:00:00+00:00
[2024-09-15T23:59:29.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
