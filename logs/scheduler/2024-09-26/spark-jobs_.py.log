[2024-09-26T17:20:17.683+0000] {processor.py:157} INFO - Started process (PID=186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:20:17.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:20:17.691+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:20:17.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:20:17.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:20:17.752+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:20:17.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:20:17.779+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:20:17.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:20:17.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-26T17:20:48.085+0000] {processor.py:157} INFO - Started process (PID=911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:20:48.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:20:48.091+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:20:48.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:20:48.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:20:48.151+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:20:48.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:20:48.183+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:20:48.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:20:48.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-26T17:21:18.363+0000] {processor.py:157} INFO - Started process (PID=922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:21:18.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:21:18.369+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:21:18.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:21:18.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:21:18.465+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:21:18.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:21:18.489+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:21:18.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:21:18.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-26T17:21:48.863+0000] {processor.py:157} INFO - Started process (PID=932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:21:48.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:21:48.870+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:21:48.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:21:48.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:21:48.941+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:21:48.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:21:48.969+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:21:48.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:21:48.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-26T17:22:19.241+0000] {processor.py:157} INFO - Started process (PID=941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:22:19.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:22:19.253+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:22:19.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:22:19.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:22:19.370+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:22:19.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:22:19.384+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:22:19.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:22:19.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-09-26T17:22:49.681+0000] {processor.py:157} INFO - Started process (PID=952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:22:49.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:22:49.685+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:22:49.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:22:49.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:22:49.734+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:22:49.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:22:49.747+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:22:49.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:22:49.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-26T17:23:19.942+0000] {processor.py:157} INFO - Started process (PID=962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:23:19.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:23:19.945+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:23:19.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:23:19.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:23:19.988+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:23:19.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:23:19.999+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:23:19.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:23:20.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-26T17:23:50.253+0000] {processor.py:157} INFO - Started process (PID=972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:23:50.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:23:50.256+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:23:50.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:23:50.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:23:50.283+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:23:50.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:23:50.293+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:23:50.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:23:50.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-26T17:24:20.571+0000] {processor.py:157} INFO - Started process (PID=982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:24:20.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:24:20.575+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:24:20.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:24:20.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:24:20.611+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:24:20.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:24:20.623+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:24:20.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:24:20.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-26T17:24:50.924+0000] {processor.py:157} INFO - Started process (PID=992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:24:50.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:24:50.928+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:24:50.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:24:50.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:24:50.964+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:24:50.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:24:50.976+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:24:50.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:24:50.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-26T17:25:21.189+0000] {processor.py:157} INFO - Started process (PID=1002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:25:21.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:25:21.202+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:25:21.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:25:21.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:25:21.245+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:25:21.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:25:21.262+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:25:21.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:25:21.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-26T17:25:51.431+0000] {processor.py:157} INFO - Started process (PID=1012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:25:51.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:25:51.435+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:25:51.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:25:51.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:25:51.472+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:25:51.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:25:51.484+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:25:51.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:25:51.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-26T17:26:21.778+0000] {processor.py:157} INFO - Started process (PID=1022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:26:21.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:26:21.783+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:26:21.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:26:21.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:26:21.847+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:26:21.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:26:21.865+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:26:21.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:26:21.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-26T17:26:52.157+0000] {processor.py:157} INFO - Started process (PID=1032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:26:52.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:26:52.164+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:26:52.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:26:52.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:26:52.204+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:26:52.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:26:52.217+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:26:52.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:26:52.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-26T17:27:22.451+0000] {processor.py:157} INFO - Started process (PID=1042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:27:22.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:27:22.465+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:27:22.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:27:22.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:27:22.504+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:27:22.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:27:22.516+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:27:22.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:27:22.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-26T17:27:52.716+0000] {processor.py:157} INFO - Started process (PID=1052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:27:52.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:27:52.720+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:27:52.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:27:52.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:27:52.761+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:27:52.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:27:52.774+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:27:52.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:27:52.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-26T17:28:23.081+0000] {processor.py:157} INFO - Started process (PID=1062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:28:23.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:28:23.088+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:28:23.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:28:23.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:28:23.148+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:28:23.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:28:23.211+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:28:23.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:28:23.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-09-26T17:28:53.437+0000] {processor.py:157} INFO - Started process (PID=1072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:28:53.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:28:53.444+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:28:53.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:28:53.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:28:53.496+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:28:53.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:28:53.508+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:28:53.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:28:53.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-26T17:29:23.699+0000] {processor.py:157} INFO - Started process (PID=1082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:29:23.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:29:23.707+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:29:23.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:29:23.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:29:23.797+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:29:23.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:29:23.822+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:29:23.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:29:23.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-26T17:29:54.020+0000] {processor.py:157} INFO - Started process (PID=1092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:29:54.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:29:54.031+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:29:54.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:29:54.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:29:54.073+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:29:54.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:29:54.088+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:29:54.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:29:54.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-26T17:30:24.360+0000] {processor.py:157} INFO - Started process (PID=1102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:30:24.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:30:24.367+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:30:24.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:30:24.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:30:24.412+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:30:24.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:30:24.426+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:30:24.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:30:24.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-26T17:30:54.604+0000] {processor.py:157} INFO - Started process (PID=1112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:30:54.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:30:54.612+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:30:54.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:30:54.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:30:54.642+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:30:54.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:30:54.654+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:30:54.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:30:54.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-26T17:31:24.888+0000] {processor.py:157} INFO - Started process (PID=1122) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:31:24.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:31:24.891+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:31:24.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:31:24.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:31:24.918+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:31:24.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:31:24.929+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:31:24.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:31:24.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-26T17:31:55.274+0000] {processor.py:157} INFO - Started process (PID=1132) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:31:55.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:31:55.749+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:31:55.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:31:55.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:31:55.843+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:31:55.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:31:55.866+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:31:55.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:31:55.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.610 seconds
[2024-09-26T17:32:26.196+0000] {processor.py:157} INFO - Started process (PID=1142) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:32:26.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:32:26.202+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:32:26.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:32:26.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:32:26.288+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:32:26.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:32:26.308+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:32:26.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:32:26.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-26T17:32:56.591+0000] {processor.py:157} INFO - Started process (PID=1152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:32:56.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:32:56.608+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:32:56.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:32:56.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:32:56.700+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:32:56.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:32:56.766+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:32:56.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:32:56.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-09-26T17:33:27.029+0000] {processor.py:157} INFO - Started process (PID=1162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:33:27.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:33:27.059+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:33:27.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:33:27.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:33:27.217+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:33:27.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:33:27.235+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:33:27.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:33:27.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.227 seconds
[2024-09-26T17:33:57.636+0000] {processor.py:157} INFO - Started process (PID=1171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:33:57.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:33:57.645+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:33:57.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:33:57.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:33:57.752+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:33:57.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:33:57.776+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:33:57.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:33:57.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-26T17:34:28.099+0000] {processor.py:157} INFO - Started process (PID=1182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:34:28.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:34:28.125+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:34:28.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:34:28.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:34:28.209+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:34:28.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:34:28.234+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:34:28.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:34:28.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-26T17:34:58.421+0000] {processor.py:157} INFO - Started process (PID=1192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:34:58.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:34:58.430+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:34:58.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:34:58.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:34:58.510+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:34:58.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:34:58.529+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:34:58.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:34:58.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-26T17:35:28.795+0000] {processor.py:157} INFO - Started process (PID=1202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:35:28.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:35:28.803+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:35:28.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:35:28.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:35:28.866+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:35:28.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:35:28.886+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:35:28.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:35:28.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-26T17:35:59.112+0000] {processor.py:157} INFO - Started process (PID=1212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:35:59.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:35:59.121+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:35:59.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:35:59.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:35:59.198+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:35:59.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:35:59.216+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:35:59.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:35:59.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-26T17:36:29.465+0000] {processor.py:157} INFO - Started process (PID=1222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:36:29.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:36:29.474+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:36:29.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:36:29.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:36:29.517+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:36:29.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:36:29.540+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:36:29.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:36:29.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-26T17:36:59.760+0000] {processor.py:157} INFO - Started process (PID=1232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:36:59.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:36:59.768+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:36:59.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:36:59.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:36:59.835+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:36:59.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:36:59.872+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:36:59.872+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:36:59.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-26T17:37:30.048+0000] {processor.py:157} INFO - Started process (PID=1241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:37:30.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:37:30.055+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:37:30.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:37:30.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:37:30.106+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:37:30.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:37:30.118+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:37:30.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:37:30.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-26T17:38:00.433+0000] {processor.py:157} INFO - Started process (PID=1252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:38:00.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:38:00.439+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:38:00.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:38:00.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:38:00.518+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:38:00.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:38:00.536+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:38:00.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:38:00.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-26T17:38:30.706+0000] {processor.py:157} INFO - Started process (PID=1262) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:38:30.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:38:30.715+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:38:30.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:38:30.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:38:30.787+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:38:30.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:38:30.804+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:38:30.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:38:30.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-26T17:39:01.171+0000] {processor.py:157} INFO - Started process (PID=1271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:39:01.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:39:01.204+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:39:01.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:39:01.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:39:01.286+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:39:01.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:39:01.301+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:39:01.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:39:01.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-26T17:39:31.497+0000] {processor.py:157} INFO - Started process (PID=1282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:39:31.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:39:31.507+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:39:31.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:39:31.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:39:31.574+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:39:31.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:39:31.589+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:39:31.589+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:39:31.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-26T17:40:01.873+0000] {processor.py:157} INFO - Started process (PID=1292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:40:01.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:40:01.883+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:40:01.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:40:01.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:40:01.961+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:40:01.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:40:01.980+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:40:01.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:40:02.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-26T17:40:32.191+0000] {processor.py:157} INFO - Started process (PID=1302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:40:32.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:40:32.198+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:40:32.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:40:32.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:40:32.257+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:40:32.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:40:32.275+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:40:32.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:40:32.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-26T17:41:02.536+0000] {processor.py:157} INFO - Started process (PID=1312) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:41:02.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:41:02.544+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:41:02.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:41:02.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:41:02.626+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:41:02.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:41:02.659+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:41:02.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:41:02.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-26T17:41:32.782+0000] {processor.py:157} INFO - Started process (PID=1322) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:41:32.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:41:32.784+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:41:32.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:41:32.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:41:32.814+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:41:32.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:41:32.825+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:41:32.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:41:32.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-26T17:42:03.135+0000] {processor.py:157} INFO - Started process (PID=1331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:42:03.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:42:03.153+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:42:03.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:42:03.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:42:03.248+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:42:03.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:42:03.268+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:42:03.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:42:03.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-26T17:42:33.440+0000] {processor.py:157} INFO - Started process (PID=1342) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:42:33.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:42:33.463+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:42:33.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:42:33.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:42:33.541+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:42:33.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:42:33.558+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:42:33.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:42:33.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-26T17:43:03.916+0000] {processor.py:157} INFO - Started process (PID=1352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:43:03.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:43:03.926+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:43:03.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:43:03.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:43:04.013+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:43:04.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:43:04.035+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:43:04.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:43:04.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-26T17:43:34.167+0000] {processor.py:157} INFO - Started process (PID=1362) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:43:34.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:43:34.175+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:43:34.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:43:34.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:43:34.274+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:43:34.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:43:34.295+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:43:34.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:43:34.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-26T17:44:04.575+0000] {processor.py:157} INFO - Started process (PID=1372) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:44:04.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:44:04.588+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:44:04.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:44:04.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:44:04.648+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:44:04.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:44:04.661+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:44:04.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:44:04.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-26T17:44:34.876+0000] {processor.py:157} INFO - Started process (PID=1382) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:44:34.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:44:34.882+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:44:34.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:44:34.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:44:34.957+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:44:34.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:44:34.982+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:44:34.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:44:34.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-09-26T17:45:05.216+0000] {processor.py:157} INFO - Started process (PID=1392) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:45:05.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:45:05.224+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:45:05.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:45:05.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:45:05.319+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:45:05.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:45:05.340+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:45:05.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:45:05.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-26T17:45:35.572+0000] {processor.py:157} INFO - Started process (PID=1402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:45:35.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:45:35.585+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:45:35.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:45:35.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:45:35.662+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:45:35.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:45:35.697+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:45:35.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:45:35.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-26T17:46:05.925+0000] {processor.py:157} INFO - Started process (PID=1412) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:46:05.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:46:05.937+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:46:05.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:46:05.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:46:05.990+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:46:05.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:46:06.002+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:46:06.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:46:06.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-26T17:46:36.319+0000] {processor.py:157} INFO - Started process (PID=1422) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:46:36.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:46:36.328+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:46:36.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:46:36.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:46:36.374+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:46:36.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:46:36.386+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:46:36.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:46:36.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-26T17:47:06.778+0000] {processor.py:157} INFO - Started process (PID=1432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:47:06.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:47:06.796+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:47:06.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:47:06.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:47:06.864+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:47:06.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:47:06.885+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:47:06.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:47:06.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-26T17:47:37.197+0000] {processor.py:157} INFO - Started process (PID=1442) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:47:37.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:47:37.217+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:47:37.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:47:37.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:47:37.304+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:47:37.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:47:37.319+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:47:37.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:47:37.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-26T17:48:07.491+0000] {processor.py:157} INFO - Started process (PID=1452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:48:07.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:48:07.508+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:48:07.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:48:07.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:48:07.566+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:48:07.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:48:07.588+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:48:07.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:48:07.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-26T17:48:37.831+0000] {processor.py:157} INFO - Started process (PID=1461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:48:37.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:48:37.841+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:48:37.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:48:37.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:48:37.934+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:48:37.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:48:37.949+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:48:37.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:48:37.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-26T17:49:08.133+0000] {processor.py:157} INFO - Started process (PID=1472) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:49:08.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:49:08.139+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:49:08.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:49:08.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:49:08.427+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:49:08.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:49:08.455+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:49:08.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:49:08.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.352 seconds
[2024-09-26T17:49:38.791+0000] {processor.py:157} INFO - Started process (PID=1482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:49:38.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:49:38.796+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:49:38.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:49:38.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:49:38.853+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:49:38.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:49:38.865+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:49:38.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:49:38.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-26T17:50:09.115+0000] {processor.py:157} INFO - Started process (PID=1492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:50:09.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:50:09.123+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:50:09.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:50:09.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:50:09.197+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:50:09.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:50:09.227+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:50:09.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:50:09.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-26T17:50:39.766+0000] {processor.py:157} INFO - Started process (PID=1502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:50:39.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:50:39.775+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:50:39.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:50:39.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:50:39.864+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:50:39.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:50:39.879+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:50:39.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:50:39.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-26T17:51:10.069+0000] {processor.py:157} INFO - Started process (PID=1512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:51:10.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:51:10.077+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:51:10.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:51:10.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:51:10.130+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:51:10.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:51:10.143+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:51:10.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:51:10.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-26T17:51:40.458+0000] {processor.py:157} INFO - Started process (PID=1522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:51:40.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:51:40.465+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:51:40.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:51:40.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:51:40.509+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:51:40.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:51:40.521+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:51:40.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:51:40.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-26T17:52:10.985+0000] {processor.py:157} INFO - Started process (PID=1531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:52:10.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:52:10.993+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:52:10.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:52:11.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:52:11.071+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:52:11.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:52:11.089+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:52:11.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:52:11.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-26T17:52:41.301+0000] {processor.py:157} INFO - Started process (PID=1542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:52:41.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:52:41.307+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:52:41.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:52:41.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:52:41.356+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:52:41.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:52:41.369+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:52:41.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:52:41.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-26T17:53:11.544+0000] {processor.py:157} INFO - Started process (PID=1552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:53:11.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:53:11.552+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:53:11.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:53:11.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:53:11.594+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:53:11.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:53:11.607+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:53:11.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:53:11.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-26T17:53:41.913+0000] {processor.py:157} INFO - Started process (PID=1561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:53:41.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:53:41.929+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:53:41.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:53:41.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:53:42.025+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:53:42.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:53:42.043+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:53:42.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:53:42.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.161 seconds
[2024-09-26T17:54:12.183+0000] {processor.py:157} INFO - Started process (PID=1572) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:54:12.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:54:12.197+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:54:12.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:54:12.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:54:12.243+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:54:12.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:54:12.255+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:54:12.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:54:12.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-26T17:54:43.029+0000] {processor.py:157} INFO - Started process (PID=1582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:54:43.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:54:43.034+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:54:43.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:54:43.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:54:43.091+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:54:43.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:54:43.105+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:54:43.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:54:43.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-26T17:55:13.337+0000] {processor.py:157} INFO - Started process (PID=1592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:55:13.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:55:13.348+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:55:13.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:55:13.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:55:13.417+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:55:13.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:55:13.428+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:55:13.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:55:13.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-26T17:55:43.880+0000] {processor.py:157} INFO - Started process (PID=1602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:55:43.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:55:43.890+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:55:43.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:55:43.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:55:43.957+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:55:43.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:55:43.977+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:55:43.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:55:43.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-26T17:56:14.307+0000] {processor.py:157} INFO - Started process (PID=1612) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:56:14.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:56:14.315+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:56:14.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:56:14.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:56:14.367+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:56:14.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:56:14.382+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:56:14.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:56:14.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-26T17:56:44.790+0000] {processor.py:157} INFO - Started process (PID=1622) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:56:44.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:56:44.800+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:56:44.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:56:44.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:56:44.863+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:56:44.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:56:44.880+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:56:44.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:56:44.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-26T17:57:15.222+0000] {processor.py:157} INFO - Started process (PID=1632) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:57:15.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:57:15.228+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:57:15.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:57:15.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:57:15.280+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:57:15.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:57:15.301+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:57:15.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:57:15.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-26T17:57:45.597+0000] {processor.py:157} INFO - Started process (PID=1642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:57:45.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:57:45.604+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:57:45.603+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:57:45.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:57:45.650+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:57:45.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:57:45.663+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:57:45.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:57:45.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-26T17:58:15.917+0000] {processor.py:157} INFO - Started process (PID=1652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:58:15.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:58:15.920+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:58:15.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:58:15.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:58:15.947+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:58:15.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:58:15.961+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:58:15.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:58:15.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-26T17:58:46.261+0000] {processor.py:157} INFO - Started process (PID=1662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:58:46.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:58:46.265+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:58:46.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:58:46.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:58:46.295+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:58:46.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:58:46.305+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:58:46.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:58:46.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-26T17:59:16.683+0000] {processor.py:157} INFO - Started process (PID=1672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:59:16.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:59:16.690+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:59:16.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:59:16.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:59:16.777+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:59:16.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:59:16.793+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:59:16.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:59:16.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-26T17:59:47.136+0000] {processor.py:157} INFO - Started process (PID=1682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:59:47.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T17:59:47.143+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:59:47.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:59:47.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T17:59:47.192+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:59:47.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T17:59:47.204+0000] {logging_mixin.py:151} INFO - [2024-09-26T17:59:47.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T17:59:47.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-26T18:00:17.802+0000] {processor.py:157} INFO - Started process (PID=1692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:00:17.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:00:17.811+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:00:17.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:00:17.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:00:17.881+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:00:17.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:00:17.964+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:00:17.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:00:17.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-09-26T18:00:48.164+0000] {processor.py:157} INFO - Started process (PID=1702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:00:48.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:00:48.171+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:00:48.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:00:48.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:00:48.237+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:00:48.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:00:48.253+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:00:48.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:00:48.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-26T18:01:18.498+0000] {processor.py:157} INFO - Started process (PID=1712) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:01:18.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:01:18.503+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:01:18.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:01:18.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:01:18.601+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:01:18.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:01:18.615+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:01:18.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:01:18.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-26T18:01:48.854+0000] {processor.py:157} INFO - Started process (PID=1722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:01:48.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:01:48.862+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:01:48.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:01:48.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:01:48.971+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:01:48.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:01:48.990+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:01:48.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:01:49.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-26T18:02:19.206+0000] {processor.py:157} INFO - Started process (PID=1732) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:02:19.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:02:19.213+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:02:19.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:02:19.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:02:19.271+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:02:19.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:02:19.285+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:02:19.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:02:19.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-26T18:02:49.580+0000] {processor.py:157} INFO - Started process (PID=1741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:02:49.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:02:49.590+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:02:49.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:02:49.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:02:49.675+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:02:49.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:02:49.692+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:02:49.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:02:49.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-26T18:03:19.859+0000] {processor.py:157} INFO - Started process (PID=1752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:03:19.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:03:19.865+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:03:19.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:03:19.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:03:19.916+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:03:19.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:03:19.928+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:03:19.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:03:19.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-26T18:03:50.227+0000] {processor.py:157} INFO - Started process (PID=1762) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:03:50.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:03:50.238+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:03:50.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:03:50.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:03:50.315+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:03:50.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:03:50.344+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:03:50.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:03:50.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-09-26T18:04:20.535+0000] {processor.py:157} INFO - Started process (PID=1772) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:04:20.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:04:20.546+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:04:20.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:04:20.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:04:20.632+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:04:20.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:04:20.648+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:04:20.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:04:20.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-26T18:04:50.899+0000] {processor.py:157} INFO - Started process (PID=1781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:04:50.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:04:50.906+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:04:50.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:04:50.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:04:50.968+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:04:50.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:04:50.981+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:04:50.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:04:50.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-26T18:05:21.273+0000] {processor.py:157} INFO - Started process (PID=1791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:05:21.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:05:21.282+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:05:21.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:05:21.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:05:21.349+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:05:21.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:05:21.383+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:05:21.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:05:21.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-26T18:05:51.603+0000] {processor.py:157} INFO - Started process (PID=1802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:05:51.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:05:51.619+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:05:51.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:05:51.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:05:51.685+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:05:51.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:05:51.701+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:05:51.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:05:51.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-26T18:06:21.934+0000] {processor.py:157} INFO - Started process (PID=1812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:06:21.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:06:21.951+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:06:21.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:06:21.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:06:22.007+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:06:22.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:06:22.021+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:06:22.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:06:22.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-26T18:06:52.306+0000] {processor.py:157} INFO - Started process (PID=1822) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:06:52.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:06:52.312+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:06:52.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:06:52.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:06:52.366+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:06:52.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:06:52.381+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:06:52.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:06:52.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-26T18:07:22.673+0000] {processor.py:157} INFO - Started process (PID=1832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:07:22.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:07:22.682+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:07:22.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:07:22.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:07:22.768+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:07:22.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:07:22.795+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:07:22.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:07:22.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-09-26T18:07:52.998+0000] {processor.py:157} INFO - Started process (PID=1842) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:07:53.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:07:53.009+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:07:53.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:07:53.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:07:53.103+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:07:53.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:07:53.128+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:07:53.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:07:53.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-26T18:08:23.292+0000] {processor.py:157} INFO - Started process (PID=1852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:08:23.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:08:23.316+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:08:23.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:08:23.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:08:23.440+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:08:23.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:08:23.462+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:08:23.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:08:23.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-09-26T18:08:53.751+0000] {processor.py:157} INFO - Started process (PID=1862) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:08:53.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:08:53.765+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:08:53.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:08:53.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:08:53.836+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:08:53.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:08:53.856+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:08:53.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:08:53.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-26T18:09:24.051+0000] {processor.py:157} INFO - Started process (PID=1872) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:09:24.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:09:24.056+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:09:24.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:09:24.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:09:24.109+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:09:24.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:09:24.130+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:09:24.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:09:24.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-26T18:09:54.402+0000] {processor.py:157} INFO - Started process (PID=1882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:09:54.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:09:54.410+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:09:54.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:09:54.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:09:54.464+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:09:54.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:09:54.476+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:09:54.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:09:54.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-26T18:10:24.754+0000] {processor.py:157} INFO - Started process (PID=1892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:10:24.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:10:24.766+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:10:24.766+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:10:24.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:10:24.818+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:10:24.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:10:24.851+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:10:24.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:10:24.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-26T18:10:55.135+0000] {processor.py:157} INFO - Started process (PID=1902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:10:55.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:10:55.161+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:10:55.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:10:55.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:10:55.260+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:10:55.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:10:55.281+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:10:55.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:10:55.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.171 seconds
[2024-09-26T18:11:25.604+0000] {processor.py:157} INFO - Started process (PID=1912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:11:25.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:11:25.614+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:11:25.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:11:25.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:11:25.686+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:11:25.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:11:25.704+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:11:25.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:11:25.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-26T18:11:55.964+0000] {processor.py:157} INFO - Started process (PID=1922) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:11:55.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:11:55.989+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:11:55.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:11:56.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:11:56.054+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:11:56.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:11:56.068+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:11:56.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:11:56.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-26T18:12:26.290+0000] {processor.py:157} INFO - Started process (PID=1932) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:12:26.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:12:26.297+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:12:26.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:12:26.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:12:26.377+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:12:26.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:12:26.400+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:12:26.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:12:26.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-26T18:12:56.633+0000] {processor.py:157} INFO - Started process (PID=1942) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:12:56.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:12:56.645+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:12:56.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:12:56.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:12:56.707+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:12:56.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:12:56.731+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:12:56.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:12:56.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-26T18:13:26.983+0000] {processor.py:157} INFO - Started process (PID=1952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:13:26.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:13:26.995+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:13:26.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:13:27.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:13:27.092+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:13:27.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:13:27.114+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:13:27.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:13:27.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-26T18:13:57.343+0000] {processor.py:157} INFO - Started process (PID=1962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:13:57.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:13:57.354+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:13:57.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:13:57.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:13:57.451+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:13:57.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:13:57.475+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:13:57.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:13:57.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-09-26T18:14:27.711+0000] {processor.py:157} INFO - Started process (PID=1972) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:14:27.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:14:27.739+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:14:27.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:14:27.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:14:27.818+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:14:27.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:14:27.842+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:14:27.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:14:27.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-26T18:14:58.054+0000] {processor.py:157} INFO - Started process (PID=1982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:14:58.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:14:58.065+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:14:58.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:14:58.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:14:58.148+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:14:58.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:14:58.186+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:14:58.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:14:58.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-26T18:15:28.396+0000] {processor.py:157} INFO - Started process (PID=1992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:15:28.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:15:28.405+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:15:28.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:15:28.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:15:28.490+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:15:28.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:15:28.531+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:15:28.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:15:28.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.160 seconds
[2024-09-26T18:15:58.720+0000] {processor.py:157} INFO - Started process (PID=2002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:15:58.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:15:58.725+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:15:58.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:15:58.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:15:58.804+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:15:58.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:15:58.820+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:15:58.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:15:58.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-26T18:16:29.157+0000] {processor.py:157} INFO - Started process (PID=2012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:16:29.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:16:29.163+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:16:29.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:16:29.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:16:29.217+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:16:29.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:16:29.235+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:16:29.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:16:29.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-26T18:16:59.611+0000] {processor.py:157} INFO - Started process (PID=2022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:16:59.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:16:59.617+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:16:59.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:16:59.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:16:59.723+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:16:59.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:16:59.745+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:16:59.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:16:59.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-26T18:17:30.080+0000] {processor.py:157} INFO - Started process (PID=2032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:17:30.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:17:30.088+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:17:30.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:17:30.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:17:30.171+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:17:30.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:17:30.189+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:17:30.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:17:30.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-26T18:18:00.400+0000] {processor.py:157} INFO - Started process (PID=2042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:18:00.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:18:00.406+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:18:00.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:18:00.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:18:00.458+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:18:00.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:18:00.478+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:18:00.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:18:00.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-26T18:18:30.719+0000] {processor.py:157} INFO - Started process (PID=2052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:18:30.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:18:30.725+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:18:30.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:18:30.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:18:30.783+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:18:30.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:18:30.795+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:18:30.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:18:30.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-26T18:19:01.071+0000] {processor.py:157} INFO - Started process (PID=2062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:19:01.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-26T18:19:01.093+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:19:01.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:19:01.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-26T18:19:01.145+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:19:01.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-26T18:19:01.159+0000] {logging_mixin.py:151} INFO - [2024-09-26T18:19:01.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-25T01:00:00+00:00, run_after=2024-09-26T01:00:00+00:00
[2024-09-26T18:19:01.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
