[2024-08-21T00:00:17.482+0000] {processor.py:157} INFO - Started process (PID=81630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:00:17.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:00:17.489+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:00:17.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:00:17.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:00:17.530+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:00:17.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:00:17.546+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:00:17.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:00:17.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-21T00:00:47.891+0000] {processor.py:157} INFO - Started process (PID=81640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:00:47.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:00:47.895+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:00:47.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:00:47.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:00:47.924+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:00:47.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:00:47.936+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:00:47.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:00:47.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T00:01:18.261+0000] {processor.py:157} INFO - Started process (PID=81650) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:01:18.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:01:18.264+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:01:18.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:01:18.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:01:18.302+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:01:18.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:01:18.315+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:01:18.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:01:18.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-21T00:01:48.779+0000] {processor.py:157} INFO - Started process (PID=81659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:01:48.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:01:48.793+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:01:48.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:01:48.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:01:48.840+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:01:48.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:01:48.861+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:01:48.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:01:48.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-21T00:02:19.310+0000] {processor.py:157} INFO - Started process (PID=81670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:02:19.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:02:19.322+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:02:19.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:02:19.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:02:19.399+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:02:19.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:02:19.421+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:02:19.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:02:19.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-08-21T00:02:49.677+0000] {processor.py:157} INFO - Started process (PID=81680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:02:49.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:02:49.689+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:02:49.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:02:49.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:02:49.750+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:02:49.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:02:49.768+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:02:49.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:02:49.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-21T00:03:20.188+0000] {processor.py:157} INFO - Started process (PID=81689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:03:20.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:03:20.195+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:03:20.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:03:20.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:03:20.254+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:03:20.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:03:20.270+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:03:20.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:03:20.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T00:03:50.608+0000] {processor.py:157} INFO - Started process (PID=81700) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:03:50.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:03:50.613+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:03:50.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:03:50.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:03:50.654+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:03:50.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:03:50.666+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:03:50.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:03:50.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-21T00:04:20.996+0000] {processor.py:157} INFO - Started process (PID=81710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:04:20.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:04:21.003+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:04:21.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:04:21.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:04:21.063+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:04:21.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:04:21.077+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:04:21.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:04:21.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-21T00:04:51.336+0000] {processor.py:157} INFO - Started process (PID=81720) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:04:51.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:04:51.341+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:04:51.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:04:51.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:04:51.378+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:04:51.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:04:51.393+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:04:51.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:04:51.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-21T00:05:21.674+0000] {processor.py:157} INFO - Started process (PID=81730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:05:21.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:05:21.678+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:05:21.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:05:21.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:05:21.716+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:05:21.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:05:21.730+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:05:21.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:05:21.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T00:05:52.006+0000] {processor.py:157} INFO - Started process (PID=81740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:05:52.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:05:52.010+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:05:52.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:05:52.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:05:52.041+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:05:52.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:05:52.054+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:05:52.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:05:52.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-21T00:06:22.372+0000] {processor.py:157} INFO - Started process (PID=81750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:06:22.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:06:22.381+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:06:22.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:06:22.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:06:22.441+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:06:22.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:06:22.455+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:06:22.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:06:22.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-21T00:06:52.704+0000] {processor.py:157} INFO - Started process (PID=81760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:06:52.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:06:52.710+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:06:52.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:06:52.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:06:52.743+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:06:52.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:06:52.757+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:06:52.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:06:52.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-21T00:07:23.069+0000] {processor.py:157} INFO - Started process (PID=81770) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:07:23.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:07:23.092+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:07:23.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:07:23.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:07:23.164+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:07:23.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:07:23.179+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:07:23.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:07:23.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-21T00:07:53.550+0000] {processor.py:157} INFO - Started process (PID=81780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:07:53.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:07:53.555+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:07:53.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:07:53.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:07:53.581+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:07:53.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:07:53.593+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:07:53.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:07:53.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T00:08:23.985+0000] {processor.py:157} INFO - Started process (PID=81790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:08:23.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:08:23.991+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:08:23.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:08:24.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:08:24.052+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:08:24.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:08:24.066+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:08:24.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:08:24.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-21T00:08:54.286+0000] {processor.py:157} INFO - Started process (PID=81800) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:08:54.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:08:54.290+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:08:54.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:08:54.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:08:54.329+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:08:54.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:08:54.343+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:08:54.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:08:54.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-21T00:09:24.720+0000] {processor.py:157} INFO - Started process (PID=81810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:09:24.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:09:24.726+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:09:24.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:09:24.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:09:24.780+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:09:24.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:09:24.793+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:09:24.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:09:24.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-21T00:09:55.095+0000] {processor.py:157} INFO - Started process (PID=81820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:09:55.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:09:55.098+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:09:55.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:09:55.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:09:55.152+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:09:55.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:09:55.168+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:09:55.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:09:55.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-21T00:10:25.466+0000] {processor.py:157} INFO - Started process (PID=81830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:10:25.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:10:25.471+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:10:25.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:10:25.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:10:25.531+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:10:25.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:10:25.543+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:10:25.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:10:25.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-21T00:10:55.960+0000] {processor.py:157} INFO - Started process (PID=81840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:10:55.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:10:55.968+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:10:55.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:10:55.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:10:56.018+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:10:56.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:10:56.033+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:10:56.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:10:56.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-21T00:11:26.338+0000] {processor.py:157} INFO - Started process (PID=81850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:11:26.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:11:26.343+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:11:26.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:11:26.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:11:26.392+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:11:26.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:11:26.407+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:11:26.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:11:26.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-21T00:11:56.726+0000] {processor.py:157} INFO - Started process (PID=81860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:11:56.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:11:56.728+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:11:56.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:11:56.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:11:56.753+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:11:56.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:11:56.762+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:11:56.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:11:56.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-21T00:12:27.164+0000] {processor.py:157} INFO - Started process (PID=81869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:12:27.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:12:27.191+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:12:27.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:12:27.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:12:27.243+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:12:27.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:12:27.264+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:12:27.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:12:27.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-21T00:12:57.449+0000] {processor.py:157} INFO - Started process (PID=81880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:12:57.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:12:57.453+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:12:57.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:12:57.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:12:57.484+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:12:57.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:12:57.495+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:12:57.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:12:57.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T00:13:27.886+0000] {processor.py:157} INFO - Started process (PID=81890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:13:27.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:13:27.892+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:13:27.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:13:27.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:13:27.937+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:13:27.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:13:27.951+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:13:27.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:13:27.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-21T00:13:58.299+0000] {processor.py:157} INFO - Started process (PID=81900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:13:58.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:13:58.304+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:13:58.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:13:58.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:13:58.344+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:13:58.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:13:58.356+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:13:58.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:13:58.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T00:14:28.644+0000] {processor.py:157} INFO - Started process (PID=81910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:14:28.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:14:28.647+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:14:28.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:14:28.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:14:28.679+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:14:28.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:14:28.692+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:14:28.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:14:28.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-21T00:14:59.116+0000] {processor.py:157} INFO - Started process (PID=81920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:14:59.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:14:59.125+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:14:59.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:14:59.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:14:59.163+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:14:59.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:14:59.173+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:14:59.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:14:59.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-21T00:15:29.429+0000] {processor.py:157} INFO - Started process (PID=81930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:15:29.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:15:29.432+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:15:29.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:15:29.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:15:29.465+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:15:29.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:15:29.478+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:15:29.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:15:29.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-21T00:15:59.888+0000] {processor.py:157} INFO - Started process (PID=81940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:15:59.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:15:59.893+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:15:59.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:15:59.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:15:59.939+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:15:59.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:15:59.959+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:15:59.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:15:59.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-21T00:16:30.253+0000] {processor.py:157} INFO - Started process (PID=81950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:16:30.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:16:30.260+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:16:30.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:16:30.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:16:30.331+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:16:30.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:16:30.349+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:16:30.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:16:30.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-21T00:17:00.710+0000] {processor.py:157} INFO - Started process (PID=81960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:17:00.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:17:00.717+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:17:00.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:17:00.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:17:00.768+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:17:00.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:17:00.790+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:17:00.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:17:00.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-21T00:17:31.068+0000] {processor.py:157} INFO - Started process (PID=81970) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:17:31.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:17:31.074+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:17:31.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:17:31.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:17:31.129+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:17:31.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:17:31.147+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:17:31.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:17:31.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-21T00:18:01.666+0000] {processor.py:157} INFO - Started process (PID=81979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:18:01.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:18:01.674+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:18:01.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:18:01.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:18:01.739+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:18:01.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:18:01.765+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:18:01.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:18:01.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-21T00:18:32.182+0000] {processor.py:157} INFO - Started process (PID=81990) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:18:32.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:18:32.188+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:18:32.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:18:32.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:18:32.257+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:18:32.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:18:32.273+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:18:32.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:18:32.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-21T00:19:02.658+0000] {processor.py:157} INFO - Started process (PID=82000) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:19:02.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:19:02.663+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:19:02.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:19:02.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:19:02.708+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:19:02.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:19:02.723+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:19:02.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:19:02.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-21T00:19:32.970+0000] {processor.py:157} INFO - Started process (PID=82009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:19:32.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:19:32.991+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:19:32.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:19:33.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:19:33.032+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:19:33.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:19:33.046+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:19:33.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:19:33.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-21T00:20:03.477+0000] {processor.py:157} INFO - Started process (PID=82017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:20:03.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:20:03.483+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:20:03.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:20:03.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:20:03.530+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:20:03.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:20:03.543+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:20:03.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:20:03.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-21T00:20:33.769+0000] {processor.py:157} INFO - Started process (PID=82027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:20:33.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:20:33.775+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:20:33.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:20:33.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:20:33.832+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:20:33.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:20:33.846+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:20:33.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:20:33.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-21T00:21:04.083+0000] {processor.py:157} INFO - Started process (PID=82037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:21:04.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:21:04.089+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:21:04.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:21:04.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:21:04.148+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:21:04.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:21:04.160+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:21:04.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:21:04.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-21T00:21:34.362+0000] {processor.py:157} INFO - Started process (PID=82047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:21:34.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:21:34.368+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:21:34.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:21:34.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:21:34.430+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:21:34.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:21:34.443+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:21:34.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:21:34.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-21T00:22:04.709+0000] {processor.py:157} INFO - Started process (PID=82057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:22:04.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:22:04.715+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:22:04.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:22:04.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:22:04.771+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:22:04.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:22:04.783+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:22:04.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:22:04.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-21T00:22:35.105+0000] {processor.py:157} INFO - Started process (PID=82067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:22:35.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:22:35.110+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:22:35.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:22:35.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:22:35.154+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:22:35.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:22:35.166+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:22:35.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:22:35.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-21T00:23:05.474+0000] {processor.py:157} INFO - Started process (PID=82077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:23:05.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:23:05.479+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:23:05.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:23:05.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:23:05.521+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:23:05.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:23:05.532+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:23:05.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:23:05.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-21T00:23:35.808+0000] {processor.py:157} INFO - Started process (PID=82087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:23:35.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:23:35.810+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:23:35.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:23:35.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:23:35.833+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:23:35.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:23:35.844+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:23:35.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:23:35.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-21T00:24:06.130+0000] {processor.py:157} INFO - Started process (PID=82097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:24:06.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:24:06.134+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:24:06.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:24:06.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:24:06.161+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:24:06.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:24:06.171+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:24:06.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:24:06.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-21T00:24:36.482+0000] {processor.py:157} INFO - Started process (PID=82107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:24:36.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:24:36.490+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:24:36.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:24:36.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:24:36.529+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:24:36.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:24:36.540+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:24:36.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:24:36.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-21T00:25:06.994+0000] {processor.py:157} INFO - Started process (PID=82117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:25:07.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:25:07.042+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:25:07.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:25:07.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:25:07.142+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:25:07.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:25:07.170+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:25:07.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:25:07.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-08-21T00:25:37.308+0000] {processor.py:157} INFO - Started process (PID=82127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:25:37.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:25:37.315+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:25:37.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:25:37.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:25:37.371+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:25:37.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:25:37.384+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:25:37.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:25:37.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.312 seconds
[2024-08-21T00:26:07.695+0000] {processor.py:157} INFO - Started process (PID=82137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:26:07.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:26:07.735+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:26:07.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:26:07.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:26:07.786+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:26:07.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:26:07.813+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:26:07.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:26:07.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-21T00:26:37.996+0000] {processor.py:157} INFO - Started process (PID=82147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:26:37.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:26:38.006+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:26:38.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:26:38.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:26:38.049+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:26:38.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:26:38.061+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:26:38.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:26:38.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-21T00:27:08.436+0000] {processor.py:157} INFO - Started process (PID=82157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:27:08.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:27:08.450+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:27:08.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:27:08.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:27:08.530+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:27:08.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:27:08.552+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:27:08.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:27:08.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-21T00:27:38.719+0000] {processor.py:157} INFO - Started process (PID=82167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:27:38.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:27:38.734+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:27:38.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:27:38.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:27:38.792+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:27:38.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:27:38.806+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:27:38.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:27:38.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T00:28:08.942+0000] {processor.py:157} INFO - Started process (PID=82177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:28:08.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:28:08.946+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:28:08.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:28:08.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:28:08.965+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:28:08.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:28:08.973+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:28:08.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:28:08.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.040 seconds
[2024-08-21T00:28:39.256+0000] {processor.py:157} INFO - Started process (PID=82187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:28:39.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:28:39.261+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:28:39.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:28:39.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:28:39.309+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:28:39.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:28:39.323+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:28:39.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:28:39.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-08-21T00:29:09.560+0000] {processor.py:157} INFO - Started process (PID=82197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:29:09.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:29:09.567+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:29:09.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:29:09.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:29:09.607+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:29:09.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:29:09.620+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:29:09.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:29:09.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-21T00:29:39.957+0000] {processor.py:157} INFO - Started process (PID=82207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:29:39.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:29:39.962+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:29:39.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:29:39.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:29:39.998+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:29:39.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:29:40.010+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:29:40.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:29:40.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-21T00:30:10.315+0000] {processor.py:157} INFO - Started process (PID=82546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:30:10.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:30:10.325+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:30:10.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:30:10.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:30:10.502+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:30:10.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:30:10.542+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:30:10.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:30:10.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.269 seconds
[2024-08-21T00:30:41.569+0000] {processor.py:157} INFO - Started process (PID=82841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:30:41.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:30:41.586+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:30:41.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:30:41.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:30:41.660+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:30:41.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:30:41.674+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:30:41.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:30:41.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-21T00:31:12.049+0000] {processor.py:157} INFO - Started process (PID=82851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:31:12.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:31:12.058+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:31:12.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:31:12.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:31:12.118+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:31:12.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:31:12.130+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:31:12.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:31:12.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-21T00:31:42.340+0000] {processor.py:157} INFO - Started process (PID=82861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:31:42.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:31:42.345+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:31:42.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:31:42.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:31:42.387+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:31:42.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:31:42.403+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:31:42.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:31:42.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.229 seconds
[2024-08-21T00:32:12.695+0000] {processor.py:157} INFO - Started process (PID=82899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:32:12.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:32:12.698+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:32:12.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:32:12.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:32:12.740+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:32:12.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:32:12.755+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:32:12.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:32:12.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T00:32:43.083+0000] {processor.py:157} INFO - Started process (PID=83048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:32:43.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:32:43.091+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:32:43.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:32:43.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:32:43.133+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:32:43.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:32:43.153+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:32:43.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:32:43.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-21T00:33:13.457+0000] {processor.py:157} INFO - Started process (PID=83058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:33:13.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:33:13.460+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:33:13.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:33:13.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:33:13.498+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:33:13.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:33:13.513+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:33:13.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:33:13.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-21T00:33:43.871+0000] {processor.py:157} INFO - Started process (PID=83067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:33:43.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:33:43.876+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:33:43.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:33:43.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:33:43.923+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:33:43.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:33:43.945+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:33:43.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:33:43.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-21T00:34:14.174+0000] {processor.py:157} INFO - Started process (PID=83078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:34:14.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:34:14.178+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:34:14.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:34:14.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:34:14.207+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:34:14.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:34:14.219+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:34:14.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:34:14.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T00:34:44.547+0000] {processor.py:157} INFO - Started process (PID=83088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:34:44.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:34:44.550+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:34:44.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:34:44.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:34:44.573+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:34:44.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:34:44.583+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:34:44.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:34:44.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-21T00:35:15.204+0000] {processor.py:157} INFO - Started process (PID=83098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:35:15.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:35:15.214+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:35:15.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:35:15.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:35:15.269+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:35:15.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:35:15.287+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:35:15.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:35:15.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-21T00:35:45.630+0000] {processor.py:157} INFO - Started process (PID=83108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:35:45.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:35:45.635+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:35:45.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:35:45.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:35:45.659+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:35:45.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:35:45.669+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:35:45.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:35:45.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-21T00:36:16.030+0000] {processor.py:157} INFO - Started process (PID=83118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:36:16.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:36:16.037+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:36:16.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:36:16.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:36:16.073+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:36:16.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:36:16.088+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:36:16.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:36:16.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-21T00:36:46.322+0000] {processor.py:157} INFO - Started process (PID=83128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:36:46.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:36:46.327+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:36:46.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:36:46.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:36:46.355+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:36:46.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:36:46.369+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:36:46.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:36:46.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T00:37:16.740+0000] {processor.py:157} INFO - Started process (PID=83138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:37:16.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:37:16.749+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:37:16.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:37:16.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:37:16.806+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:37:16.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:37:16.820+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:37:16.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:37:16.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-21T00:37:47.035+0000] {processor.py:157} INFO - Started process (PID=83148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:37:47.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:37:47.038+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:37:47.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:37:47.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:37:47.063+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:37:47.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:37:47.205+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:37:47.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:37:47.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-08-21T00:38:17.346+0000] {processor.py:157} INFO - Started process (PID=83157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:38:17.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:38:17.353+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:38:17.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:38:17.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:38:17.408+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:38:17.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:38:17.424+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:38:17.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:38:17.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-21T00:38:47.740+0000] {processor.py:157} INFO - Started process (PID=83168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:38:47.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:38:47.745+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:38:47.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:38:47.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:38:47.772+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:38:47.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:38:47.783+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:38:47.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:38:47.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T00:39:18.060+0000] {processor.py:157} INFO - Started process (PID=83178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:39:18.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:39:18.065+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:39:18.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:39:18.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:39:18.103+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:39:18.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:39:18.115+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:39:18.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:39:18.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T00:39:48.438+0000] {processor.py:157} INFO - Started process (PID=83188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:39:48.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:39:48.444+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:39:48.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:39:48.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:39:48.482+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:39:48.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:39:48.494+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:39:48.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:39:48.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-21T00:40:18.775+0000] {processor.py:157} INFO - Started process (PID=83198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:40:18.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:40:18.779+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:40:18.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:40:18.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:40:18.806+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:40:18.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:40:18.818+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:40:18.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:40:18.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T00:40:49.186+0000] {processor.py:157} INFO - Started process (PID=83208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:40:49.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:40:49.192+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:40:49.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:40:49.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:40:49.244+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:40:49.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:40:49.263+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:40:49.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:40:49.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-21T00:41:19.552+0000] {processor.py:157} INFO - Started process (PID=83218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:41:19.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:41:19.556+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:41:19.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:41:19.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:41:19.618+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:41:19.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:41:19.634+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:41:19.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:41:19.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-21T00:41:49.894+0000] {processor.py:157} INFO - Started process (PID=83228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:41:49.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:41:49.899+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:41:49.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:41:49.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:41:49.925+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:41:49.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:41:49.935+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:41:49.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:41:49.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T00:42:20.259+0000] {processor.py:157} INFO - Started process (PID=83238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:42:20.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:42:20.264+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:42:20.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:42:20.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:42:20.314+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:42:20.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:42:20.327+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:42:20.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:42:20.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-21T00:42:50.528+0000] {processor.py:157} INFO - Started process (PID=83248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:42:50.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:42:50.532+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:42:50.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:42:50.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:42:50.571+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:42:50.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:42:50.583+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:42:50.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:42:50.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T00:43:20.915+0000] {processor.py:157} INFO - Started process (PID=83258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:43:20.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:43:20.918+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:43:20.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:43:20.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:43:20.945+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:43:20.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:43:20.955+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:43:20.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:43:20.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-21T00:43:51.331+0000] {processor.py:157} INFO - Started process (PID=83268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:43:51.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:43:51.337+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:43:51.337+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:43:51.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:43:51.384+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:43:51.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:43:51.545+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:43:51.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:43:51.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.229 seconds
[2024-08-21T00:44:21.929+0000] {processor.py:157} INFO - Started process (PID=83278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:44:21.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:44:21.937+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:44:21.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:44:21.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:44:22.004+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:44:22.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:44:22.019+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:44:22.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:44:22.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-21T00:44:52.411+0000] {processor.py:157} INFO - Started process (PID=83288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:44:52.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:44:52.416+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:44:52.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:44:52.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:44:52.444+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:44:52.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:44:52.457+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:44:52.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:44:52.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-21T00:45:22.871+0000] {processor.py:157} INFO - Started process (PID=83298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:45:22.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:45:22.875+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:45:22.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:45:22.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:45:22.918+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:45:22.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:45:22.933+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:45:22.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:45:22.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-21T00:45:53.371+0000] {processor.py:157} INFO - Started process (PID=83308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:45:53.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:45:53.378+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:45:53.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:45:53.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:45:53.432+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:45:53.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:45:53.447+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:45:53.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:45:53.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-21T00:46:23.750+0000] {processor.py:157} INFO - Started process (PID=83318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:46:23.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:46:23.755+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:46:23.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:46:23.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:46:23.792+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:46:23.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:46:23.803+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:46:23.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:46:23.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-08-21T00:46:54.286+0000] {processor.py:157} INFO - Started process (PID=83328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:46:54.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:46:54.290+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:46:54.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:46:54.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:46:54.319+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:46:54.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:46:54.332+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:46:54.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:46:54.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-21T00:47:24.706+0000] {processor.py:157} INFO - Started process (PID=83337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:47:24.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:47:24.722+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:47:24.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:47:24.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:47:24.767+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:47:24.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:47:24.781+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:47:24.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:47:24.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-21T00:47:55.106+0000] {processor.py:157} INFO - Started process (PID=83348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:47:55.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:47:55.109+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:47:55.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:47:55.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:47:55.138+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:47:55.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:47:55.149+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:47:55.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:47:55.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T00:48:25.487+0000] {processor.py:157} INFO - Started process (PID=83357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:48:25.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:48:25.502+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:48:25.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:48:25.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:48:25.576+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:48:25.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:48:25.590+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:48:25.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:48:25.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-21T00:48:55.818+0000] {processor.py:157} INFO - Started process (PID=83368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:48:55.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:48:55.823+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:48:55.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:48:55.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:48:55.846+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:48:55.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:48:55.856+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:48:55.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:48:55.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-21T00:49:26.270+0000] {processor.py:157} INFO - Started process (PID=83378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:49:26.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:49:26.277+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:49:26.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:49:26.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:49:26.320+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:49:26.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:49:26.334+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:49:26.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:49:26.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.247 seconds
[2024-08-21T00:49:56.691+0000] {processor.py:157} INFO - Started process (PID=83388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:49:56.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:49:56.695+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:49:56.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:49:56.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:49:56.755+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:49:56.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:49:56.771+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:49:56.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:49:56.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-21T00:50:27.143+0000] {processor.py:157} INFO - Started process (PID=83398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:50:27.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:50:27.152+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:50:27.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:50:27.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:50:27.217+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:50:27.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:50:27.229+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:50:27.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:50:27.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T00:50:57.527+0000] {processor.py:157} INFO - Started process (PID=83408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:50:57.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:50:57.531+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:50:57.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:50:57.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:50:57.570+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:50:57.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:50:57.583+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:50:57.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:50:57.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-21T00:51:27.957+0000] {processor.py:157} INFO - Started process (PID=83418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:51:27.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:51:27.962+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:51:27.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:51:27.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:51:28.020+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:51:28.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:51:28.046+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:51:28.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:51:28.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-21T00:51:58.446+0000] {processor.py:157} INFO - Started process (PID=83427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:51:58.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:51:58.453+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:51:58.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:51:58.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:51:58.500+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:51:58.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:51:58.514+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:51:58.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:51:58.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-21T00:52:28.981+0000] {processor.py:157} INFO - Started process (PID=83437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:52:28.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:52:28.986+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:52:28.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:52:29.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:52:29.040+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:52:29.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:52:29.054+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:52:29.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:52:29.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.231 seconds
[2024-08-21T00:52:59.324+0000] {processor.py:157} INFO - Started process (PID=83447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:52:59.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:52:59.329+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:52:59.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:52:59.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:52:59.384+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:52:59.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:52:59.398+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:52:59.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:52:59.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-21T00:53:29.745+0000] {processor.py:157} INFO - Started process (PID=83458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:53:29.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:53:29.750+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:53:29.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:53:29.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:53:29.776+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:53:29.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:53:29.785+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:53:29.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:53:29.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-21T00:54:00.110+0000] {processor.py:157} INFO - Started process (PID=83468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:54:00.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:54:00.112+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:54:00.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:54:00.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:54:00.142+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:54:00.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:54:00.154+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:54:00.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:54:00.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T00:54:30.487+0000] {processor.py:157} INFO - Started process (PID=83478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:54:30.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:54:30.490+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:54:30.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:54:30.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:54:30.520+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:54:30.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:54:30.529+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:54:30.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:54:30.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T00:55:00.914+0000] {processor.py:157} INFO - Started process (PID=83488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:55:00.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:55:00.932+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:55:00.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:55:00.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:55:00.978+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:55:00.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:55:01.012+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:55:01.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:55:01.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-21T00:55:31.188+0000] {processor.py:157} INFO - Started process (PID=83498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:55:31.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:55:31.193+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:55:31.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:55:31.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:55:31.223+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:55:31.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:55:31.233+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:55:31.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:55:31.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.237 seconds
[2024-08-21T00:56:01.593+0000] {processor.py:157} INFO - Started process (PID=83508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:56:01.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:56:01.607+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:56:01.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:56:01.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:56:01.672+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:56:01.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:56:01.685+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:56:01.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:56:01.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-21T00:56:31.883+0000] {processor.py:157} INFO - Started process (PID=83518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:56:31.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:56:31.887+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:56:31.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:56:31.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:56:31.918+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:56:31.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:56:31.927+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:56:31.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:56:31.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T00:57:02.231+0000] {processor.py:157} INFO - Started process (PID=83528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:57:02.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:57:02.239+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:57:02.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:57:02.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:57:02.276+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:57:02.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:57:02.288+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:57:02.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:57:02.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-21T00:57:32.706+0000] {processor.py:157} INFO - Started process (PID=83538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:57:32.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:57:32.711+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:57:32.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:57:32.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:57:32.747+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:57:32.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:57:32.762+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:57:32.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:57:32.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-21T00:58:03.043+0000] {processor.py:157} INFO - Started process (PID=83548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:58:03.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:58:03.050+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:58:03.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:58:03.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:58:03.083+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:58:03.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:58:03.095+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:58:03.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:58:03.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-21T00:58:33.476+0000] {processor.py:157} INFO - Started process (PID=83558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:58:33.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:58:33.495+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:58:33.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:58:33.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:58:33.551+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:58:33.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:58:33.740+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:58:33.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:58:33.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.288 seconds
[2024-08-21T00:59:04.164+0000] {processor.py:157} INFO - Started process (PID=83568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:59:04.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:59:04.170+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:59:04.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:59:04.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:59:04.216+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:59:04.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:59:04.230+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:59:04.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:59:04.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-21T00:59:34.521+0000] {processor.py:157} INFO - Started process (PID=83578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:59:34.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T00:59:34.527+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:59:34.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:59:34.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T00:59:34.563+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:59:34.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T00:59:34.576+0000] {logging_mixin.py:151} INFO - [2024-08-21T00:59:34.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-19T01:00:00+00:00, run_after=2024-08-20T01:00:00+00:00
[2024-08-21T00:59:34.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-21T01:00:05.008+0000] {processor.py:157} INFO - Started process (PID=83588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:00:05.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:00:05.014+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:00:05.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:00:05.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:00:05.077+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:00:05.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:00:05.097+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:00:05.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:00:05.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-21T01:00:35.457+0000] {processor.py:157} INFO - Started process (PID=83598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:00:35.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:00:35.462+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:00:35.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:00:35.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:00:35.491+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:00:35.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:00:35.502+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:00:35.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:00:35.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-21T01:01:05.845+0000] {processor.py:157} INFO - Started process (PID=83608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:01:05.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:01:05.848+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:01:05.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:01:05.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:01:05.891+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:01:05.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:01:05.907+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:01:05.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:01:05.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-21T01:01:36.236+0000] {processor.py:157} INFO - Started process (PID=83618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:01:36.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:01:36.243+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:01:36.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:01:36.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:01:36.350+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:01:36.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:01:36.581+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:01:36.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:01:36.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.361 seconds
[2024-08-21T01:02:06.874+0000] {processor.py:157} INFO - Started process (PID=83628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:02:06.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:02:06.882+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:02:06.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:02:06.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:02:06.962+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:02:06.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:02:06.976+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:02:06.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:02:06.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-21T01:02:37.170+0000] {processor.py:157} INFO - Started process (PID=83638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:02:37.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:02:37.175+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:02:37.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:02:37.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:02:37.224+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:02:37.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:02:37.237+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:02:37.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:02:37.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-21T01:03:07.567+0000] {processor.py:157} INFO - Started process (PID=83648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:03:07.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:03:07.574+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:03:07.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:03:07.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:03:07.623+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:03:07.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:03:07.639+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:03:07.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:03:07.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-21T01:03:37.997+0000] {processor.py:157} INFO - Started process (PID=83658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:03:38.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:03:38.013+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:03:38.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:03:38.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:03:38.067+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:03:38.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:03:38.081+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:03:38.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:03:38.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-21T01:04:08.397+0000] {processor.py:157} INFO - Started process (PID=83668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:04:08.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:04:08.408+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:04:08.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:04:08.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:04:08.500+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:04:08.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:04:08.525+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:04:08.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:04:08.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-08-21T01:04:38.744+0000] {processor.py:157} INFO - Started process (PID=83678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:04:38.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:04:38.747+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:04:38.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:04:38.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:04:38.794+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:04:38.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:04:39.118+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:04:39.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:04:39.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.388 seconds
[2024-08-21T01:05:09.389+0000] {processor.py:157} INFO - Started process (PID=83688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:05:09.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:05:09.392+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:05:09.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:05:09.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:05:09.424+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:05:09.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:05:09.435+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:05:09.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:05:09.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T01:05:39.702+0000] {processor.py:157} INFO - Started process (PID=83698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:05:39.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:05:39.706+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:05:39.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:05:39.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:05:39.734+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:05:39.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:05:39.745+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:05:39.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:05:39.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T01:06:10.066+0000] {processor.py:157} INFO - Started process (PID=83708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:06:10.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:06:10.070+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:06:10.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:06:10.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:06:10.096+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:06:10.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:06:10.106+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:06:10.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:06:10.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-21T01:06:40.492+0000] {processor.py:157} INFO - Started process (PID=83718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:06:40.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:06:40.499+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:06:40.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:06:40.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:06:40.556+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:06:40.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:06:40.569+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:06:40.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:06:40.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-21T01:07:10.882+0000] {processor.py:157} INFO - Started process (PID=83728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:07:10.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:07:10.886+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:07:10.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:07:10.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:07:10.913+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:07:10.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:07:10.926+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:07:10.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:07:11.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.207 seconds
[2024-08-21T01:07:41.430+0000] {processor.py:157} INFO - Started process (PID=83738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:07:41.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:07:41.456+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:07:41.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:07:41.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:07:41.501+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:07:41.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:07:41.599+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:07:41.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:07:41.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-08-21T01:08:11.894+0000] {processor.py:157} INFO - Started process (PID=83748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:08:11.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:08:11.898+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:08:11.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:08:11.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:08:11.928+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:08:11.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:08:11.941+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:08:11.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:08:11.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T01:08:42.313+0000] {processor.py:157} INFO - Started process (PID=83758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:08:42.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:08:42.319+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:08:42.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:08:42.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:08:42.363+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:08:42.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:08:42.377+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:08:42.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:08:42.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-21T01:09:12.699+0000] {processor.py:157} INFO - Started process (PID=83768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:09:12.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:09:12.702+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:09:12.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:09:12.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:09:12.729+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:09:12.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:09:12.740+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:09:12.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:09:12.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T01:09:43.093+0000] {processor.py:157} INFO - Started process (PID=83778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:09:43.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:09:43.099+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:09:43.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:09:43.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:09:43.151+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:09:43.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:09:43.176+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:09:43.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:09:43.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-21T01:10:13.429+0000] {processor.py:157} INFO - Started process (PID=83788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:10:13.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:10:13.432+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:10:13.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:10:13.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:10:13.460+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:10:13.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:10:13.474+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:10:13.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:10:13.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.202 seconds
[2024-08-21T01:10:43.742+0000] {processor.py:157} INFO - Started process (PID=83797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:10:43.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:10:43.752+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:10:43.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:10:43.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:10:43.800+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:10:43.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:10:43.957+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:10:43.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:10:43.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.228 seconds
[2024-08-21T01:11:14.303+0000] {processor.py:157} INFO - Started process (PID=83808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:11:14.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:11:14.309+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:11:14.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:11:14.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:11:14.374+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:11:14.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:11:14.388+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:11:14.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:11:14.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-21T01:11:44.705+0000] {processor.py:157} INFO - Started process (PID=83818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:11:44.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:11:44.708+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:11:44.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:11:44.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:11:44.737+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:11:44.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:11:44.747+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:11:44.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:11:44.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T01:12:15.064+0000] {processor.py:157} INFO - Started process (PID=83828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:12:15.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:12:15.068+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:12:15.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:12:15.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:12:15.101+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:12:15.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:12:15.111+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:12:15.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:12:15.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-21T01:12:45.369+0000] {processor.py:157} INFO - Started process (PID=83836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:12:45.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:12:45.376+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:12:45.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:12:45.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:12:45.438+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:12:45.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:12:45.453+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:12:45.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:12:45.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-21T01:13:15.772+0000] {processor.py:157} INFO - Started process (PID=83848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:13:15.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:13:15.776+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:13:15.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:13:15.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:13:15.810+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:13:15.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:13:15.824+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:13:15.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:13:15.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.224 seconds
[2024-08-21T01:13:46.049+0000] {processor.py:157} INFO - Started process (PID=83858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:13:46.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:13:46.056+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:13:46.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:13:46.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:13:46.096+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:13:46.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:13:46.182+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:13:46.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:13:46.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-21T01:14:16.351+0000] {processor.py:157} INFO - Started process (PID=83868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:14:16.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:14:16.353+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:14:16.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:14:16.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:14:16.389+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:14:16.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:14:16.398+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:14:16.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:14:16.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T01:14:46.753+0000] {processor.py:157} INFO - Started process (PID=83878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:14:46.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:14:46.758+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:14:46.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:14:46.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:14:46.784+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:14:46.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:14:46.794+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:14:46.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:14:46.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T01:15:17.021+0000] {processor.py:157} INFO - Started process (PID=83888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:15:17.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:15:17.031+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:15:17.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:15:17.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:15:17.061+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:15:17.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:15:17.075+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:15:17.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:15:17.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-21T01:15:47.366+0000] {processor.py:157} INFO - Started process (PID=83898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:15:47.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:15:47.370+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:15:47.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:15:47.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:15:47.399+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:15:47.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:15:47.410+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:15:47.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:15:47.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T01:16:17.789+0000] {processor.py:157} INFO - Started process (PID=83908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:16:17.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:16:17.793+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:16:17.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:16:17.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:16:17.820+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:16:17.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:16:17.831+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:16:17.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:16:17.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-08-21T01:16:48.101+0000] {processor.py:157} INFO - Started process (PID=83918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:16:48.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:16:48.112+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:16:48.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:16:48.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:16:48.151+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:16:48.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:16:48.232+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:16:48.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:16:48.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.144 seconds
[2024-08-21T01:17:18.561+0000] {processor.py:157} INFO - Started process (PID=83928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:17:18.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:17:18.565+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:17:18.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:17:18.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:17:18.594+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:17:18.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:17:18.608+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:17:18.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:17:18.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T01:17:48.990+0000] {processor.py:157} INFO - Started process (PID=83938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:17:48.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:17:48.996+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:17:48.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:17:49.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:17:49.025+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:17:49.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:17:49.039+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:17:49.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:17:49.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-21T01:18:19.410+0000] {processor.py:157} INFO - Started process (PID=83948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:18:19.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:18:19.414+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:18:19.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:18:19.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:18:19.439+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:18:19.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:18:19.449+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:18:19.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:18:19.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-21T01:18:49.785+0000] {processor.py:157} INFO - Started process (PID=83958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:18:49.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:18:49.792+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:18:49.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:18:49.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:18:49.830+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:18:49.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:18:49.842+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:18:49.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:18:49.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-21T01:19:20.132+0000] {processor.py:157} INFO - Started process (PID=83968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:19:20.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:19:20.135+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:19:20.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:19:20.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:19:20.164+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:19:20.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:19:20.303+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:19:20.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:19:20.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-08-21T01:19:50.476+0000] {processor.py:157} INFO - Started process (PID=83978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:19:50.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:19:50.483+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:19:50.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:19:50.499+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:19:50.521+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:19:50.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:19:50.616+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:19:50.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:19:50.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-21T01:20:20.856+0000] {processor.py:157} INFO - Started process (PID=83988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:20:20.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:20:20.860+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:20:20.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:20:20.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:20:20.890+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:20:20.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:20:20.900+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:20:20.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:20:20.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T01:20:51.175+0000] {processor.py:157} INFO - Started process (PID=83997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:20:51.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:20:51.181+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:20:51.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:20:51.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:20:51.249+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:20:51.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:20:51.263+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:20:51.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:20:51.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-21T01:21:21.474+0000] {processor.py:157} INFO - Started process (PID=84008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:21:21.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:21:21.478+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:21:21.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:21:21.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:21:21.508+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:21:21.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:21:21.520+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:21:21.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:21:21.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T01:21:51.827+0000] {processor.py:157} INFO - Started process (PID=84018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:21:51.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:21:51.831+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:21:51.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:21:51.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:21:51.861+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:21:51.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:21:51.873+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:21:51.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:21:51.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-21T01:22:22.170+0000] {processor.py:157} INFO - Started process (PID=84028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:22:22.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:22:22.173+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:22:22.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:22:22.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:22:22.227+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:22:22.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:22:22.390+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:22:22.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:22:22.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-08-21T01:22:52.543+0000] {processor.py:157} INFO - Started process (PID=84038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:22:52.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:22:52.558+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:22:52.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:22:52.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:22:52.617+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:22:52.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:22:52.796+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:22:52.796+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:22:52.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.268 seconds
[2024-08-21T01:23:23.087+0000] {processor.py:157} INFO - Started process (PID=84048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:23:23.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:23:23.095+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:23:23.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:23:23.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:23:23.118+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:23:23.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:23:23.127+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:23:23.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:23:23.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-21T01:23:53.428+0000] {processor.py:157} INFO - Started process (PID=84058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:23:53.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:23:53.432+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:23:53.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:23:53.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:23:53.470+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:23:53.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:23:53.480+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:23:53.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:23:53.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-21T01:24:23.830+0000] {processor.py:157} INFO - Started process (PID=84068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:24:23.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:24:23.834+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:24:23.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:24:23.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:24:23.864+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:24:23.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:24:23.877+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:24:23.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:24:23.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T01:24:54.205+0000] {processor.py:157} INFO - Started process (PID=84078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:24:54.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:24:54.209+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:24:54.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:24:54.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:24:54.229+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:24:54.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:24:54.239+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:24:54.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:24:54.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-08-21T01:25:24.484+0000] {processor.py:157} INFO - Started process (PID=84088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:25:24.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:25:24.490+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:25:24.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:25:24.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:25:24.528+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:25:24.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:25:24.611+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:25:24.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:25:24.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-21T01:25:54.786+0000] {processor.py:157} INFO - Started process (PID=84098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:25:54.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:25:54.789+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:25:54.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:25:54.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:25:54.819+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:25:54.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:25:54.928+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:25:54.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:25:54.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-21T01:26:25.327+0000] {processor.py:157} INFO - Started process (PID=84108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:26:25.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:26:25.334+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:26:25.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:26:25.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:26:25.369+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:26:25.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:26:25.379+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:26:25.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:26:25.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-21T01:26:55.618+0000] {processor.py:157} INFO - Started process (PID=84118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:26:55.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:26:55.621+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:26:55.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:26:55.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:26:55.652+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:26:55.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:26:55.665+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:26:55.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:26:55.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T01:27:25.934+0000] {processor.py:157} INFO - Started process (PID=84128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:27:25.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:27:25.939+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:27:25.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:27:25.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:27:25.967+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:27:25.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:27:25.980+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:27:25.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:27:25.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T01:27:56.342+0000] {processor.py:157} INFO - Started process (PID=84138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:27:56.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:27:56.346+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:27:56.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:27:56.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:27:56.375+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:27:56.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:27:56.385+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:27:56.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:27:56.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.221 seconds
[2024-08-21T01:28:26.662+0000] {processor.py:157} INFO - Started process (PID=84148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:28:26.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:28:26.667+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:28:26.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:28:26.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:28:26.696+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:28:26.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:28:26.776+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:28:26.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:28:26.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-21T01:28:57.131+0000] {processor.py:157} INFO - Started process (PID=84158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:28:57.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:28:57.138+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:28:57.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:28:57.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:28:57.176+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:28:57.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:28:57.256+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:28:57.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:28:57.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-21T01:29:27.605+0000] {processor.py:157} INFO - Started process (PID=84168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:29:27.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:29:27.608+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:29:27.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:29:27.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:29:27.636+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:29:27.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:29:27.648+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:29:27.648+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:29:27.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T01:29:58.061+0000] {processor.py:157} INFO - Started process (PID=84178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:29:58.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:29:58.074+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:29:58.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:29:58.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:29:58.118+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:29:58.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:29:58.132+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:29:58.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:29:58.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-21T01:30:28.355+0000] {processor.py:157} INFO - Started process (PID=84188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:30:28.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:30:28.358+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:30:28.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:30:28.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:30:28.387+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:30:28.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:30:28.397+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:30:28.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:30:28.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T01:30:58.734+0000] {processor.py:157} INFO - Started process (PID=84198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:30:58.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:30:58.759+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:30:58.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:30:58.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:30:58.806+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:30:58.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:30:58.821+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:30:58.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:30:58.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.237 seconds
[2024-08-21T01:31:29.062+0000] {processor.py:157} INFO - Started process (PID=84208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:31:29.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:31:29.065+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:31:29.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:31:29.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:31:29.092+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:31:29.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:31:29.174+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:31:29.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:31:29.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-21T01:31:59.365+0000] {processor.py:157} INFO - Started process (PID=84218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:31:59.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:31:59.368+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:31:59.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:31:59.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:31:59.396+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:31:59.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:31:59.475+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:31:59.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:31:59.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-21T01:32:29.707+0000] {processor.py:157} INFO - Started process (PID=84228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:32:29.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:32:29.712+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:32:29.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:32:29.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:32:29.748+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:32:29.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:32:29.762+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:32:29.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:32:29.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-21T01:33:00.005+0000] {processor.py:157} INFO - Started process (PID=84238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:33:00.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:33:00.008+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:33:00.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:33:00.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:33:00.050+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:33:00.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:33:00.071+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:33:00.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:33:00.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-21T01:33:30.439+0000] {processor.py:157} INFO - Started process (PID=84248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:33:30.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:33:30.442+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:33:30.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:33:30.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:33:30.468+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:33:30.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:33:30.477+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:33:30.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:33:30.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-21T01:34:00.772+0000] {processor.py:157} INFO - Started process (PID=84258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:34:00.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:34:00.777+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:34:00.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:34:00.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:34:00.816+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:34:00.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:34:00.829+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:34:00.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:34:00.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.230 seconds
[2024-08-21T01:34:31.312+0000] {processor.py:157} INFO - Started process (PID=84268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:34:31.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:34:31.314+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:34:31.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:34:31.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:34:31.341+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:34:31.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:34:31.421+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:34:31.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:34:31.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-21T01:35:01.640+0000] {processor.py:157} INFO - Started process (PID=84278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:35:01.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:35:01.642+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:35:01.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:35:01.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:35:01.672+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:35:01.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:35:01.747+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:35:01.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:35:01.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-21T01:35:31.904+0000] {processor.py:157} INFO - Started process (PID=84288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:35:31.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:35:31.908+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:35:31.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:35:31.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:35:31.939+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:35:31.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:35:31.951+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:35:31.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:35:31.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T01:36:02.292+0000] {processor.py:157} INFO - Started process (PID=84298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:36:02.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:36:02.299+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:36:02.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:36:02.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:36:02.335+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:36:02.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:36:02.350+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:36:02.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:36:02.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-21T01:36:32.714+0000] {processor.py:157} INFO - Started process (PID=84308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:36:32.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:36:32.718+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:36:32.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:36:32.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:36:32.747+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:36:32.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:36:32.759+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:36:32.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:36:32.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T01:37:03.087+0000] {processor.py:157} INFO - Started process (PID=84318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:37:03.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:37:03.090+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:37:03.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:37:03.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:37:03.117+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:37:03.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:37:03.127+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:37:03.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:37:03.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.217 seconds
[2024-08-21T01:37:33.481+0000] {processor.py:157} INFO - Started process (PID=84328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:37:33.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:37:33.486+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:37:33.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:37:33.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:37:33.518+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:37:33.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:37:33.597+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:37:33.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:37:33.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-21T01:38:03.900+0000] {processor.py:157} INFO - Started process (PID=84338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:38:03.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:38:03.906+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:38:03.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:38:03.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:38:04.128+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:38:04.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:38:04.139+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:38:04.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:38:04.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.253 seconds
[2024-08-21T01:38:34.245+0000] {processor.py:157} INFO - Started process (PID=84348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:38:34.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:38:34.250+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:38:34.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:38:34.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:38:34.283+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:38:34.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:38:34.294+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:38:34.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:38:34.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-21T01:39:04.635+0000] {processor.py:157} INFO - Started process (PID=84358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:39:04.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:39:04.641+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:39:04.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:39:04.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:39:04.706+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:39:04.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:39:04.720+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:39:04.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:39:04.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-21T01:39:35.062+0000] {processor.py:157} INFO - Started process (PID=84368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:39:35.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:39:35.066+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:39:35.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:39:35.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:39:35.093+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:39:35.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:39:35.105+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:39:35.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:39:35.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T01:40:05.483+0000] {processor.py:157} INFO - Started process (PID=84378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:40:05.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:40:05.491+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:40:05.491+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:40:05.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:40:05.533+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:40:05.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:40:05.675+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:40:05.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:40:05.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.206 seconds
[2024-08-21T01:40:35.860+0000] {processor.py:157} INFO - Started process (PID=84388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:40:35.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:40:35.867+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:40:35.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:40:35.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:40:35.939+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:40:35.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:40:36.125+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:40:36.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:40:36.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.292 seconds
[2024-08-21T01:41:06.340+0000] {processor.py:157} INFO - Started process (PID=84398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:41:06.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:41:06.347+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:41:06.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:41:06.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:41:06.541+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:41:06.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:41:06.550+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:41:06.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:41:06.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.235 seconds
[2024-08-21T01:41:36.702+0000] {processor.py:157} INFO - Started process (PID=84408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:41:36.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:41:36.706+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:41:36.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:41:36.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:41:36.736+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:41:36.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:41:36.747+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:41:36.747+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:41:36.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T01:42:07.137+0000] {processor.py:157} INFO - Started process (PID=84418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:42:07.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:42:07.147+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:42:07.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:42:07.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:42:07.215+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:42:07.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:42:07.229+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:42:07.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:42:07.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-21T01:42:37.461+0000] {processor.py:157} INFO - Started process (PID=84428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:42:37.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:42:37.464+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:42:37.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:42:37.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:42:37.496+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:42:37.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:42:37.506+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:42:37.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:42:37.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T01:43:07.883+0000] {processor.py:157} INFO - Started process (PID=84438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:43:07.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:43:07.889+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:43:07.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:43:07.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:43:07.928+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:43:07.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:43:08.032+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:43:08.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:43:08.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-08-21T01:43:38.234+0000] {processor.py:157} INFO - Started process (PID=84448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:43:38.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:43:38.240+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:43:38.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:43:38.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:43:38.269+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:43:38.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:43:38.397+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:43:38.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:43:38.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-08-21T01:44:08.812+0000] {processor.py:157} INFO - Started process (PID=84458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:44:08.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:44:08.817+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:44:08.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:44:08.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:44:08.935+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:44:08.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:44:08.944+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:44:08.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:44:08.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-21T01:44:39.131+0000] {processor.py:157} INFO - Started process (PID=84468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:44:39.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:44:39.135+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:44:39.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:44:39.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:44:39.166+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:44:39.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:44:39.178+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:44:39.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:44:39.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T01:45:09.504+0000] {processor.py:157} INFO - Started process (PID=84478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:45:09.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:45:09.508+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:45:09.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:45:09.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:45:09.535+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:45:09.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:45:09.548+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:45:09.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:45:09.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T01:45:39.844+0000] {processor.py:157} INFO - Started process (PID=84488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:45:39.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:45:39.849+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:45:39.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:45:39.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:45:39.895+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:45:39.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:45:39.908+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:45:39.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:45:40.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.201 seconds
[2024-08-21T01:46:10.135+0000] {processor.py:157} INFO - Started process (PID=84498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:46:10.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:46:10.143+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:46:10.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:46:10.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:46:10.213+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:46:10.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:46:10.387+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:46:10.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:46:10.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.268 seconds
[2024-08-21T01:46:40.639+0000] {processor.py:157} INFO - Started process (PID=84508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:46:40.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:46:40.643+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:46:40.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:46:40.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:46:40.673+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:46:40.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:46:40.753+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:46:40.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:46:40.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-21T01:47:11.157+0000] {processor.py:157} INFO - Started process (PID=84518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:47:11.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:47:11.163+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:47:11.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:47:11.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:47:11.381+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:47:11.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:47:11.390+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:47:11.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:47:11.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.246 seconds
[2024-08-21T01:47:41.494+0000] {processor.py:157} INFO - Started process (PID=84528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:47:41.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:47:41.501+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:47:41.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:47:41.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:47:41.547+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:47:41.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:47:41.561+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:47:41.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:47:41.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-21T01:48:11.924+0000] {processor.py:157} INFO - Started process (PID=84538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:48:11.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:48:11.927+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:48:11.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:48:11.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:48:11.959+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:48:11.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:48:11.972+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:48:11.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:48:11.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-21T01:48:42.376+0000] {processor.py:157} INFO - Started process (PID=84548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:48:42.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:48:42.382+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:48:42.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:48:42.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:48:42.414+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:48:42.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:48:42.428+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:48:42.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:48:42.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.226 seconds
[2024-08-21T01:49:12.872+0000] {processor.py:157} INFO - Started process (PID=84558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:49:12.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:49:12.878+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:49:12.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:49:12.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:49:12.931+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:49:12.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:49:13.018+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:49:13.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:49:13.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-21T01:49:43.395+0000] {processor.py:157} INFO - Started process (PID=84568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:49:43.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:49:43.402+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:49:43.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:49:43.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:49:43.432+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:49:43.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:49:43.539+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:49:43.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:49:43.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-21T01:50:13.721+0000] {processor.py:157} INFO - Started process (PID=84578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:50:13.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:50:13.725+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:50:13.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:50:13.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:50:13.880+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:50:13.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:50:13.888+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:50:13.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:50:13.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-08-21T01:50:44.251+0000] {processor.py:157} INFO - Started process (PID=84588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:50:44.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:50:44.256+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:50:44.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:50:44.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:50:44.288+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:50:44.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:50:44.298+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:50:44.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:50:44.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-21T01:51:14.639+0000] {processor.py:157} INFO - Started process (PID=84598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:51:14.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:51:14.643+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:51:14.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:51:14.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:51:14.693+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:51:14.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:51:14.707+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:51:14.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:51:14.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-21T01:51:45.061+0000] {processor.py:157} INFO - Started process (PID=84608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:51:45.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:51:45.066+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:51:45.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:51:45.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:51:45.106+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:51:45.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:51:45.120+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:51:45.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:51:45.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.208 seconds
[2024-08-21T01:52:15.623+0000] {processor.py:157} INFO - Started process (PID=84618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:52:15.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:52:15.626+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:52:15.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:52:15.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:52:15.654+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:52:15.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:52:15.740+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:52:15.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:52:15.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-08-21T01:52:46.109+0000] {processor.py:157} INFO - Started process (PID=84628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:52:46.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:52:46.116+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:52:46.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:52:46.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:52:46.151+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:52:46.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:52:46.265+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:52:46.265+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:52:46.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.169 seconds
[2024-08-21T01:53:16.466+0000] {processor.py:157} INFO - Started process (PID=84638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:53:16.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:53:16.482+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:53:16.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:53:16.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:53:16.699+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:53:16.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:53:16.708+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:53:16.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:53:16.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.262 seconds
[2024-08-21T01:53:46.997+0000] {processor.py:157} INFO - Started process (PID=84648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:53:46.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:53:47.003+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:53:47.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:53:47.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:53:47.054+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:53:47.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:53:47.067+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:53:47.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:53:47.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-21T01:54:17.473+0000] {processor.py:157} INFO - Started process (PID=84658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:54:17.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:54:17.488+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:54:17.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:54:17.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:54:17.565+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:54:17.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:54:17.584+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:54:17.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:54:17.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-21T01:54:48.045+0000] {processor.py:157} INFO - Started process (PID=84668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:54:48.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:54:48.069+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:54:48.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:54:48.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:54:48.118+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:54:48.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:54:48.134+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:54:48.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:54:48.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.247 seconds
[2024-08-21T01:55:18.374+0000] {processor.py:157} INFO - Started process (PID=84678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:55:18.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:55:18.379+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:55:18.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:55:18.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:55:18.425+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:55:18.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:55:18.544+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:55:18.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:55:18.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-08-21T01:55:48.860+0000] {processor.py:157} INFO - Started process (PID=84688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:55:48.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:55:48.864+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:55:48.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:55:48.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:55:48.908+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:55:48.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:55:49.036+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:55:49.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:55:49.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-08-21T01:56:19.422+0000] {processor.py:157} INFO - Started process (PID=84698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:56:19.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:56:19.431+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:56:19.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:56:19.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:56:19.653+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:56:19.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:56:19.662+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:56:19.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:56:19.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.254 seconds
[2024-08-21T01:56:49.952+0000] {processor.py:157} INFO - Started process (PID=84707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:56:49.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:56:49.961+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:56:49.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:56:50.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:56:50.026+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:56:50.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:56:50.045+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:56:50.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:56:50.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-21T01:57:20.322+0000] {processor.py:157} INFO - Started process (PID=84718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:57:20.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:57:20.340+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:57:20.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:57:20.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:57:20.427+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:57:20.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:57:20.491+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:57:20.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:57:20.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.196 seconds
[2024-08-21T01:57:50.661+0000] {processor.py:157} INFO - Started process (PID=84727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:57:50.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:57:50.673+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:57:50.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:57:50.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:57:50.739+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:57:50.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:57:50.758+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:57:50.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:57:50.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.282 seconds
[2024-08-21T01:58:21.062+0000] {processor.py:157} INFO - Started process (PID=84738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:58:21.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:58:21.071+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:58:21.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:58:21.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:58:21.146+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:58:21.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:58:21.331+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:58:21.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:58:21.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.284 seconds
[2024-08-21T01:58:51.483+0000] {processor.py:157} INFO - Started process (PID=84748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:58:51.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:58:51.497+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:58:51.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:58:51.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:58:51.722+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:58:51.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:58:51.731+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:58:51.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:58:51.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.262 seconds
[2024-08-21T01:59:22.088+0000] {processor.py:157} INFO - Started process (PID=84758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:59:22.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:59:22.096+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:59:22.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:59:22.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:59:22.301+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:59:22.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:59:22.311+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:59:22.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:59:22.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.240 seconds
[2024-08-21T01:59:52.836+0000] {processor.py:157} INFO - Started process (PID=84768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:59:52.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T01:59:52.842+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:59:52.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:59:52.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T01:59:52.929+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:59:52.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T01:59:52.956+0000] {logging_mixin.py:151} INFO - [2024-08-21T01:59:52.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T01:59:52.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-08-21T02:00:23.136+0000] {processor.py:157} INFO - Started process (PID=84778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:00:23.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:00:23.146+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:00:23.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:00:23.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:00:23.216+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:00:23.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:00:23.231+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:00:23.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:00:23.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-21T02:00:53.558+0000] {processor.py:157} INFO - Started process (PID=84788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:00:53.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:00:53.578+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:00:53.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:00:53.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:00:53.678+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:00:53.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:00:53.835+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:00:53.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:00:53.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.293 seconds
[2024-08-21T02:01:23.919+0000] {processor.py:157} INFO - Started process (PID=84798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:01:23.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:01:23.941+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:01:23.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:01:23.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:01:23.988+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:01:23.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:01:24.139+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:01:24.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:01:24.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.236 seconds
[2024-08-21T02:01:54.537+0000] {processor.py:157} INFO - Started process (PID=84808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:01:54.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:01:54.543+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:01:54.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:01:54.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:01:54.846+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:01:54.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:01:54.860+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:01:54.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:01:54.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.342 seconds
[2024-08-21T02:02:25.128+0000] {processor.py:157} INFO - Started process (PID=84818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:02:25.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:02:25.135+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:02:25.134+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:02:25.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:02:25.349+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:02:25.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:02:25.359+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:02:25.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:02:25.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.246 seconds
[2024-08-21T02:02:55.516+0000] {processor.py:157} INFO - Started process (PID=84828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:02:55.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:02:55.524+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:02:55.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:02:55.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:02:55.603+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:02:55.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:02:55.625+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:02:55.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:02:55.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-08-21T02:03:26.069+0000] {processor.py:157} INFO - Started process (PID=84838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:03:26.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:03:26.088+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:03:26.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:03:26.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:03:26.176+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:03:26.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:03:26.193+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:03:26.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:03:26.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-08-21T02:03:56.784+0000] {processor.py:157} INFO - Started process (PID=84848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:03:56.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:03:56.791+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:03:56.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:03:56.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:03:56.851+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:03:56.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:03:57.011+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:03:57.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:03:57.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.243 seconds
[2024-08-21T02:04:27.151+0000] {processor.py:157} INFO - Started process (PID=84858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:04:27.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:04:27.159+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:04:27.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:04:27.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:04:27.220+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:04:27.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:04:27.395+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:04:27.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:04:27.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.260 seconds
[2024-08-21T02:04:57.695+0000] {processor.py:157} INFO - Started process (PID=84868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:04:57.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:04:57.700+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:04:57.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:04:57.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:04:57.914+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:04:57.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:04:57.926+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:04:57.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:04:57.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.244 seconds
[2024-08-21T02:05:28.251+0000] {processor.py:157} INFO - Started process (PID=84878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:05:28.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:05:28.267+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:05:28.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:05:28.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:05:28.559+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:05:28.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:05:28.568+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:05:28.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:05:28.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.352 seconds
[2024-08-21T02:05:58.932+0000] {processor.py:157} INFO - Started process (PID=84888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:05:58.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:05:58.941+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:05:58.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:05:58.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:05:59.023+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:05:59.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:05:59.039+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:05:59.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:05:59.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-21T02:06:29.286+0000] {processor.py:157} INFO - Started process (PID=84897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:06:29.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:06:29.297+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:06:29.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:06:29.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:06:29.352+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:06:29.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:06:29.367+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:06:29.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:06:29.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.250 seconds
[2024-08-21T02:06:59.642+0000] {processor.py:157} INFO - Started process (PID=84908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:06:59.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:06:59.649+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:06:59.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:06:59.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:06:59.748+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:06:59.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:06:59.918+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:06:59.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:06:59.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.296 seconds
[2024-08-21T02:07:30.118+0000] {processor.py:157} INFO - Started process (PID=84918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:07:30.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:07:30.127+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:07:30.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:07:30.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:07:30.217+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:07:30.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:07:30.395+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:07:30.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:07:30.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.304 seconds
[2024-08-21T02:08:00.504+0000] {processor.py:157} INFO - Started process (PID=84928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:08:00.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:08:00.510+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:08:00.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:08:00.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:08:00.750+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:08:00.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:08:00.761+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:08:00.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:08:00.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.291 seconds
[2024-08-21T02:08:31.008+0000] {processor.py:157} INFO - Started process (PID=84938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:08:31.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:08:31.018+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:08:31.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:08:31.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:08:31.282+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:08:31.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:08:31.293+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:08:31.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:08:31.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.303 seconds
[2024-08-21T02:09:01.561+0000] {processor.py:157} INFO - Started process (PID=84948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:09:01.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:09:01.574+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:09:01.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:09:01.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:09:01.624+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:09:01.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:09:01.637+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:09:01.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:09:01.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-21T02:09:31.945+0000] {processor.py:157} INFO - Started process (PID=84958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:09:31.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:09:31.954+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:09:31.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:09:31.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:09:32.019+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:09:32.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:09:32.037+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:09:32.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:09:32.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.298 seconds
[2024-08-21T02:10:02.339+0000] {processor.py:157} INFO - Started process (PID=84968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:10:02.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:10:02.351+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:10:02.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:10:02.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:10:02.444+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:10:02.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:10:02.668+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:10:02.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:10:02.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.349 seconds
[2024-08-21T02:10:32.782+0000] {processor.py:157} INFO - Started process (PID=84978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:10:32.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:10:32.793+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:10:32.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:10:32.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:10:32.855+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:10:32.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:10:33.019+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:10:33.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:10:33.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.253 seconds
[2024-08-21T02:11:03.416+0000] {processor.py:157} INFO - Started process (PID=84988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:11:03.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:11:03.429+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:11:03.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:11:03.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:11:03.638+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:11:03.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:11:03.650+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:11:03.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:11:03.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.249 seconds
[2024-08-21T02:11:34.038+0000] {processor.py:157} INFO - Started process (PID=84998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:11:34.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:11:34.054+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:11:34.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:11:34.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:11:34.243+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:11:34.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:11:34.254+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:11:34.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:11:34.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.230 seconds
[2024-08-21T02:12:04.631+0000] {processor.py:157} INFO - Started process (PID=85008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:12:04.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:12:04.638+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:12:04.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:12:04.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:12:04.702+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:12:04.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:12:04.719+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:12:04.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:12:04.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-21T02:12:35.144+0000] {processor.py:157} INFO - Started process (PID=85018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:12:35.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:12:35.153+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:12:35.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:12:35.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:12:35.213+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:12:35.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:12:35.228+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:12:35.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:12:35.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.258 seconds
[2024-08-21T02:13:05.806+0000] {processor.py:157} INFO - Started process (PID=85027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:13:05.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:13:05.813+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:13:05.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:13:05.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:13:05.856+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:13:05.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:13:06.006+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:13:06.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:13:06.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.220 seconds
[2024-08-21T02:13:36.425+0000] {processor.py:157} INFO - Started process (PID=85038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:13:36.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:13:36.437+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:13:36.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:13:36.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:13:36.495+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:13:36.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:13:36.646+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:13:36.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:13:36.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.234 seconds
[2024-08-21T02:14:07.032+0000] {processor.py:157} INFO - Started process (PID=85048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:14:07.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:14:07.040+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:14:07.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:14:07.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:14:07.348+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:14:07.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:14:07.362+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:14:07.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:14:07.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.355 seconds
[2024-08-21T02:14:37.718+0000] {processor.py:157} INFO - Started process (PID=85058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:14:37.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:14:37.724+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:14:37.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:14:37.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:14:37.965+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:14:37.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:14:37.975+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:14:37.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:14:37.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.273 seconds
[2024-08-21T02:15:08.152+0000] {processor.py:157} INFO - Started process (PID=85068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:15:08.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:15:08.156+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:15:08.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:15:08.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:15:08.237+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:15:08.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:15:08.259+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:15:08.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:15:08.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-21T02:15:38.561+0000] {processor.py:157} INFO - Started process (PID=85078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:15:38.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:15:38.566+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:15:38.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:15:38.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:15:38.626+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:15:38.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:15:38.644+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:15:38.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:15:38.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T02:16:08.958+0000] {processor.py:157} INFO - Started process (PID=85088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:16:08.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:16:08.966+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:16:08.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:16:08.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:16:09.045+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:16:09.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:16:09.062+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:16:09.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:16:09.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-08-21T02:16:39.337+0000] {processor.py:157} INFO - Started process (PID=85098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:16:39.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:16:39.342+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:16:39.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:16:39.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:16:39.385+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:16:39.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:16:39.399+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:16:39.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:16:39.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-21T02:17:09.782+0000] {processor.py:157} INFO - Started process (PID=85108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:17:09.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:17:09.786+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:17:09.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:17:09.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:17:09.846+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:17:09.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:17:09.868+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:17:09.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:17:09.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-21T02:17:40.190+0000] {processor.py:157} INFO - Started process (PID=85118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:17:40.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:17:40.202+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:17:40.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:17:40.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:17:40.252+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:17:40.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:17:40.280+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:17:40.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:17:40.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-21T02:18:10.526+0000] {processor.py:157} INFO - Started process (PID=85128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:18:10.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:18:10.532+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:18:10.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:18:10.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:18:10.595+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:18:10.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:18:10.609+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:18:10.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:18:10.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-21T02:18:41.354+0000] {processor.py:157} INFO - Started process (PID=85138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:18:41.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:18:41.376+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:18:41.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:18:41.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:18:41.486+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:18:41.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:18:41.504+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:18:41.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:18:41.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.186 seconds
[2024-08-21T02:19:11.689+0000] {processor.py:157} INFO - Started process (PID=85148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:19:11.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:19:11.701+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:19:11.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:19:11.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:19:11.820+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:19:11.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:19:11.845+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:19:11.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:19:11.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.194 seconds
[2024-08-21T02:19:42.126+0000] {processor.py:157} INFO - Started process (PID=85158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:19:42.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:19:42.141+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:19:42.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:19:42.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:19:42.190+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:19:42.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:19:42.203+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:19:42.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:19:42.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-21T02:20:12.479+0000] {processor.py:157} INFO - Started process (PID=85168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:20:12.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:20:12.486+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:20:12.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:20:12.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:20:12.551+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:20:12.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:20:12.568+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:20:12.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:20:12.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T02:20:42.856+0000] {processor.py:157} INFO - Started process (PID=85178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:20:42.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:20:42.864+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:20:42.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:20:42.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:20:42.884+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:20:42.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:20:42.894+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:20:42.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:20:42.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-21T02:21:13.242+0000] {processor.py:157} INFO - Started process (PID=85187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:21:13.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:21:13.249+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:21:13.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:21:13.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:21:13.307+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:21:13.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:21:13.322+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:21:13.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:21:13.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-21T02:21:43.545+0000] {processor.py:157} INFO - Started process (PID=85198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:21:43.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:21:43.553+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:21:43.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:21:43.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:21:43.598+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:21:43.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:21:43.613+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:21:43.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:21:43.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-21T02:22:13.889+0000] {processor.py:157} INFO - Started process (PID=85208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:22:13.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:22:13.892+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:22:13.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:22:13.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:22:13.918+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:22:13.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:22:13.936+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:22:13.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:22:13.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-21T02:22:44.375+0000] {processor.py:157} INFO - Started process (PID=85218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:22:44.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:22:44.397+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:22:44.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:22:44.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:22:44.493+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:22:44.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:22:44.509+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:22:44.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:22:44.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.215 seconds
[2024-08-21T02:23:14.732+0000] {processor.py:157} INFO - Started process (PID=85227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:23:14.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:23:14.737+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:23:14.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:23:14.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:23:14.772+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:23:14.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:23:14.788+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:23:14.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:23:14.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-21T02:23:45.027+0000] {processor.py:157} INFO - Started process (PID=85238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:23:45.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:23:45.029+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:23:45.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:23:45.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:23:45.063+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:23:45.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:23:45.079+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:23:45.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:23:45.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-21T02:24:15.436+0000] {processor.py:157} INFO - Started process (PID=85248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:24:15.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:24:15.440+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:24:15.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:24:15.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:24:15.498+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:24:15.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:24:15.513+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:24:15.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:24:15.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-21T02:24:45.843+0000] {processor.py:157} INFO - Started process (PID=85258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:24:45.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:24:45.846+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:24:45.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:24:45.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:24:45.885+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:24:45.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:24:45.898+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:24:45.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:24:45.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T02:25:16.155+0000] {processor.py:157} INFO - Started process (PID=85268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:25:16.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:25:16.160+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:25:16.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:25:16.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:25:16.200+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:25:16.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:25:16.218+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:25:16.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:25:16.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-21T02:25:46.512+0000] {processor.py:157} INFO - Started process (PID=85278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:25:46.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:25:46.515+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:25:46.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:25:46.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:25:46.583+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:25:46.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:25:46.597+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:25:46.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:25:46.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T02:26:16.909+0000] {processor.py:157} INFO - Started process (PID=85288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:26:16.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:26:16.913+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:26:16.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:26:16.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:26:16.949+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:26:16.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:26:16.963+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:26:16.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:26:16.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-21T02:26:47.241+0000] {processor.py:157} INFO - Started process (PID=85298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:26:47.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:26:47.245+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:26:47.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:26:47.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:26:47.274+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:26:47.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:26:47.284+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:26:47.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:26:47.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T02:27:17.601+0000] {processor.py:157} INFO - Started process (PID=85308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:27:17.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:27:17.606+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:27:17.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:27:17.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:27:17.643+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:27:17.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:27:17.657+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:27:17.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:27:17.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-21T02:27:47.999+0000] {processor.py:157} INFO - Started process (PID=85318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:27:48.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:27:48.005+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:27:48.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:27:48.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:27:48.036+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:27:48.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:27:48.049+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:27:48.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:27:48.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-21T02:28:18.324+0000] {processor.py:157} INFO - Started process (PID=85328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:28:18.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:28:18.328+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:28:18.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:28:18.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:28:18.365+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:28:18.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:28:18.379+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:28:18.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:28:18.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-21T02:28:48.705+0000] {processor.py:157} INFO - Started process (PID=85338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:28:48.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:28:48.709+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:28:48.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:28:48.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:28:48.742+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:28:48.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:28:48.756+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:28:48.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:28:48.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-21T02:29:19.140+0000] {processor.py:157} INFO - Started process (PID=85348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:29:19.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:29:19.144+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:29:19.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:29:19.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:29:19.197+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:29:19.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:29:19.211+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:29:19.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:29:19.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-21T02:29:49.436+0000] {processor.py:157} INFO - Started process (PID=85358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:29:49.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:29:49.439+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:29:49.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:29:49.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:29:49.467+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:29:49.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:29:49.477+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:29:49.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:29:49.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-21T02:30:19.810+0000] {processor.py:157} INFO - Started process (PID=85368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:30:19.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:30:19.814+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:30:19.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:30:19.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:30:19.851+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:30:19.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:30:19.870+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:30:19.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:30:19.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-21T02:30:50.098+0000] {processor.py:157} INFO - Started process (PID=85378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:30:50.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:30:50.103+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:30:50.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:30:50.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:30:50.157+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:30:50.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:30:50.173+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:30:50.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:30:50.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-21T02:31:20.424+0000] {processor.py:157} INFO - Started process (PID=85388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:31:20.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:31:20.429+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:31:20.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:31:20.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:31:20.480+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:31:20.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:31:20.493+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:31:20.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:31:20.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-21T02:31:50.789+0000] {processor.py:157} INFO - Started process (PID=85398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:31:50.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:31:50.794+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:31:50.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:31:50.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:31:50.832+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:31:50.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:31:50.847+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:31:50.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:31:50.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-21T02:32:21.114+0000] {processor.py:157} INFO - Started process (PID=85408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:32:21.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:32:21.116+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:32:21.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:32:21.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:32:21.145+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:32:21.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:32:21.155+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:32:21.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:32:21.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T02:32:51.489+0000] {processor.py:157} INFO - Started process (PID=85418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:32:51.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:32:51.494+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:32:51.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:32:51.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:32:51.531+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:32:51.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:32:51.546+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:32:51.546+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:32:51.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T02:33:21.803+0000] {processor.py:157} INFO - Started process (PID=85428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:33:21.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:33:21.806+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:33:21.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:33:21.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:33:21.831+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:33:21.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:33:21.842+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:33:21.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:33:21.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-21T02:33:52.159+0000] {processor.py:157} INFO - Started process (PID=85438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:33:52.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:33:52.165+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:33:52.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:33:52.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:33:52.235+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:33:52.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:33:52.253+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:33:52.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:33:52.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-21T02:34:22.435+0000] {processor.py:157} INFO - Started process (PID=85448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:34:22.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:34:22.438+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:34:22.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:34:22.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:34:22.467+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:34:22.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:34:22.478+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:34:22.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:34:22.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T02:34:52.871+0000] {processor.py:157} INFO - Started process (PID=85458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:34:52.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:34:52.876+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:34:52.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:34:52.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:34:52.935+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:34:52.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:34:52.951+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:34:52.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:34:52.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-21T02:35:23.131+0000] {processor.py:157} INFO - Started process (PID=85468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:35:23.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:35:23.133+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:35:23.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:35:23.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:35:23.155+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:35:23.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:35:23.167+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:35:23.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:35:23.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-21T02:35:53.584+0000] {processor.py:157} INFO - Started process (PID=85478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:35:53.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:35:53.603+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:35:53.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:35:53.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:35:53.681+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:35:53.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:35:53.704+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:35:53.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:35:53.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.138 seconds
[2024-08-21T02:36:24.166+0000] {processor.py:157} INFO - Started process (PID=85488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:36:24.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:36:24.170+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:36:24.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:36:24.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:36:24.282+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:36:24.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:36:24.304+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:36:24.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:36:24.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-08-21T02:36:54.467+0000] {processor.py:157} INFO - Started process (PID=85497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:36:54.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:36:54.472+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:36:54.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:36:54.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:36:54.520+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:36:54.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:36:54.536+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:36:54.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:36:54.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-21T02:37:24.766+0000] {processor.py:157} INFO - Started process (PID=85508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:37:24.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:37:24.772+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:37:24.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:37:24.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:37:24.812+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:37:24.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:37:24.827+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:37:24.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:37:24.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-21T02:37:55.149+0000] {processor.py:157} INFO - Started process (PID=85517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:37:55.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:37:55.156+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:37:55.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:37:55.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:37:55.205+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:37:55.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:37:55.220+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:37:55.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:37:55.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-21T02:38:25.424+0000] {processor.py:157} INFO - Started process (PID=85527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:38:25.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:38:25.430+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:38:25.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:38:25.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:38:25.479+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:38:25.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:38:25.494+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:38:25.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:38:25.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-21T02:38:55.859+0000] {processor.py:157} INFO - Started process (PID=85538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:38:55.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:38:55.864+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:38:55.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:38:55.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:38:55.902+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:38:55.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:38:55.915+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:38:55.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:38:55.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-21T02:39:26.250+0000] {processor.py:157} INFO - Started process (PID=85548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:39:26.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:39:26.253+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:39:26.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:39:26.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:39:26.284+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:39:26.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:39:26.295+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:39:26.295+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:39:26.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T02:39:56.641+0000] {processor.py:157} INFO - Started process (PID=85558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:39:56.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:39:56.647+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:39:56.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:39:56.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:39:56.684+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:39:56.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:39:56.698+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:39:56.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:39:56.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T02:40:26.982+0000] {processor.py:157} INFO - Started process (PID=85568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:40:26.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:40:26.985+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:40:26.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:40:26.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:40:27.010+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:40:27.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:40:27.020+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:40:27.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:40:27.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-21T02:40:57.362+0000] {processor.py:157} INFO - Started process (PID=85578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:40:57.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:40:57.369+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:40:57.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:40:57.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:40:57.408+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:40:57.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:40:57.421+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:40:57.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:40:57.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-21T02:41:27.632+0000] {processor.py:157} INFO - Started process (PID=85588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:41:27.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:41:27.636+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:41:27.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:41:27.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:41:27.664+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:41:27.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:41:27.676+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:41:27.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:41:27.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T02:41:58.022+0000] {processor.py:157} INFO - Started process (PID=85598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:41:58.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:41:58.028+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:41:58.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:41:58.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:41:58.083+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:41:58.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:41:58.097+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:41:58.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:41:58.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-21T02:42:28.414+0000] {processor.py:157} INFO - Started process (PID=85608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:42:28.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:42:28.416+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:42:28.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:42:28.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:42:28.445+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:42:28.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:42:28.455+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:42:28.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:42:28.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T02:42:58.838+0000] {processor.py:157} INFO - Started process (PID=85618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:42:58.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:42:58.860+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:42:58.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:42:58.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:42:58.902+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:42:58.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:42:58.917+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:42:58.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:42:58.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-21T02:43:29.150+0000] {processor.py:157} INFO - Started process (PID=85628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:43:29.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:43:29.152+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:43:29.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:43:29.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:43:29.178+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:43:29.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:43:29.188+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:43:29.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:43:29.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-21T02:43:59.517+0000] {processor.py:157} INFO - Started process (PID=85638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:43:59.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:43:59.522+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:43:59.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:43:59.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:43:59.557+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:43:59.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:43:59.571+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:43:59.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:43:59.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-21T02:44:29.890+0000] {processor.py:157} INFO - Started process (PID=85648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:44:29.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:44:29.892+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:44:29.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:44:29.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:44:29.922+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:44:29.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:44:29.934+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:44:29.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:44:29.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T02:45:00.319+0000] {processor.py:157} INFO - Started process (PID=85658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:45:00.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:45:00.321+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:45:00.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:45:00.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:45:00.347+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:45:00.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:45:00.357+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:45:00.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:45:00.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-21T02:45:30.627+0000] {processor.py:157} INFO - Started process (PID=85668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:45:30.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:45:30.631+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:45:30.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:45:30.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:45:30.674+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:45:30.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:45:30.689+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:45:30.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:45:30.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-21T02:46:00.910+0000] {processor.py:157} INFO - Started process (PID=85678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:46:00.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:46:00.913+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:46:00.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:46:00.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:46:00.940+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:46:00.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:46:00.954+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:46:00.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:46:00.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T02:46:31.267+0000] {processor.py:157} INFO - Started process (PID=85688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:46:31.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:46:31.273+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:46:31.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:46:31.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:46:31.314+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:46:31.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:46:31.329+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:46:31.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:46:31.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-21T02:47:01.526+0000] {processor.py:157} INFO - Started process (PID=85698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:47:01.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:47:01.530+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:47:01.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:47:01.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:47:01.558+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:47:01.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:47:01.568+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:47:01.568+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:47:01.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T02:47:31.896+0000] {processor.py:157} INFO - Started process (PID=85708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:47:31.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:47:31.902+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:47:31.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:47:31.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:47:31.951+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:47:31.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:47:31.972+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:47:31.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:47:31.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-21T02:48:02.237+0000] {processor.py:157} INFO - Started process (PID=85718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:48:02.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:48:02.240+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:48:02.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:48:02.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:48:02.269+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:48:02.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:48:02.288+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:48:02.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:48:02.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-21T02:48:32.611+0000] {processor.py:157} INFO - Started process (PID=85728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:48:32.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:48:32.617+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:48:32.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:48:32.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:48:32.685+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:48:32.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:48:32.701+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:48:32.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:48:32.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-21T02:49:02.914+0000] {processor.py:157} INFO - Started process (PID=85738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:49:02.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:49:02.921+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:49:02.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:49:02.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:49:02.960+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:49:02.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:49:02.973+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:49:02.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:49:02.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-21T02:49:33.293+0000] {processor.py:157} INFO - Started process (PID=85748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:49:33.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:49:33.299+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:49:33.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:49:33.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:49:33.348+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:49:33.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:49:33.363+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:49:33.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:49:33.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-21T02:50:03.692+0000] {processor.py:157} INFO - Started process (PID=85758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:50:03.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:50:03.695+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:50:03.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:50:03.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:50:03.726+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:50:03.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:50:03.738+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:50:03.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:50:03.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T02:50:34.082+0000] {processor.py:157} INFO - Started process (PID=85768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:50:34.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:50:34.087+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:50:34.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:50:34.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:50:34.121+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:50:34.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:50:34.134+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:50:34.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:50:34.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-21T02:51:04.441+0000] {processor.py:157} INFO - Started process (PID=85778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:51:04.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:51:04.447+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:51:04.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:51:04.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:51:04.491+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:51:04.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:51:04.507+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:51:04.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:51:04.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-21T02:51:34.726+0000] {processor.py:157} INFO - Started process (PID=85788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:51:34.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:51:34.728+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:51:34.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:51:34.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:51:34.755+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:51:34.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:51:34.767+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:51:34.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:51:34.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-21T02:52:05.092+0000] {processor.py:157} INFO - Started process (PID=85798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:52:05.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:52:05.101+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:52:05.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:52:05.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:52:05.160+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:52:05.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:52:05.182+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:52:05.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:52:05.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-21T02:52:35.464+0000] {processor.py:157} INFO - Started process (PID=85807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:52:35.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:52:35.470+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:52:35.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:52:35.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:52:35.525+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:52:35.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:52:35.539+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:52:35.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:52:35.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-21T02:53:05.774+0000] {processor.py:157} INFO - Started process (PID=85818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:53:05.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:53:05.779+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:53:05.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:53:05.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:53:05.816+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:53:05.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:53:05.829+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:53:05.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:53:05.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-21T02:53:36.116+0000] {processor.py:157} INFO - Started process (PID=85828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:53:36.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:53:36.122+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:53:36.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:53:36.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:53:36.178+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:53:36.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:53:36.195+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:53:36.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:53:36.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-21T02:54:06.555+0000] {processor.py:157} INFO - Started process (PID=85837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:54:06.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:54:06.571+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:54:06.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:54:06.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:54:06.632+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:54:06.632+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:54:06.647+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:54:06.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:54:06.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-21T02:54:36.916+0000] {processor.py:157} INFO - Started process (PID=85848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:54:36.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:54:36.922+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:54:36.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:54:36.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:54:36.978+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:54:36.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:54:36.995+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:54:36.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:54:37.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-21T02:55:07.382+0000] {processor.py:157} INFO - Started process (PID=85858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:55:07.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:55:07.391+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:55:07.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:55:07.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:55:07.434+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:55:07.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:55:07.448+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:55:07.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:55:07.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-21T02:55:37.929+0000] {processor.py:157} INFO - Started process (PID=85867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:55:37.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:55:37.933+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:55:37.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:55:37.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:55:37.980+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:55:37.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:55:37.996+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:55:37.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:55:38.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-21T02:56:08.234+0000] {processor.py:157} INFO - Started process (PID=85878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:56:08.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:56:08.238+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:56:08.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:56:08.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:56:08.274+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:56:08.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:56:08.286+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:56:08.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:56:08.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-21T02:56:38.622+0000] {processor.py:157} INFO - Started process (PID=85888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:56:38.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:56:38.627+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:56:38.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:56:38.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:56:38.657+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:56:38.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:56:38.671+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:56:38.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:56:38.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-21T02:57:08.968+0000] {processor.py:157} INFO - Started process (PID=85898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:57:08.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:57:08.975+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:57:08.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:57:08.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:57:09.014+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:57:09.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:57:09.031+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:57:09.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:57:09.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-21T02:57:39.251+0000] {processor.py:157} INFO - Started process (PID=85906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:57:39.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:57:39.255+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:57:39.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:57:39.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:57:39.291+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:57:39.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:57:39.315+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:57:39.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:57:39.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-21T02:58:09.559+0000] {processor.py:157} INFO - Started process (PID=85918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:58:09.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:58:09.562+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:58:09.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:58:09.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:58:09.591+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:58:09.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:58:09.602+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:58:09.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:58:09.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T02:58:39.915+0000] {processor.py:157} INFO - Started process (PID=85928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:58:39.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:58:39.920+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:58:39.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:58:39.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:58:39.957+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:58:39.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:58:39.969+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:58:39.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:58:39.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-21T02:59:10.269+0000] {processor.py:157} INFO - Started process (PID=85938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:59:10.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:59:10.272+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:59:10.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:59:10.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:59:10.300+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:59:10.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:59:10.314+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:59:10.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:59:10.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T02:59:40.564+0000] {processor.py:157} INFO - Started process (PID=85948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:59:40.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T02:59:40.567+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:59:40.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:59:40.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T02:59:40.593+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:59:40.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T02:59:40.603+0000] {logging_mixin.py:151} INFO - [2024-08-21T02:59:40.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T02:59:40.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-21T03:00:10.920+0000] {processor.py:157} INFO - Started process (PID=85958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:00:10.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:00:10.925+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:00:10.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:00:10.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:00:10.954+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:00:10.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:00:10.968+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:00:10.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:00:10.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-21T03:00:41.197+0000] {processor.py:157} INFO - Started process (PID=85968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:00:41.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:00:41.200+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:00:41.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:00:41.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:00:41.236+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:00:41.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:00:41.250+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:00:41.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:00:41.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-21T03:01:11.492+0000] {processor.py:157} INFO - Started process (PID=85978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:01:11.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:01:11.496+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:01:11.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:01:11.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:01:11.526+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:01:11.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:01:11.544+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:01:11.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:01:11.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-21T03:01:41.841+0000] {processor.py:157} INFO - Started process (PID=85988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:01:41.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:01:41.848+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:01:41.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:01:41.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:01:41.889+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:01:41.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:01:41.901+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:01:41.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:01:41.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-21T03:02:12.527+0000] {processor.py:157} INFO - Started process (PID=85998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:02:12.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:02:12.533+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:02:12.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:02:12.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:02:12.592+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:02:12.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:02:12.606+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:02:12.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:02:12.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-21T03:02:42.851+0000] {processor.py:157} INFO - Started process (PID=86008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:02:42.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:02:42.860+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:02:42.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:02:42.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:02:42.922+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:02:42.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:02:42.936+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:02:42.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:02:42.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-21T03:03:13.245+0000] {processor.py:157} INFO - Started process (PID=86018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:03:13.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:03:13.248+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:03:13.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:03:13.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:03:13.276+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:03:13.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:03:13.289+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:03:13.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:03:13.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-21T03:03:43.713+0000] {processor.py:157} INFO - Started process (PID=86028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:03:43.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:03:43.719+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:03:43.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:03:43.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:03:43.774+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:03:43.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:03:43.789+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:03:43.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:03:43.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-21T03:04:14.005+0000] {processor.py:157} INFO - Started process (PID=86038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:04:14.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:04:14.008+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:04:14.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:04:14.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:04:14.045+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:04:14.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:04:14.058+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:04:14.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:04:14.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T03:04:44.357+0000] {processor.py:157} INFO - Started process (PID=86048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:04:44.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:04:44.362+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:04:44.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:04:44.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:04:44.426+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:04:44.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:04:44.440+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:04:44.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:04:44.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-21T03:05:14.656+0000] {processor.py:157} INFO - Started process (PID=86058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:05:14.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:05:14.659+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:05:14.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:05:14.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:05:14.685+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:05:14.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:05:14.698+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:05:14.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:05:14.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T03:05:45.014+0000] {processor.py:157} INFO - Started process (PID=86068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:05:45.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:05:45.017+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:05:45.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:05:45.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:05:45.044+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:05:45.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:05:45.058+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:05:45.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:05:45.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T03:06:15.359+0000] {processor.py:157} INFO - Started process (PID=86078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:06:15.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:06:15.363+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:06:15.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:06:15.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:06:15.396+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:06:15.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:06:15.410+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:06:15.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:06:15.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-21T03:06:45.769+0000] {processor.py:157} INFO - Started process (PID=86088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:06:45.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:06:45.772+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:06:45.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:06:45.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:06:45.798+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:06:45.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:06:45.810+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:06:45.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:06:45.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T03:07:16.125+0000] {processor.py:157} INFO - Started process (PID=86098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:07:16.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:07:16.127+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:07:16.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:07:16.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:07:16.155+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:07:16.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:07:16.165+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:07:16.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:07:16.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T03:07:46.483+0000] {processor.py:157} INFO - Started process (PID=86108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:07:46.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:07:46.489+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:07:46.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:07:46.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:07:46.525+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:07:46.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:07:46.538+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:07:46.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:07:46.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-21T03:08:16.776+0000] {processor.py:157} INFO - Started process (PID=86118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:08:16.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:08:16.779+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:08:16.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:08:16.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:08:16.808+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:08:16.808+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:08:16.818+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:08:16.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:08:16.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T03:08:47.148+0000] {processor.py:157} INFO - Started process (PID=86128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:08:47.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:08:47.150+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:08:47.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:08:47.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:08:47.177+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:08:47.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:08:47.190+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:08:47.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:08:47.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T03:09:17.486+0000] {processor.py:157} INFO - Started process (PID=86138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:09:17.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:09:17.490+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:09:17.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:09:17.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:09:17.517+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:09:17.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:09:17.529+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:09:17.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:09:17.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T03:09:47.856+0000] {processor.py:157} INFO - Started process (PID=86148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:09:47.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:09:47.862+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:09:47.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:09:47.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:09:47.897+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:09:47.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:09:47.911+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:09:47.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:09:47.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-21T03:10:18.177+0000] {processor.py:157} INFO - Started process (PID=86158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:10:18.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:10:18.180+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:10:18.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:10:18.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:10:18.207+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:10:18.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:10:18.220+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:10:18.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:10:18.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T03:10:48.535+0000] {processor.py:157} INFO - Started process (PID=86167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:10:48.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:10:48.541+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:10:48.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:10:48.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:10:48.567+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:10:48.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:10:48.576+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:10:48.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:10:48.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T03:11:18.870+0000] {processor.py:157} INFO - Started process (PID=86178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:11:18.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:11:18.872+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:11:18.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:11:18.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:11:18.902+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:11:18.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:11:18.913+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:11:18.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:11:18.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T03:11:49.246+0000] {processor.py:157} INFO - Started process (PID=86188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:11:49.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:11:49.248+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:11:49.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:11:49.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:11:49.282+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:11:49.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:11:49.296+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:11:49.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:11:49.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-21T03:12:19.540+0000] {processor.py:157} INFO - Started process (PID=86198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:12:19.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:12:19.543+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:12:19.543+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:12:19.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:12:19.569+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:12:19.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:12:19.580+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:12:19.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:12:19.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T03:12:49.929+0000] {processor.py:157} INFO - Started process (PID=86208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:12:49.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:12:49.931+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:12:49.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:12:49.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:12:49.959+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:12:49.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:12:49.971+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:12:49.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:12:49.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T03:13:20.372+0000] {processor.py:157} INFO - Started process (PID=86218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:13:20.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:13:20.378+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:13:20.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:13:20.401+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:13:20.420+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:13:20.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:13:20.430+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:13:20.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:13:20.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-21T03:13:51.324+0000] {processor.py:157} INFO - Started process (PID=86228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:13:51.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:13:51.332+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:13:51.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:13:51.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:13:51.384+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:13:51.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:13:51.403+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:13:51.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:13:51.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-21T03:14:21.659+0000] {processor.py:157} INFO - Started process (PID=86238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:14:21.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:14:21.663+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:14:21.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:14:21.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:14:21.727+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:14:21.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:14:21.743+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:14:21.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:14:21.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T03:14:51.961+0000] {processor.py:157} INFO - Started process (PID=86248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:14:51.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:14:51.980+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:14:51.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:14:52.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:14:52.044+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:14:52.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:14:52.058+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:14:52.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:14:52.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-21T03:15:22.306+0000] {processor.py:157} INFO - Started process (PID=86258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:15:22.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:15:22.313+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:15:22.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:15:22.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:15:22.361+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:15:22.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:15:22.377+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:15:22.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:15:22.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-21T03:15:52.704+0000] {processor.py:157} INFO - Started process (PID=86268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:15:52.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:15:52.713+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:15:52.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:15:52.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:15:52.775+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:15:52.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:15:52.799+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:15:52.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:15:52.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-21T03:16:23.108+0000] {processor.py:157} INFO - Started process (PID=86278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:16:23.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:16:23.123+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:16:23.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:16:23.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:16:23.311+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:16:23.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:16:23.341+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:16:23.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:16:23.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.274 seconds
[2024-08-21T03:16:53.701+0000] {processor.py:157} INFO - Started process (PID=86287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:16:53.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:16:53.716+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:16:53.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:16:53.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:16:53.757+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:16:53.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:16:53.772+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:16:53.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:16:53.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-21T03:17:23.972+0000] {processor.py:157} INFO - Started process (PID=86298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:17:23.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:17:23.982+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:17:23.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:17:23.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:17:24.013+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:17:24.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:17:24.026+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:17:24.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:17:24.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-21T03:17:54.402+0000] {processor.py:157} INFO - Started process (PID=86308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:17:54.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:17:54.417+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:17:54.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:17:54.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:17:54.461+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:17:54.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:17:54.477+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:17:54.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:17:54.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-21T03:18:24.701+0000] {processor.py:157} INFO - Started process (PID=86318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:18:24.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:18:24.705+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:18:24.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:18:24.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:18:24.731+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:18:24.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:18:24.743+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:18:24.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:18:24.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-21T03:18:55.047+0000] {processor.py:157} INFO - Started process (PID=86328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:18:55.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:18:55.054+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:18:55.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:18:55.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:18:55.117+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:18:55.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:18:55.131+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:18:55.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:18:55.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-21T03:19:25.336+0000] {processor.py:157} INFO - Started process (PID=86338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:19:25.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:19:25.341+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:19:25.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:19:25.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:19:25.366+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:19:25.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:19:25.376+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:19:25.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:19:25.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-21T03:19:55.795+0000] {processor.py:157} INFO - Started process (PID=86348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:19:55.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:19:55.800+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:19:55.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:19:55.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:19:55.858+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:19:55.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:19:55.873+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:19:55.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:19:55.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-21T03:20:26.088+0000] {processor.py:157} INFO - Started process (PID=86358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:20:26.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:20:26.090+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:20:26.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:20:26.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:20:26.118+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:20:26.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:20:26.129+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:20:26.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:20:26.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T03:20:56.397+0000] {processor.py:157} INFO - Started process (PID=86368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:20:56.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:20:56.403+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:20:56.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:20:56.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:20:56.438+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:20:56.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:20:56.452+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:20:56.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:20:56.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-21T03:21:26.818+0000] {processor.py:157} INFO - Started process (PID=86378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:21:26.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:21:26.823+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:21:26.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:21:26.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:21:26.874+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:21:26.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:21:26.892+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:21:26.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:21:26.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-21T03:21:57.218+0000] {processor.py:157} INFO - Started process (PID=86388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:21:57.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:21:57.223+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:21:57.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:21:57.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:21:57.254+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:21:57.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:21:57.272+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:21:57.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:21:57.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-21T03:22:27.616+0000] {processor.py:157} INFO - Started process (PID=86398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:22:27.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:22:27.623+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:22:27.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:22:27.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:22:27.657+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:22:27.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:22:27.667+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:22:27.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:22:27.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-21T03:22:57.972+0000] {processor.py:157} INFO - Started process (PID=86408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:22:57.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:22:57.976+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:22:57.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:22:57.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:22:58.035+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:22:58.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:22:58.052+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:22:58.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:22:58.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-21T03:23:28.326+0000] {processor.py:157} INFO - Started process (PID=86418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:23:28.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:23:28.329+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:23:28.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:23:28.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:23:28.354+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:23:28.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:23:28.368+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:23:28.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:23:28.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T03:23:58.731+0000] {processor.py:157} INFO - Started process (PID=86428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:23:58.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:23:58.737+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:23:58.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:23:58.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:23:58.809+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:23:58.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:23:58.829+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:23:58.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:23:58.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-21T03:24:29.053+0000] {processor.py:157} INFO - Started process (PID=86438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:24:29.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:24:29.055+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:24:29.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:24:29.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:24:29.084+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:24:29.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:24:29.094+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:24:29.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:24:29.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-21T03:24:59.365+0000] {processor.py:157} INFO - Started process (PID=86448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:24:59.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:24:59.369+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:24:59.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:24:59.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:24:59.439+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:24:59.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:24:59.453+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:24:59.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:24:59.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-21T03:25:29.684+0000] {processor.py:157} INFO - Started process (PID=86458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:25:29.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:25:29.686+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:25:29.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:25:29.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:25:29.712+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:25:29.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:25:29.725+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:25:29.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:25:29.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T03:26:00.061+0000] {processor.py:157} INFO - Started process (PID=86468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:26:00.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:26:00.065+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:26:00.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:26:00.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:26:00.103+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:26:00.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:26:00.116+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:26:00.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:26:00.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T03:26:30.361+0000] {processor.py:157} INFO - Started process (PID=86478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:26:30.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:26:30.364+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:26:30.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:26:30.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:26:30.393+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:26:30.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:26:30.403+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:26:30.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:26:30.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T03:27:00.790+0000] {processor.py:157} INFO - Started process (PID=86488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:27:00.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:27:00.812+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:27:00.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:27:00.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:27:00.866+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:27:00.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:27:00.881+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:27:00.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:27:00.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-21T03:27:31.128+0000] {processor.py:157} INFO - Started process (PID=86498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:27:31.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:27:31.130+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:27:31.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:27:31.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:27:31.159+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:27:31.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:27:31.171+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:27:31.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:27:31.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T03:28:01.530+0000] {processor.py:157} INFO - Started process (PID=86507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:28:01.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:28:01.536+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:28:01.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:28:01.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:28:01.591+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:28:01.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:28:01.606+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:28:01.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:28:01.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-21T03:28:31.858+0000] {processor.py:157} INFO - Started process (PID=86518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:28:31.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:28:31.860+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:28:31.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:28:31.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:28:31.888+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:28:31.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:28:31.903+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:28:31.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:28:31.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T03:29:02.247+0000] {processor.py:157} INFO - Started process (PID=86528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:29:02.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:29:02.252+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:29:02.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:29:02.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:29:02.295+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:29:02.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:29:02.321+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:29:02.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:29:02.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-21T03:29:32.710+0000] {processor.py:157} INFO - Started process (PID=86538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:29:32.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:29:32.714+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:29:32.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:29:32.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:29:32.748+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:29:32.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:29:32.759+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:29:32.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:29:32.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-21T03:30:03.066+0000] {processor.py:157} INFO - Started process (PID=86548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:30:03.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:30:03.071+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:30:03.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:30:03.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:30:03.130+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:30:03.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:30:03.145+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:30:03.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:30:03.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-21T03:30:33.321+0000] {processor.py:157} INFO - Started process (PID=86558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:30:33.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:30:33.325+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:30:33.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:30:33.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:30:33.354+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:30:33.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:30:33.364+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:30:33.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:30:33.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T03:31:03.697+0000] {processor.py:157} INFO - Started process (PID=86568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:31:03.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:31:03.708+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:31:03.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:31:03.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:31:03.750+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:31:03.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:31:03.764+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:31:03.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:31:03.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-21T03:31:34.034+0000] {processor.py:157} INFO - Started process (PID=86578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:31:34.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:31:34.041+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:31:34.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:31:34.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:31:34.062+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:31:34.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:31:34.072+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:31:34.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:31:34.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-21T03:32:04.338+0000] {processor.py:157} INFO - Started process (PID=86588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:32:04.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:32:04.342+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:32:04.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:32:04.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:32:04.399+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:32:04.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:32:04.413+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:32:04.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:32:04.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-21T03:32:34.697+0000] {processor.py:157} INFO - Started process (PID=86598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:32:34.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:32:34.701+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:32:34.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:32:34.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:32:34.751+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:32:34.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:32:34.768+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:32:34.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:32:34.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-21T03:33:04.999+0000] {processor.py:157} INFO - Started process (PID=86608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:33:05.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:33:05.002+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:33:05.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:33:05.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:33:05.027+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:33:05.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:33:05.040+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:33:05.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:33:05.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-21T03:33:35.372+0000] {processor.py:157} INFO - Started process (PID=86618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:33:35.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:33:35.378+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:33:35.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:33:35.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:33:35.423+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:33:35.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:33:35.438+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:33:35.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:33:35.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-21T03:34:05.696+0000] {processor.py:157} INFO - Started process (PID=86628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:34:05.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:34:05.699+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:34:05.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:34:05.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:34:05.725+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:34:05.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:34:05.736+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:34:05.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:34:05.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T03:34:36.120+0000] {processor.py:157} INFO - Started process (PID=86638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:34:36.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:34:36.124+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:34:36.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:34:36.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:34:36.200+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:34:36.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:34:36.213+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:34:36.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:34:36.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-21T03:35:06.417+0000] {processor.py:157} INFO - Started process (PID=86648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:35:06.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:35:06.419+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:35:06.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:35:06.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:35:06.449+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:35:06.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:35:06.459+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:35:06.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:35:06.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T03:35:36.805+0000] {processor.py:157} INFO - Started process (PID=86658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:35:36.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:35:36.811+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:35:36.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:35:36.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:35:36.856+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:35:36.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:35:36.869+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:35:36.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:35:36.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-21T03:36:07.182+0000] {processor.py:157} INFO - Started process (PID=86668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:36:07.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:36:07.184+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:36:07.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:36:07.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:36:07.211+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:36:07.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:36:07.223+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:36:07.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:36:07.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-21T03:36:37.479+0000] {processor.py:157} INFO - Started process (PID=86678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:36:37.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:36:37.482+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:36:37.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:36:37.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:36:37.510+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:36:37.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:36:37.520+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:36:37.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:36:37.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-21T03:37:07.924+0000] {processor.py:157} INFO - Started process (PID=86687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:37:07.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:37:07.934+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:37:07.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:37:07.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:37:07.977+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:37:07.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:37:07.990+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:37:07.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:37:08.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T03:37:38.259+0000] {processor.py:157} INFO - Started process (PID=86698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:37:38.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:37:38.263+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:37:38.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:37:38.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:37:38.309+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:37:38.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:37:38.323+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:37:38.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:37:38.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-21T03:38:08.629+0000] {processor.py:157} INFO - Started process (PID=86708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:38:08.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:38:08.636+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:38:08.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:38:08.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:38:08.677+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:38:08.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:38:08.696+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:38:08.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:38:08.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-21T03:38:38.994+0000] {processor.py:157} INFO - Started process (PID=86718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:38:38.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:38:39.001+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:38:39.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:38:39.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:38:39.046+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:38:39.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:38:39.062+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:38:39.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:38:39.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-21T03:39:09.318+0000] {processor.py:157} INFO - Started process (PID=86728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:39:09.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:39:09.322+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:39:09.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:39:09.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:39:09.348+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:39:09.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:39:09.358+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:39:09.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:39:09.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-21T03:39:39.604+0000] {processor.py:157} INFO - Started process (PID=86738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:39:39.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:39:39.610+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:39:39.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:39:39.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:39:39.683+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:39:39.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:39:39.697+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:39:39.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:39:39.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-21T03:40:09.931+0000] {processor.py:157} INFO - Started process (PID=86748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:40:09.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:40:09.936+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:40:09.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:40:09.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:40:09.964+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:40:09.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:40:09.975+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:40:09.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:40:09.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T03:40:40.292+0000] {processor.py:157} INFO - Started process (PID=86758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:40:40.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:40:40.304+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:40:40.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:40:40.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:40:40.346+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:40:40.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:40:40.367+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:40:40.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:40:40.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-21T03:41:10.534+0000] {processor.py:157} INFO - Started process (PID=86768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:41:10.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:41:10.540+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:41:10.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:41:10.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:41:10.561+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:41:10.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:41:10.571+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:41:10.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:41:10.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-21T03:41:40.891+0000] {processor.py:157} INFO - Started process (PID=86778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:41:40.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:41:40.897+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:41:40.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:41:40.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:41:40.972+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:41:40.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:41:40.986+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:41:40.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:41:40.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-21T03:42:11.204+0000] {processor.py:157} INFO - Started process (PID=86788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:42:11.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:42:11.208+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:42:11.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:42:11.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:42:11.237+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:42:11.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:42:11.247+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:42:11.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:42:11.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T03:42:41.591+0000] {processor.py:157} INFO - Started process (PID=86798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:42:41.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:42:41.596+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:42:41.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:42:41.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:42:41.669+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:42:41.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:42:41.684+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:42:41.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:42:41.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-21T03:43:11.898+0000] {processor.py:157} INFO - Started process (PID=86808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:43:11.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:43:11.903+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:43:11.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:43:11.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:43:11.930+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:43:11.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:43:11.940+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:43:11.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:43:11.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-21T03:43:42.242+0000] {processor.py:157} INFO - Started process (PID=86818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:43:42.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:43:42.252+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:43:42.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:43:42.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:43:42.300+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:43:42.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:43:42.314+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:43:42.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:43:42.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-21T03:44:12.668+0000] {processor.py:157} INFO - Started process (PID=86828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:44:12.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:44:12.678+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:44:12.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:44:12.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:44:12.736+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:44:12.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:44:12.749+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:44:12.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:44:12.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-21T03:44:43.091+0000] {processor.py:157} INFO - Started process (PID=86838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:44:43.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:44:43.095+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:44:43.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:44:43.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:44:43.130+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:44:43.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:44:43.141+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:44:43.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:44:43.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-21T03:45:13.447+0000] {processor.py:157} INFO - Started process (PID=86848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:45:13.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:45:13.452+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:45:13.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:45:13.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:45:13.484+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:45:13.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:45:13.501+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:45:13.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:45:13.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T03:45:43.811+0000] {processor.py:157} INFO - Started process (PID=86858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:45:43.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:45:43.817+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:45:43.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:45:43.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:45:43.864+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:45:43.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:45:43.877+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:45:43.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:45:43.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-21T03:46:14.325+0000] {processor.py:157} INFO - Started process (PID=86868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:46:14.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:46:14.330+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:46:14.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:46:14.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:46:14.371+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:46:14.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:46:14.385+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:46:14.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:46:14.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-21T03:46:44.771+0000] {processor.py:157} INFO - Started process (PID=86878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:46:44.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:46:44.775+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:46:44.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:46:44.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:46:44.814+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:46:44.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:46:44.825+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:46:44.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:46:44.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-21T03:47:15.213+0000] {processor.py:157} INFO - Started process (PID=86888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:47:15.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:47:15.219+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:47:15.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:47:15.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:47:15.258+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:47:15.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:47:15.270+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:47:15.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:47:15.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-21T03:47:45.555+0000] {processor.py:157} INFO - Started process (PID=86898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:47:45.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:47:45.560+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:47:45.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:47:45.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:47:45.593+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:47:45.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:47:45.606+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:47:45.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:47:45.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-21T03:48:15.950+0000] {processor.py:157} INFO - Started process (PID=86908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:48:15.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:48:15.955+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:48:15.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:48:15.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:48:16.019+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:48:16.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:48:16.030+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:48:16.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:48:16.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-21T03:48:46.385+0000] {processor.py:157} INFO - Started process (PID=86918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:48:46.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:48:46.390+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:48:46.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:48:46.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:48:46.449+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:48:46.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:48:46.470+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:48:46.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:48:46.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T03:49:16.815+0000] {processor.py:157} INFO - Started process (PID=86928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:49:16.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:49:16.822+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:49:16.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:49:16.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:49:16.885+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:49:16.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:49:16.911+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:49:16.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:49:16.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-21T03:49:47.288+0000] {processor.py:157} INFO - Started process (PID=86938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:49:47.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:49:47.291+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:49:47.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:49:47.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:49:47.318+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:49:47.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:49:47.330+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:49:47.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:49:47.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-21T03:50:17.766+0000] {processor.py:157} INFO - Started process (PID=86948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:50:17.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:50:17.783+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:50:17.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:50:17.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:50:17.831+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:50:17.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:50:17.846+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:50:17.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:50:17.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-21T03:50:48.195+0000] {processor.py:157} INFO - Started process (PID=86958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:50:48.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:50:48.205+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:50:48.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:50:48.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:50:48.266+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:50:48.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:50:48.283+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:50:48.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:50:48.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-21T03:51:18.669+0000] {processor.py:157} INFO - Started process (PID=86967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:51:18.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:51:18.673+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:51:18.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:51:18.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:51:18.713+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:51:18.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:51:18.726+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:51:18.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:51:18.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-21T03:51:49.017+0000] {processor.py:157} INFO - Started process (PID=86978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:51:49.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:51:49.020+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:51:49.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:51:49.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:51:49.050+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:51:49.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:51:49.063+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:51:49.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:51:49.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-21T03:52:19.396+0000] {processor.py:157} INFO - Started process (PID=86988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:52:19.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:52:19.401+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:52:19.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:52:19.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:52:19.442+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:52:19.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:52:19.454+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:52:19.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:52:19.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-21T03:52:49.875+0000] {processor.py:157} INFO - Started process (PID=86998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:52:49.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:52:49.887+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:52:49.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:52:49.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:52:49.941+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:52:49.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:52:49.954+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:52:49.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:52:49.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-21T03:53:20.192+0000] {processor.py:157} INFO - Started process (PID=87008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:53:20.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:53:20.194+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:53:20.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:53:20.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:53:20.221+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:53:20.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:53:20.233+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:53:20.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:53:20.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-21T03:53:50.679+0000] {processor.py:157} INFO - Started process (PID=87018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:53:50.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:53:50.690+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:53:50.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:53:50.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:53:50.744+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:53:50.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:53:50.769+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:53:50.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:53:50.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-21T03:54:21.155+0000] {processor.py:157} INFO - Started process (PID=87028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:54:21.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:54:21.159+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:54:21.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:54:21.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:54:21.187+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:54:21.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:54:21.199+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:54:21.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:54:21.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T03:54:51.612+0000] {processor.py:157} INFO - Started process (PID=87038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:54:51.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:54:51.619+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:54:51.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:54:51.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:54:51.676+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:54:51.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:54:51.690+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:54:51.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:54:51.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-21T03:55:21.923+0000] {processor.py:157} INFO - Started process (PID=87048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:55:21.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:55:21.927+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:55:21.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:55:21.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:55:21.964+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:55:21.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:55:21.977+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:55:21.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:55:21.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-21T03:55:52.278+0000] {processor.py:157} INFO - Started process (PID=87058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:55:52.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:55:52.285+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:55:52.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:55:52.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:55:52.308+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:55:52.308+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:55:52.318+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:55:52.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:55:52.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T03:56:22.647+0000] {processor.py:157} INFO - Started process (PID=87068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:56:22.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:56:22.657+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:56:22.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:56:22.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:56:22.717+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:56:22.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:56:22.735+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:56:22.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:56:22.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-21T03:56:53.051+0000] {processor.py:157} INFO - Started process (PID=87078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:56:53.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:56:53.056+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:56:53.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:56:53.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:56:53.097+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:56:53.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:56:53.112+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:56:53.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:56:53.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-21T03:57:23.349+0000] {processor.py:157} INFO - Started process (PID=87087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:57:23.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:57:23.351+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:57:23.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:57:23.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:57:23.374+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:57:23.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:57:23.383+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:57:23.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:57:23.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-08-21T03:57:53.779+0000] {processor.py:157} INFO - Started process (PID=87098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:57:53.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:57:53.785+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:57:53.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:57:53.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:57:53.848+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:57:53.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:57:53.863+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:57:53.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:57:53.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-21T03:58:24.112+0000] {processor.py:157} INFO - Started process (PID=87108) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:58:24.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:58:24.117+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:58:24.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:58:24.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:58:24.146+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:58:24.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:58:24.156+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:58:24.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:58:24.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T03:58:54.550+0000] {processor.py:157} INFO - Started process (PID=87118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:58:54.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:58:54.562+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:58:54.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:58:54.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:58:54.630+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:58:54.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:58:54.644+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:58:54.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:58:54.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-21T03:59:24.908+0000] {processor.py:157} INFO - Started process (PID=87128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:59:24.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:59:24.916+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:59:24.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:59:24.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:59:24.938+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:59:24.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:59:24.947+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:59:24.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:59:24.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-21T03:59:55.238+0000] {processor.py:157} INFO - Started process (PID=87138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:59:55.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T03:59:55.261+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:59:55.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:59:55.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T03:59:55.309+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:59:55.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T03:59:55.324+0000] {logging_mixin.py:151} INFO - [2024-08-21T03:59:55.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T03:59:55.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-21T04:00:25.562+0000] {processor.py:157} INFO - Started process (PID=87148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:00:25.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:00:25.568+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:00:25.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:00:25.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:00:25.629+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:00:25.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:00:25.642+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:00:25.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:00:25.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-21T04:00:55.989+0000] {processor.py:157} INFO - Started process (PID=87158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:00:55.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:00:55.995+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:00:55.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:00:56.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:00:56.030+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:00:56.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:00:56.043+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:00:56.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:00:56.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-21T04:01:26.362+0000] {processor.py:157} INFO - Started process (PID=87168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:01:26.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:01:26.366+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:01:26.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:01:26.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:01:26.396+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:01:26.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:01:26.413+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:01:26.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:01:26.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-21T04:01:56.809+0000] {processor.py:157} INFO - Started process (PID=87178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:01:56.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:01:56.816+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:01:56.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:01:56.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:01:56.873+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:01:56.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:01:56.886+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:01:56.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:01:56.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-21T04:02:27.164+0000] {processor.py:157} INFO - Started process (PID=87188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:02:27.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:02:27.168+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:02:27.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:02:27.180+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:02:27.196+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:02:27.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:02:27.208+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:02:27.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:02:27.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T04:02:57.539+0000] {processor.py:157} INFO - Started process (PID=87198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:02:57.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:02:57.551+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:02:57.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:02:57.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:02:57.600+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:02:57.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:02:57.636+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:02:57.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:02:57.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-21T04:03:27.880+0000] {processor.py:157} INFO - Started process (PID=87208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:03:27.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:03:27.884+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:03:27.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:03:27.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:03:27.914+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:03:27.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:03:27.924+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:03:27.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:03:27.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T04:03:58.340+0000] {processor.py:157} INFO - Started process (PID=87217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:03:58.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:03:58.358+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:03:58.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:03:58.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:03:58.429+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:03:58.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:03:58.442+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:03:58.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:03:58.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-21T04:04:28.787+0000] {processor.py:157} INFO - Started process (PID=87228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:04:28.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:04:28.790+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:04:28.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:04:28.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:04:28.820+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:04:28.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:04:28.831+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:04:28.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:04:28.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T04:04:59.175+0000] {processor.py:157} INFO - Started process (PID=87237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:04:59.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:04:59.181+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:04:59.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:04:59.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:04:59.255+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:04:59.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:04:59.268+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:04:59.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:04:59.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-21T04:05:29.493+0000] {processor.py:157} INFO - Started process (PID=87248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:05:29.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:05:29.496+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:05:29.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:05:29.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:05:29.526+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:05:29.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:05:29.539+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:05:29.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:05:29.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-21T04:05:59.859+0000] {processor.py:157} INFO - Started process (PID=87258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:05:59.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:05:59.865+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:05:59.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:05:59.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:05:59.899+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:05:59.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:05:59.912+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:05:59.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:05:59.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-21T04:06:30.320+0000] {processor.py:157} INFO - Started process (PID=87268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:06:30.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:06:30.324+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:06:30.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:06:30.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:06:30.375+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:06:30.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:06:30.389+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:06:30.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:06:30.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-21T04:07:00.624+0000] {processor.py:157} INFO - Started process (PID=87278) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:07:00.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:07:00.627+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:07:00.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:07:00.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:07:00.654+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:07:00.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:07:00.665+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:07:00.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:07:00.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T04:07:30.970+0000] {processor.py:157} INFO - Started process (PID=87287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:07:30.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:07:30.977+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:07:30.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:07:31.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:07:31.028+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:07:31.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:07:31.044+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:07:31.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:07:31.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-21T04:08:01.287+0000] {processor.py:157} INFO - Started process (PID=87298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:08:01.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:08:01.292+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:08:01.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:08:01.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:08:01.342+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:08:01.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:08:01.355+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:08:01.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:08:01.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-21T04:08:31.661+0000] {processor.py:157} INFO - Started process (PID=87308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:08:31.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:08:31.663+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:08:31.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:08:31.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:08:31.693+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:08:31.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:08:31.704+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:08:31.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:08:31.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T04:09:02.007+0000] {processor.py:157} INFO - Started process (PID=87318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:09:02.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:09:02.013+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:09:02.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:09:02.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:09:02.079+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:09:02.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:09:02.092+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:09:02.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:09:02.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T04:09:32.422+0000] {processor.py:157} INFO - Started process (PID=87328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:09:32.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:09:32.426+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:09:32.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:09:32.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:09:32.452+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:09:32.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:09:32.463+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:09:32.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:09:32.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-21T04:10:02.849+0000] {processor.py:157} INFO - Started process (PID=87338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:10:02.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:10:02.855+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:10:02.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:10:02.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:10:02.898+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:10:02.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:10:02.913+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:10:02.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:10:02.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-21T04:10:33.243+0000] {processor.py:157} INFO - Started process (PID=87348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:10:33.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:10:33.248+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:10:33.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:10:33.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:10:33.275+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:10:33.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:10:33.285+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:10:33.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:10:33.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-21T04:11:03.637+0000] {processor.py:157} INFO - Started process (PID=87358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:11:03.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:11:03.652+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:11:03.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:11:03.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:11:03.715+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:11:03.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:11:03.729+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:11:03.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:11:03.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-21T04:11:34.232+0000] {processor.py:157} INFO - Started process (PID=87368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:11:34.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:11:34.239+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:11:34.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:11:34.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:11:34.304+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:11:34.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:11:34.319+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:11:34.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:11:34.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-21T04:12:04.542+0000] {processor.py:157} INFO - Started process (PID=87378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:12:04.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:12:04.546+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:12:04.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:12:04.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:12:04.575+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:12:04.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:12:04.587+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:12:04.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:12:04.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T04:12:34.878+0000] {processor.py:157} INFO - Started process (PID=87388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:12:34.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:12:34.881+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:12:34.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:12:34.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:12:34.909+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:12:34.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:12:34.919+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:12:34.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:12:34.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-21T04:13:05.184+0000] {processor.py:157} INFO - Started process (PID=87398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:13:05.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:13:05.191+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:13:05.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:13:05.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:13:05.234+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:13:05.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:13:05.250+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:13:05.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:13:05.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-21T04:13:35.573+0000] {processor.py:157} INFO - Started process (PID=87408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:13:35.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:13:35.578+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:13:35.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:13:35.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:13:35.602+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:13:35.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:13:35.611+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:13:35.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:13:35.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-21T04:14:05.911+0000] {processor.py:157} INFO - Started process (PID=87418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:14:05.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:14:05.914+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:14:05.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:14:05.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:14:05.944+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:14:05.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:14:05.956+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:14:05.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:14:05.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T04:14:36.288+0000] {processor.py:157} INFO - Started process (PID=87428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:14:36.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:14:36.293+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:14:36.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:14:36.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:14:36.340+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:14:36.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:14:36.353+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:14:36.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:14:36.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-21T04:15:06.672+0000] {processor.py:157} INFO - Started process (PID=87438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:15:06.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:15:06.677+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:15:06.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:15:06.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:15:06.705+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:15:06.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:15:06.715+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:15:06.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:15:06.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T04:15:37.057+0000] {processor.py:157} INFO - Started process (PID=87448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:15:37.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:15:37.064+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:15:37.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:15:37.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:15:37.128+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:15:37.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:15:37.154+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:15:37.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:15:37.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-21T04:16:07.311+0000] {processor.py:157} INFO - Started process (PID=87458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:16:07.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:16:07.314+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:16:07.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:16:07.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:16:07.355+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:16:07.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:16:07.365+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:16:07.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:16:07.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-21T04:16:37.703+0000] {processor.py:157} INFO - Started process (PID=87467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:16:37.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:16:37.708+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:16:37.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:16:37.724+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:16:37.748+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:16:37.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:16:37.764+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:16:37.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:16:37.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-21T04:17:08.093+0000] {processor.py:157} INFO - Started process (PID=87478) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:17:08.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:17:08.097+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:17:08.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:17:08.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:17:08.125+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:17:08.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:17:08.140+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:17:08.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:17:08.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T04:17:38.374+0000] {processor.py:157} INFO - Started process (PID=87488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:17:38.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:17:38.377+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:17:38.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:17:38.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:17:38.407+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:17:38.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:17:38.419+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:17:38.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:17:38.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T04:18:08.805+0000] {processor.py:157} INFO - Started process (PID=87498) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:18:08.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:18:08.821+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:18:08.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:18:08.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:18:08.869+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:18:08.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:18:08.880+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:18:08.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:18:08.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-21T04:18:39.154+0000] {processor.py:157} INFO - Started process (PID=87508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:18:39.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:18:39.158+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:18:39.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:18:39.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:18:39.191+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:18:39.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:18:39.203+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:18:39.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:18:39.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-21T04:19:09.408+0000] {processor.py:157} INFO - Started process (PID=87518) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:19:09.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:19:09.412+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:19:09.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:19:09.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:19:09.445+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:19:09.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:19:09.456+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:19:09.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:19:09.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T04:19:39.770+0000] {processor.py:157} INFO - Started process (PID=87528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:19:39.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:19:39.776+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:19:39.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:19:39.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:19:39.803+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:19:39.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:19:39.814+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:19:39.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:19:39.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T04:20:10.165+0000] {processor.py:157} INFO - Started process (PID=87537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:20:10.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:20:10.172+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:20:10.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:20:10.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:20:10.231+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:20:10.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:20:10.254+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:20:10.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:20:10.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-21T04:20:40.434+0000] {processor.py:157} INFO - Started process (PID=87548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:20:40.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:20:40.437+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:20:40.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:20:40.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:20:40.468+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:20:40.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:20:40.479+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:20:40.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:20:40.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-21T04:21:10.801+0000] {processor.py:157} INFO - Started process (PID=87558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:21:10.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:21:10.807+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:21:10.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:21:10.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:21:10.863+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:21:10.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:21:10.883+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:21:10.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:21:10.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-21T04:21:41.110+0000] {processor.py:157} INFO - Started process (PID=87568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:21:41.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:21:41.116+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:21:41.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:21:41.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:21:41.174+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:21:41.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:21:41.187+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:21:41.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:21:41.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-21T04:22:11.452+0000] {processor.py:157} INFO - Started process (PID=87578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:22:11.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:22:11.460+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:22:11.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:22:11.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:22:11.530+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:22:11.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:22:11.547+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:22:11.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:22:11.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-21T04:22:41.759+0000] {processor.py:157} INFO - Started process (PID=87588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:22:41.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:22:41.763+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:22:41.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:22:41.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:22:41.795+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:22:41.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:22:41.806+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:22:41.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:22:41.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T04:23:12.135+0000] {processor.py:157} INFO - Started process (PID=87598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:23:12.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:23:12.138+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:23:12.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:23:12.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:23:12.184+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:23:12.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:23:12.200+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:23:12.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:23:12.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-21T04:23:42.407+0000] {processor.py:157} INFO - Started process (PID=87608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:23:42.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:23:42.412+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:23:42.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:23:42.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:23:42.452+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:23:42.452+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:23:42.467+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:23:42.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:23:42.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-21T04:24:12.716+0000] {processor.py:157} INFO - Started process (PID=87618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:24:12.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:24:12.719+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:24:12.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:24:12.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:24:12.747+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:24:12.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:24:12.758+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:24:12.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:24:12.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T04:24:43.122+0000] {processor.py:157} INFO - Started process (PID=87628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:24:43.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:24:43.128+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:24:43.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:24:43.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:24:43.165+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:24:43.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:24:43.178+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:24:43.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:24:43.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-21T04:25:13.469+0000] {processor.py:157} INFO - Started process (PID=87638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:25:13.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:25:13.473+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:25:13.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:25:13.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:25:13.501+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:25:13.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:25:13.512+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:25:13.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:25:13.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T04:25:43.833+0000] {processor.py:157} INFO - Started process (PID=87648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:25:43.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:25:43.836+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:25:43.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:25:43.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:25:43.861+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:25:43.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:25:43.870+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:25:43.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:25:43.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-21T04:26:14.180+0000] {processor.py:157} INFO - Started process (PID=87658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:26:14.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:26:14.185+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:26:14.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:26:14.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:26:14.212+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:26:14.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:26:14.222+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:26:14.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:26:14.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T04:26:44.501+0000] {processor.py:157} INFO - Started process (PID=87668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:26:44.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:26:44.506+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:26:44.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:26:44.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:26:44.551+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:26:44.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:26:44.563+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:26:44.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:26:44.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-21T04:27:14.760+0000] {processor.py:157} INFO - Started process (PID=87678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:27:14.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:27:14.765+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:27:14.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:27:14.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:27:14.790+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:27:14.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:27:14.799+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:27:14.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:27:14.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-21T04:27:45.106+0000] {processor.py:157} INFO - Started process (PID=87688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:27:45.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:27:45.113+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:27:45.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:27:45.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:27:45.152+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:27:45.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:27:45.167+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:27:45.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:27:45.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-21T04:28:15.435+0000] {processor.py:157} INFO - Started process (PID=87698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:28:15.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:28:15.438+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:28:15.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:28:15.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:28:15.467+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:28:15.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:28:15.478+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:28:15.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:28:15.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T04:28:45.784+0000] {processor.py:157} INFO - Started process (PID=87708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:28:45.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:28:45.791+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:28:45.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:28:45.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:28:45.832+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:28:45.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:28:45.846+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:28:45.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:28:45.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-21T04:29:16.117+0000] {processor.py:157} INFO - Started process (PID=87718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:29:16.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:29:16.121+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:29:16.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:29:16.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:29:16.152+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:29:16.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:29:16.164+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:29:16.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:29:16.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T04:29:46.439+0000] {processor.py:157} INFO - Started process (PID=87728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:29:46.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:29:46.444+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:29:46.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:29:46.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:29:46.472+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:29:46.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:29:46.481+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:29:46.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:29:46.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T04:30:16.827+0000] {processor.py:157} INFO - Started process (PID=87738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:30:16.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:30:16.830+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:30:16.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:30:16.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:30:16.868+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:30:16.868+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:30:16.881+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:30:16.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:30:16.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-21T04:30:47.115+0000] {processor.py:157} INFO - Started process (PID=87748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:30:47.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:30:47.118+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:30:47.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:30:47.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:30:47.143+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:30:47.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:30:47.153+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:30:47.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:30:47.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-21T04:31:17.555+0000] {processor.py:157} INFO - Started process (PID=87758) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:31:17.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:31:17.558+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:31:17.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:31:17.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:31:17.587+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:31:17.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:31:17.598+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:31:17.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:31:17.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T04:31:47.947+0000] {processor.py:157} INFO - Started process (PID=87768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:31:47.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:31:47.953+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:31:47.953+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:31:47.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:31:47.995+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:31:47.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:31:48.015+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:31:48.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:31:48.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-21T04:32:18.388+0000] {processor.py:157} INFO - Started process (PID=87778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:32:18.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:32:18.391+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:32:18.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:32:18.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:32:18.429+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:32:18.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:32:18.444+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:32:18.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:32:18.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T04:32:48.771+0000] {processor.py:157} INFO - Started process (PID=87788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:32:48.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:32:48.775+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:32:48.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:32:48.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:32:48.829+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:32:48.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:32:48.843+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:32:48.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:32:48.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-21T04:33:19.121+0000] {processor.py:157} INFO - Started process (PID=87798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:33:19.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:33:19.123+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:33:19.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:33:19.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:33:19.158+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:33:19.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:33:19.169+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:33:19.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:33:19.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-21T04:33:49.474+0000] {processor.py:157} INFO - Started process (PID=87808) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:33:49.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:33:49.480+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:33:49.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:33:49.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:33:49.553+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:33:49.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:33:49.566+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:33:49.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:33:49.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-21T04:34:19.804+0000] {processor.py:157} INFO - Started process (PID=87818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:34:19.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:34:19.808+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:34:19.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:34:19.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:34:19.838+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:34:19.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:34:19.851+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:34:19.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:34:19.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-21T04:34:50.251+0000] {processor.py:157} INFO - Started process (PID=87828) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:34:50.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:34:50.257+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:34:50.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:34:50.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:34:50.325+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:34:50.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:34:50.338+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:34:50.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:34:50.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T04:35:20.618+0000] {processor.py:157} INFO - Started process (PID=87838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:35:20.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:35:20.621+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:35:20.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:35:20.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:35:20.647+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:35:20.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:35:20.657+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:35:20.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:35:20.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-21T04:35:51.003+0000] {processor.py:157} INFO - Started process (PID=87848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:35:51.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:35:51.008+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:35:51.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:35:51.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:35:51.072+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:35:51.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:35:51.083+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:35:51.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:35:51.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-21T04:36:21.362+0000] {processor.py:157} INFO - Started process (PID=87858) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:36:21.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:36:21.365+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:36:21.365+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:36:21.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:36:21.390+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:36:21.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:36:21.401+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:36:21.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:36:21.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-21T04:36:51.717+0000] {processor.py:157} INFO - Started process (PID=87868) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:36:51.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:36:51.722+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:36:51.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:36:51.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:36:51.760+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:36:51.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:36:51.772+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:36:51.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:36:51.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-21T04:37:22.115+0000] {processor.py:157} INFO - Started process (PID=87878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:37:22.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:37:22.118+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:37:22.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:37:22.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:37:22.143+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:37:22.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:37:22.154+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:37:22.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:37:22.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T04:37:52.505+0000] {processor.py:157} INFO - Started process (PID=87888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:37:52.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:37:52.523+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:37:52.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:37:52.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:37:52.592+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:37:52.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:37:52.605+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:37:52.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:37:52.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-21T04:38:22.991+0000] {processor.py:157} INFO - Started process (PID=87898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:38:22.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:38:22.997+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:38:22.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:38:23.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:38:23.033+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:38:23.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:38:23.049+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:38:23.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:38:23.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-21T04:38:53.384+0000] {processor.py:157} INFO - Started process (PID=87908) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:38:53.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:38:53.390+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:38:53.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:38:53.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:38:53.430+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:38:53.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:38:53.442+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:38:53.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:38:53.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-21T04:39:23.770+0000] {processor.py:157} INFO - Started process (PID=87918) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:39:23.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:39:23.775+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:39:23.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:39:23.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:39:23.826+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:39:23.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:39:23.839+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:39:23.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:39:23.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-21T04:39:54.159+0000] {processor.py:157} INFO - Started process (PID=87928) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:39:54.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:39:54.164+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:39:54.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:39:54.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:39:54.222+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:39:54.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:39:54.240+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:39:54.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:39:54.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-21T04:40:24.500+0000] {processor.py:157} INFO - Started process (PID=87938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:40:24.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:40:24.507+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:40:24.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:40:24.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:40:24.540+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:40:24.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:40:24.551+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:40:24.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:40:24.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-21T04:40:54.882+0000] {processor.py:157} INFO - Started process (PID=87948) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:40:54.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:40:54.889+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:40:54.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:40:54.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:40:54.955+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:40:54.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:40:54.969+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:40:54.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:40:54.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-21T04:41:25.259+0000] {processor.py:157} INFO - Started process (PID=87958) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:41:25.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:41:25.263+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:41:25.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:41:25.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:41:25.304+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:41:25.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:41:25.322+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:41:25.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:41:25.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-21T04:41:55.716+0000] {processor.py:157} INFO - Started process (PID=87968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:41:55.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:41:55.722+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:41:55.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:41:55.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:41:55.768+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:41:55.767+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:41:55.784+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:41:55.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:41:55.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-21T04:42:26.168+0000] {processor.py:157} INFO - Started process (PID=87978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:42:26.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:42:26.172+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:42:26.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:42:26.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:42:26.222+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:42:26.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:42:26.240+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:42:26.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:42:26.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-21T04:42:56.686+0000] {processor.py:157} INFO - Started process (PID=87987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:42:56.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:42:56.692+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:42:56.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:42:56.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:42:56.765+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:42:56.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:42:56.774+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:42:56.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:42:56.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-21T04:43:27.089+0000] {processor.py:157} INFO - Started process (PID=87998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:43:27.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:43:27.093+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:43:27.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:43:27.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:43:27.122+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:43:27.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:43:27.135+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:43:27.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:43:27.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-21T04:43:57.529+0000] {processor.py:157} INFO - Started process (PID=88008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:43:57.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:43:57.536+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:43:57.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:43:57.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:43:57.586+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:43:57.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:43:57.602+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:43:57.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:43:57.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-21T04:44:28.032+0000] {processor.py:157} INFO - Started process (PID=88018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:44:28.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:44:28.035+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:44:28.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:44:28.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:44:28.065+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:44:28.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:44:28.075+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:44:28.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:44:28.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T04:44:58.383+0000] {processor.py:157} INFO - Started process (PID=88028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:44:58.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:44:58.390+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:44:58.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:44:58.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:44:58.459+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:44:58.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:44:58.474+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:44:58.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:44:58.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-21T04:45:28.889+0000] {processor.py:157} INFO - Started process (PID=88038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:45:28.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:45:28.912+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:45:28.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:45:28.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:45:28.997+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:45:28.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:45:29.014+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:45:29.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:45:29.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-08-21T04:45:59.278+0000] {processor.py:157} INFO - Started process (PID=88048) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:45:59.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:45:59.286+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:45:59.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:45:59.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:45:59.353+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:45:59.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:45:59.369+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:45:59.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:45:59.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-21T04:46:29.648+0000] {processor.py:157} INFO - Started process (PID=88058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:46:29.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:46:29.657+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:46:29.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:46:29.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:46:29.679+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:46:29.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:46:29.689+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:46:29.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:46:29.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-21T04:47:00.046+0000] {processor.py:157} INFO - Started process (PID=88067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:47:00.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:47:00.052+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:47:00.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:47:00.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:47:00.096+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:47:00.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:47:00.129+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:47:00.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:47:00.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-21T04:47:30.481+0000] {processor.py:157} INFO - Started process (PID=88078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:47:30.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:47:30.485+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:47:30.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:47:30.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:47:30.513+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:47:30.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:47:30.522+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:47:30.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:47:30.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T04:48:00.914+0000] {processor.py:157} INFO - Started process (PID=88088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:48:00.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:48:00.939+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:48:00.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:48:00.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:48:00.984+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:48:00.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:48:00.998+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:48:00.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:48:01.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-21T04:48:31.281+0000] {processor.py:157} INFO - Started process (PID=88098) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:48:31.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:48:31.285+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:48:31.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:48:31.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:48:31.313+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:48:31.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:48:31.323+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:48:31.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:48:31.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T04:49:01.701+0000] {processor.py:157} INFO - Started process (PID=88107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:49:01.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:49:01.706+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:49:01.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:49:01.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:49:01.760+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:49:01.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:49:01.781+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:49:01.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:49:01.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-21T04:49:32.045+0000] {processor.py:157} INFO - Started process (PID=88118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:49:32.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:49:32.048+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:49:32.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:49:32.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:49:32.090+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:49:32.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:49:32.103+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:49:32.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:49:32.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-21T04:50:02.529+0000] {processor.py:157} INFO - Started process (PID=88128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:50:02.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:50:02.534+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:50:02.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:50:02.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:50:02.589+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:50:02.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:50:02.611+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:50:02.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:50:02.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-08-21T04:50:32.837+0000] {processor.py:157} INFO - Started process (PID=88138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:50:32.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:50:32.841+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:50:32.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:50:32.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:50:32.873+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:50:32.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:50:32.884+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:50:32.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:50:32.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-21T04:51:03.297+0000] {processor.py:157} INFO - Started process (PID=88148) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:51:03.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:51:03.302+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:51:03.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:51:03.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:51:03.366+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:51:03.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:51:03.378+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:51:03.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:51:03.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-21T04:51:33.638+0000] {processor.py:157} INFO - Started process (PID=88158) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:51:33.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:51:33.643+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:51:33.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:51:33.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:51:33.674+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:51:33.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:51:33.684+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:51:33.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:51:33.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T04:52:03.951+0000] {processor.py:157} INFO - Started process (PID=88168) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:52:03.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:52:03.956+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:52:03.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:52:03.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:52:04.008+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:52:04.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:52:04.036+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:52:04.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:52:04.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T04:52:34.254+0000] {processor.py:157} INFO - Started process (PID=88178) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:52:34.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:52:34.259+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:52:34.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:52:34.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:52:34.294+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:52:34.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:52:34.307+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:52:34.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:52:34.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-08-21T04:53:04.653+0000] {processor.py:157} INFO - Started process (PID=88188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:53:04.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:53:04.659+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:53:04.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:53:04.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:53:04.730+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:53:04.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:53:04.744+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:53:04.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:53:04.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-21T04:53:34.945+0000] {processor.py:157} INFO - Started process (PID=88198) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:53:34.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:53:34.948+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:53:34.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:53:34.964+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:53:34.978+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:53:34.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:53:34.990+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:53:34.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:53:34.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T04:54:05.299+0000] {processor.py:157} INFO - Started process (PID=88208) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:54:05.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:54:05.306+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:54:05.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:54:05.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:54:05.368+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:54:05.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:54:05.381+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:54:05.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:54:05.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-21T04:54:35.693+0000] {processor.py:157} INFO - Started process (PID=88218) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:54:35.694+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:54:35.696+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:54:35.696+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:54:35.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:54:35.782+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:54:35.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:54:35.797+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:54:35.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:54:35.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-21T04:55:06.075+0000] {processor.py:157} INFO - Started process (PID=88228) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:55:06.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:55:06.081+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:55:06.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:55:06.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:55:06.146+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:55:06.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:55:06.161+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:55:06.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:55:06.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-21T04:55:36.429+0000] {processor.py:157} INFO - Started process (PID=88238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:55:36.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:55:36.445+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:55:36.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:55:36.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:55:36.482+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:55:36.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:55:36.496+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:55:36.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:55:36.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-21T04:56:06.904+0000] {processor.py:157} INFO - Started process (PID=88248) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:56:06.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:56:06.909+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:56:06.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:56:06.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:56:06.937+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:56:06.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:56:06.947+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:56:06.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:56:06.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T04:56:37.392+0000] {processor.py:157} INFO - Started process (PID=88258) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:56:37.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:56:37.397+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:56:37.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:56:37.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:56:37.449+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:56:37.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:56:37.474+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:56:37.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:56:37.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T04:57:07.665+0000] {processor.py:157} INFO - Started process (PID=88268) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:57:07.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:57:07.670+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:57:07.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:57:07.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:57:07.698+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:57:07.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:57:07.709+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:57:07.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:57:07.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T04:57:38.041+0000] {processor.py:157} INFO - Started process (PID=88277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:57:38.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:57:38.047+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:57:38.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:57:38.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:57:38.090+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:57:38.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:57:38.104+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:57:38.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:57:38.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-21T04:58:08.435+0000] {processor.py:157} INFO - Started process (PID=88288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:58:08.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:58:08.439+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:58:08.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:58:08.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:58:08.467+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:58:08.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:58:08.476+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:58:08.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:58:08.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-21T04:58:38.772+0000] {processor.py:157} INFO - Started process (PID=88298) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:58:38.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:58:38.778+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:58:38.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:58:38.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:58:38.814+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:58:38.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:58:38.832+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:58:38.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:58:38.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-21T04:59:09.120+0000] {processor.py:157} INFO - Started process (PID=88308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:59:09.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:59:09.128+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:59:09.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:59:09.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:59:09.160+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:59:09.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:59:09.172+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:59:09.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:59:09.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-21T04:59:39.620+0000] {processor.py:157} INFO - Started process (PID=88318) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:59:39.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T04:59:39.624+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:59:39.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:59:39.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T04:59:39.691+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:59:39.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T04:59:39.705+0000] {logging_mixin.py:151} INFO - [2024-08-21T04:59:39.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T04:59:39.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T05:00:10.023+0000] {processor.py:157} INFO - Started process (PID=88328) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:00:10.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:00:10.027+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:00:10.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:00:10.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:00:10.062+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:00:10.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:00:10.074+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:00:10.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:00:10.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-21T05:00:40.439+0000] {processor.py:157} INFO - Started process (PID=88338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:00:40.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:00:40.443+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:00:40.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:00:40.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:00:40.489+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:00:40.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:00:40.504+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:00:40.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:00:40.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-21T05:01:10.804+0000] {processor.py:157} INFO - Started process (PID=88348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:01:10.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:01:10.810+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:01:10.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:01:10.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:01:10.841+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:01:10.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:01:10.851+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:01:10.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:01:10.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-21T05:01:41.224+0000] {processor.py:157} INFO - Started process (PID=88358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:01:41.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:01:41.244+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:01:41.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:01:41.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:01:41.284+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:01:41.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:01:41.303+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:01:41.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:01:41.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-21T05:02:11.502+0000] {processor.py:157} INFO - Started process (PID=88368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:02:11.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:02:11.509+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:02:11.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:02:11.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:02:11.538+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:02:11.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:02:11.549+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:02:11.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:02:11.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T05:02:41.920+0000] {processor.py:157} INFO - Started process (PID=88378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:02:41.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:02:41.930+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:02:41.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:02:41.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:02:41.993+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:02:41.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:02:42.005+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:02:42.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:02:42.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-21T05:03:12.303+0000] {processor.py:157} INFO - Started process (PID=88388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:03:12.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:03:12.312+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:03:12.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:03:12.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:03:12.359+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:03:12.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:03:12.372+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:03:12.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:03:12.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-21T05:03:42.641+0000] {processor.py:157} INFO - Started process (PID=88398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:03:42.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:03:42.645+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:03:42.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:03:42.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:03:42.688+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:03:42.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:03:42.701+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:03:42.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:03:42.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-21T05:04:13.043+0000] {processor.py:157} INFO - Started process (PID=88408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:04:13.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:04:13.047+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:04:13.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:04:13.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:04:13.093+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:04:13.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:04:13.107+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:04:13.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:04:13.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-21T05:04:43.547+0000] {processor.py:157} INFO - Started process (PID=88418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:04:43.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:04:43.553+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:04:43.552+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:04:43.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:04:43.620+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:04:43.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:04:43.637+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:04:43.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:04:43.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-21T05:05:13.894+0000] {processor.py:157} INFO - Started process (PID=88428) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:05:13.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:05:13.897+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:05:13.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:05:13.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:05:13.924+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:05:13.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:05:13.935+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:05:13.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:05:13.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-21T05:05:44.281+0000] {processor.py:157} INFO - Started process (PID=88438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:05:44.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:05:44.289+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:05:44.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:05:44.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:05:44.365+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:05:44.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:05:44.379+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:05:44.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:05:44.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-21T05:06:14.744+0000] {processor.py:157} INFO - Started process (PID=88448) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:06:14.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:06:14.749+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:06:14.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:06:14.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:06:14.796+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:06:14.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:06:14.810+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:06:14.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:06:14.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-08-21T05:06:45.161+0000] {processor.py:157} INFO - Started process (PID=88458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:06:45.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:06:45.166+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:06:45.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:06:45.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:06:45.213+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:06:45.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:06:45.226+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:06:45.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:06:45.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-21T05:07:15.469+0000] {processor.py:157} INFO - Started process (PID=88468) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:07:15.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:07:15.474+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:07:15.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:07:15.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:07:15.500+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:07:15.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:07:15.512+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:07:15.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:07:15.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T05:07:45.864+0000] {processor.py:157} INFO - Started process (PID=88477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:07:45.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:07:45.871+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:07:45.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:07:45.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:07:45.942+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:07:45.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:07:45.955+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:07:45.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:07:45.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-21T05:08:16.242+0000] {processor.py:157} INFO - Started process (PID=88488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:08:16.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:08:16.245+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:08:16.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:08:16.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:08:16.277+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:08:16.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:08:16.287+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:08:16.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:08:16.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T05:08:46.613+0000] {processor.py:157} INFO - Started process (PID=88497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:08:46.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:08:46.619+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:08:46.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:08:46.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:08:46.677+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:08:46.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:08:46.689+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:08:46.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:08:46.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-21T05:09:17.022+0000] {processor.py:157} INFO - Started process (PID=88508) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:09:17.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:09:17.026+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:09:17.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:09:17.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:09:17.055+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:09:17.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:09:17.077+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:09:17.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:09:17.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-21T05:09:47.367+0000] {processor.py:157} INFO - Started process (PID=88517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:09:47.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:09:47.372+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:09:47.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:09:47.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:09:47.443+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:09:47.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:09:47.458+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:09:47.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:09:47.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-21T05:10:17.870+0000] {processor.py:157} INFO - Started process (PID=88528) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:10:17.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:10:17.876+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:10:17.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:10:17.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:10:17.915+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:10:17.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:10:17.930+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:10:17.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:10:17.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-21T05:10:48.285+0000] {processor.py:157} INFO - Started process (PID=88538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:10:48.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:10:48.288+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:10:48.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:10:48.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:10:48.317+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:10:48.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:10:48.336+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:10:48.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:10:48.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-21T05:11:18.716+0000] {processor.py:157} INFO - Started process (PID=88548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:11:18.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:11:18.732+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:11:18.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:11:18.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:11:18.782+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:11:18.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:11:18.815+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:11:18.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:11:18.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-21T05:11:49.082+0000] {processor.py:157} INFO - Started process (PID=88558) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:11:49.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:11:49.087+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:11:49.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:11:49.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:11:49.127+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:11:49.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:11:49.141+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:11:49.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:11:49.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-21T05:12:19.474+0000] {processor.py:157} INFO - Started process (PID=88568) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:12:19.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:12:19.479+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:12:19.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:12:19.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:12:19.508+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:12:19.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:12:19.518+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:12:19.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:12:19.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T05:12:49.836+0000] {processor.py:157} INFO - Started process (PID=88578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:12:49.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:12:49.844+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:12:49.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:12:49.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:12:49.909+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:12:49.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:12:49.932+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:12:49.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:12:49.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-21T05:13:20.316+0000] {processor.py:157} INFO - Started process (PID=88588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:13:20.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:13:20.320+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:13:20.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:13:20.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:13:20.346+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:13:20.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:13:20.357+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:13:20.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:13:20.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T05:13:50.704+0000] {processor.py:157} INFO - Started process (PID=88598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:13:50.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:13:50.710+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:13:50.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:13:50.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:13:50.778+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:13:50.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:13:50.795+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:13:50.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:13:50.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-21T05:14:21.101+0000] {processor.py:157} INFO - Started process (PID=88608) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:14:21.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:14:21.106+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:14:21.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:14:21.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:14:21.149+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:14:21.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:14:21.165+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:14:21.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:14:21.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-21T05:14:51.543+0000] {processor.py:157} INFO - Started process (PID=88618) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:14:51.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:14:51.549+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:14:51.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:14:51.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:14:51.583+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:14:51.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:14:51.593+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:14:51.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:14:51.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-21T05:15:22.044+0000] {processor.py:157} INFO - Started process (PID=88628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:15:22.049+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:15:22.053+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:15:22.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:15:22.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:15:22.116+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:15:22.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:15:22.131+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:15:22.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:15:22.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-21T05:15:52.441+0000] {processor.py:157} INFO - Started process (PID=88637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:15:52.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:15:52.449+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:15:52.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:15:52.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:15:52.514+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:15:52.514+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:15:52.528+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:15:52.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:15:52.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-21T05:16:22.765+0000] {processor.py:157} INFO - Started process (PID=88648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:16:22.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:16:22.773+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:16:22.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:16:22.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:16:22.813+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:16:22.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:16:22.827+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:16:22.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:16:22.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-21T05:16:53.090+0000] {processor.py:157} INFO - Started process (PID=88658) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:16:53.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:16:53.093+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:16:53.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:16:53.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:16:53.121+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:16:53.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:16:53.143+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:16:53.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:16:53.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-21T05:17:23.353+0000] {processor.py:157} INFO - Started process (PID=88668) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:17:23.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:17:23.360+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:17:23.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:17:23.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:17:23.407+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:17:23.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:17:23.420+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:17:23.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:17:23.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-21T05:17:53.750+0000] {processor.py:157} INFO - Started process (PID=88678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:17:53.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:17:53.752+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:17:53.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:17:53.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:17:53.793+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:17:53.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:17:53.805+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:17:53.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:17:53.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-21T05:18:24.123+0000] {processor.py:157} INFO - Started process (PID=88688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:18:24.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:18:24.129+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:18:24.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:18:24.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:18:24.176+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:18:24.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:18:24.189+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:18:24.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:18:24.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-21T05:18:54.510+0000] {processor.py:157} INFO - Started process (PID=88698) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:18:54.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:18:54.512+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:18:54.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:18:54.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:18:54.539+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:18:54.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:18:54.548+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:18:54.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:18:54.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-21T05:19:24.922+0000] {processor.py:157} INFO - Started process (PID=88708) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:19:24.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:19:24.926+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:19:24.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:19:24.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:19:24.966+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:19:24.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:19:24.979+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:19:24.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:19:24.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-21T05:19:55.349+0000] {processor.py:157} INFO - Started process (PID=88718) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:19:55.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:19:55.352+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:19:55.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:19:55.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:19:55.382+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:19:55.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:19:55.395+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:19:55.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:19:55.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T05:20:25.745+0000] {processor.py:157} INFO - Started process (PID=88728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:20:25.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:20:25.748+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:20:25.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:20:25.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:20:25.776+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:20:25.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:20:25.786+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:20:25.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:20:25.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T05:20:56.131+0000] {processor.py:157} INFO - Started process (PID=88738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:20:56.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:20:56.135+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:20:56.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:20:56.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:20:56.172+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:20:56.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:20:56.182+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:20:56.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:20:56.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-21T05:21:26.670+0000] {processor.py:157} INFO - Started process (PID=88748) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:21:26.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:21:26.675+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:21:26.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:21:26.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:21:26.762+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:21:26.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:21:26.784+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:21:26.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:21:26.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-21T05:37:49.143+0000] {processor.py:157} INFO - Started process (PID=88760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:37:49.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:37:49.184+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:37:49.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:37:49.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:37:49.907+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:37:49.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:37:50.422+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:37:50.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:37:50.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 1.426 seconds
[2024-08-21T05:38:20.889+0000] {processor.py:157} INFO - Started process (PID=88768) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:38:20.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:38:20.898+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:38:20.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:38:20.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:38:20.963+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:38:20.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:38:20.981+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:38:20.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:38:21.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-21T05:38:51.150+0000] {processor.py:157} INFO - Started process (PID=88780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:38:51.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:38:51.156+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:38:51.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:38:51.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:38:51.181+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:38:51.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:38:51.191+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:38:51.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:38:51.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T05:39:21.485+0000] {processor.py:157} INFO - Started process (PID=88790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:39:21.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:39:21.493+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:39:21.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:39:21.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:39:21.569+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:39:21.569+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:39:21.583+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:39:21.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:39:21.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-21T05:39:51.898+0000] {processor.py:157} INFO - Started process (PID=88799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:39:51.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:39:51.902+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:39:51.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:39:51.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:39:51.929+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:39:51.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:39:51.943+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:39:51.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:39:51.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T05:40:22.269+0000] {processor.py:157} INFO - Started process (PID=88810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:40:22.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:40:22.276+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:40:22.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:40:22.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:40:22.348+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:40:22.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:40:22.363+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:40:22.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:40:22.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-21T05:40:52.686+0000] {processor.py:157} INFO - Started process (PID=88820) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:40:52.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:40:52.690+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:40:52.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:40:52.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:40:52.717+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:40:52.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:40:52.728+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:40:52.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:40:52.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T05:41:23.001+0000] {processor.py:157} INFO - Started process (PID=88830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:41:23.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:41:23.009+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:41:23.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:41:23.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:41:23.050+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:41:23.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:41:23.066+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:41:23.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:41:23.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-21T05:41:53.400+0000] {processor.py:157} INFO - Started process (PID=88840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:41:53.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:41:53.407+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:41:53.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:41:53.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:41:53.436+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:41:53.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:41:53.448+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:41:53.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:41:53.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-21T05:42:23.765+0000] {processor.py:157} INFO - Started process (PID=88850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:42:23.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:42:23.773+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:42:23.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:42:23.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:42:23.841+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:42:23.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:42:23.854+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:42:23.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:42:23.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-21T05:42:54.249+0000] {processor.py:157} INFO - Started process (PID=88860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:42:54.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:42:54.252+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:42:54.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:42:54.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:42:54.289+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:42:54.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:42:54.299+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:42:54.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:42:54.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-21T05:43:24.624+0000] {processor.py:157} INFO - Started process (PID=88870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:43:24.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:43:24.643+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:43:24.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:43:24.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:43:24.717+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:43:24.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:43:24.730+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:43:24.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:43:24.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-21T05:43:54.928+0000] {processor.py:157} INFO - Started process (PID=88880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:43:54.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:43:54.931+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:43:54.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:43:54.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:43:54.981+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:43:54.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:43:54.991+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:43:54.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:43:55.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-21T05:44:25.243+0000] {processor.py:157} INFO - Started process (PID=88890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:44:25.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:44:25.250+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:44:25.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:44:25.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:44:25.293+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:44:25.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:44:25.313+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:44:25.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:44:25.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-21T05:44:55.543+0000] {processor.py:157} INFO - Started process (PID=88900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:44:55.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:44:55.546+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:44:55.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:44:55.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:44:55.576+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:44:55.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:44:55.587+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:44:55.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:44:55.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T05:45:25.881+0000] {processor.py:157} INFO - Started process (PID=88910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:45:25.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:45:25.890+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:45:25.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:45:25.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:45:25.956+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:45:25.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:45:25.979+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:45:25.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:45:25.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-21T05:45:56.177+0000] {processor.py:157} INFO - Started process (PID=88920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:45:56.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:45:56.193+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:45:56.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:45:56.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:45:56.242+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:45:56.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:45:56.270+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:45:56.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:45:56.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-21T05:46:26.512+0000] {processor.py:157} INFO - Started process (PID=88930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:46:26.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:46:26.516+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:46:26.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:46:26.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:46:26.547+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:46:26.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:46:26.558+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:46:26.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:46:26.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T05:46:56.846+0000] {processor.py:157} INFO - Started process (PID=88940) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:46:56.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:46:56.853+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:46:56.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:46:56.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:46:56.892+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:46:56.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:46:56.906+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:46:56.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:46:56.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-21T05:47:27.249+0000] {processor.py:157} INFO - Started process (PID=88950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:47:27.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:47:27.252+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:47:27.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:47:27.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:47:27.282+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:47:27.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:47:27.292+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:47:27.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:47:27.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T05:47:57.645+0000] {processor.py:157} INFO - Started process (PID=88960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:47:57.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T05:47:57.651+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:47:57.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:47:57.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T05:47:57.689+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:47:57.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T05:47:57.702+0000] {logging_mixin.py:151} INFO - [2024-08-21T05:47:57.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T05:47:57.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-21T06:03:51.743+0000] {processor.py:157} INFO - Started process (PID=88971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:03:51.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:03:51.750+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:03:51.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:03:51.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:03:51.803+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:03:51.803+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:03:51.816+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:03:51.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:03:51.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-21T06:04:22.094+0000] {processor.py:157} INFO - Started process (PID=88982) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:04:22.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:04:22.099+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:04:22.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:04:22.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:04:22.149+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:04:22.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:04:22.164+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:04:22.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:04:22.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-08-21T06:20:21.694+0000] {processor.py:157} INFO - Started process (PID=88991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:20:21.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:20:21.706+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:20:21.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:20:21.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:20:21.789+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:20:21.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:20:21.821+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:20:21.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:20:21.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-08-21T06:20:51.962+0000] {processor.py:157} INFO - Started process (PID=89002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:20:51.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:20:51.968+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:20:51.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:20:51.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:20:52.014+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:20:52.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:20:52.028+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:20:52.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:20:52.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-21T06:21:22.226+0000] {processor.py:157} INFO - Started process (PID=89012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:21:22.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:21:22.229+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:21:22.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:21:22.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:21:22.261+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:21:22.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:21:22.278+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:21:22.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:21:22.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-21T06:21:52.626+0000] {processor.py:157} INFO - Started process (PID=89022) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:21:52.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:21:52.631+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:21:52.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:21:52.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:21:52.670+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:21:52.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:21:52.682+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:21:52.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:21:52.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-21T06:22:22.915+0000] {processor.py:157} INFO - Started process (PID=89032) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:22:22.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:22:22.918+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:22:22.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:22:22.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:22:22.947+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:22:22.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:22:22.958+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:22:22.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:22:22.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T06:22:53.243+0000] {processor.py:157} INFO - Started process (PID=89042) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:22:53.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:22:53.247+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:22:53.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:22:53.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:22:53.275+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:22:53.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:22:53.285+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:22:53.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:22:53.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T06:23:23.588+0000] {processor.py:157} INFO - Started process (PID=89052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:23:23.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:23:23.593+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:23:23.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:23:23.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:23:23.619+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:23:23.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:23:23.630+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:23:23.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:23:23.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T06:23:53.944+0000] {processor.py:157} INFO - Started process (PID=89062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:23:53.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:23:53.950+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:23:53.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:23:53.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:23:53.985+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:23:53.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:23:53.997+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:23:53.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:23:54.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-21T06:24:24.205+0000] {processor.py:157} INFO - Started process (PID=89072) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:24:24.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:24:24.210+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:24:24.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:24:24.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:24:24.235+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:24:24.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:24:24.248+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:24:24.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:24:24.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T06:24:54.521+0000] {processor.py:157} INFO - Started process (PID=89082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:24:54.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:24:54.524+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:24:54.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:24:54.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:24:54.551+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:24:54.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:24:54.561+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:24:54.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:24:54.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-21T06:25:25.220+0000] {processor.py:157} INFO - Started process (PID=89092) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:25:25.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:25:25.224+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:25:25.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:25:25.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:25:25.272+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:25:25.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:25:25.296+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:25:25.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:25:25.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-21T06:41:44.009+0000] {processor.py:157} INFO - Started process (PID=89104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:41:44.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:41:44.012+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:41:44.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:41:44.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:41:44.048+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:41:44.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:41:44.061+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:41:44.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:41:44.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-21T06:51:33.010+0000] {processor.py:157} INFO - Started process (PID=89114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:51:33.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:51:33.021+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:51:33.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:51:33.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:51:33.070+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:51:33.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:51:33.092+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:51:33.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:51:33.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-21T06:52:03.429+0000] {processor.py:157} INFO - Started process (PID=89124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:52:03.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:52:03.436+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:52:03.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:52:03.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:52:03.501+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:52:03.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:52:03.515+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:52:03.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:52:03.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-21T06:52:33.836+0000] {processor.py:157} INFO - Started process (PID=89134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:52:33.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:52:33.855+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:52:33.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:52:33.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:52:33.904+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:52:33.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:52:33.918+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:52:33.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:52:33.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-21T06:53:04.249+0000] {processor.py:157} INFO - Started process (PID=89144) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:53:04.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:53:04.258+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:53:04.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:53:04.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:53:04.329+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:53:04.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:53:04.353+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:53:04.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:53:04.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-08-21T06:53:34.587+0000] {processor.py:157} INFO - Started process (PID=89154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:53:34.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:53:34.592+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:53:34.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:53:34.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:53:34.625+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:53:34.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:53:34.634+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:53:34.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:53:34.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T06:54:04.913+0000] {processor.py:157} INFO - Started process (PID=89164) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:54:04.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:54:04.920+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:54:04.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:54:04.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:54:04.989+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:54:04.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:54:05.011+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:54:05.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:54:05.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-08-21T06:54:35.219+0000] {processor.py:157} INFO - Started process (PID=89173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:54:35.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:54:35.224+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:54:35.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:54:35.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:54:35.257+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:54:35.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:54:35.270+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:54:35.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:54:35.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-21T06:55:05.574+0000] {processor.py:157} INFO - Started process (PID=89184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:55:05.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:55:05.577+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:55:05.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:55:05.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:55:05.656+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:55:05.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:55:05.673+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:55:05.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:55:05.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-21T06:55:35.934+0000] {processor.py:157} INFO - Started process (PID=89194) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:55:35.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:55:35.939+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:55:35.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:55:35.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:55:35.991+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:55:35.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:55:36.006+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:55:36.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:55:36.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-21T06:56:06.311+0000] {processor.py:157} INFO - Started process (PID=89204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:56:06.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:56:06.315+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:56:06.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:56:06.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:56:06.370+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:56:06.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:56:06.383+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:56:06.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:56:06.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-21T06:56:36.625+0000] {processor.py:157} INFO - Started process (PID=89214) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:56:36.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T06:56:36.629+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:56:36.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:56:36.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T06:56:36.658+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:56:36.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T06:56:36.668+0000] {logging_mixin.py:151} INFO - [2024-08-21T06:56:36.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T06:56:36.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T07:12:48.682+0000] {processor.py:157} INFO - Started process (PID=89224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:12:48.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T07:12:48.688+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:12:48.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:12:48.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:12:48.752+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:12:48.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T07:12:48.781+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:12:48.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T07:12:48.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-21T07:13:19.128+0000] {processor.py:157} INFO - Started process (PID=89234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:13:19.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T07:13:19.151+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:13:19.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:13:19.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:13:19.205+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:13:19.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T07:13:19.218+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:13:19.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T07:13:19.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-21T07:30:23.479+0000] {processor.py:157} INFO - Started process (PID=89244) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:30:23.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T07:30:23.487+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:30:23.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:30:23.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:30:23.547+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:30:23.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T07:30:23.566+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:30:23.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T07:30:23.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-21T07:30:53.827+0000] {processor.py:157} INFO - Started process (PID=89254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:30:53.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T07:30:53.838+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:30:53.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:30:53.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:30:53.933+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:30:53.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T07:30:53.960+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:30:53.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T07:30:53.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-08-21T07:31:24.229+0000] {processor.py:157} INFO - Started process (PID=89264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:31:24.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T07:31:24.237+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:31:24.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:31:24.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:31:24.297+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:31:24.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T07:31:24.313+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:31:24.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T07:31:24.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T07:31:54.560+0000] {processor.py:157} INFO - Started process (PID=89274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:31:54.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T07:31:54.564+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:31:54.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:31:54.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:31:54.594+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:31:54.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T07:31:54.603+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:31:54.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T07:31:54.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-21T07:32:24.996+0000] {processor.py:157} INFO - Started process (PID=89284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:32:24.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T07:32:25.001+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:32:25.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:32:25.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:32:25.042+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:32:25.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T07:32:25.056+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:32:25.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T07:32:25.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-21T07:48:02.828+0000] {processor.py:157} INFO - Started process (PID=89294) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:48:02.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T07:48:02.838+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:48:02.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:48:02.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T07:48:02.896+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:48:02.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T07:48:02.911+0000] {logging_mixin.py:151} INFO - [2024-08-21T07:48:02.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T07:48:02.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-21T08:04:03.342+0000] {processor.py:157} INFO - Started process (PID=89304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:04:03.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:04:03.348+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:04:03.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:04:03.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:04:03.412+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:04:03.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:04:03.443+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:04:03.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:04:03.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-08-21T08:04:33.850+0000] {processor.py:157} INFO - Started process (PID=89315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:04:33.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:04:33.857+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:04:33.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:04:33.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:04:33.923+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:04:33.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:04:33.944+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:04:33.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:04:33.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-21T08:05:04.326+0000] {processor.py:157} INFO - Started process (PID=89325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:05:04.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:05:04.331+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:05:04.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:05:04.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:05:04.381+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:05:04.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:05:04.396+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:05:04.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:05:04.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-21T08:05:34.811+0000] {processor.py:157} INFO - Started process (PID=89335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:05:34.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:05:34.813+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:05:34.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:05:34.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:05:34.845+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:05:34.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:05:34.858+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:05:34.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:05:34.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T08:06:05.271+0000] {processor.py:157} INFO - Started process (PID=89345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:06:05.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:06:05.275+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:06:05.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:06:05.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:06:05.311+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:06:05.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:06:05.322+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:06:05.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:06:05.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-21T08:06:35.652+0000] {processor.py:157} INFO - Started process (PID=89355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:06:35.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:06:35.655+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:06:35.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:06:35.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:06:35.693+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:06:35.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:06:35.708+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:06:35.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:06:35.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-08-21T08:07:06.017+0000] {processor.py:157} INFO - Started process (PID=89365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:07:06.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:07:06.022+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:07:06.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:07:06.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:07:06.053+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:07:06.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:07:06.064+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:07:06.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:07:06.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T08:07:36.437+0000] {processor.py:157} INFO - Started process (PID=89375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:07:36.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:07:36.440+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:07:36.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:07:36.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:07:36.476+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:07:36.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:07:36.490+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:07:36.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:07:36.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-21T08:08:06.757+0000] {processor.py:157} INFO - Started process (PID=89385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:08:06.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:08:06.763+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:08:06.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:08:06.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:08:06.794+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:08:06.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:08:06.806+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:08:06.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:08:06.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-21T08:08:37.041+0000] {processor.py:157} INFO - Started process (PID=89395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:08:37.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:08:37.044+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:08:37.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:08:37.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:08:37.079+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:08:37.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:08:37.092+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:08:37.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:08:37.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-21T08:25:16.896+0000] {processor.py:157} INFO - Started process (PID=89405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:25:16.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:25:16.922+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:25:16.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:25:16.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:25:16.974+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:25:16.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:25:16.986+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:25:16.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:25:16.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-21T08:41:56.356+0000] {processor.py:157} INFO - Started process (PID=89418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:41:56.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:41:56.363+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:41:56.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:41:56.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:41:56.427+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:41:56.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:41:56.452+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:41:56.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:41:56.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-21T08:42:26.731+0000] {processor.py:157} INFO - Started process (PID=89429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:42:26.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:42:26.735+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:42:26.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:42:26.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:42:26.785+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:42:26.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:42:26.800+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:42:26.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:42:26.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-21T08:42:57.141+0000] {processor.py:157} INFO - Started process (PID=89439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:42:57.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:42:57.145+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:42:57.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:42:57.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:42:57.172+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:42:57.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:42:57.183+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:42:57.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:42:57.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T08:43:27.549+0000] {processor.py:157} INFO - Started process (PID=89449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:43:27.551+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:43:27.556+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:43:27.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:43:27.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:43:27.593+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:43:27.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:43:27.606+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:43:27.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:43:27.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-21T08:59:03.782+0000] {processor.py:157} INFO - Started process (PID=89459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:59:03.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:59:03.787+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:59:03.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:59:03.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:59:03.880+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:59:03.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:59:03.917+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:59:03.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:59:03.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-08-21T08:59:34.154+0000] {processor.py:157} INFO - Started process (PID=89469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:59:34.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T08:59:34.170+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:59:34.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:59:34.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T08:59:34.223+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:59:34.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T08:59:34.237+0000] {logging_mixin.py:151} INFO - [2024-08-21T08:59:34.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T08:59:34.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-21T09:00:04.619+0000] {processor.py:157} INFO - Started process (PID=89479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:00:04.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:00:04.629+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:00:04.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:00:04.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:00:04.650+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:00:04.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:00:04.660+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:00:04.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:00:04.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-21T09:00:35.022+0000] {processor.py:157} INFO - Started process (PID=89489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:00:35.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:00:35.026+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:00:35.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:00:35.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:00:35.067+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:00:35.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:00:35.081+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:00:35.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:00:35.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-21T09:01:05.442+0000] {processor.py:157} INFO - Started process (PID=89499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:01:05.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:01:05.447+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:01:05.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:01:05.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:01:05.473+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:01:05.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:01:05.483+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:01:05.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:01:05.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-21T09:17:31.858+0000] {processor.py:157} INFO - Started process (PID=89509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:17:31.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:17:31.863+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:17:31.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:17:31.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:17:31.914+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:17:31.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:17:31.928+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:17:31.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:17:31.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-21T09:18:02.215+0000] {processor.py:157} INFO - Started process (PID=89519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:18:02.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:18:02.226+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:18:02.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:18:02.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:18:02.293+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:18:02.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:18:02.311+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:18:02.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:18:02.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-21T09:26:46.117+0000] {processor.py:157} INFO - Started process (PID=89531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:26:46.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:26:46.125+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:26:46.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:26:46.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:26:46.232+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:26:46.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:26:46.263+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:26:46.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:26:46.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-08-21T09:27:16.403+0000] {processor.py:157} INFO - Started process (PID=89540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:27:16.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:27:16.411+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:27:16.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:27:16.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:27:16.479+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:27:16.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:27:16.505+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:27:16.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:27:16.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-21T09:27:46.788+0000] {processor.py:157} INFO - Started process (PID=89551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:27:46.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:27:46.791+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:27:46.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:27:46.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:27:46.818+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:27:46.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:27:46.829+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:27:46.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:27:46.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T09:28:17.162+0000] {processor.py:157} INFO - Started process (PID=89561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:28:17.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:28:17.170+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:28:17.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:28:17.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:28:17.208+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:28:17.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:28:17.222+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:28:17.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:28:17.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-21T09:43:54.729+0000] {processor.py:157} INFO - Started process (PID=89573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:43:54.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:43:54.735+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:43:54.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:43:54.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:43:54.806+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:43:54.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:43:54.828+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:43:54.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:43:54.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-21T09:44:25.112+0000] {processor.py:157} INFO - Started process (PID=89581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:44:25.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:44:25.125+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:44:25.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:44:25.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:44:25.182+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:44:25.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:44:25.195+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:44:25.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:44:25.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T09:44:55.520+0000] {processor.py:157} INFO - Started process (PID=89593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:44:55.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:44:55.525+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:44:55.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:44:55.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:44:55.565+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:44:55.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:44:55.580+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:44:55.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:44:55.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-21T09:45:25.897+0000] {processor.py:157} INFO - Started process (PID=89603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:45:25.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:45:25.901+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:45:25.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:45:25.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:45:25.926+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:45:25.926+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:45:25.936+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:45:25.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:45:25.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-21T09:45:56.313+0000] {processor.py:157} INFO - Started process (PID=89613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:45:56.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:45:56.319+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:45:56.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:45:56.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:45:56.363+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:45:56.363+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:45:56.376+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:45:56.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:45:56.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-21T09:46:26.635+0000] {processor.py:157} INFO - Started process (PID=89623) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:46:26.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:46:26.642+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:46:26.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:46:26.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:46:26.682+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:46:26.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:46:26.697+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:46:26.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:46:26.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-21T09:46:56.913+0000] {processor.py:157} INFO - Started process (PID=89633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:46:56.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:46:56.917+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:46:56.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:46:56.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:46:56.943+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:46:56.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:46:56.953+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:46:56.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:46:56.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-21T09:47:27.282+0000] {processor.py:157} INFO - Started process (PID=89643) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:47:27.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:47:27.286+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:47:27.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:47:27.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:47:27.312+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:47:27.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:47:27.321+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:47:27.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:47:27.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-08-21T09:47:57.636+0000] {processor.py:157} INFO - Started process (PID=89653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:47:57.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T09:47:57.641+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:47:57.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:47:57.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T09:47:57.668+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:47:57.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T09:47:57.682+0000] {logging_mixin.py:151} INFO - [2024-08-21T09:47:57.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T09:47:57.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-21T10:03:34.780+0000] {processor.py:157} INFO - Started process (PID=89663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:03:34.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T10:03:34.787+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:03:34.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:03:34.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:03:34.853+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:03:34.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T10:03:34.867+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:03:34.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T10:03:34.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-21T10:04:05.112+0000] {processor.py:157} INFO - Started process (PID=89671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:04:05.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T10:04:05.120+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:04:05.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:04:05.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:04:05.170+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:04:05.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T10:04:05.186+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:04:05.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T10:04:05.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-21T10:04:35.410+0000] {processor.py:157} INFO - Started process (PID=89683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:04:35.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T10:04:35.418+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:04:35.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:04:35.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:04:35.445+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:04:35.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T10:04:35.456+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:04:35.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T10:04:35.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T10:05:05.767+0000] {processor.py:157} INFO - Started process (PID=89693) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:05:05.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T10:05:05.771+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:05:05.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:05:05.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:05:05.807+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:05:05.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T10:05:05.819+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:05:05.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T10:05:05.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-21T10:05:36.079+0000] {processor.py:157} INFO - Started process (PID=89703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:05:36.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T10:05:36.084+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:05:36.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:05:36.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:05:36.111+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:05:36.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T10:05:36.121+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:05:36.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T10:05:36.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T10:23:30.552+0000] {processor.py:157} INFO - Started process (PID=89715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:23:30.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T10:23:30.573+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:23:30.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:23:30.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:23:30.676+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:23:30.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T10:23:30.693+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:23:30.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T10:23:30.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-08-21T10:27:27.925+0000] {processor.py:157} INFO - Started process (PID=89725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:27:27.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T10:27:27.934+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:27:27.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:27:27.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:27:28.017+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:27:28.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T10:27:28.051+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:27:28.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T10:27:28.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-08-21T10:27:58.293+0000] {processor.py:157} INFO - Started process (PID=89735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:27:58.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T10:27:58.300+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:27:58.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:27:58.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:27:58.351+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:27:58.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T10:27:58.371+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:27:58.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T10:27:58.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-21T10:43:38.753+0000] {processor.py:157} INFO - Started process (PID=89746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:43:38.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T10:43:38.770+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:43:38.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:43:38.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:43:38.853+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:43:38.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T10:43:38.893+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:43:38.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T10:43:38.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-08-21T10:44:09.282+0000] {processor.py:157} INFO - Started process (PID=89756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:44:09.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T10:44:09.288+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:44:09.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:44:09.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:44:09.340+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:44:09.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T10:44:09.362+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:44:09.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T10:44:09.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-21T10:44:39.636+0000] {processor.py:157} INFO - Started process (PID=89767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:44:39.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T10:44:39.641+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:44:39.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:44:39.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:44:39.682+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:44:39.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T10:44:39.708+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:44:39.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T10:44:39.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-21T10:45:09.949+0000] {processor.py:157} INFO - Started process (PID=89777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:45:09.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T10:45:09.952+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:45:09.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:45:09.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T10:45:09.980+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:45:09.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T10:45:09.993+0000] {logging_mixin.py:151} INFO - [2024-08-21T10:45:09.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T10:45:10.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T11:00:44.713+0000] {processor.py:157} INFO - Started process (PID=89787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:00:44.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T11:00:44.719+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:00:44.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:00:44.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:00:44.763+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:00:44.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T11:00:44.779+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:00:44.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T11:00:44.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-21T11:01:15.040+0000] {processor.py:157} INFO - Started process (PID=89799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:01:15.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T11:01:15.055+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:01:15.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:01:15.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:01:15.104+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:01:15.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T11:01:15.118+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:01:15.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T11:01:15.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-21T11:01:45.281+0000] {processor.py:157} INFO - Started process (PID=89809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:01:45.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T11:01:45.284+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:01:45.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:01:45.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:01:45.309+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:01:45.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T11:01:45.319+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:01:45.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T11:01:45.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-21T11:02:15.637+0000] {processor.py:157} INFO - Started process (PID=89819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:02:15.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T11:02:15.639+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:02:15.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:02:15.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:02:15.665+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:02:15.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T11:02:15.675+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:02:15.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T11:02:15.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-21T11:02:45.958+0000] {processor.py:157} INFO - Started process (PID=89829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:02:45.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T11:02:45.968+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:02:45.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:02:45.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:02:46.007+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:02:46.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T11:02:46.021+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:02:46.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T11:02:46.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-21T11:18:36.253+0000] {processor.py:157} INFO - Started process (PID=89840) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:18:36.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T11:18:36.256+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:18:36.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:18:36.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:18:36.312+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:18:36.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T11:18:36.345+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:18:36.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T11:18:36.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-21T11:27:42.804+0000] {processor.py:157} INFO - Started process (PID=89851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:27:42.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T11:27:42.810+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:27:42.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:27:42.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:27:42.885+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:27:42.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T11:27:42.902+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:27:42.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T11:27:42.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-08-21T11:28:13.153+0000] {processor.py:157} INFO - Started process (PID=89861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:28:13.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T11:28:13.161+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:28:13.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:28:13.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:28:13.214+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:28:13.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T11:28:13.229+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:28:13.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T11:28:13.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-21T11:28:43.525+0000] {processor.py:157} INFO - Started process (PID=89871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:28:43.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T11:28:43.530+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:28:43.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:28:43.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:28:43.565+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:28:43.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T11:28:43.575+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:28:43.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T11:28:43.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-21T11:29:13.876+0000] {processor.py:157} INFO - Started process (PID=89881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:29:13.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T11:29:13.881+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:29:13.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:29:13.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:29:13.921+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:29:13.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T11:29:13.935+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:29:13.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T11:29:13.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-21T11:46:08.719+0000] {processor.py:157} INFO - Started process (PID=89892) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:46:08.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T11:46:08.726+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:46:08.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:46:08.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:46:08.778+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:46:08.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T11:46:08.801+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:46:08.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T11:46:08.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-21T11:46:39.175+0000] {processor.py:157} INFO - Started process (PID=89903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:46:39.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T11:46:39.181+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:46:39.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:46:39.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T11:46:39.234+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:46:39.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T11:46:39.248+0000] {logging_mixin.py:151} INFO - [2024-08-21T11:46:39.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T11:46:39.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-21T12:02:53.837+0000] {processor.py:157} INFO - Started process (PID=89912) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:02:53.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T12:02:53.843+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:02:53.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:02:53.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:02:53.911+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:02:53.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T12:02:53.936+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:02:53.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T12:02:53.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-21T12:03:24.135+0000] {processor.py:157} INFO - Started process (PID=89923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:03:24.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T12:03:24.153+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:03:24.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:03:24.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:03:24.221+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:03:24.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T12:03:24.238+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:03:24.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T12:03:24.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-21T12:03:54.569+0000] {processor.py:157} INFO - Started process (PID=89933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:03:54.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T12:03:54.574+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:03:54.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:03:54.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:03:54.601+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:03:54.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T12:03:54.611+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:03:54.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T12:03:54.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T12:04:24.952+0000] {processor.py:157} INFO - Started process (PID=89943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:04:24.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T12:04:24.955+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:04:24.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:04:24.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:04:24.991+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:04:24.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T12:04:25.003+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:04:25.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T12:04:25.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-08-21T12:04:55.309+0000] {processor.py:157} INFO - Started process (PID=89953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:04:55.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T12:04:55.313+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:04:55.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:04:55.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:04:55.340+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:04:55.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T12:04:55.351+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:04:55.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T12:04:55.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T12:22:08.259+0000] {processor.py:157} INFO - Started process (PID=89962) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:22:08.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T12:22:08.274+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:22:08.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:22:08.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:22:08.339+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:22:08.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T12:22:08.362+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:22:08.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T12:22:08.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-21T12:22:38.673+0000] {processor.py:157} INFO - Started process (PID=89973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:22:38.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T12:22:38.679+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:22:38.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:22:38.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:22:38.733+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:22:38.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T12:22:38.749+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:22:38.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T12:22:38.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-21T12:23:09.120+0000] {processor.py:157} INFO - Started process (PID=89983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:23:09.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T12:23:09.128+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:23:09.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:23:09.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:23:09.155+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:23:09.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T12:23:09.166+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:23:09.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T12:23:09.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-21T12:23:39.564+0000] {processor.py:157} INFO - Started process (PID=89992) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:23:39.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T12:23:39.568+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:23:39.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:23:39.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:23:39.625+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:23:39.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T12:23:39.637+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:23:39.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T12:23:39.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-21T12:28:40.920+0000] {processor.py:157} INFO - Started process (PID=90003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:28:40.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T12:28:40.931+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:28:40.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:28:40.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:28:40.979+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:28:40.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T12:28:40.991+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:28:40.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T12:28:41.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-21T12:29:11.418+0000] {processor.py:157} INFO - Started process (PID=90015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:29:11.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T12:29:11.436+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:29:11.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:29:11.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:29:11.502+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:29:11.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T12:29:11.519+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:29:11.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T12:29:11.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-21T12:46:06.913+0000] {processor.py:157} INFO - Started process (PID=90025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:46:06.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T12:46:06.920+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:46:06.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:46:06.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:46:06.966+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:46:06.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T12:46:06.984+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:46:06.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T12:46:06.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-21T12:46:37.248+0000] {processor.py:157} INFO - Started process (PID=90035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:46:37.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T12:46:37.263+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:46:37.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:46:37.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:46:37.310+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:46:37.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T12:46:37.324+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:46:37.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T12:46:37.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-21T12:47:07.539+0000] {processor.py:157} INFO - Started process (PID=90045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:47:07.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T12:47:07.542+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:47:07.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:47:07.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:47:07.571+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:47:07.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T12:47:07.581+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:47:07.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T12:47:07.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T12:47:37.880+0000] {processor.py:157} INFO - Started process (PID=90055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:47:37.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T12:47:37.885+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:47:37.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:47:37.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T12:47:37.912+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:47:37.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T12:47:37.921+0000] {logging_mixin.py:151} INFO - [2024-08-21T12:47:37.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T12:47:37.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-21T13:03:09.460+0000] {processor.py:157} INFO - Started process (PID=90066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:03:09.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:03:09.472+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:03:09.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:03:09.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:03:09.529+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:03:09.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:03:09.551+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:03:09.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:03:09.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-08-21T13:03:39.987+0000] {processor.py:157} INFO - Started process (PID=90076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:03:39.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:03:39.992+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:03:39.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:03:40.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:03:40.066+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:03:40.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:03:40.086+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:03:40.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:03:40.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-21T13:04:10.364+0000] {processor.py:157} INFO - Started process (PID=90087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:04:10.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:04:10.368+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:04:10.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:04:10.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:04:10.405+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:04:10.405+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:04:10.417+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:04:10.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:04:10.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-21T13:04:40.799+0000] {processor.py:157} INFO - Started process (PID=90097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:04:40.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:04:40.802+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:04:40.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:04:40.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:04:40.832+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:04:40.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:04:40.847+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:04:40.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:04:40.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-08-21T13:05:11.067+0000] {processor.py:157} INFO - Started process (PID=90107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:05:11.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:05:11.070+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:05:11.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:05:11.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:05:11.093+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:05:11.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:05:11.103+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:05:11.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:05:11.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-21T13:21:41.198+0000] {processor.py:157} INFO - Started process (PID=90118) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:21:41.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:21:41.202+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:21:41.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:21:41.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:21:41.289+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:21:41.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:21:41.316+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:21:41.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:21:41.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-21T13:22:11.774+0000] {processor.py:157} INFO - Started process (PID=90129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:22:11.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:22:11.780+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:22:11.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:22:11.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:22:11.829+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:22:11.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:22:11.842+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:22:11.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:22:11.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-21T13:22:42.122+0000] {processor.py:157} INFO - Started process (PID=90139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:22:42.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:22:42.124+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:22:42.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:22:42.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:22:42.150+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:22:42.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:22:42.161+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:22:42.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:22:42.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-21T13:23:12.550+0000] {processor.py:157} INFO - Started process (PID=90149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:23:12.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:23:12.554+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:23:12.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:23:12.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:23:12.579+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:23:12.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:23:12.592+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:23:12.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:23:12.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T13:23:42.934+0000] {processor.py:157} INFO - Started process (PID=90159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:23:42.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:23:42.937+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:23:42.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:23:42.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:23:42.972+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:23:42.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:23:42.985+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:23:42.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:23:42.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-21T13:30:02.882+0000] {processor.py:157} INFO - Started process (PID=90171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:30:02.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:30:02.887+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:30:02.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:30:02.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:30:02.950+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:30:02.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:30:02.977+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:30:02.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:30:02.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-21T13:30:33.408+0000] {processor.py:157} INFO - Started process (PID=90181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:30:33.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:30:33.414+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:30:33.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:30:33.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:30:33.450+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:30:33.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:30:33.463+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:30:33.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:30:33.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-21T13:31:03.698+0000] {processor.py:157} INFO - Started process (PID=90191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:31:03.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:31:03.702+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:31:03.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:31:03.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:31:03.742+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:31:03.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:31:03.757+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:31:03.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:31:03.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-21T13:31:33.995+0000] {processor.py:157} INFO - Started process (PID=90201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:31:33.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:31:33.998+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:31:33.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:31:34.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:31:34.025+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:31:34.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:31:34.035+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:31:34.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:31:34.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-21T13:32:04.432+0000] {processor.py:157} INFO - Started process (PID=90211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:32:04.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:32:04.438+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:32:04.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:32:04.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:32:04.469+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:32:04.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:32:04.482+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:32:04.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:32:04.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-21T13:48:12.357+0000] {processor.py:157} INFO - Started process (PID=90223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:48:12.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:48:12.367+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:48:12.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:48:12.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:48:12.449+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:48:12.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:48:12.468+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:48:12.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:48:12.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-21T13:48:42.877+0000] {processor.py:157} INFO - Started process (PID=90233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:48:42.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T13:48:42.883+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:48:42.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:48:42.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T13:48:42.964+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:48:42.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T13:48:42.980+0000] {logging_mixin.py:151} INFO - [2024-08-21T13:48:42.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T13:48:42.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-21T14:06:15.753+0000] {processor.py:157} INFO - Started process (PID=90241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:06:15.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T14:06:15.759+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:06:15.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:06:15.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:06:15.798+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:06:15.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T14:06:15.814+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:06:15.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T14:06:15.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-21T14:06:46.201+0000] {processor.py:157} INFO - Started process (PID=90252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:06:46.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T14:06:46.220+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:06:46.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:06:46.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:06:46.265+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:06:46.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T14:06:46.281+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:06:46.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T14:06:46.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-21T14:07:16.485+0000] {processor.py:157} INFO - Started process (PID=90263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:07:16.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T14:07:16.492+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:07:16.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:07:16.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:07:16.513+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:07:16.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T14:07:16.523+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:07:16.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T14:07:16.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-08-21T14:07:46.849+0000] {processor.py:157} INFO - Started process (PID=90273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:07:46.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T14:07:46.853+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:07:46.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:07:46.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:07:46.876+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:07:46.876+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T14:07:46.886+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:07:46.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T14:07:46.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-21T14:23:50.941+0000] {processor.py:157} INFO - Started process (PID=90284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:23:50.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T14:23:50.947+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:23:50.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:23:50.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:23:50.992+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:23:50.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T14:23:51.012+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:23:51.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T14:23:51.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T14:30:40.207+0000] {processor.py:157} INFO - Started process (PID=90295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:30:40.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T14:30:40.217+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:30:40.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:30:40.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:30:40.322+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:30:40.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T14:30:40.351+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:30:40.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T14:30:40.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-08-21T14:31:10.496+0000] {processor.py:157} INFO - Started process (PID=90303) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:31:10.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T14:31:10.509+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:31:10.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:31:10.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:31:10.580+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:31:10.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T14:31:10.593+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:31:10.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T14:31:10.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-08-21T14:31:40.911+0000] {processor.py:157} INFO - Started process (PID=90315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:31:40.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T14:31:40.917+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:31:40.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:31:40.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:31:40.955+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:31:40.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T14:31:40.968+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:31:40.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T14:31:40.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-21T14:32:11.226+0000] {processor.py:157} INFO - Started process (PID=90325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:32:11.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T14:32:11.230+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:32:11.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:32:11.243+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:32:11.261+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:32:11.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T14:32:11.272+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:32:11.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T14:32:11.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-08-21T14:32:41.583+0000] {processor.py:157} INFO - Started process (PID=90335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:32:41.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T14:32:41.594+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:32:41.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:32:41.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:32:41.636+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:32:41.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T14:32:41.649+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:32:41.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T14:32:41.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-21T14:48:41.392+0000] {processor.py:157} INFO - Started process (PID=90345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:48:41.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T14:48:41.400+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:48:41.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:48:41.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:48:41.478+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:48:41.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T14:48:41.499+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:48:41.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T14:48:41.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-21T14:49:11.723+0000] {processor.py:157} INFO - Started process (PID=90356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:49:11.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T14:49:11.731+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:49:11.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:49:11.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:49:11.776+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:49:11.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T14:49:11.789+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:49:11.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T14:49:11.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-21T14:49:42.031+0000] {processor.py:157} INFO - Started process (PID=90367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:49:42.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T14:49:42.036+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:49:42.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:49:42.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:49:42.076+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:49:42.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T14:49:42.089+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:49:42.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T14:49:42.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-08-21T14:50:12.355+0000] {processor.py:157} INFO - Started process (PID=90377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:50:12.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T14:50:12.361+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:50:12.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:50:12.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T14:50:12.393+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:50:12.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T14:50:12.404+0000] {logging_mixin.py:151} INFO - [2024-08-21T14:50:12.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T14:50:12.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-21T15:07:57.458+0000] {processor.py:157} INFO - Started process (PID=90389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:07:57.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:07:57.463+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:07:57.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:07:57.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:07:57.525+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:07:57.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:07:57.538+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:07:57.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:07:57.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-21T15:08:27.909+0000] {processor.py:157} INFO - Started process (PID=90398) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:08:27.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:08:27.916+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:08:27.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:08:27.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:08:27.966+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:08:27.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:08:27.979+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:08:27.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:08:27.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-21T15:08:58.220+0000] {processor.py:157} INFO - Started process (PID=90409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:08:58.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:08:58.227+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:08:58.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:08:58.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:08:58.255+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:08:58.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:08:58.267+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:08:58.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:08:58.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-08-21T15:09:28.632+0000] {processor.py:157} INFO - Started process (PID=90419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:09:28.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:09:28.637+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:09:28.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:09:28.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:09:28.675+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:09:28.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:09:28.688+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:09:28.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:09:28.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T15:09:58.994+0000] {processor.py:157} INFO - Started process (PID=90429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:09:58.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:09:59.000+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:09:59.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:09:59.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:09:59.025+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:09:59.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:09:59.035+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:09:59.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:09:59.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T15:14:02.778+0000] {processor.py:157} INFO - Started process (PID=90440) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:14:02.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:14:02.782+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:14:02.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:14:02.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:14:02.805+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:14:02.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:14:02.814+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:14:02.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:14:02.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-08-21T15:14:33.094+0000] {processor.py:157} INFO - Started process (PID=90450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:14:33.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:14:33.111+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:14:33.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:14:33.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:14:33.152+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:14:33.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:14:33.167+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:14:33.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:14:33.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-21T15:15:03.355+0000] {processor.py:157} INFO - Started process (PID=90460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:15:03.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:15:03.358+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:15:03.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:15:03.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:15:03.387+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:15:03.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:15:03.397+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:15:03.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:15:03.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T15:15:33.664+0000] {processor.py:157} INFO - Started process (PID=90470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:15:33.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:15:33.669+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:15:33.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:15:33.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:15:33.711+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:15:33.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:15:33.725+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:15:33.725+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:15:33.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-21T15:16:31.453+0000] {processor.py:157} INFO - Started process (PID=90480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:16:31.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:16:31.463+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:16:31.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:16:31.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:16:31.512+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:16:31.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:16:31.527+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:16:31.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:16:31.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-21T15:17:01.717+0000] {processor.py:157} INFO - Started process (PID=90492) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:17:01.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:17:01.719+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:17:01.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:17:01.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:17:01.746+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:17:01.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:17:01.755+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:17:01.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:17:01.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-21T15:18:34.012+0000] {processor.py:157} INFO - Started process (PID=90502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:18:34.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:18:34.020+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:18:34.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:18:34.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:18:34.097+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:18:34.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:18:34.136+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:18:34.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:18:34.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.155 seconds
[2024-08-21T15:19:32.883+0000] {processor.py:157} INFO - Started process (PID=90512) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:19:32.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:19:32.889+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:19:32.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:19:32.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:19:32.927+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:19:32.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:19:32.944+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:19:32.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:19:32.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-21T15:20:03.268+0000] {processor.py:157} INFO - Started process (PID=90522) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:20:03.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:20:03.272+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:20:03.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:20:03.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:20:03.305+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:20:03.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:20:03.318+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:20:03.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:20:03.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-21T15:36:04.020+0000] {processor.py:157} INFO - Started process (PID=90533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:36:04.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:36:04.031+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:36:04.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:36:04.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:36:04.081+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:36:04.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:36:04.110+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:36:04.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:36:04.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-08-21T15:36:34.477+0000] {processor.py:157} INFO - Started process (PID=90543) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:36:34.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:36:34.482+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:36:34.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:36:34.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:36:34.529+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:36:34.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:36:34.549+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:36:34.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:36:34.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-21T15:37:39.019+0000] {processor.py:157} INFO - Started process (PID=90556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:37:39.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:37:39.025+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:37:39.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:37:39.049+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:37:39.080+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:37:39.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:37:39.101+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:37:39.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:37:39.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-21T15:38:09.325+0000] {processor.py:157} INFO - Started process (PID=90566) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:38:09.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:38:09.331+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:38:09.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:38:09.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:38:09.372+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:38:09.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:38:09.386+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:38:09.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:38:09.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-21T15:38:39.573+0000] {processor.py:157} INFO - Started process (PID=90576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:38:39.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:38:39.576+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:38:39.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:38:39.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:38:39.604+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:38:39.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:38:39.614+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:38:39.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:38:39.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T15:39:09.940+0000] {processor.py:157} INFO - Started process (PID=90586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:39:09.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:39:09.945+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:39:09.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:39:09.965+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:39:10.005+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:39:10.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:39:10.022+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:39:10.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:39:10.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-21T15:39:40.381+0000] {processor.py:157} INFO - Started process (PID=90596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:39:40.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:39:40.392+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:39:40.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:39:40.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:39:40.458+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:39:40.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:39:40.480+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:39:40.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:39:40.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-21T15:40:10.679+0000] {processor.py:157} INFO - Started process (PID=90606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:40:10.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:40:10.687+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:40:10.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:40:10.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:40:10.732+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:40:10.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:40:10.746+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:40:10.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:40:10.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-08-21T15:40:41.001+0000] {processor.py:157} INFO - Started process (PID=90616) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:40:41.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:40:41.012+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:40:41.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:40:41.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:40:41.071+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:40:41.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:40:41.094+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:40:41.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:40:41.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-21T15:41:11.452+0000] {processor.py:157} INFO - Started process (PID=90626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:41:11.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:41:11.472+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:41:11.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:41:11.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:41:11.519+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:41:11.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:41:11.538+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:41:11.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:41:11.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-21T15:41:41.900+0000] {processor.py:157} INFO - Started process (PID=90636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:41:41.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:41:41.911+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:41:41.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:41:41.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:41:42.008+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:41:42.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:41:42.027+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:41:42.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:41:42.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-21T15:42:12.251+0000] {processor.py:157} INFO - Started process (PID=90644) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:42:12.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:42:12.258+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:42:12.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:42:12.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:42:12.317+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:42:12.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:42:12.332+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:42:12.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:42:12.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-21T15:42:42.543+0000] {processor.py:157} INFO - Started process (PID=90656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:42:42.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:42:42.550+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:42:42.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:42:42.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:42:42.604+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:42:42.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:42:42.624+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:42:42.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:42:42.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-08-21T15:43:12.865+0000] {processor.py:157} INFO - Started process (PID=90666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:43:12.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:43:12.872+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:43:12.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:43:12.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:43:12.933+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:43:12.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:43:12.947+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:43:12.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:43:12.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-08-21T15:43:43.322+0000] {processor.py:157} INFO - Started process (PID=90676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:43:43.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:43:43.336+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:43:43.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:43:43.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:43:43.401+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:43:43.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:43:43.419+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:43:43.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:43:43.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-08-21T15:44:13.673+0000] {processor.py:157} INFO - Started process (PID=90686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:44:13.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:44:13.682+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:44:13.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:44:13.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:44:13.820+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:44:13.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:44:13.842+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:44:13.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:44:13.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.187 seconds
[2024-08-21T15:44:44.000+0000] {processor.py:157} INFO - Started process (PID=90696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:44:44.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:44:44.006+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:44:44.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:44:44.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:44:44.063+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:44:44.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:44:44.080+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:44:44.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:44:44.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-21T15:45:14.675+0000] {processor.py:157} INFO - Started process (PID=90706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:45:14.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:45:14.732+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:45:14.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:45:14.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:45:15.081+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:45:15.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:45:15.192+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:45:15.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:45:15.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.631 seconds
[2024-08-21T15:45:45.543+0000] {processor.py:157} INFO - Started process (PID=90716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:45:45.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:45:45.556+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:45:45.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:45:45.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:45:45.659+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:45:45.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:45:45.677+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:45:45.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:45:45.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-08-21T15:46:15.879+0000] {processor.py:157} INFO - Started process (PID=90726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:46:15.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:46:15.884+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:46:15.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:46:15.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:46:15.930+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:46:15.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:46:15.946+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:46:15.945+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:46:15.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-21T15:46:46.228+0000] {processor.py:157} INFO - Started process (PID=90736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:46:46.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:46:46.234+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:46:46.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:46:46.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:46:46.273+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:46:46.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:46:46.286+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:46:46.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:46:46.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-21T15:47:16.642+0000] {processor.py:157} INFO - Started process (PID=90746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:47:16.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:47:16.647+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:47:16.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:47:16.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:47:16.710+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:47:16.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:47:16.724+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:47:16.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:47:16.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-21T15:47:47.263+0000] {processor.py:157} INFO - Started process (PID=90756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:47:47.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:47:47.276+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:47:47.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:47:47.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:47:47.369+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:47:47.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:47:47.389+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:47:47.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:47:47.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-08-21T15:48:17.651+0000] {processor.py:157} INFO - Started process (PID=90766) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:48:17.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:48:17.664+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:48:17.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:48:17.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:48:17.743+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:48:17.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:48:17.762+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:48:17.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:48:17.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-08-21T15:48:47.912+0000] {processor.py:157} INFO - Started process (PID=90775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:48:47.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:48:47.917+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:48:47.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:48:47.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:48:47.957+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:48:47.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:48:47.973+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:48:47.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:48:47.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-08-21T15:49:18.272+0000] {processor.py:157} INFO - Started process (PID=90786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:49:18.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:49:18.275+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:49:18.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:49:18.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:49:18.300+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:49:18.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:49:18.310+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:49:18.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:49:18.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-08-21T15:49:48.701+0000] {processor.py:157} INFO - Started process (PID=90796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:49:48.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:49:48.717+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:49:48.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:49:48.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:49:48.776+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:49:48.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:49:48.790+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:49:48.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:49:48.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-21T15:50:19.001+0000] {processor.py:157} INFO - Started process (PID=90806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:50:19.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:50:19.006+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:50:19.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:50:19.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:50:19.059+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:50:19.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:50:19.088+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:50:19.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:50:19.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-08-21T15:50:49.437+0000] {processor.py:157} INFO - Started process (PID=90816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:50:49.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:50:49.451+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:50:49.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:50:49.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:50:49.518+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:50:49.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:50:49.534+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:50:49.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:50:49.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-21T15:51:19.858+0000] {processor.py:157} INFO - Started process (PID=90826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:51:19.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:51:19.865+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:51:19.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:51:19.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:51:19.920+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:51:19.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:51:19.936+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:51:19.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:51:19.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-08-21T15:51:50.263+0000] {processor.py:157} INFO - Started process (PID=90836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:51:50.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:51:50.266+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:51:50.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:51:50.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:51:50.298+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:51:50.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:51:50.310+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:51:50.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:51:50.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-08-21T15:52:20.571+0000] {processor.py:157} INFO - Started process (PID=90846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:52:20.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:52:20.585+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:52:20.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:52:20.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:52:20.639+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:52:20.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:52:20.658+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:52:20.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:52:20.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-08-21T15:52:50.869+0000] {processor.py:157} INFO - Started process (PID=90856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:52:50.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:52:50.878+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:52:50.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:52:50.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:52:50.915+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:52:50.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:52:50.928+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:52:50.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:52:50.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-08-21T15:53:21.212+0000] {processor.py:157} INFO - Started process (PID=90866) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:53:21.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:53:21.215+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:53:21.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:53:21.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:53:21.241+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:53:21.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:53:21.251+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:53:21.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:53:21.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-21T15:53:51.516+0000] {processor.py:157} INFO - Started process (PID=90876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:53:51.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:53:51.519+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:53:51.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:53:51.530+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:53:51.546+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:53:51.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:53:51.560+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:53:51.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:53:51.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-08-21T15:54:21.854+0000] {processor.py:157} INFO - Started process (PID=90886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:54:21.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:54:21.857+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:54:21.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:54:21.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:54:21.883+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:54:21.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:54:21.893+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:54:21.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:54:21.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-21T15:54:52.216+0000] {processor.py:157} INFO - Started process (PID=90896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:54:52.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:54:52.220+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:54:52.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:54:52.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:54:52.258+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:54:52.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:54:52.272+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:54:52.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:54:52.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T15:55:22.554+0000] {processor.py:157} INFO - Started process (PID=90906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:55:22.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:55:22.560+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:55:22.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:55:22.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:55:22.587+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:55:22.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:55:22.596+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:55:22.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:55:22.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-08-21T15:55:52.914+0000] {processor.py:157} INFO - Started process (PID=90916) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:55:52.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:55:52.922+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:55:52.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:55:52.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:55:52.959+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:55:52.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:55:52.975+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:55:52.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:55:52.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-21T15:56:23.683+0000] {processor.py:157} INFO - Started process (PID=90926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:56:23.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:56:23.690+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:56:23.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:56:23.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:56:23.763+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:56:23.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:56:23.777+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:56:23.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:56:23.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-08-21T15:57:07.565+0000] {processor.py:157} INFO - Started process (PID=90936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:57:07.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T15:57:07.569+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:57:07.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:57:07.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T15:57:07.599+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:57:07.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T15:57:07.611+0000] {logging_mixin.py:151} INFO - [2024-08-21T15:57:07.611+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T15:57:07.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-08-21T16:15:03.296+0000] {processor.py:157} INFO - Started process (PID=90946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:15:03.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:15:03.306+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:15:03.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:15:03.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:15:03.402+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:15:03.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:15:03.421+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:15:03.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:15:03.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-08-21T16:15:33.909+0000] {processor.py:157} INFO - Started process (PID=90957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:15:33.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:15:33.915+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:15:33.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:15:33.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:15:33.975+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:15:33.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:15:33.992+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:15:33.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:15:34.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-21T16:16:04.232+0000] {processor.py:157} INFO - Started process (PID=90968) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:16:04.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:16:04.238+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:16:04.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:16:04.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:16:04.271+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:16:04.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:16:04.284+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:16:04.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:16:04.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-08-21T16:16:34.674+0000] {processor.py:157} INFO - Started process (PID=90978) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:16:34.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:16:34.678+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:16:34.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:16:34.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:16:34.713+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:16:34.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:16:34.726+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:16:34.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:16:34.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-21T16:17:05.045+0000] {processor.py:157} INFO - Started process (PID=90988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:17:05.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:17:05.050+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:17:05.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:17:05.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:17:05.087+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:17:05.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:17:05.098+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:17:05.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:17:05.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-21T16:17:35.427+0000] {processor.py:157} INFO - Started process (PID=90998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:17:35.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:17:35.433+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:17:35.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:17:35.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:17:35.468+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:17:35.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:17:35.483+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:17:35.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:17:35.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-21T16:18:05.788+0000] {processor.py:157} INFO - Started process (PID=91008) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:18:05.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:18:05.805+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:18:05.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:18:05.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:18:05.857+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:18:05.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:18:05.870+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:18:05.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:18:05.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-21T16:18:36.284+0000] {processor.py:157} INFO - Started process (PID=91018) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:18:36.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:18:36.286+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:18:36.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:18:36.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:18:36.309+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:18:36.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:18:36.318+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:18:36.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:18:36.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-08-21T16:19:06.703+0000] {processor.py:157} INFO - Started process (PID=91028) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:19:06.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:19:06.717+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:19:06.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:19:06.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:19:06.768+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:19:06.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:19:06.781+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:19:06.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:19:06.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-08-21T16:19:37.137+0000] {processor.py:157} INFO - Started process (PID=91038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:19:37.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:19:37.143+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:19:37.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:19:37.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:19:37.176+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:19:37.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:19:37.189+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:19:37.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:19:37.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-08-21T16:20:07.591+0000] {processor.py:157} INFO - Started process (PID=91047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:20:07.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:20:07.597+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:20:07.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:20:07.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:20:07.652+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:20:07.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:20:07.673+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:20:07.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:20:07.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-21T16:20:38.006+0000] {processor.py:157} INFO - Started process (PID=91058) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:20:38.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:20:38.012+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:20:38.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:20:38.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:20:38.044+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:20:38.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:20:38.053+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:20:38.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:20:38.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-08-21T16:21:08.413+0000] {processor.py:157} INFO - Started process (PID=91068) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:21:08.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:21:08.421+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:21:08.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:21:08.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:21:08.464+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:21:08.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:21:08.480+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:21:08.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:21:08.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-21T16:21:38.913+0000] {processor.py:157} INFO - Started process (PID=91078) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:21:38.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:21:38.918+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:21:38.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:21:38.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:21:38.957+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:21:38.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:21:38.972+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:21:38.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:21:38.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-21T16:22:09.344+0000] {processor.py:157} INFO - Started process (PID=91087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:22:09.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:22:09.347+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:22:09.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:22:09.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:22:09.393+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:22:09.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:22:09.406+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:22:09.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:22:09.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-21T16:37:42.745+0000] {processor.py:157} INFO - Started process (PID=91099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:37:42.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:37:42.758+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:37:42.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:37:42.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:37:42.851+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:37:42.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:37:42.873+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:37:42.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:37:42.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-08-21T16:38:13.097+0000] {processor.py:157} INFO - Started process (PID=91110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:38:13.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:38:13.103+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:38:13.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:38:13.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:38:13.150+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:38:13.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:38:13.167+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:38:13.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:38:13.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-21T16:38:43.406+0000] {processor.py:157} INFO - Started process (PID=91120) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:38:43.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:38:43.412+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:38:43.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:38:43.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:38:43.448+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:38:43.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:38:43.462+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:38:43.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:38:43.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-21T16:39:13.675+0000] {processor.py:157} INFO - Started process (PID=91130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:39:13.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:39:13.679+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:39:13.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:39:13.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:39:13.704+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:39:13.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:39:13.714+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:39:13.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:39:13.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-08-21T16:39:44.069+0000] {processor.py:157} INFO - Started process (PID=91139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:39:44.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:39:44.074+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:39:44.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:39:44.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:39:44.113+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:39:44.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:39:44.127+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:39:44.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:39:44.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-08-21T16:55:44.451+0000] {processor.py:157} INFO - Started process (PID=91152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:55:44.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:55:44.459+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:55:44.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:55:44.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:55:44.537+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:55:44.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:55:44.563+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:55:44.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:55:44.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-08-21T16:56:14.912+0000] {processor.py:157} INFO - Started process (PID=91162) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:56:14.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:56:14.919+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:56:14.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:56:14.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:56:14.990+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:56:14.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:56:15.004+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:56:15.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:56:15.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-08-21T16:56:45.247+0000] {processor.py:157} INFO - Started process (PID=91172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:56:45.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:56:45.249+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:56:45.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:56:45.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:56:45.278+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:56:45.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:56:45.293+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:56:45.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:56:45.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-08-21T16:57:15.620+0000] {processor.py:157} INFO - Started process (PID=91182) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:57:15.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T16:57:15.625+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:57:15.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:57:15.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T16:57:15.663+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:57:15.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T16:57:15.676+0000] {logging_mixin.py:151} INFO - [2024-08-21T16:57:15.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T16:57:15.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T17:14:15.522+0000] {processor.py:157} INFO - Started process (PID=91192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:14:15.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T17:14:15.526+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:14:15.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:14:15.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:14:15.566+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:14:15.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T17:14:15.579+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:14:15.579+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T17:14:15.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T17:14:45.884+0000] {processor.py:157} INFO - Started process (PID=91202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:14:45.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T17:14:45.900+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:14:45.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:14:45.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:14:45.967+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:14:45.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T17:14:45.981+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:14:45.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T17:14:45.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-08-21T17:15:16.198+0000] {processor.py:157} INFO - Started process (PID=91212) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:15:16.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T17:15:16.203+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:15:16.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:15:16.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:15:16.226+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:15:16.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T17:15:16.239+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:15:16.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T17:15:16.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-08-21T17:15:46.569+0000] {processor.py:157} INFO - Started process (PID=91222) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:15:46.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T17:15:46.574+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:15:46.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:15:46.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:15:46.635+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:15:46.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T17:15:46.650+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:15:46.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T17:15:46.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-21T17:16:16.928+0000] {processor.py:157} INFO - Started process (PID=91232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:16:16.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T17:16:16.934+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:16:16.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:16:16.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:16:16.994+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:16:16.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T17:16:17.010+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:16:17.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T17:16:17.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-21T17:32:00.029+0000] {processor.py:157} INFO - Started process (PID=91242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:32:00.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T17:32:00.036+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:32:00.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:32:00.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:32:00.091+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:32:00.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T17:32:00.112+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:32:00.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T17:32:00.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-08-21T17:32:30.529+0000] {processor.py:157} INFO - Started process (PID=91254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:32:30.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T17:32:30.536+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:32:30.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:32:30.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:32:30.583+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:32:30.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T17:32:30.601+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:32:30.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T17:32:30.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-21T17:33:00.843+0000] {processor.py:157} INFO - Started process (PID=91264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:33:00.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T17:33:00.849+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:33:00.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:33:00.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:33:00.873+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:33:00.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T17:33:00.885+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:33:00.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T17:33:00.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-08-21T17:33:31.142+0000] {processor.py:157} INFO - Started process (PID=91274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:33:31.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T17:33:31.147+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:33:31.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:33:31.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:33:31.187+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:33:31.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T17:33:31.199+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:33:31.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T17:33:31.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-08-21T17:34:01.487+0000] {processor.py:157} INFO - Started process (PID=91284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:34:01.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T17:34:01.496+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:34:01.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:34:01.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:34:01.517+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:34:01.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T17:34:01.527+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:34:01.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T17:34:01.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-08-21T17:45:30.216+0000] {processor.py:157} INFO - Started process (PID=91296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:45:30.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T17:45:30.222+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:45:30.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:45:30.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:45:30.270+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:45:30.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T17:45:30.291+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:45:30.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T17:45:30.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-08-21T17:46:00.612+0000] {processor.py:157} INFO - Started process (PID=91305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:46:00.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T17:46:00.618+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:46:00.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:46:00.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:46:00.665+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:46:00.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T17:46:00.683+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:46:00.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T17:46:00.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-21T17:50:26.494+0000] {processor.py:157} INFO - Started process (PID=91315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:50:26.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T17:50:26.501+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:50:26.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:50:26.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:50:26.550+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:50:26.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T17:50:26.565+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:50:26.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T17:50:26.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-08-21T17:57:20.829+0000] {processor.py:157} INFO - Started process (PID=91326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:57:20.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T17:57:20.834+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:57:20.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:57:20.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:57:20.905+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:57:20.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T17:57:20.920+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:57:20.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T17:57:20.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-08-21T17:57:51.112+0000] {processor.py:157} INFO - Started process (PID=91336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:57:51.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T17:57:51.118+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:57:51.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:57:51.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T17:57:51.173+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:57:51.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T17:57:51.184+0000] {logging_mixin.py:151} INFO - [2024-08-21T17:57:51.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T17:57:51.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-21T18:30:14.249+0000] {processor.py:157} INFO - Started process (PID=91348) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T18:30:14.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T18:30:14.256+0000] {logging_mixin.py:151} INFO - [2024-08-21T18:30:14.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T18:30:14.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T18:30:14.328+0000] {logging_mixin.py:151} INFO - [2024-08-21T18:30:14.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T18:30:14.357+0000] {logging_mixin.py:151} INFO - [2024-08-21T18:30:14.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T18:30:14.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-08-21T18:30:44.703+0000] {processor.py:157} INFO - Started process (PID=91357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T18:30:44.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T18:30:44.708+0000] {logging_mixin.py:151} INFO - [2024-08-21T18:30:44.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T18:30:44.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T18:30:44.756+0000] {logging_mixin.py:151} INFO - [2024-08-21T18:30:44.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T18:30:44.773+0000] {logging_mixin.py:151} INFO - [2024-08-21T18:30:44.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T18:30:44.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-08-21T18:58:23.745+0000] {processor.py:157} INFO - Started process (PID=91368) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T18:58:23.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T18:58:23.748+0000] {logging_mixin.py:151} INFO - [2024-08-21T18:58:23.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T18:58:23.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T18:58:23.836+0000] {logging_mixin.py:151} INFO - [2024-08-21T18:58:23.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T18:58:23.863+0000] {logging_mixin.py:151} INFO - [2024-08-21T18:58:23.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T18:58:23.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-08-21T18:58:54.090+0000] {processor.py:157} INFO - Started process (PID=91377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T18:58:54.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T18:58:54.097+0000] {logging_mixin.py:151} INFO - [2024-08-21T18:58:54.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T18:58:54.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T18:58:54.154+0000] {logging_mixin.py:151} INFO - [2024-08-21T18:58:54.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T18:58:54.168+0000] {logging_mixin.py:151} INFO - [2024-08-21T18:58:54.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T18:58:54.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-08-21T19:40:39.012+0000] {processor.py:157} INFO - Started process (PID=91390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:40:39.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T19:40:39.018+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:40:39.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:40:39.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:40:39.062+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:40:39.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T19:40:39.083+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:40:39.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T19:40:39.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-08-21T19:41:09.393+0000] {processor.py:157} INFO - Started process (PID=91400) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:41:09.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T19:41:09.400+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:41:09.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:41:09.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:41:09.446+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:41:09.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T19:41:09.459+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:41:09.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T19:41:09.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-08-21T19:55:21.939+0000] {processor.py:157} INFO - Started process (PID=91410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:55:21.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T19:55:21.948+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:55:21.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:55:21.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:55:22.001+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:55:22.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T19:55:22.016+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:55:22.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T19:55:22.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-21T19:55:52.235+0000] {processor.py:157} INFO - Started process (PID=91420) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:55:52.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T19:55:52.242+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:55:52.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:55:52.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:55:52.302+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:55:52.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T19:55:52.316+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:55:52.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T19:55:52.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-08-21T19:56:22.510+0000] {processor.py:157} INFO - Started process (PID=91430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:56:22.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T19:56:22.516+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:56:22.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:56:22.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:56:22.559+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:56:22.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T19:56:22.573+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:56:22.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T19:56:22.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-21T19:56:52.904+0000] {processor.py:157} INFO - Started process (PID=91439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:56:52.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T19:56:52.915+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:56:52.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:56:52.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:56:53.002+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:56:53.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T19:56:53.021+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:56:53.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T19:56:53.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-08-21T19:57:23.249+0000] {processor.py:157} INFO - Started process (PID=91450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:57:23.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T19:57:23.256+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:57:23.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:57:23.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:57:23.350+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:57:23.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T19:57:23.368+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:57:23.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T19:57:23.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-08-21T19:57:53.729+0000] {processor.py:157} INFO - Started process (PID=91460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:57:53.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T19:57:53.738+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:57:53.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:57:53.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:57:53.790+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:57:53.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T19:57:53.810+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:57:53.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T19:57:53.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-08-21T19:58:24.073+0000] {processor.py:157} INFO - Started process (PID=91470) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:58:24.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T19:58:24.078+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:58:24.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:58:24.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:58:24.118+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:58:24.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T19:58:24.131+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:58:24.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T19:58:24.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-08-21T19:58:54.368+0000] {processor.py:157} INFO - Started process (PID=91480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:58:54.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T19:58:54.371+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:58:54.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:58:54.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:58:54.408+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:58:54.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T19:58:54.423+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:58:54.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T19:58:54.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-08-21T19:59:24.806+0000] {processor.py:157} INFO - Started process (PID=91490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:59:24.807+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T19:59:24.813+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:59:24.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:59:24.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:59:24.860+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:59:24.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T19:59:24.889+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:59:24.889+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T19:59:24.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-08-21T19:59:55.237+0000] {processor.py:157} INFO - Started process (PID=91499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:59:55.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T19:59:55.256+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:59:55.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:59:55.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T19:59:55.332+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:59:55.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T19:59:55.350+0000] {logging_mixin.py:151} INFO - [2024-08-21T19:59:55.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T19:59:55.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-08-21T20:00:25.597+0000] {processor.py:157} INFO - Started process (PID=91510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:00:25.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:00:25.617+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:00:25.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:00:25.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:00:25.705+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:00:25.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:00:25.721+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:00:25.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:00:25.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-08-21T20:00:55.946+0000] {processor.py:157} INFO - Started process (PID=91519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:00:55.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:00:55.962+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:00:55.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:00:56.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:00:56.066+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:00:56.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:00:56.099+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:00:56.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:00:56.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-08-21T20:01:26.546+0000] {processor.py:157} INFO - Started process (PID=91530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:01:26.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:01:26.551+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:01:26.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:01:26.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:01:26.605+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:01:26.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:01:26.620+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:01:26.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:01:26.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-08-21T20:01:56.933+0000] {processor.py:157} INFO - Started process (PID=91540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:01:56.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:01:56.943+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:01:56.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:01:56.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:01:57.044+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:01:57.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:01:57.063+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:01:57.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:01:57.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-08-21T20:02:27.266+0000] {processor.py:157} INFO - Started process (PID=91550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:02:27.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:02:27.272+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:02:27.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:02:27.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:02:27.332+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:02:27.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:02:27.364+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:02:27.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:02:27.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-08-21T20:02:57.638+0000] {processor.py:157} INFO - Started process (PID=91560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:02:57.640+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:02:57.650+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:02:57.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:02:57.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:02:57.734+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:02:57.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:02:57.763+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:02:57.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:02:57.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-08-21T20:03:27.962+0000] {processor.py:157} INFO - Started process (PID=91570) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:03:27.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:03:27.968+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:03:27.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:03:27.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:03:28.019+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:03:28.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:03:28.033+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:03:28.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:03:28.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-08-21T20:03:58.405+0000] {processor.py:157} INFO - Started process (PID=91580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:03:58.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:03:58.410+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:03:58.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:03:58.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:03:58.456+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:03:58.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:03:58.470+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:03:58.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:03:58.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-21T20:04:28.807+0000] {processor.py:157} INFO - Started process (PID=91590) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:04:28.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:04:28.824+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:04:28.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:04:28.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:04:28.891+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:04:28.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:04:28.908+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:04:28.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:04:28.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-08-21T20:04:59.157+0000] {processor.py:157} INFO - Started process (PID=91599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:04:59.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:04:59.163+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:04:59.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:04:59.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:04:59.226+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:04:59.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:04:59.241+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:04:59.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:04:59.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-08-21T20:05:29.610+0000] {processor.py:157} INFO - Started process (PID=91610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:05:29.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:05:29.617+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:05:29.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:05:29.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:05:29.681+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:05:29.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:05:29.705+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:05:29.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:05:29.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-21T20:05:59.963+0000] {processor.py:157} INFO - Started process (PID=91620) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:05:59.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:05:59.969+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:05:59.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:05:59.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:06:00.022+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:06:00.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:06:00.047+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:06:00.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:06:00.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-08-21T20:06:30.296+0000] {processor.py:157} INFO - Started process (PID=91630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:06:30.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:06:30.302+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:06:30.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:06:30.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:06:30.348+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:06:30.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:06:30.361+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:06:30.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:06:30.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-08-21T20:07:00.795+0000] {processor.py:157} INFO - Started process (PID=91640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:07:00.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:07:00.804+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:07:00.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:07:00.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:07:00.870+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:07:00.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:07:00.891+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:07:00.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:07:00.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-08-21T20:08:24.701+0000] {processor.py:157} INFO - Started process (PID=91651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:08:24.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:08:24.704+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:08:24.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:08:24.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:08:24.741+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:08:24.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:08:24.752+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:08:24.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:08:24.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-08-21T20:09:10.813+0000] {processor.py:157} INFO - Started process (PID=91662) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:09:10.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:09:10.830+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:09:10.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:09:10.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:09:10.896+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:09:10.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:09:10.919+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:09:10.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:09:10.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-08-21T20:09:41.143+0000] {processor.py:157} INFO - Started process (PID=91672) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:09:41.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:09:41.148+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:09:41.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:09:41.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:09:41.190+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:09:41.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:09:41.203+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:09:41.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:09:41.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-08-21T20:10:49.825+0000] {processor.py:157} INFO - Started process (PID=91682) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:10:49.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:10:49.829+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:10:49.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:10:49.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:10:49.892+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:10:49.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:10:49.906+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:10:49.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:10:49.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-21T20:11:41.685+0000] {processor.py:157} INFO - Started process (PID=91692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:11:41.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:11:41.693+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:11:41.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:11:41.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:11:41.747+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:11:41.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:11:41.764+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:11:41.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:11:41.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-08-21T20:12:12.040+0000] {processor.py:157} INFO - Started process (PID=91704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:12:12.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:12:12.052+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:12:12.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:12:12.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:12:12.097+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:12:12.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:12:12.111+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:12:12.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:12:12.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-08-21T20:12:52.603+0000] {processor.py:157} INFO - Started process (PID=91714) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:12:52.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:12:52.610+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:12:52.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:12:52.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:12:52.665+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:12:52.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:12:52.682+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:12:52.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:12:52.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-08-21T20:13:42.016+0000] {processor.py:157} INFO - Started process (PID=91724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:13:42.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:13:42.028+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:13:42.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:13:42.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:13:42.102+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:13:42.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:13:42.117+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:13:42.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:13:42.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-08-21T20:14:12.349+0000] {processor.py:157} INFO - Started process (PID=91734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:14:12.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:14:12.354+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:14:12.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:14:12.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:14:12.397+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:14:12.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:14:12.410+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:14:12.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:14:12.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-21T20:14:47.661+0000] {processor.py:157} INFO - Started process (PID=91744) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:14:47.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:14:47.676+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:14:47.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:14:47.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:14:47.721+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:14:47.721+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:14:47.745+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:14:47.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:14:47.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-08-21T20:15:18.217+0000] {processor.py:157} INFO - Started process (PID=91754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:15:18.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:15:18.223+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:15:18.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:15:18.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:15:18.271+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:15:18.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:15:18.283+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:15:18.283+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:15:18.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-08-21T20:15:53.578+0000] {processor.py:157} INFO - Started process (PID=91764) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:15:53.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:15:53.590+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:15:53.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:15:53.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:15:53.636+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:15:53.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:15:53.653+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:15:53.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:15:53.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-08-21T20:16:24.085+0000] {processor.py:157} INFO - Started process (PID=91773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:16:24.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T20:16:24.092+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:16:24.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:16:24.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T20:16:24.165+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:16:24.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T20:16:24.179+0000] {logging_mixin.py:151} INFO - [2024-08-21T20:16:24.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T20:16:24.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-08-21T21:40:59.245+0000] {processor.py:157} INFO - Started process (PID=91784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T21:40:59.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T21:40:59.254+0000] {logging_mixin.py:151} INFO - [2024-08-21T21:40:59.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T21:40:59.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T21:40:59.323+0000] {logging_mixin.py:151} INFO - [2024-08-21T21:40:59.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T21:40:59.354+0000] {logging_mixin.py:151} INFO - [2024-08-21T21:40:59.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T21:40:59.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-08-21T22:08:13.121+0000] {processor.py:157} INFO - Started process (PID=91794) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T22:08:13.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T22:08:13.140+0000] {logging_mixin.py:151} INFO - [2024-08-21T22:08:13.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T22:08:13.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T22:08:13.255+0000] {logging_mixin.py:151} INFO - [2024-08-21T22:08:13.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T22:08:13.304+0000] {logging_mixin.py:151} INFO - [2024-08-21T22:08:13.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T22:08:13.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.223 seconds
[2024-08-21T22:25:43.590+0000] {processor.py:157} INFO - Started process (PID=91806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T22:25:43.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T22:25:43.596+0000] {logging_mixin.py:151} INFO - [2024-08-21T22:25:43.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T22:25:43.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T22:25:43.641+0000] {logging_mixin.py:151} INFO - [2024-08-21T22:25:43.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T22:25:43.667+0000] {logging_mixin.py:151} INFO - [2024-08-21T22:25:43.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T22:25:43.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-08-21T22:35:40.477+0000] {processor.py:157} INFO - Started process (PID=91816) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T22:35:40.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T22:35:40.483+0000] {logging_mixin.py:151} INFO - [2024-08-21T22:35:40.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T22:35:40.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T22:35:40.527+0000] {logging_mixin.py:151} INFO - [2024-08-21T22:35:40.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T22:35:40.541+0000] {logging_mixin.py:151} INFO - [2024-08-21T22:35:40.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T22:35:40.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-08-21T23:24:00.243+0000] {processor.py:157} INFO - Started process (PID=91826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-08-21T23:24:00.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-08-21T23:24:00.248+0000] {logging_mixin.py:151} INFO - [2024-08-21T23:24:00.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T23:24:00.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-08-21T23:24:00.327+0000] {logging_mixin.py:151} INFO - [2024-08-21T23:24:00.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-08-21T23:24:00.348+0000] {logging_mixin.py:151} INFO - [2024-08-21T23:24:00.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-08-20T01:00:00+00:00, run_after=2024-08-21T01:00:00+00:00
[2024-08-21T23:24:00.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
