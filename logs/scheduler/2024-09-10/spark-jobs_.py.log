[2024-09-10T00:00:17.357+0000] {processor.py:157} INFO - Started process (PID=24835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:00:17.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:00:17.362+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:00:17.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:00:17.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:00:17.414+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:00:17.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:00:17.427+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:00:17.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:00:17.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T00:00:47.683+0000] {processor.py:157} INFO - Started process (PID=24845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:00:47.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:00:47.688+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:00:47.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:00:47.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:00:47.743+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:00:47.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:00:47.758+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:00:47.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:00:47.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-10T00:01:17.978+0000] {processor.py:157} INFO - Started process (PID=24855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:01:17.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:01:17.981+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:01:17.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:01:17.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:01:18.007+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:01:18.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:01:18.017+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:01:18.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:01:18.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T00:01:48.321+0000] {processor.py:157} INFO - Started process (PID=24865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:01:48.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:01:48.329+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:01:48.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:01:48.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:01:48.393+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:01:48.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:01:48.414+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:01:48.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:01:48.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-10T00:02:18.601+0000] {processor.py:157} INFO - Started process (PID=24875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:02:18.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:02:18.608+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:02:18.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:02:18.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:02:18.646+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:02:18.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:02:18.657+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:02:18.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:02:18.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T00:02:48.900+0000] {processor.py:157} INFO - Started process (PID=24885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:02:48.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:02:48.902+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:02:48.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:02:48.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:02:48.933+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:02:48.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:02:48.943+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:02:48.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:02:48.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T00:03:19.204+0000] {processor.py:157} INFO - Started process (PID=24895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:03:19.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:03:19.209+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:03:19.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:03:19.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:03:19.264+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:03:19.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:03:19.282+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:03:19.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:03:19.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-10T00:03:49.605+0000] {processor.py:157} INFO - Started process (PID=24904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:03:49.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:03:49.610+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:03:49.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:03:49.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:03:49.667+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:03:49.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:03:49.680+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:03:49.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:03:49.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-10T00:04:20.043+0000] {processor.py:157} INFO - Started process (PID=24914) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:04:20.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:04:20.048+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:04:20.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:04:20.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:04:20.087+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:04:20.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:04:20.102+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:04:20.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:04:20.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-10T00:04:50.383+0000] {processor.py:157} INFO - Started process (PID=24924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:04:50.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:04:50.388+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:04:50.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:04:50.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:04:50.428+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:04:50.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:04:50.443+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:04:50.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:04:50.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-10T00:05:20.799+0000] {processor.py:157} INFO - Started process (PID=24935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:05:20.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:05:20.801+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:05:20.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:05:20.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:05:20.831+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:05:20.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:05:20.840+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:05:20.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:05:20.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T00:05:51.166+0000] {processor.py:157} INFO - Started process (PID=24945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:05:51.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:05:51.169+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:05:51.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:05:51.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:05:51.208+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:05:51.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:05:51.236+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:05:51.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:05:51.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T00:06:21.504+0000] {processor.py:157} INFO - Started process (PID=24954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:06:21.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:06:21.508+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:06:21.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:06:21.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:06:21.538+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:06:21.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:06:21.548+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:06:21.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:06:21.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T00:06:51.783+0000] {processor.py:157} INFO - Started process (PID=24965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:06:51.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:06:51.786+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:06:51.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:06:51.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:06:51.820+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:06:51.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:06:51.833+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:06:51.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:06:51.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T00:07:22.136+0000] {processor.py:157} INFO - Started process (PID=24975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:07:22.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:07:22.139+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:07:22.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:07:22.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:07:22.168+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:07:22.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:07:22.179+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:07:22.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:07:22.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T00:07:52.517+0000] {processor.py:157} INFO - Started process (PID=24985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:07:52.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:07:52.519+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:07:52.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:07:52.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:07:52.555+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:07:52.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:07:52.570+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:07:52.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:07:52.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T00:08:22.887+0000] {processor.py:157} INFO - Started process (PID=24994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:08:22.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:08:22.892+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:08:22.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:08:22.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:08:22.922+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:08:22.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:08:22.931+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:08:22.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:08:22.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T00:08:53.259+0000] {processor.py:157} INFO - Started process (PID=25005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:08:53.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:08:53.262+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:08:53.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:08:53.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:08:53.296+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:08:53.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:08:53.308+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:08:53.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:08:53.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T00:09:23.746+0000] {processor.py:157} INFO - Started process (PID=25015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:09:23.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:09:23.752+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:09:23.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:09:23.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:09:23.787+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:09:23.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:09:23.798+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:09:23.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:09:23.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-10T00:09:54.061+0000] {processor.py:157} INFO - Started process (PID=25024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:09:54.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:09:54.069+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:09:54.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:09:54.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:09:54.127+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:09:54.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:09:54.138+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:09:54.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:09:54.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-10T00:10:24.471+0000] {processor.py:157} INFO - Started process (PID=25035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:10:24.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:10:24.473+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:10:24.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:10:24.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:10:24.497+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:10:24.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:10:24.507+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:10:24.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:10:24.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T00:10:54.835+0000] {processor.py:157} INFO - Started process (PID=25045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:10:54.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:10:54.840+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:10:54.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:10:54.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:10:54.887+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:10:54.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:10:54.914+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:10:54.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:10:54.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-10T00:11:25.070+0000] {processor.py:157} INFO - Started process (PID=25055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:11:25.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:11:25.075+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:11:25.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:11:25.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:11:25.105+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:11:25.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:11:25.116+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:11:25.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:11:25.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T00:11:55.431+0000] {processor.py:157} INFO - Started process (PID=25065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:11:55.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:11:55.436+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:11:55.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:11:55.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:11:55.462+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:11:55.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:11:55.475+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:11:55.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:11:55.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T00:12:25.839+0000] {processor.py:157} INFO - Started process (PID=25074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:12:25.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:12:25.845+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:12:25.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:12:25.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:12:25.882+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:12:25.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:12:25.904+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:12:25.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:12:25.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-10T00:12:56.125+0000] {processor.py:157} INFO - Started process (PID=25085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:12:56.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:12:56.138+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:12:56.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:12:56.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:12:56.184+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:12:56.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:12:56.196+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:12:56.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:12:56.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-10T00:13:26.463+0000] {processor.py:157} INFO - Started process (PID=25095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:13:26.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:13:26.466+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:13:26.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:13:26.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:13:26.494+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:13:26.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:13:26.504+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:13:26.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:13:26.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T00:13:56.847+0000] {processor.py:157} INFO - Started process (PID=25105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:13:56.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:13:56.851+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:13:56.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:13:56.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:13:56.892+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:13:56.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:13:56.905+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:13:56.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:13:56.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-10T00:14:27.277+0000] {processor.py:157} INFO - Started process (PID=25115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:14:27.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:14:27.284+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:14:27.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:14:27.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:14:27.322+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:14:27.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:14:27.335+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:14:27.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:14:27.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T00:14:57.661+0000] {processor.py:157} INFO - Started process (PID=25125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:14:57.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:14:57.669+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:14:57.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:14:57.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:14:57.694+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:14:57.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:14:57.705+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:14:57.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:14:57.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T00:15:28.067+0000] {processor.py:157} INFO - Started process (PID=25135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:15:28.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:15:28.072+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:15:28.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:15:28.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:15:28.110+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:15:28.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:15:28.123+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:15:28.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:15:28.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-10T00:15:58.447+0000] {processor.py:157} INFO - Started process (PID=25145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:15:58.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:15:58.450+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:15:58.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:15:58.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:15:58.476+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:15:58.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:15:58.488+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:15:58.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:15:58.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T00:16:28.888+0000] {processor.py:157} INFO - Started process (PID=25155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:16:28.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:16:28.893+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:16:28.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:16:28.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:16:28.957+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:16:28.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:16:28.981+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:16:28.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:16:28.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-10T00:16:59.439+0000] {processor.py:157} INFO - Started process (PID=25165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:16:59.440+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:16:59.454+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:16:59.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:16:59.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:16:59.490+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:16:59.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:16:59.502+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:16:59.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:16:59.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-10T00:17:29.752+0000] {processor.py:157} INFO - Started process (PID=25175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:17:29.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:17:29.756+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:17:29.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:17:29.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:17:29.791+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:17:29.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:17:29.804+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:17:29.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:17:29.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T00:18:00.065+0000] {processor.py:157} INFO - Started process (PID=25185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:18:00.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:18:00.069+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:18:00.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:18:00.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:18:00.097+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:18:00.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:18:00.107+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:18:00.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:18:00.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T00:18:30.429+0000] {processor.py:157} INFO - Started process (PID=25195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:18:30.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:18:30.436+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:18:30.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:18:30.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:18:30.471+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:18:30.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:18:30.483+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:18:30.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:18:30.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T00:19:00.750+0000] {processor.py:157} INFO - Started process (PID=25205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:19:00.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:19:00.754+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:19:00.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:19:00.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:19:00.784+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:19:00.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:19:00.798+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:19:00.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:19:00.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T00:19:31.035+0000] {processor.py:157} INFO - Started process (PID=25215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:19:31.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:19:31.039+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:19:31.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:19:31.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:19:31.065+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:19:31.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:19:31.078+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:19:31.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:19:31.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T00:20:01.385+0000] {processor.py:157} INFO - Started process (PID=25224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:20:01.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:20:01.395+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:20:01.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:20:01.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:20:01.445+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:20:01.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:20:01.457+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:20:01.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:20:01.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-10T00:20:31.780+0000] {processor.py:157} INFO - Started process (PID=25235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:20:31.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:20:31.788+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:20:31.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:20:31.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:20:31.815+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:20:31.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:20:31.824+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:20:31.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:20:31.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T00:21:02.149+0000] {processor.py:157} INFO - Started process (PID=25245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:21:02.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:21:02.155+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:21:02.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:21:02.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:21:02.192+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:21:02.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:21:02.205+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:21:02.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:21:02.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T00:21:32.406+0000] {processor.py:157} INFO - Started process (PID=25255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:21:32.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:21:32.411+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:21:32.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:21:32.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:21:32.441+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:21:32.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:21:32.451+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:21:32.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:21:32.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T00:22:02.698+0000] {processor.py:157} INFO - Started process (PID=25265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:22:02.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:22:02.702+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:22:02.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:22:02.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:22:02.740+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:22:02.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:22:02.753+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:22:02.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:22:02.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T00:22:33.015+0000] {processor.py:157} INFO - Started process (PID=25275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:22:33.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:22:33.021+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:22:33.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:22:33.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:22:33.063+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:22:33.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:22:33.076+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:22:33.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:22:33.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T00:23:03.396+0000] {processor.py:157} INFO - Started process (PID=25285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:23:03.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:23:03.400+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:23:03.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:23:03.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:23:03.436+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:23:03.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:23:03.449+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:23:03.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:23:03.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T00:23:33.719+0000] {processor.py:157} INFO - Started process (PID=25295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:23:33.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:23:33.725+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:23:33.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:23:33.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:23:33.752+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:23:33.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:23:33.762+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:23:33.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:23:33.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T00:24:04.119+0000] {processor.py:157} INFO - Started process (PID=25305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:24:04.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:24:04.123+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:24:04.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:24:04.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:24:04.147+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:24:04.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:24:04.158+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:24:04.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:24:04.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T00:24:34.479+0000] {processor.py:157} INFO - Started process (PID=25315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:24:34.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:24:34.483+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:24:34.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:24:34.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:24:34.516+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:24:34.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:24:34.528+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:24:34.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:24:34.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T00:25:04.930+0000] {processor.py:157} INFO - Started process (PID=25325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:25:04.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:25:04.933+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:25:04.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:25:04.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:25:04.963+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:25:04.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:25:04.974+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:25:04.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:25:04.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T00:25:35.283+0000] {processor.py:157} INFO - Started process (PID=25335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:25:35.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:25:35.287+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:25:35.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:25:35.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:25:35.323+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:25:35.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:25:35.337+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:25:35.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:25:35.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-10T00:26:05.530+0000] {processor.py:157} INFO - Started process (PID=25343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:26:05.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:26:05.540+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:26:05.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:26:05.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:26:05.578+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:26:05.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:26:05.592+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:26:05.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:26:05.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-10T00:26:35.817+0000] {processor.py:157} INFO - Started process (PID=25355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:26:35.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:26:35.825+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:26:35.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:26:35.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:26:35.869+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:26:35.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:26:35.885+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:26:35.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:26:35.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-10T00:27:06.149+0000] {processor.py:157} INFO - Started process (PID=25365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:27:06.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:27:06.156+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:27:06.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:27:06.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:27:06.227+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:27:06.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:27:06.246+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:27:06.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:27:06.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-10T00:27:36.546+0000] {processor.py:157} INFO - Started process (PID=25375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:27:36.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:27:36.569+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:27:36.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:27:36.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:27:36.675+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:27:36.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:27:36.695+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:27:36.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:27:36.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.178 seconds
[2024-09-10T00:28:06.961+0000] {processor.py:157} INFO - Started process (PID=25385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:28:06.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:28:06.968+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:28:06.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:28:06.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:28:07.048+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:28:07.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:28:07.068+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:28:07.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:28:07.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-10T00:28:37.370+0000] {processor.py:157} INFO - Started process (PID=25395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:28:37.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:28:37.379+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:28:37.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:28:37.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:28:37.436+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:28:37.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:28:37.459+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:28:37.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:28:37.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-10T00:29:07.701+0000] {processor.py:157} INFO - Started process (PID=25405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:29:07.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:29:07.732+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:29:07.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:29:07.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:29:07.800+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:29:07.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:29:07.820+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:29:07.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:29:07.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-10T00:29:38.068+0000] {processor.py:157} INFO - Started process (PID=25415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:29:38.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:29:38.074+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:29:38.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:29:38.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:29:38.205+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:29:38.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:29:38.220+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:29:38.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:29:38.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-09-10T00:30:08.382+0000] {processor.py:157} INFO - Started process (PID=25749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:30:08.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:30:08.392+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:30:08.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:30:08.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:30:08.469+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:30:08.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:30:08.521+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:30:08.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:30:08.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-10T00:30:38.709+0000] {processor.py:157} INFO - Started process (PID=26029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:30:38.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:30:38.724+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:30:38.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:30:38.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:30:38.812+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:30:38.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:30:38.829+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:30:38.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:30:38.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-10T00:31:09.060+0000] {processor.py:157} INFO - Started process (PID=26039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:31:09.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:31:09.095+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:31:09.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:31:09.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:31:09.157+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:31:09.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:31:09.177+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:31:09.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:31:09.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-10T00:31:39.556+0000] {processor.py:157} INFO - Started process (PID=26049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:31:39.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:31:39.566+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:31:39.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:31:39.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:31:39.617+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:31:39.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:31:39.637+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:31:39.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:31:39.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-10T00:32:09.862+0000] {processor.py:157} INFO - Started process (PID=26059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:32:09.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:32:09.872+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:32:09.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:32:09.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:32:09.928+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:32:09.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:32:09.956+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:32:09.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:32:09.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-10T00:32:40.262+0000] {processor.py:157} INFO - Started process (PID=26239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:32:40.264+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:32:40.269+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:32:40.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:32:40.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:32:40.324+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:32:40.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:32:40.341+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:32:40.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:32:40.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-10T00:33:10.609+0000] {processor.py:157} INFO - Started process (PID=26249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:33:10.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:33:10.613+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:33:10.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:33:10.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:33:10.653+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:33:10.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:33:10.670+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:33:10.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:33:10.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-10T00:33:40.873+0000] {processor.py:157} INFO - Started process (PID=26259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:33:40.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:33:40.879+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:33:40.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:33:40.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:33:40.925+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:33:40.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:33:40.941+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:33:40.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:33:40.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-10T00:34:11.143+0000] {processor.py:157} INFO - Started process (PID=26269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:34:11.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:34:11.146+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:34:11.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:34:11.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:34:11.195+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:34:11.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:34:11.234+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:34:11.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:34:11.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-10T00:34:41.508+0000] {processor.py:157} INFO - Started process (PID=26279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:34:41.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:34:41.520+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:34:41.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:34:41.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:34:41.614+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:34:41.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:34:41.656+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:34:41.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:34:41.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.203 seconds
[2024-09-10T00:35:11.816+0000] {processor.py:157} INFO - Started process (PID=26289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:35:11.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:35:11.825+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:35:11.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:35:11.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:35:11.901+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:35:11.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:35:11.926+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:35:11.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:35:11.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-10T00:35:42.213+0000] {processor.py:157} INFO - Started process (PID=26299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:35:42.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:35:42.219+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:35:42.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:35:42.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:35:42.290+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:35:42.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:35:42.310+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:35:42.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:35:42.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-10T00:36:12.551+0000] {processor.py:157} INFO - Started process (PID=26309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:36:12.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:36:12.560+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:36:12.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:36:12.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:36:12.623+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:36:12.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:36:12.665+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:36:12.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:36:12.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-10T00:36:42.892+0000] {processor.py:157} INFO - Started process (PID=26319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:36:42.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:36:42.901+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:36:42.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:36:42.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:36:42.984+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:36:42.984+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:36:43.004+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:36:43.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:36:43.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-10T00:37:13.379+0000] {processor.py:157} INFO - Started process (PID=26329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:37:13.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:37:13.401+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:37:13.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:37:13.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:37:13.478+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:37:13.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:37:13.497+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:37:13.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:37:13.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-10T00:37:43.694+0000] {processor.py:157} INFO - Started process (PID=26339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:37:43.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:37:43.718+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:37:43.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:37:43.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:37:43.790+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:37:43.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:37:43.809+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:37:43.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:37:43.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-10T00:38:14.024+0000] {processor.py:157} INFO - Started process (PID=26349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:38:14.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:38:14.028+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:38:14.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:38:14.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:38:14.128+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:38:14.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:38:14.148+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:38:14.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:38:14.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-09-10T00:38:44.508+0000] {processor.py:157} INFO - Started process (PID=26359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:38:44.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:38:44.521+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:38:44.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:38:44.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:38:44.576+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:38:44.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:38:44.593+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:38:44.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:38:44.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-10T00:39:14.798+0000] {processor.py:157} INFO - Started process (PID=26369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:39:14.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:39:14.805+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:39:14.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:39:14.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:39:14.889+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:39:14.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:39:14.923+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:39:14.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:39:14.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-09-10T00:39:45.115+0000] {processor.py:157} INFO - Started process (PID=26379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:39:45.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:39:45.122+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:39:45.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:39:45.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:39:45.176+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:39:45.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:39:45.191+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:39:45.190+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:39:45.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-10T00:40:15.464+0000] {processor.py:157} INFO - Started process (PID=26389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:40:15.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:40:15.474+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:40:15.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:40:15.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:40:15.550+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:40:15.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:40:15.572+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:40:15.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:40:15.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-10T00:40:45.872+0000] {processor.py:157} INFO - Started process (PID=26399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:40:45.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:40:45.878+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:40:45.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:40:45.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:40:45.954+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:40:45.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:40:45.973+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:40:45.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:40:45.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-10T00:41:16.251+0000] {processor.py:157} INFO - Started process (PID=26409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:41:16.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:41:16.255+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:41:16.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:41:16.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:41:16.325+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:41:16.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:41:16.347+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:41:16.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:41:16.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-10T00:41:46.574+0000] {processor.py:157} INFO - Started process (PID=26419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:41:46.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:41:46.593+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:41:46.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:41:46.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:41:46.641+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:41:46.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:41:46.657+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:41:46.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:41:46.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-10T00:42:16.910+0000] {processor.py:157} INFO - Started process (PID=26429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:42:16.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:42:16.919+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:42:16.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:42:16.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:42:16.980+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:42:16.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:42:17.007+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:42:17.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:42:17.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-10T00:42:47.252+0000] {processor.py:157} INFO - Started process (PID=26439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:42:47.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:42:47.263+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:42:47.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:42:47.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:42:47.318+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:42:47.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:42:47.349+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:42:47.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:42:47.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-10T00:43:17.526+0000] {processor.py:157} INFO - Started process (PID=26449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:43:17.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:43:17.533+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:43:17.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:43:17.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:43:17.567+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:43:17.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:43:17.582+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:43:17.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:43:17.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T00:43:47.927+0000] {processor.py:157} INFO - Started process (PID=26459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:43:47.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:43:47.950+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:43:47.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:43:47.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:43:48.009+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:43:48.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:43:48.041+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:43:48.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:43:48.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.159 seconds
[2024-09-10T00:44:18.190+0000] {processor.py:157} INFO - Started process (PID=26469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:44:18.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:44:18.195+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:44:18.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:44:18.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:44:18.243+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:44:18.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:44:18.258+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:44:18.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:44:18.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T00:44:48.508+0000] {processor.py:157} INFO - Started process (PID=26479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:44:48.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:44:48.514+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:44:48.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:44:48.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:44:48.572+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:44:48.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:44:48.590+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:44:48.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:44:48.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-10T00:45:18.806+0000] {processor.py:157} INFO - Started process (PID=26489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:45:18.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:45:18.829+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:45:18.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:45:18.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:45:18.895+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:45:18.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:45:18.914+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:45:18.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:45:18.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-10T00:45:49.080+0000] {processor.py:157} INFO - Started process (PID=26499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:45:49.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:45:49.085+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:45:49.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:45:49.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:45:49.132+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:45:49.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:45:49.154+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:45:49.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:45:49.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-10T00:46:19.385+0000] {processor.py:157} INFO - Started process (PID=26509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:46:19.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:46:19.397+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:46:19.396+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:46:19.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:46:19.469+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:46:19.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:46:19.484+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:46:19.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:46:19.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-10T00:46:49.684+0000] {processor.py:157} INFO - Started process (PID=26519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:46:49.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:46:49.691+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:46:49.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:46:49.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:46:49.737+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:46:49.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:46:49.753+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:46:49.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:46:49.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-10T00:47:20.005+0000] {processor.py:157} INFO - Started process (PID=26529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:47:20.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:47:20.010+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:47:20.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:47:20.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:47:20.072+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:47:20.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:47:20.094+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:47:20.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:47:20.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-10T00:47:50.326+0000] {processor.py:157} INFO - Started process (PID=26539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:47:50.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:47:50.334+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:47:50.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:47:50.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:47:50.410+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:47:50.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:47:50.429+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:47:50.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:47:50.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-09-10T00:48:20.645+0000] {processor.py:157} INFO - Started process (PID=26548) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:48:20.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:48:20.654+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:48:20.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:48:20.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:48:20.710+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:48:20.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:48:20.730+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:48:20.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:48:20.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-10T00:48:50.964+0000] {processor.py:157} INFO - Started process (PID=26559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:48:50.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:48:50.970+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:48:50.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:48:50.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:48:51.016+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:48:51.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:48:51.034+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:48:51.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:48:51.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-10T00:49:21.293+0000] {processor.py:157} INFO - Started process (PID=26569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:49:21.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:49:21.298+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:49:21.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:49:21.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:49:21.349+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:49:21.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:49:21.371+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:49:21.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:49:21.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-10T00:49:51.625+0000] {processor.py:157} INFO - Started process (PID=26579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:49:51.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:49:51.652+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:49:51.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:49:51.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:49:51.712+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:49:51.712+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:49:51.743+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:49:51.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:49:51.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-09-10T00:50:21.923+0000] {processor.py:157} INFO - Started process (PID=26589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:50:21.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:50:21.942+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:50:21.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:50:21.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:50:22.027+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:50:22.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:50:22.046+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:50:22.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:50:22.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-10T00:50:52.346+0000] {processor.py:157} INFO - Started process (PID=26599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:50:52.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:50:52.356+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:50:52.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:50:52.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:50:52.424+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:50:52.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:50:52.451+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:50:52.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:50:52.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-10T00:51:22.685+0000] {processor.py:157} INFO - Started process (PID=26609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:51:22.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:51:22.693+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:51:22.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:51:22.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:51:22.766+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:51:22.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:51:22.783+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:51:22.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:51:22.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-10T00:51:53.267+0000] {processor.py:157} INFO - Started process (PID=26619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:51:53.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:51:53.275+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:51:53.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:51:53.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:51:53.396+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:51:53.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:51:53.414+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:51:53.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:51:53.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.165 seconds
[2024-09-10T00:52:23.736+0000] {processor.py:157} INFO - Started process (PID=26629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:52:23.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:52:23.750+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:52:23.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:52:23.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:52:23.812+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:52:23.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:52:23.835+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:52:23.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:52:23.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-09-10T00:52:54.087+0000] {processor.py:157} INFO - Started process (PID=26639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:52:54.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:52:54.098+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:52:54.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:52:54.119+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:52:54.181+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:52:54.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:52:54.200+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:52:54.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:52:54.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-10T00:53:24.451+0000] {processor.py:157} INFO - Started process (PID=26649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:53:24.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:53:24.461+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:53:24.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:53:24.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:53:24.537+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:53:24.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:53:24.552+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:53:24.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:53:24.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-10T00:53:54.795+0000] {processor.py:157} INFO - Started process (PID=26659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:53:54.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:53:54.806+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:53:54.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:53:54.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:53:54.875+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:53:54.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:53:54.893+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:53:54.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:53:54.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-10T00:54:25.194+0000] {processor.py:157} INFO - Started process (PID=26669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:54:25.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:54:25.207+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:54:25.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:54:25.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:54:25.277+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:54:25.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:54:25.293+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:54:25.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:54:25.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-10T00:54:55.506+0000] {processor.py:157} INFO - Started process (PID=26679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:54:55.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:54:55.518+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:54:55.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:54:55.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:54:55.595+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:54:55.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:54:55.612+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:54:55.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:54:55.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-10T00:55:25.864+0000] {processor.py:157} INFO - Started process (PID=26688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:55:25.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:55:25.875+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:55:25.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:55:25.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:55:25.958+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:55:25.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:55:25.978+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:55:25.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:55:25.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-10T00:55:56.223+0000] {processor.py:157} INFO - Started process (PID=26699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:55:56.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:55:56.231+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:55:56.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:55:56.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:55:56.309+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:55:56.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:55:56.328+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:55:56.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:55:56.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-10T00:56:26.561+0000] {processor.py:157} INFO - Started process (PID=26709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:56:26.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:56:26.570+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:56:26.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:56:26.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:56:26.630+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:56:26.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:56:26.671+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:56:26.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:56:26.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.148 seconds
[2024-09-10T00:56:56.918+0000] {processor.py:157} INFO - Started process (PID=26719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:56:56.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:56:56.932+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:56:56.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:56:56.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:56:57.007+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:56:57.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:56:57.028+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:56:57.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:56:57.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-09-10T00:57:27.253+0000] {processor.py:157} INFO - Started process (PID=26728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:57:27.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:57:27.266+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:57:27.265+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:57:27.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:57:27.350+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:57:27.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:57:27.367+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:57:27.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:57:27.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-10T00:57:57.602+0000] {processor.py:157} INFO - Started process (PID=26739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:57:57.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:57:57.622+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:57:57.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:57:57.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:57:57.697+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:57:57.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:57:57.712+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:57:57.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:57:57.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-09-10T00:58:27.954+0000] {processor.py:157} INFO - Started process (PID=26749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:58:27.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:58:27.977+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:58:27.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:58:28.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:58:28.071+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:58:28.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:58:28.093+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:58:28.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:58:28.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-10T00:58:58.282+0000] {processor.py:157} INFO - Started process (PID=26759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:58:58.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:58:58.293+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:58:58.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:58:58.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:58:58.385+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:58:58.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:58:58.408+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:58:58.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:58:58.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-09-10T00:59:28.699+0000] {processor.py:157} INFO - Started process (PID=26769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:59:28.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:59:28.706+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:59:28.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:59:28.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:59:28.805+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:59:28.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:59:28.830+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:59:28.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:59:28.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-10T00:59:59.033+0000] {processor.py:157} INFO - Started process (PID=26778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:59:59.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T00:59:59.043+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:59:59.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:59:59.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T00:59:59.117+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:59:59.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T00:59:59.137+0000] {logging_mixin.py:151} INFO - [2024-09-10T00:59:59.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-08T01:00:00+00:00, run_after=2024-09-09T01:00:00+00:00
[2024-09-10T00:59:59.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-09-10T01:00:29.570+0000] {processor.py:157} INFO - Started process (PID=26789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:00:29.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:00:29.593+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:00:29.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:00:29.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:00:29.700+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:00:29.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:00:29.735+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:00:29.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:00:29.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-09-10T01:00:59.868+0000] {processor.py:157} INFO - Started process (PID=26799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:00:59.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:00:59.877+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:00:59.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:00:59.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:00:59.946+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:00:59.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:00:59.963+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:00:59.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:00:59.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-10T01:01:30.185+0000] {processor.py:157} INFO - Started process (PID=26809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:01:30.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:01:30.194+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:01:30.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:01:30.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:01:30.275+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:01:30.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:01:30.297+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:01:30.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:01:30.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-10T01:02:00.677+0000] {processor.py:157} INFO - Started process (PID=26818) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:02:00.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:02:00.700+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:02:00.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:02:00.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:02:00.774+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:02:00.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:02:00.795+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:02:00.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:02:00.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-10T01:02:30.967+0000] {processor.py:157} INFO - Started process (PID=26829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:02:30.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:02:30.976+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:02:30.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:02:30.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:02:31.045+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:02:31.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:02:31.065+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:02:31.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:02:31.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-10T01:03:01.428+0000] {processor.py:157} INFO - Started process (PID=26839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:03:01.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:03:01.438+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:03:01.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:03:01.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:03:01.500+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:03:01.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:03:01.518+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:03:01.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:03:01.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-10T01:03:31.740+0000] {processor.py:157} INFO - Started process (PID=26848) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:03:31.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:03:31.749+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:03:31.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:03:31.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:03:31.806+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:03:31.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:03:31.823+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:03:31.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:03:31.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-10T01:04:02.068+0000] {processor.py:157} INFO - Started process (PID=26859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:04:02.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:04:02.077+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:04:02.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:04:02.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:04:02.143+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:04:02.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:04:02.160+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:04:02.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:04:02.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-10T01:04:32.523+0000] {processor.py:157} INFO - Started process (PID=26869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:04:32.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:04:32.530+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:04:32.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:04:32.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:04:32.580+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:04:32.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:04:32.596+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:04:32.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:04:32.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-10T01:05:02.905+0000] {processor.py:157} INFO - Started process (PID=26879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:05:02.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:05:02.943+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:05:02.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:05:02.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:05:02.994+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:05:02.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:05:03.012+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:05:03.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:05:03.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-10T01:05:33.164+0000] {processor.py:157} INFO - Started process (PID=26889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:05:33.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:05:33.171+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:05:33.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:05:33.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:05:33.236+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:05:33.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:05:33.251+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:05:33.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:05:33.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-10T01:06:03.495+0000] {processor.py:157} INFO - Started process (PID=26899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:06:03.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:06:03.503+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:06:03.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:06:03.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:06:03.551+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:06:03.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:06:03.565+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:06:03.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:06:03.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T01:06:33.837+0000] {processor.py:157} INFO - Started process (PID=26909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:06:33.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:06:33.846+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:06:33.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:06:33.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:06:33.900+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:06:33.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:06:33.915+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:06:33.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:06:33.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-10T01:07:04.118+0000] {processor.py:157} INFO - Started process (PID=26919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:07:04.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:07:04.129+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:07:04.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:07:04.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:07:04.178+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:07:04.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:07:04.195+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:07:04.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:07:04.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-10T01:07:34.348+0000] {processor.py:157} INFO - Started process (PID=26929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:07:34.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:07:34.356+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:07:34.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:07:34.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:07:34.403+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:07:34.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:07:34.416+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:07:34.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:07:34.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-10T01:08:04.654+0000] {processor.py:157} INFO - Started process (PID=26938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:08:04.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:08:04.661+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:08:04.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:08:04.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:08:04.727+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:08:04.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:08:04.757+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:08:04.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:08:04.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-10T01:08:35.221+0000] {processor.py:157} INFO - Started process (PID=26949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:08:35.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:08:35.249+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:08:35.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:08:35.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:08:35.393+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:08:35.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:08:35.434+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:08:35.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:08:35.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.270 seconds
[2024-09-10T01:09:05.731+0000] {processor.py:157} INFO - Started process (PID=26959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:09:05.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:09:05.739+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:09:05.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:09:05.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:09:05.800+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:09:05.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:09:05.817+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:09:05.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:09:05.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-10T01:09:36.086+0000] {processor.py:157} INFO - Started process (PID=26969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:09:36.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:09:36.098+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:09:36.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:09:36.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:09:36.149+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:09:36.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:09:36.161+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:09:36.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:09:36.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-10T01:10:06.401+0000] {processor.py:157} INFO - Started process (PID=26979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:10:06.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:10:06.404+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:10:06.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:10:06.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:10:06.431+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:10:06.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:10:06.442+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:10:06.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:10:06.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T01:10:36.808+0000] {processor.py:157} INFO - Started process (PID=26989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:10:36.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:10:36.814+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:10:36.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:10:36.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:10:36.879+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:10:36.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:10:36.894+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:10:36.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:10:36.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-10T01:11:07.110+0000] {processor.py:157} INFO - Started process (PID=26998) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:11:07.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:11:07.116+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:11:07.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:11:07.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:11:07.155+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:11:07.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:11:07.167+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:11:07.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:11:07.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-10T01:11:37.441+0000] {processor.py:157} INFO - Started process (PID=27009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:11:37.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:11:37.444+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:11:37.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:11:37.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:11:37.475+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:11:37.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:11:37.485+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:11:37.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:11:37.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T01:12:07.845+0000] {processor.py:157} INFO - Started process (PID=27019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:12:07.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:12:07.851+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:12:07.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:12:07.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:12:07.890+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:12:07.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:12:07.907+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:12:07.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:12:07.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T01:12:38.211+0000] {processor.py:157} INFO - Started process (PID=27029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:12:38.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:12:38.215+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:12:38.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:12:38.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:12:38.243+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:12:38.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:12:38.254+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:12:38.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:12:38.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T01:13:08.620+0000] {processor.py:157} INFO - Started process (PID=27039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:13:08.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:13:08.626+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:13:08.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:13:08.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:13:08.668+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:13:08.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:13:08.681+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:13:08.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:13:08.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T01:13:38.906+0000] {processor.py:157} INFO - Started process (PID=27049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:13:38.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:13:38.909+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:13:38.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:13:38.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:13:38.935+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:13:38.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:13:38.946+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:13:38.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:13:38.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T01:14:09.311+0000] {processor.py:157} INFO - Started process (PID=27059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:14:09.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:14:09.320+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:14:09.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:14:09.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:14:09.367+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:14:09.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:14:09.380+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:14:09.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:14:09.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-10T01:14:39.634+0000] {processor.py:157} INFO - Started process (PID=27069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:14:39.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:14:39.637+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:14:39.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:14:39.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:14:39.664+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:14:39.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:14:39.674+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:14:39.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:14:39.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T01:15:10.110+0000] {processor.py:157} INFO - Started process (PID=27079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:15:10.116+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:15:10.133+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:15:10.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:15:10.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:15:10.173+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:15:10.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:15:10.184+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:15:10.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:15:10.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-10T01:15:40.498+0000] {processor.py:157} INFO - Started process (PID=27089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:15:40.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:15:40.503+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:15:40.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:15:40.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:15:40.529+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:15:40.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:15:40.538+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:15:40.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:15:40.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T01:16:10.930+0000] {processor.py:157} INFO - Started process (PID=27099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:16:10.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:16:10.939+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:16:10.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:16:10.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:16:10.975+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:16:10.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:16:11.000+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:16:11.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:16:11.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-10T01:16:41.349+0000] {processor.py:157} INFO - Started process (PID=27109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:16:41.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:16:41.353+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:16:41.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:16:41.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:16:41.379+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:16:41.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:16:41.388+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:16:41.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:16:41.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T01:17:11.785+0000] {processor.py:157} INFO - Started process (PID=27119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:17:11.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:17:11.793+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:17:11.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:17:11.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:17:11.844+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:17:11.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:17:11.857+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:17:11.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:17:11.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-10T01:17:42.193+0000] {processor.py:157} INFO - Started process (PID=27129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:17:42.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:17:42.196+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:17:42.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:17:42.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:17:42.220+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:17:42.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:17:42.233+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:17:42.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:17:42.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T01:18:12.672+0000] {processor.py:157} INFO - Started process (PID=27139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:18:12.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:18:12.677+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:18:12.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:18:12.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:18:12.717+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:18:12.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:18:12.743+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:18:12.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:18:12.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-10T01:18:43.035+0000] {processor.py:157} INFO - Started process (PID=27149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:18:43.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:18:43.038+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:18:43.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:18:43.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:18:43.061+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:18:43.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:18:43.071+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:18:43.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:18:43.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T01:19:13.399+0000] {processor.py:157} INFO - Started process (PID=27159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:19:13.402+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:19:13.407+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:19:13.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:19:13.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:19:13.444+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:19:13.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:19:13.455+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:19:13.455+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:19:13.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-10T01:19:43.779+0000] {processor.py:157} INFO - Started process (PID=27169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:19:43.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:19:43.783+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:19:43.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:19:43.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:19:43.810+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:19:43.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:19:43.821+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:19:43.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:19:43.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T01:20:14.199+0000] {processor.py:157} INFO - Started process (PID=27179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:20:14.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:20:14.203+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:20:14.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:20:14.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:20:14.242+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:20:14.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:20:14.261+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:20:14.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:20:14.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-10T01:20:44.510+0000] {processor.py:157} INFO - Started process (PID=27189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:20:44.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:20:44.513+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:20:44.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:20:44.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:20:44.538+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:20:44.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:20:44.550+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:20:44.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:20:44.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T01:21:14.838+0000] {processor.py:157} INFO - Started process (PID=27199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:21:14.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:21:14.844+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:21:14.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:21:14.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:21:14.906+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:21:14.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:21:14.921+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:21:14.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:21:14.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-10T01:21:45.307+0000] {processor.py:157} INFO - Started process (PID=27209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:21:45.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:21:45.313+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:21:45.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:21:45.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:21:45.348+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:21:45.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:21:45.359+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:21:45.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:21:45.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T01:22:15.678+0000] {processor.py:157} INFO - Started process (PID=27219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:22:15.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:22:15.685+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:22:15.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:22:15.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:22:15.725+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:22:15.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:22:15.738+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:22:15.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:22:15.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-10T01:22:46.065+0000] {processor.py:157} INFO - Started process (PID=27229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:22:46.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:22:46.068+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:22:46.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:22:46.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:22:46.096+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:22:46.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:22:46.107+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:22:46.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:22:46.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T01:23:16.505+0000] {processor.py:157} INFO - Started process (PID=27239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:23:16.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:23:16.510+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:23:16.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:23:16.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:23:16.547+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:23:16.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:23:16.559+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:23:16.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:23:16.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-10T01:23:46.872+0000] {processor.py:157} INFO - Started process (PID=27249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:23:46.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:23:46.876+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:23:46.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:23:46.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:23:46.902+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:23:46.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:23:46.913+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:23:46.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:23:46.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T01:24:17.253+0000] {processor.py:157} INFO - Started process (PID=27259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:24:17.260+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:24:17.273+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:24:17.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:24:17.299+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:24:17.323+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:24:17.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:24:17.335+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:24:17.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:24:17.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-10T01:24:47.586+0000] {processor.py:157} INFO - Started process (PID=27269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:24:47.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:24:47.596+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:24:47.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:24:47.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:24:47.626+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:24:47.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:24:47.637+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:24:47.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:24:47.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-10T01:25:17.912+0000] {processor.py:157} INFO - Started process (PID=27279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:25:17.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:25:17.919+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:25:17.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:25:17.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:25:17.953+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:25:17.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:25:17.965+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:25:17.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:25:17.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T01:25:48.347+0000] {processor.py:157} INFO - Started process (PID=27289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:25:48.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:25:48.374+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:25:48.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:25:48.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:25:48.417+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:25:48.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:25:48.429+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:25:48.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:25:48.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T01:26:18.785+0000] {processor.py:157} INFO - Started process (PID=27299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:26:18.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:26:18.789+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:26:18.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:26:18.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:26:18.817+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:26:18.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:26:18.829+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:26:18.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:26:18.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T01:26:49.201+0000] {processor.py:157} INFO - Started process (PID=27309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:26:49.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:26:49.206+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:26:49.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:26:49.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:26:49.257+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:26:49.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:26:49.274+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:26:49.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:26:49.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-10T01:27:19.546+0000] {processor.py:157} INFO - Started process (PID=27319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:27:19.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:27:19.552+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:27:19.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:27:19.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:27:19.577+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:27:19.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:27:19.588+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:27:19.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:27:19.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T01:27:49.892+0000] {processor.py:157} INFO - Started process (PID=27329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:27:49.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:27:49.895+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:27:49.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:27:49.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:27:49.923+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:27:49.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:27:49.932+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:27:49.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:27:49.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T01:28:20.321+0000] {processor.py:157} INFO - Started process (PID=27339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:28:20.322+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:28:20.327+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:28:20.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:28:20.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:28:20.375+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:28:20.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:28:20.387+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:28:20.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:28:20.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-10T01:28:50.714+0000] {processor.py:157} INFO - Started process (PID=27349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:28:50.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:28:50.718+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:28:50.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:28:50.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:28:50.743+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:28:50.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:28:50.753+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:28:50.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:28:50.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T01:29:21.094+0000] {processor.py:157} INFO - Started process (PID=27359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:29:21.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:29:21.103+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:29:21.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:29:21.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:29:21.155+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:29:21.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:29:21.167+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:29:21.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:29:21.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-10T01:29:51.433+0000] {processor.py:157} INFO - Started process (PID=27369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:29:51.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:29:51.437+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:29:51.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:29:51.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:29:51.463+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:29:51.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:29:51.473+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:29:51.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:29:51.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T01:30:21.838+0000] {processor.py:157} INFO - Started process (PID=27378) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:30:21.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:30:21.854+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:30:21.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:30:21.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:30:21.894+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:30:21.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:30:21.918+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:30:21.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:30:21.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-10T01:30:52.141+0000] {processor.py:157} INFO - Started process (PID=27389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:30:52.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:30:52.147+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:30:52.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:30:52.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:30:52.171+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:30:52.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:30:52.180+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:30:52.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:30:52.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T01:31:22.527+0000] {processor.py:157} INFO - Started process (PID=27399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:31:22.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:31:22.530+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:31:22.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:31:22.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:31:22.591+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:31:22.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:31:22.603+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:31:22.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:31:22.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-10T01:31:52.883+0000] {processor.py:157} INFO - Started process (PID=27409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:31:52.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:31:52.888+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:31:52.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:31:52.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:31:52.918+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:31:52.918+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:31:52.929+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:31:52.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:31:52.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T01:32:23.306+0000] {processor.py:157} INFO - Started process (PID=27418) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:32:23.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:32:23.312+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:32:23.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:32:23.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:32:23.377+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:32:23.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:32:23.391+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:32:23.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:32:23.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-10T01:32:53.642+0000] {processor.py:157} INFO - Started process (PID=27429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:32:53.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:32:53.648+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:32:53.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:32:53.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:32:53.674+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:32:53.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:32:53.683+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:32:53.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:32:53.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T01:33:24.066+0000] {processor.py:157} INFO - Started process (PID=27438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:33:24.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:33:24.093+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:33:24.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:33:24.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:33:24.143+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:33:24.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:33:24.158+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:33:24.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:33:24.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-10T01:33:54.400+0000] {processor.py:157} INFO - Started process (PID=27449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:33:54.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:33:54.407+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:33:54.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:33:54.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:33:54.432+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:33:54.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:33:54.442+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:33:54.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:33:54.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T01:34:24.835+0000] {processor.py:157} INFO - Started process (PID=27458) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:34:24.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:34:24.844+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:34:24.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:34:24.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:34:24.899+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:34:24.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:34:24.912+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:34:24.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:34:24.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T01:34:55.247+0000] {processor.py:157} INFO - Started process (PID=27469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:34:55.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:34:55.250+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:34:55.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:34:55.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:34:55.276+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:34:55.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:34:55.286+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:34:55.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:34:55.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T01:35:25.676+0000] {processor.py:157} INFO - Started process (PID=27479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:35:25.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:35:25.688+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:35:25.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:35:25.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:35:25.740+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:35:25.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:35:25.753+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:35:25.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:35:25.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-10T01:35:56.014+0000] {processor.py:157} INFO - Started process (PID=27488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:35:56.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:35:56.016+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:35:56.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:35:56.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:35:56.040+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:35:56.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:35:56.050+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:35:56.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:35:56.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T01:36:26.442+0000] {processor.py:157} INFO - Started process (PID=27499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:36:26.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:36:26.447+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:36:26.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:36:26.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:36:26.485+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:36:26.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:36:26.497+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:36:26.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:36:26.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T01:36:56.815+0000] {processor.py:157} INFO - Started process (PID=27509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:36:56.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:36:56.822+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:36:56.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:36:56.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:36:56.880+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:36:56.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:36:56.894+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:36:56.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:36:56.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-10T01:37:27.098+0000] {processor.py:157} INFO - Started process (PID=27519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:37:27.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:37:27.101+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:37:27.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:37:27.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:37:27.130+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:37:27.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:37:27.139+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:37:27.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:37:27.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T01:37:57.452+0000] {processor.py:157} INFO - Started process (PID=27529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:37:57.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:37:57.459+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:37:57.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:37:57.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:37:57.494+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:37:57.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:37:57.507+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:37:57.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:37:57.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T01:38:27.735+0000] {processor.py:157} INFO - Started process (PID=27539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:38:27.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:38:27.738+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:38:27.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:38:27.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:38:27.764+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:38:27.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:38:27.777+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:38:27.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:38:27.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T01:38:58.189+0000] {processor.py:157} INFO - Started process (PID=27549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:38:58.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:38:58.194+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:38:58.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:38:58.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:38:58.247+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:38:58.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:38:58.260+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:38:58.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:38:58.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-10T01:39:28.538+0000] {processor.py:157} INFO - Started process (PID=27559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:39:28.540+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:39:28.542+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:39:28.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:39:28.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:39:28.567+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:39:28.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:39:28.577+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:39:28.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:39:28.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T01:39:58.898+0000] {processor.py:157} INFO - Started process (PID=27569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:39:58.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:39:58.902+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:39:58.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:39:58.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:39:58.929+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:39:58.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:39:58.941+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:39:58.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:39:58.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T01:40:29.354+0000] {processor.py:157} INFO - Started process (PID=27579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:40:29.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:40:29.359+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:40:29.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:40:29.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:40:29.400+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:40:29.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:40:29.412+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:40:29.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:40:29.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-10T01:40:59.646+0000] {processor.py:157} INFO - Started process (PID=27589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:40:59.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:40:59.650+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:40:59.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:40:59.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:40:59.681+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:40:59.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:40:59.693+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:40:59.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:40:59.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T01:41:30.044+0000] {processor.py:157} INFO - Started process (PID=27598) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:41:30.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:41:30.050+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:41:30.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:41:30.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:41:30.093+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:41:30.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:41:30.105+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:41:30.105+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:41:30.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T01:42:00.462+0000] {processor.py:157} INFO - Started process (PID=27609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:42:00.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:42:00.466+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:42:00.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:42:00.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:42:00.493+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:42:00.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:42:00.502+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:42:00.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:42:00.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T01:42:30.802+0000] {processor.py:157} INFO - Started process (PID=27619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:42:30.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:42:30.806+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:42:30.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:42:30.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:42:30.842+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:42:30.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:42:30.854+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:42:30.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:42:30.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T01:43:01.076+0000] {processor.py:157} INFO - Started process (PID=27629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:43:01.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:43:01.083+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:43:01.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:43:01.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:43:01.138+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:43:01.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:43:01.151+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:43:01.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:43:01.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-10T01:43:31.397+0000] {processor.py:157} INFO - Started process (PID=27639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:43:31.401+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:43:31.403+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:43:31.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:43:31.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:43:31.429+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:43:31.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:43:31.438+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:43:31.438+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:43:31.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T01:44:01.786+0000] {processor.py:157} INFO - Started process (PID=27648) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:44:01.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:44:01.793+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:44:01.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:44:01.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:44:01.842+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:44:01.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:44:01.855+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:44:01.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:44:01.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T01:44:32.233+0000] {processor.py:157} INFO - Started process (PID=27659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:44:32.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:44:32.235+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:44:32.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:44:32.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:44:32.261+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:44:32.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:44:32.273+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:44:32.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:44:32.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T01:45:02.646+0000] {processor.py:157} INFO - Started process (PID=27669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:45:02.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:45:02.651+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:45:02.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:45:02.666+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:45:02.693+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:45:02.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:45:02.712+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:45:02.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:45:02.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-10T01:45:33.057+0000] {processor.py:157} INFO - Started process (PID=27679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:45:33.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:45:33.061+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:45:33.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:45:33.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:45:33.086+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:45:33.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:45:33.095+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:45:33.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:45:33.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T01:46:03.464+0000] {processor.py:157} INFO - Started process (PID=27688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:46:03.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:46:03.472+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:46:03.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:46:03.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:46:03.515+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:46:03.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:46:03.527+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:46:03.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:46:03.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-10T01:46:33.913+0000] {processor.py:157} INFO - Started process (PID=27699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:46:33.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:46:33.915+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:46:33.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:46:33.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:46:33.942+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:46:33.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:46:33.953+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:46:33.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:46:33.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T01:47:04.386+0000] {processor.py:157} INFO - Started process (PID=27709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:47:04.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:47:04.393+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:47:04.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:47:04.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:47:04.450+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:47:04.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:47:04.463+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:47:04.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:47:04.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-10T01:47:34.703+0000] {processor.py:157} INFO - Started process (PID=27719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:47:34.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:47:34.706+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:47:34.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:47:34.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:47:34.732+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:47:34.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:47:34.741+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:47:34.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:47:34.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T01:48:05.102+0000] {processor.py:157} INFO - Started process (PID=27729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:48:05.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:48:05.109+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:48:05.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:48:05.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:48:05.154+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:48:05.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:48:05.168+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:48:05.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:48:05.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-10T01:48:35.403+0000] {processor.py:157} INFO - Started process (PID=27739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:48:35.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:48:35.407+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:48:35.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:48:35.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:48:35.431+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:48:35.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:48:35.441+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:48:35.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:48:35.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T01:49:05.806+0000] {processor.py:157} INFO - Started process (PID=27749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:49:05.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:49:05.813+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:49:05.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:49:05.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:49:05.851+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:49:05.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:49:05.867+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:49:05.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:49:05.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-10T01:49:36.308+0000] {processor.py:157} INFO - Started process (PID=27759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:49:36.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:49:36.311+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:49:36.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:49:36.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:49:36.338+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:49:36.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:49:36.349+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:49:36.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:49:36.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T01:50:06.746+0000] {processor.py:157} INFO - Started process (PID=27769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:50:06.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:50:06.770+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:50:06.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:50:06.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:50:06.809+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:50:06.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:50:06.832+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:50:06.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:50:06.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-10T01:50:37.042+0000] {processor.py:157} INFO - Started process (PID=27779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:50:37.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:50:37.046+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:50:37.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:50:37.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:50:37.075+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:50:37.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:50:37.086+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:50:37.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:50:37.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T01:51:07.476+0000] {processor.py:157} INFO - Started process (PID=27789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:51:07.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:51:07.482+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:51:07.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:51:07.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:51:07.534+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:51:07.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:51:07.547+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:51:07.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:51:07.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-10T01:51:37.808+0000] {processor.py:157} INFO - Started process (PID=27799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:51:37.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:51:37.813+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:51:37.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:51:37.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:51:37.840+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:51:37.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:51:37.852+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:51:37.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:51:37.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T01:52:08.232+0000] {processor.py:157} INFO - Started process (PID=27809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:52:08.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:52:08.237+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:52:08.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:52:08.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:52:08.294+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:52:08.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:52:08.306+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:52:08.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:52:08.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-10T01:52:38.524+0000] {processor.py:157} INFO - Started process (PID=27819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:52:38.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:52:38.527+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:52:38.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:52:38.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:52:38.553+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:52:38.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:52:38.566+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:52:38.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:52:38.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T01:53:08.956+0000] {processor.py:157} INFO - Started process (PID=27829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:53:08.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:53:08.963+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:53:08.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:53:08.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:53:09.000+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:53:09.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:53:09.012+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:53:09.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:53:09.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T01:53:39.306+0000] {processor.py:157} INFO - Started process (PID=27839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:53:39.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:53:39.311+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:53:39.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:53:39.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:53:39.338+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:53:39.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:53:39.351+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:53:39.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:53:39.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T01:54:09.655+0000] {processor.py:157} INFO - Started process (PID=27849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:54:09.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:54:09.662+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:54:09.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:54:09.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:54:09.699+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:54:09.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:54:09.711+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:54:09.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:54:09.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T01:54:40.179+0000] {processor.py:157} INFO - Started process (PID=27859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:54:40.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:54:40.183+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:54:40.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:54:40.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:54:40.225+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:54:40.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:54:40.238+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:54:40.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:54:40.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-10T01:55:10.499+0000] {processor.py:157} INFO - Started process (PID=27869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:55:10.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:55:10.506+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:55:10.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:55:10.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:55:10.543+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:55:10.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:55:10.557+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:55:10.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:55:10.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-10T01:55:40.892+0000] {processor.py:157} INFO - Started process (PID=27879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:55:40.893+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:55:40.895+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:55:40.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:55:40.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:55:40.923+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:55:40.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:55:40.933+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:55:40.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:55:40.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T01:56:11.195+0000] {processor.py:157} INFO - Started process (PID=27889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:56:11.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:56:11.199+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:56:11.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:56:11.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:56:11.226+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:56:11.225+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:56:11.238+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:56:11.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:56:11.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T01:56:41.557+0000] {processor.py:157} INFO - Started process (PID=27899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:56:41.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:56:41.560+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:56:41.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:56:41.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:56:41.588+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:56:41.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:56:41.599+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:56:41.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:56:41.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T01:57:11.888+0000] {processor.py:157} INFO - Started process (PID=27909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:57:11.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:57:11.895+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:57:11.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:57:11.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:57:11.927+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:57:11.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:57:11.939+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:57:11.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:57:11.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T01:57:42.205+0000] {processor.py:157} INFO - Started process (PID=27919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:57:42.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:57:42.207+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:57:42.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:57:42.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:57:42.233+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:57:42.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:57:42.243+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:57:42.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:57:42.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T01:58:12.530+0000] {processor.py:157} INFO - Started process (PID=27929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:58:12.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:58:12.534+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:58:12.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:58:12.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:58:12.563+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:58:12.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:58:12.575+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:58:12.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:58:12.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T01:58:42.851+0000] {processor.py:157} INFO - Started process (PID=27939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:58:42.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:58:42.854+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:58:42.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:58:42.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:58:42.890+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:58:42.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:58:42.906+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:58:42.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:58:42.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T01:59:13.246+0000] {processor.py:157} INFO - Started process (PID=27949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:59:13.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:59:13.250+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:59:13.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:59:13.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:59:13.277+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:59:13.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:59:13.291+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:59:13.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:59:13.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T01:59:43.613+0000] {processor.py:157} INFO - Started process (PID=27959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:59:43.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T01:59:43.617+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:59:43.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:59:43.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T01:59:43.644+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:59:43.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T01:59:43.655+0000] {logging_mixin.py:151} INFO - [2024-09-10T01:59:43.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T01:59:43.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T02:00:13.989+0000] {processor.py:157} INFO - Started process (PID=27969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:00:13.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:00:13.994+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:00:13.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:00:14.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:00:14.029+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:00:14.029+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:00:14.042+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:00:14.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:00:14.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T02:00:44.308+0000] {processor.py:157} INFO - Started process (PID=27979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:00:44.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:00:44.312+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:00:44.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:00:44.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:00:44.336+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:00:44.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:00:44.346+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:00:44.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:00:44.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T02:01:14.675+0000] {processor.py:157} INFO - Started process (PID=27989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:01:14.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:01:14.681+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:01:14.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:01:14.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:01:14.716+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:01:14.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:01:14.729+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:01:14.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:01:14.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T02:01:44.989+0000] {processor.py:157} INFO - Started process (PID=27999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:01:44.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:01:45.000+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:01:45.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:01:45.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:01:45.042+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:01:45.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:01:45.056+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:01:45.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:01:45.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-10T02:02:15.311+0000] {processor.py:157} INFO - Started process (PID=28009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:02:15.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:02:15.314+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:02:15.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:02:15.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:02:15.340+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:02:15.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:02:15.350+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:02:15.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:02:15.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T02:02:45.692+0000] {processor.py:157} INFO - Started process (PID=28019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:02:45.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:02:45.699+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:02:45.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:02:45.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:02:45.736+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:02:45.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:02:45.750+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:02:45.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:02:45.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-10T02:03:16.033+0000] {processor.py:157} INFO - Started process (PID=28029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:03:16.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:03:16.037+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:03:16.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:03:16.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:03:16.064+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:03:16.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:03:16.075+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:03:16.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:03:16.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T02:03:46.371+0000] {processor.py:157} INFO - Started process (PID=28039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:03:46.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:03:46.376+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:03:46.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:03:46.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:03:46.433+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:03:46.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:03:46.446+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:03:46.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:03:46.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T02:04:16.674+0000] {processor.py:157} INFO - Started process (PID=28049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:04:16.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:04:16.677+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:04:16.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:04:16.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:04:16.711+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:04:16.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:04:16.724+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:04:16.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:04:16.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T02:04:47.410+0000] {processor.py:157} INFO - Started process (PID=28059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:04:47.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:04:47.430+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:04:47.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:04:47.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:04:47.470+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:04:47.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:04:47.488+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:04:47.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:04:47.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-10T02:05:24.999+0000] {processor.py:157} INFO - Started process (PID=28069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:05:25.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:05:25.001+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:05:25.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:05:25.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:05:25.026+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:05:25.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:05:25.037+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:05:25.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:05:25.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T02:21:09.208+0000] {processor.py:157} INFO - Started process (PID=28083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:21:09.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:21:09.228+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:21:09.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:21:09.280+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:21:09.334+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:21:09.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:21:09.370+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:21:09.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:21:09.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.200 seconds
[2024-09-10T02:21:39.573+0000] {processor.py:157} INFO - Started process (PID=28093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:21:39.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:21:39.579+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:21:39.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:21:39.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:21:39.643+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:21:39.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:21:39.656+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:21:39.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:21:39.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-10T02:22:09.986+0000] {processor.py:157} INFO - Started process (PID=28103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:22:09.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:22:09.989+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:22:09.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:22:10.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:22:10.031+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:22:10.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:22:10.044+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:22:10.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:22:10.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-10T02:22:40.394+0000] {processor.py:157} INFO - Started process (PID=28112) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:22:40.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:22:40.401+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:22:40.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:22:40.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:22:40.445+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:22:40.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:22:40.459+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:22:40.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:22:40.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-10T02:23:10.798+0000] {processor.py:157} INFO - Started process (PID=28123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:23:10.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:23:10.802+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:23:10.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:23:10.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:23:10.829+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:23:10.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:23:10.840+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:23:10.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:23:10.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T02:23:41.223+0000] {processor.py:157} INFO - Started process (PID=28133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:23:41.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:23:41.226+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:23:41.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:23:41.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:23:41.263+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:23:41.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:23:41.277+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:23:41.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:23:41.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T02:24:11.565+0000] {processor.py:157} INFO - Started process (PID=28143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:24:11.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:24:11.568+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:24:11.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:24:11.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:24:11.595+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:24:11.595+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:24:11.607+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:24:11.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:24:11.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T02:24:41.883+0000] {processor.py:157} INFO - Started process (PID=28153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:24:41.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:24:41.886+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:24:41.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:24:41.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:24:41.932+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:24:41.931+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:24:41.944+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:24:41.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:24:41.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T02:25:12.238+0000] {processor.py:157} INFO - Started process (PID=28163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:25:12.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:25:12.241+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:25:12.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:25:12.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:25:12.266+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:25:12.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:25:12.275+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:25:12.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:25:12.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T02:25:42.670+0000] {processor.py:157} INFO - Started process (PID=28172) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:25:42.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:25:42.683+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:25:42.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:25:42.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:25:42.725+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:25:42.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:25:42.739+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:25:42.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:25:42.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T02:26:13.040+0000] {processor.py:157} INFO - Started process (PID=28183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:26:13.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:26:13.042+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:26:13.042+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:26:13.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:26:13.067+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:26:13.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:26:13.078+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:26:13.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:26:13.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T02:26:43.397+0000] {processor.py:157} INFO - Started process (PID=28193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:26:43.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:26:43.407+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:26:43.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:26:43.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:26:43.455+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:26:43.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:26:43.468+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:26:43.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:26:43.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-10T02:27:13.841+0000] {processor.py:157} INFO - Started process (PID=28203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:27:13.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:27:13.845+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:27:13.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:27:13.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:27:13.872+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:27:13.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:27:13.883+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:27:13.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:27:13.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T02:27:44.165+0000] {processor.py:157} INFO - Started process (PID=28213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:27:44.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:27:44.169+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:27:44.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:27:44.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:27:44.196+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:27:44.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:27:44.207+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:27:44.206+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:27:44.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T02:28:14.525+0000] {processor.py:157} INFO - Started process (PID=28223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:28:14.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:28:14.529+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:28:14.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:28:14.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:28:14.554+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:28:14.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:28:14.564+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:28:14.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:28:14.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T02:28:44.890+0000] {processor.py:157} INFO - Started process (PID=28232) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:28:44.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:28:44.896+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:28:44.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:28:44.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:28:44.958+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:28:44.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:28:44.970+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:28:44.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:28:44.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T02:29:15.246+0000] {processor.py:157} INFO - Started process (PID=28243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:29:15.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:29:15.249+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:29:15.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:29:15.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:29:15.274+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:29:15.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:29:15.284+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:29:15.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:29:15.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T02:29:45.650+0000] {processor.py:157} INFO - Started process (PID=28253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:29:45.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:29:45.653+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:29:45.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:29:45.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:29:45.679+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:29:45.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:29:45.691+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:29:45.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:29:45.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T02:30:16.102+0000] {processor.py:157} INFO - Started process (PID=28263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:30:16.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:30:16.107+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:30:16.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:30:16.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:30:16.144+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:30:16.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:30:16.157+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:30:16.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:30:16.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T02:30:46.494+0000] {processor.py:157} INFO - Started process (PID=28273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:30:46.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:30:46.496+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:30:46.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:30:46.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:30:46.523+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:30:46.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:30:46.534+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:30:46.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:30:46.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T02:31:16.971+0000] {processor.py:157} INFO - Started process (PID=28282) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:31:16.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:31:16.978+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:31:16.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:31:16.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:31:17.019+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:31:17.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:31:17.044+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:31:17.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:31:17.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-10T02:31:47.452+0000] {processor.py:157} INFO - Started process (PID=28293) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:31:47.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:31:47.457+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:31:47.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:31:47.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:31:47.495+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:31:47.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:31:47.508+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:31:47.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:31:47.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T02:32:17.927+0000] {processor.py:157} INFO - Started process (PID=28301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:32:17.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:32:17.931+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:32:17.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:32:17.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:32:17.965+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:32:17.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:32:17.978+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:32:17.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:32:17.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T02:32:48.254+0000] {processor.py:157} INFO - Started process (PID=28313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:32:48.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:32:48.256+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:32:48.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:32:48.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:32:48.281+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:32:48.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:32:48.292+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:32:48.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:32:48.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T02:33:18.659+0000] {processor.py:157} INFO - Started process (PID=28323) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:33:18.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:33:18.662+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:33:18.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:33:18.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:33:18.701+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:33:18.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:33:18.714+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:33:18.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:33:18.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T02:33:49.159+0000] {processor.py:157} INFO - Started process (PID=28333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:33:49.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:33:49.162+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:33:49.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:33:49.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:33:49.190+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:33:49.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:33:49.202+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:33:49.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:33:49.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T02:34:19.610+0000] {processor.py:157} INFO - Started process (PID=28343) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:34:19.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:34:19.613+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:34:19.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:34:19.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:34:19.640+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:34:19.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:34:19.650+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:34:19.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:34:19.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T02:34:50.096+0000] {processor.py:157} INFO - Started process (PID=28353) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:34:50.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:34:50.100+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:34:50.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:34:50.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:34:50.140+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:34:50.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:34:50.153+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:34:50.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:34:50.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-10T02:35:20.500+0000] {processor.py:157} INFO - Started process (PID=28363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:35:20.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:35:20.503+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:35:20.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:35:20.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:35:20.526+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:35:20.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:35:20.536+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:35:20.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:35:20.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T02:35:50.884+0000] {processor.py:157} INFO - Started process (PID=28373) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:35:50.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:35:50.888+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:35:50.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:35:50.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:35:50.928+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:35:50.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:35:50.941+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:35:50.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:35:50.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-10T02:36:21.402+0000] {processor.py:157} INFO - Started process (PID=28383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:36:21.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:36:21.404+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:36:21.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:36:21.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:36:21.433+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:36:21.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:36:21.446+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:36:21.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:36:21.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T02:36:51.876+0000] {processor.py:157} INFO - Started process (PID=28393) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:36:51.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:36:51.880+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:36:51.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:36:51.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:36:51.938+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:36:51.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:36:51.951+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:36:51.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:36:51.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-10T02:37:22.304+0000] {processor.py:157} INFO - Started process (PID=28403) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:37:22.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:37:22.308+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:37:22.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:37:22.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:37:22.334+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:37:22.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:37:22.343+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:37:22.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:37:22.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T02:37:52.733+0000] {processor.py:157} INFO - Started process (PID=28413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:37:52.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:37:52.737+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:37:52.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:37:52.751+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:37:52.773+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:37:52.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:37:52.786+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:37:52.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:37:52.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T02:38:23.111+0000] {processor.py:157} INFO - Started process (PID=28423) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:38:23.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:38:23.113+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:38:23.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:38:23.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:38:23.142+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:38:23.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:38:23.155+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:38:23.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:38:23.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T02:38:53.546+0000] {processor.py:157} INFO - Started process (PID=28432) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:38:53.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:38:53.551+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:38:53.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:38:53.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:38:53.620+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:38:53.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:38:53.634+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:38:53.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:38:53.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-10T02:39:23.908+0000] {processor.py:157} INFO - Started process (PID=28443) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:39:23.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:39:23.911+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:39:23.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:39:23.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:39:23.947+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:39:23.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:39:23.961+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:39:23.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:39:23.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T02:39:54.245+0000] {processor.py:157} INFO - Started process (PID=28453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:39:54.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:39:54.249+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:39:54.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:39:54.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:39:54.292+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:39:54.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:39:54.306+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:39:54.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:39:54.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-10T02:40:24.684+0000] {processor.py:157} INFO - Started process (PID=28463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:40:24.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:40:24.687+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:40:24.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:40:24.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:40:24.725+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:40:24.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:40:24.737+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:40:24.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:40:24.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T02:40:54.976+0000] {processor.py:157} INFO - Started process (PID=28473) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:40:54.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:40:54.981+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:40:54.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:40:54.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:40:55.013+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:40:55.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:40:55.023+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:40:55.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:40:55.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T02:41:25.407+0000] {processor.py:157} INFO - Started process (PID=28482) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:41:25.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:41:25.417+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:41:25.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:41:25.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:41:25.456+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:41:25.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:41:25.471+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:41:25.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:41:25.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-10T02:41:55.841+0000] {processor.py:157} INFO - Started process (PID=28493) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:41:55.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:41:55.843+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:41:55.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:41:55.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:41:55.874+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:41:55.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:41:55.887+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:41:55.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:41:55.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T02:42:26.352+0000] {processor.py:157} INFO - Started process (PID=28503) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:42:26.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:42:26.357+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:42:26.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:42:26.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:42:26.420+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:42:26.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:42:26.433+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:42:26.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:42:26.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T02:42:56.855+0000] {processor.py:157} INFO - Started process (PID=28513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:42:56.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:42:56.859+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:42:56.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:42:56.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:42:56.887+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:42:56.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:42:56.899+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:42:56.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:42:56.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T02:43:27.246+0000] {processor.py:157} INFO - Started process (PID=28523) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:43:27.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:43:27.251+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:43:27.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:43:27.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:43:27.285+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:43:27.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:43:27.297+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:43:27.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:43:27.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T02:43:57.711+0000] {processor.py:157} INFO - Started process (PID=28533) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:43:57.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:43:57.716+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:43:57.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:43:57.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:43:57.743+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:43:57.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:43:57.757+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:43:57.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:43:57.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T02:44:28.095+0000] {processor.py:157} INFO - Started process (PID=28542) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:44:28.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:44:28.121+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:44:28.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:44:28.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:44:28.161+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:44:28.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:44:28.187+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:44:28.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:44:28.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-10T02:44:58.423+0000] {processor.py:157} INFO - Started process (PID=28553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:44:58.424+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:44:58.426+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:44:58.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:44:58.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:44:58.455+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:44:58.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:44:58.467+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:44:58.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:44:58.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T02:45:28.881+0000] {processor.py:157} INFO - Started process (PID=28563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:45:28.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:45:28.886+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:45:28.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:45:28.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:45:28.921+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:45:28.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:45:28.935+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:45:28.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:45:28.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T02:45:59.304+0000] {processor.py:157} INFO - Started process (PID=28573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:45:59.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:45:59.307+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:45:59.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:45:59.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:45:59.350+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:45:59.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:45:59.361+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:45:59.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:45:59.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T02:46:29.812+0000] {processor.py:157} INFO - Started process (PID=28583) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:46:29.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:46:29.818+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:46:29.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:46:29.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:46:29.879+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:46:29.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:46:29.893+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:46:29.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:46:29.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T02:47:00.205+0000] {processor.py:157} INFO - Started process (PID=28593) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:47:00.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:47:00.209+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:47:00.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:47:00.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:47:00.247+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:47:00.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:47:00.259+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:47:00.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:47:00.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T02:47:30.544+0000] {processor.py:157} INFO - Started process (PID=28602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:47:30.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:47:30.557+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:47:30.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:47:30.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:47:30.597+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:47:30.597+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:47:30.609+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:47:30.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:47:30.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-10T02:48:00.917+0000] {processor.py:157} INFO - Started process (PID=28613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:48:00.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:48:00.920+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:48:00.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:48:00.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:48:00.947+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:48:00.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:48:00.963+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:48:00.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:48:00.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T02:48:31.288+0000] {processor.py:157} INFO - Started process (PID=28621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:48:31.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:48:31.297+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:48:31.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:48:31.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:48:31.359+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:48:31.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:48:31.371+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:48:31.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:48:31.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T02:49:01.674+0000] {processor.py:157} INFO - Started process (PID=28633) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:49:01.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:49:01.678+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:49:01.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:49:01.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:49:01.718+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:49:01.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:49:01.731+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:49:01.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:49:01.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T02:49:32.095+0000] {processor.py:157} INFO - Started process (PID=28642) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:49:32.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:49:32.100+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:49:32.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:49:32.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:49:32.139+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:49:32.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:49:32.167+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:49:32.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:49:32.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-10T02:50:02.425+0000] {processor.py:157} INFO - Started process (PID=28653) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:50:02.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:50:02.428+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:50:02.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:50:02.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:50:02.457+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:50:02.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:50:02.468+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:50:02.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:50:02.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T02:50:32.751+0000] {processor.py:157} INFO - Started process (PID=28663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:50:32.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:50:32.756+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:50:32.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:50:32.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:50:32.798+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:50:32.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:50:32.811+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:50:32.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:50:32.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-10T02:51:03.083+0000] {processor.py:157} INFO - Started process (PID=28673) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:51:03.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:51:03.089+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:51:03.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:51:03.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:51:03.132+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:51:03.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:51:03.146+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:51:03.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:51:03.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-10T02:51:33.558+0000] {processor.py:157} INFO - Started process (PID=28683) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:51:33.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:51:33.562+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:51:33.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:51:33.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:51:33.613+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:51:33.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:51:33.626+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:51:33.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:51:33.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-10T02:52:04.038+0000] {processor.py:157} INFO - Started process (PID=28692) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:52:04.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:52:04.044+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:52:04.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:52:04.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:52:04.095+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:52:04.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:52:04.113+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:52:04.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:52:04.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-10T02:52:34.435+0000] {processor.py:157} INFO - Started process (PID=28703) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:52:34.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:52:34.439+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:52:34.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:52:34.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:52:34.488+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:52:34.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:52:34.502+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:52:34.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:52:34.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-10T02:53:04.798+0000] {processor.py:157} INFO - Started process (PID=28713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:53:04.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:53:04.802+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:53:04.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:53:04.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:53:04.829+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:53:04.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:53:04.839+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:53:04.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:53:04.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T02:53:35.312+0000] {processor.py:157} INFO - Started process (PID=28722) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:53:35.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:53:35.316+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:53:35.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:53:35.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:53:35.348+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:53:35.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:53:35.360+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:53:35.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:53:35.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T02:54:05.617+0000] {processor.py:157} INFO - Started process (PID=28733) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:54:05.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:54:05.620+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:54:05.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:54:05.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:54:05.645+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:54:05.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:54:05.656+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:54:05.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:54:05.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T02:54:35.989+0000] {processor.py:157} INFO - Started process (PID=28742) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:54:35.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:54:35.995+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:54:35.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:54:36.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:54:36.037+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:54:36.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:54:36.064+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:54:36.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:54:36.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-10T02:55:06.456+0000] {processor.py:157} INFO - Started process (PID=28753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:55:06.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:55:06.461+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:55:06.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:55:06.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:55:06.487+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:55:06.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:55:06.499+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:55:06.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:55:06.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T02:55:36.817+0000] {processor.py:157} INFO - Started process (PID=28763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:55:36.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:55:36.820+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:55:36.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:55:36.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:55:36.844+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:55:36.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:55:36.854+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:55:36.854+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:55:36.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T02:56:07.346+0000] {processor.py:157} INFO - Started process (PID=28773) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:56:07.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:56:07.352+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:56:07.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:56:07.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:56:07.388+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:56:07.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:56:07.401+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:56:07.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:56:07.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T02:56:37.655+0000] {processor.py:157} INFO - Started process (PID=28783) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:56:37.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:56:37.657+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:56:37.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:56:37.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:56:37.678+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:56:37.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:56:37.687+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:56:37.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:56:37.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-09-10T02:57:08.099+0000] {processor.py:157} INFO - Started process (PID=28793) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:57:08.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:57:08.104+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:57:08.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:57:08.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:57:08.141+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:57:08.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:57:08.154+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:57:08.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:57:08.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T02:57:38.496+0000] {processor.py:157} INFO - Started process (PID=28803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:57:38.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:57:38.498+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:57:38.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:57:38.512+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:57:38.531+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:57:38.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:57:38.542+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:57:38.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:57:38.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T02:58:08.960+0000] {processor.py:157} INFO - Started process (PID=28812) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:58:08.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:58:08.964+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:58:08.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:58:08.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:58:09.001+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:58:09.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:58:09.018+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:58:09.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:58:09.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-10T02:58:39.461+0000] {processor.py:157} INFO - Started process (PID=28823) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:58:39.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:58:39.464+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:58:39.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:58:39.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:58:39.487+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:58:39.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:58:39.497+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:58:39.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:58:39.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-10T02:59:09.820+0000] {processor.py:157} INFO - Started process (PID=28833) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:59:09.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:59:09.824+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:59:09.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:59:09.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:59:09.853+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:59:09.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:59:09.865+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:59:09.865+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:59:09.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T02:59:40.342+0000] {processor.py:157} INFO - Started process (PID=28843) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:59:40.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T02:59:40.346+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:59:40.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:59:40.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T02:59:40.381+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:59:40.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T02:59:40.394+0000] {logging_mixin.py:151} INFO - [2024-09-10T02:59:40.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T02:59:40.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T03:00:10.723+0000] {processor.py:157} INFO - Started process (PID=28852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:00:10.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:00:10.729+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:00:10.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:00:10.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:00:10.776+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:00:10.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:00:10.793+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:00:10.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:00:10.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-10T03:00:41.097+0000] {processor.py:157} INFO - Started process (PID=28863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:00:41.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:00:41.100+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:00:41.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:00:41.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:00:41.124+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:00:41.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:00:41.133+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:00:41.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:00:41.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T03:01:11.531+0000] {processor.py:157} INFO - Started process (PID=28873) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:01:11.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:01:11.534+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:01:11.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:01:11.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:01:11.560+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:01:11.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:01:11.570+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:01:11.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:01:11.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T03:01:41.934+0000] {processor.py:157} INFO - Started process (PID=28882) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:01:41.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:01:41.939+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:01:41.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:01:41.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:01:41.973+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:01:41.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:01:41.989+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:01:41.989+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:01:42.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T03:02:12.365+0000] {processor.py:157} INFO - Started process (PID=28893) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:02:12.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:02:12.368+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:02:12.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:02:12.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:02:12.391+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:02:12.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:02:12.401+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:02:12.401+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:02:12.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T03:02:42.720+0000] {processor.py:157} INFO - Started process (PID=28903) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:02:42.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:02:42.725+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:02:42.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:02:42.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:02:42.757+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:02:42.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:02:42.769+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:02:42.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:02:42.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T03:03:13.113+0000] {processor.py:157} INFO - Started process (PID=28913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:03:13.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:03:13.116+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:03:13.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:03:13.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:03:13.142+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:03:13.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:03:13.153+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:03:13.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:03:13.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T03:03:43.556+0000] {processor.py:157} INFO - Started process (PID=28923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:03:43.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:03:43.560+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:03:43.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:03:43.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:03:43.585+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:03:43.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:03:43.594+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:03:43.594+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:03:43.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T03:04:14.019+0000] {processor.py:157} INFO - Started process (PID=28933) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:04:14.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:04:14.022+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:04:14.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:04:14.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:04:14.046+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:04:14.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:04:14.058+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:04:14.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:04:14.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T03:04:44.420+0000] {processor.py:157} INFO - Started process (PID=28943) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:04:44.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:04:44.423+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:04:44.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:04:44.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:04:44.450+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:04:44.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:04:44.460+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:04:44.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:04:44.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T03:05:14.834+0000] {processor.py:157} INFO - Started process (PID=28953) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:05:14.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:05:14.836+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:05:14.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:05:14.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:05:14.866+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:05:14.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:05:14.880+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:05:14.880+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:05:14.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T03:05:45.245+0000] {processor.py:157} INFO - Started process (PID=28963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:05:45.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:05:45.248+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:05:45.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:05:45.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:05:45.275+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:05:45.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:05:45.285+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:05:45.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:05:45.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T03:06:15.726+0000] {processor.py:157} INFO - Started process (PID=28973) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:06:15.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:06:15.728+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:06:15.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:06:15.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:06:15.757+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:06:15.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:06:15.768+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:06:15.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:06:15.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T03:06:46.120+0000] {processor.py:157} INFO - Started process (PID=28983) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:06:46.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:06:46.123+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:06:46.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:06:46.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:06:46.147+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:06:46.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:06:46.157+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:06:46.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:06:46.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T03:07:16.397+0000] {processor.py:157} INFO - Started process (PID=28993) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:07:16.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:07:16.403+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:07:16.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:07:16.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:07:16.440+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:07:16.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:07:16.453+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:07:16.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:07:16.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T03:07:46.803+0000] {processor.py:157} INFO - Started process (PID=29003) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:07:46.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:07:46.805+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:07:46.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:07:46.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:07:46.833+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:07:46.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:07:46.846+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:07:46.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:07:46.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T03:08:17.236+0000] {processor.py:157} INFO - Started process (PID=29013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:08:17.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:08:17.238+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:08:17.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:08:17.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:08:17.264+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:08:17.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:08:17.276+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:08:17.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:08:17.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T03:08:47.609+0000] {processor.py:157} INFO - Started process (PID=29023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:08:47.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:08:47.611+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:08:47.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:08:47.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:08:47.639+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:08:47.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:08:47.653+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:08:47.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:08:47.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T03:09:18.090+0000] {processor.py:157} INFO - Started process (PID=29033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:09:18.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:09:18.093+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:09:18.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:09:18.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:09:18.122+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:09:18.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:09:18.132+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:09:18.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:09:18.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T03:09:48.435+0000] {processor.py:157} INFO - Started process (PID=29043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:09:48.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:09:48.438+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:09:48.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:09:48.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:09:48.465+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:09:48.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:09:48.475+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:09:48.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:09:48.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T03:10:18.898+0000] {processor.py:157} INFO - Started process (PID=29053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:10:18.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:10:18.901+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:10:18.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:10:18.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:10:18.928+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:10:18.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:10:18.940+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:10:18.940+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:10:18.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T03:10:49.282+0000] {processor.py:157} INFO - Started process (PID=29063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:10:49.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:10:49.285+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:10:49.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:10:49.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:10:49.310+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:10:49.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:10:49.320+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:10:49.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:10:49.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T03:11:19.686+0000] {processor.py:157} INFO - Started process (PID=29073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:11:19.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:11:19.689+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:11:19.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:11:19.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:11:19.715+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:11:19.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:11:19.727+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:11:19.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:11:19.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T03:11:50.074+0000] {processor.py:157} INFO - Started process (PID=29083) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:11:50.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:11:50.081+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:11:50.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:11:50.095+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:11:50.116+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:11:50.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:11:50.128+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:11:50.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:11:50.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T03:12:20.408+0000] {processor.py:157} INFO - Started process (PID=29093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:12:20.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:12:20.411+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:12:20.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:12:20.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:12:20.438+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:12:20.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:12:20.449+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:12:20.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:12:20.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T03:12:50.818+0000] {processor.py:157} INFO - Started process (PID=29103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:12:50.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:12:50.822+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:12:50.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:12:50.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:12:50.862+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:12:50.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:12:50.875+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:12:50.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:12:50.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T03:13:21.261+0000] {processor.py:157} INFO - Started process (PID=29113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:13:21.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:13:21.263+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:13:21.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:13:21.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:13:21.290+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:13:21.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:13:21.302+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:13:21.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:13:21.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T03:13:51.687+0000] {processor.py:157} INFO - Started process (PID=29123) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:13:51.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:13:51.690+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:13:51.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:13:51.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:13:51.718+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:13:51.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:13:51.730+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:13:51.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:13:51.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T03:14:22.164+0000] {processor.py:157} INFO - Started process (PID=29133) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:14:22.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:14:22.167+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:14:22.167+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:14:22.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:14:22.198+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:14:22.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:14:22.210+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:14:22.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:14:22.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T03:14:52.582+0000] {processor.py:157} INFO - Started process (PID=29143) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:14:52.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:14:52.584+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:14:52.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:14:52.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:14:52.611+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:14:52.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:14:52.623+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:14:52.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:14:52.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T03:15:22.965+0000] {processor.py:157} INFO - Started process (PID=29153) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:15:22.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:15:22.967+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:15:22.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:15:22.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:15:22.998+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:15:22.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:15:23.009+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:15:23.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:15:23.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T03:15:53.431+0000] {processor.py:157} INFO - Started process (PID=29163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:15:53.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:15:53.435+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:15:53.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:15:53.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:15:53.462+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:15:53.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:15:53.471+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:15:53.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:15:53.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T03:16:23.710+0000] {processor.py:157} INFO - Started process (PID=29173) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:16:23.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:16:23.712+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:16:23.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:16:23.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:16:23.734+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:16:23.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:16:23.743+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:16:23.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:16:23.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-09-10T03:16:54.100+0000] {processor.py:157} INFO - Started process (PID=29183) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:16:54.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:16:54.102+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:16:54.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:16:54.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:16:54.129+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:16:54.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:16:54.139+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:16:54.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:16:54.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T03:17:24.481+0000] {processor.py:157} INFO - Started process (PID=29193) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:17:24.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:17:24.486+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:17:24.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:17:24.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:17:24.519+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:17:24.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:17:24.529+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:17:24.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:17:24.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T03:17:54.910+0000] {processor.py:157} INFO - Started process (PID=29203) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:17:54.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:17:54.915+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:17:54.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:17:54.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:17:54.950+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:17:54.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:17:54.965+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:17:54.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:17:54.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T03:18:25.304+0000] {processor.py:157} INFO - Started process (PID=29213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:18:25.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:18:25.307+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:18:25.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:18:25.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:18:25.333+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:18:25.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:18:25.343+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:18:25.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:18:25.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T03:18:55.674+0000] {processor.py:157} INFO - Started process (PID=29223) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:18:55.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:18:55.677+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:18:55.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:18:55.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:18:55.702+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:18:55.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:18:55.711+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:18:55.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:18:55.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T03:19:26.067+0000] {processor.py:157} INFO - Started process (PID=29233) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:19:26.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:19:26.069+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:19:26.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:19:26.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:19:26.097+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:19:26.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:19:26.109+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:19:26.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:19:26.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T03:19:56.443+0000] {processor.py:157} INFO - Started process (PID=29243) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:19:56.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:19:56.446+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:19:56.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:19:56.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:19:56.476+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:19:56.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:19:56.487+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:19:56.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:19:56.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T03:20:26.880+0000] {processor.py:157} INFO - Started process (PID=29253) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:20:26.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:20:26.883+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:20:26.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:20:26.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:20:26.908+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:20:26.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:20:26.919+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:20:26.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:20:26.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T03:20:57.178+0000] {processor.py:157} INFO - Started process (PID=29263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:20:57.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:20:57.181+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:20:57.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:20:57.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:20:57.205+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:20:57.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:20:57.216+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:20:57.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:20:57.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T03:21:27.662+0000] {processor.py:157} INFO - Started process (PID=29273) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:21:27.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:21:27.667+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:21:27.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:21:27.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:21:27.704+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:21:27.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:21:27.717+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:21:27.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:21:27.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T03:22:07.312+0000] {processor.py:157} INFO - Started process (PID=29283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:22:07.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:22:07.315+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:22:07.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:22:07.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:22:07.341+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:22:07.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:22:07.352+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:22:07.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:22:07.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T03:22:37.656+0000] {processor.py:157} INFO - Started process (PID=29295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:22:37.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:22:37.660+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:22:37.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:22:37.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:22:37.685+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:22:37.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:22:37.696+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:22:37.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:22:37.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T03:39:35.495+0000] {processor.py:157} INFO - Started process (PID=29307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:39:35.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:39:35.507+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:39:35.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:39:35.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:39:35.612+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:39:35.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:39:35.644+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:39:35.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:39:35.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-10T03:40:06.019+0000] {processor.py:157} INFO - Started process (PID=29317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:40:06.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:40:06.022+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:40:06.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:40:06.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:40:06.061+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:40:06.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:40:06.074+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:40:06.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:40:06.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T03:40:36.377+0000] {processor.py:157} INFO - Started process (PID=29327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:40:36.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:40:36.381+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:40:36.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:40:36.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:40:36.418+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:40:36.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:40:36.430+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:40:36.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:40:36.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T03:41:06.801+0000] {processor.py:157} INFO - Started process (PID=29337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:41:06.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:41:06.806+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:41:06.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:41:06.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:41:06.840+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:41:06.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:41:06.853+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:41:06.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:41:06.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T03:41:37.246+0000] {processor.py:157} INFO - Started process (PID=29346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:41:37.248+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:41:37.250+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:41:37.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:41:37.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:41:37.283+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:41:37.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:41:37.292+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:41:37.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:41:37.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T03:42:07.635+0000] {processor.py:157} INFO - Started process (PID=29357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:42:07.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:42:07.639+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:42:07.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:42:07.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:42:07.671+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:42:07.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:42:07.684+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:42:07.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:42:07.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T03:42:38.023+0000] {processor.py:157} INFO - Started process (PID=29367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:42:38.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:42:38.027+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:42:38.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:42:38.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:42:38.057+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:42:38.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:42:38.067+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:42:38.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:42:38.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T03:43:08.412+0000] {processor.py:157} INFO - Started process (PID=29377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:43:08.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:43:08.415+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:43:08.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:43:08.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:43:08.441+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:43:08.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:43:08.453+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:43:08.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:43:08.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T03:43:38.790+0000] {processor.py:157} INFO - Started process (PID=29387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:43:38.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:43:38.795+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:43:38.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:43:38.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:43:38.826+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:43:38.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:43:38.837+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:43:38.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:43:38.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T03:44:09.139+0000] {processor.py:157} INFO - Started process (PID=29397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:44:09.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:44:09.142+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:44:09.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:44:09.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:44:09.167+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:44:09.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:44:09.178+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:44:09.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:44:09.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T03:44:39.525+0000] {processor.py:157} INFO - Started process (PID=29407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:44:39.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:44:39.530+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:44:39.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:44:39.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:44:39.559+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:44:39.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:44:39.571+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:44:39.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:44:39.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T03:45:09.932+0000] {processor.py:157} INFO - Started process (PID=29417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:45:09.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:45:09.935+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:45:09.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:45:09.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:45:09.962+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:45:09.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:45:09.974+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:45:09.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:45:09.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T03:45:40.290+0000] {processor.py:157} INFO - Started process (PID=29427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:45:40.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:45:40.294+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:45:40.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:45:40.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:45:40.318+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:45:40.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:45:40.330+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:45:40.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:45:40.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T03:46:10.714+0000] {processor.py:157} INFO - Started process (PID=29437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:46:10.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:46:10.720+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:46:10.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:46:10.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:46:10.751+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:46:10.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:46:10.765+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:46:10.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:46:10.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T03:46:41.167+0000] {processor.py:157} INFO - Started process (PID=29447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:46:41.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:46:41.170+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:46:41.170+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:46:41.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:46:41.194+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:46:41.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:46:41.205+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:46:41.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:46:41.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T03:47:11.537+0000] {processor.py:157} INFO - Started process (PID=29457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:47:11.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:47:11.544+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:47:11.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:47:11.561+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:47:11.581+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:47:11.581+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:47:11.593+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:47:11.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:47:11.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T03:47:41.966+0000] {processor.py:157} INFO - Started process (PID=29467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:47:41.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:47:41.969+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:47:41.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:47:41.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:47:41.993+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:47:41.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:47:42.005+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:47:42.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:47:42.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T03:48:12.378+0000] {processor.py:157} INFO - Started process (PID=29477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:48:12.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:48:12.381+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:48:12.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:48:12.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:48:12.411+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:48:12.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:48:12.423+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:48:12.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:48:12.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T03:48:42.800+0000] {processor.py:157} INFO - Started process (PID=29487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:48:42.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:48:42.807+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:48:42.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:48:42.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:48:42.844+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:48:42.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:48:42.856+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:48:42.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:48:42.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T03:49:13.233+0000] {processor.py:157} INFO - Started process (PID=29497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:49:13.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:49:13.236+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:49:13.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:49:13.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:49:13.264+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:49:13.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:49:13.276+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:49:13.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:49:13.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T03:49:43.629+0000] {processor.py:157} INFO - Started process (PID=29506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:49:43.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:49:43.633+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:49:43.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:49:43.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:49:43.663+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:49:43.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:49:43.674+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:49:43.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:49:43.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T03:50:13.961+0000] {processor.py:157} INFO - Started process (PID=29517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:50:13.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:50:13.966+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:50:13.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:50:13.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:50:13.999+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:50:13.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:50:14.012+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:50:14.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:50:14.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T03:50:44.273+0000] {processor.py:157} INFO - Started process (PID=29527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:50:44.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:50:44.278+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:50:44.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:50:44.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:50:44.302+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:50:44.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:50:44.311+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:50:44.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:50:44.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T03:51:14.689+0000] {processor.py:157} INFO - Started process (PID=29537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:51:14.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:51:14.693+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:51:14.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:51:14.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:51:14.719+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:51:14.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:51:14.730+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:51:14.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:51:14.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T03:51:45.024+0000] {processor.py:157} INFO - Started process (PID=29547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:51:45.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:51:45.028+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:51:45.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:51:45.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:51:45.057+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:51:45.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:51:45.070+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:51:45.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:51:45.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T03:52:15.413+0000] {processor.py:157} INFO - Started process (PID=29557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:52:15.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:52:15.419+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:52:15.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:52:15.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:52:15.453+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:52:15.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:52:15.463+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:52:15.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:52:15.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T03:52:45.768+0000] {processor.py:157} INFO - Started process (PID=29567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:52:45.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:52:45.771+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:52:45.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:52:45.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:52:45.797+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:52:45.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:52:45.807+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:52:45.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:52:45.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T03:53:16.171+0000] {processor.py:157} INFO - Started process (PID=29577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:53:16.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:53:16.175+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:53:16.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:53:16.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:53:16.200+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:53:16.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:53:16.212+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:53:16.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:53:16.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T03:53:46.531+0000] {processor.py:157} INFO - Started process (PID=29587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:53:46.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:53:46.535+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:53:46.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:53:46.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:53:46.569+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:53:46.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:53:46.583+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:53:46.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:53:46.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T03:54:16.943+0000] {processor.py:157} INFO - Started process (PID=29597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:54:16.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:54:16.947+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:54:16.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:54:16.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:54:16.980+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:54:16.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:54:16.991+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:54:16.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:54:17.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T03:54:47.391+0000] {processor.py:157} INFO - Started process (PID=29607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:54:47.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:54:47.394+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:54:47.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:54:47.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:54:47.422+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:54:47.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:54:47.432+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:54:47.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:54:47.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T03:55:17.799+0000] {processor.py:157} INFO - Started process (PID=29617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:55:17.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:55:17.802+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:55:17.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:55:17.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:55:17.832+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:55:17.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:55:17.846+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:55:17.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:55:17.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T03:55:48.228+0000] {processor.py:157} INFO - Started process (PID=29627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:55:48.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:55:48.232+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:55:48.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:55:48.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:55:48.260+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:55:48.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:55:48.271+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:55:48.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:55:48.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T03:56:18.612+0000] {processor.py:157} INFO - Started process (PID=29637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:56:18.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:56:18.615+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:56:18.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:56:18.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:56:18.647+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:56:18.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:56:18.656+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:56:18.656+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:56:18.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T03:56:48.988+0000] {processor.py:157} INFO - Started process (PID=29647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:56:48.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:56:48.992+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:56:48.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:56:49.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:56:49.018+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:56:49.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:56:49.028+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:56:49.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:56:49.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T03:57:19.382+0000] {processor.py:157} INFO - Started process (PID=29657) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:57:19.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:57:19.386+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:57:19.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:57:19.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:57:19.413+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:57:19.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:57:19.425+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:57:19.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:57:19.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T03:57:49.713+0000] {processor.py:157} INFO - Started process (PID=29667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:57:49.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:57:49.718+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:57:49.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:57:49.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:57:49.750+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:57:49.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:57:49.760+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:57:49.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:57:49.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T03:58:20.089+0000] {processor.py:157} INFO - Started process (PID=29677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:58:20.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:58:20.092+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:58:20.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:58:20.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:58:20.122+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:58:20.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:58:20.136+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:58:20.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:58:20.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T03:58:50.514+0000] {processor.py:157} INFO - Started process (PID=29686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:58:50.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:58:50.519+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:58:50.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:58:50.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:58:50.554+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:58:50.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:58:50.565+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:58:50.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:58:50.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T03:59:20.878+0000] {processor.py:157} INFO - Started process (PID=29697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:59:20.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:59:20.881+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:59:20.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:59:20.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:59:20.906+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:59:20.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:59:20.918+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:59:20.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:59:20.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T03:59:51.299+0000] {processor.py:157} INFO - Started process (PID=29707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:59:51.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T03:59:51.303+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:59:51.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:59:51.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T03:59:51.335+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:59:51.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T03:59:51.345+0000] {logging_mixin.py:151} INFO - [2024-09-10T03:59:51.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T03:59:51.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T04:00:21.709+0000] {processor.py:157} INFO - Started process (PID=29717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:00:21.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:00:21.714+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:00:21.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:00:21.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:00:21.754+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:00:21.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:00:21.767+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:00:21.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:00:21.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T04:00:52.117+0000] {processor.py:157} INFO - Started process (PID=29727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:00:52.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:00:52.123+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:00:52.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:00:52.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:00:52.176+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:00:52.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:00:52.193+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:00:52.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:00:52.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-10T04:01:22.459+0000] {processor.py:157} INFO - Started process (PID=29737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:01:22.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:01:22.461+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:01:22.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:01:22.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:01:22.488+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:01:22.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:01:22.497+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:01:22.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:01:22.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T04:01:52.922+0000] {processor.py:157} INFO - Started process (PID=29747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:01:52.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:01:52.928+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:01:52.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:01:52.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:01:52.986+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:01:52.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:01:52.998+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:01:52.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:01:53.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-10T04:02:23.213+0000] {processor.py:157} INFO - Started process (PID=29757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:02:23.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:02:23.216+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:02:23.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:02:23.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:02:23.244+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:02:23.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:02:23.255+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:02:23.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:02:23.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T04:02:53.635+0000] {processor.py:157} INFO - Started process (PID=29767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:02:53.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:02:53.641+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:02:53.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:02:53.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:02:53.679+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:02:53.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:02:53.694+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:02:53.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:02:53.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-10T04:03:24.106+0000] {processor.py:157} INFO - Started process (PID=29777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:03:24.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:03:24.108+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:03:24.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:03:24.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:03:24.130+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:03:24.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:03:24.140+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:03:24.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:03:24.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-09-10T04:03:54.522+0000] {processor.py:157} INFO - Started process (PID=29787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:03:54.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:03:54.528+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:03:54.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:03:54.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:03:54.562+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:03:54.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:03:54.574+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:03:54.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:03:54.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T04:04:24.937+0000] {processor.py:157} INFO - Started process (PID=29797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:04:24.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:04:24.939+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:04:24.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:04:24.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:04:24.968+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:04:24.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:04:24.979+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:04:24.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:04:24.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T04:04:55.320+0000] {processor.py:157} INFO - Started process (PID=29807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:04:55.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:04:55.324+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:04:55.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:04:55.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:04:55.360+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:04:55.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:04:55.373+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:04:55.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:04:55.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T04:05:25.739+0000] {processor.py:157} INFO - Started process (PID=29817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:05:25.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:05:25.741+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:05:25.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:05:25.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:05:25.769+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:05:25.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:05:25.779+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:05:25.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:05:25.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T04:05:56.134+0000] {processor.py:157} INFO - Started process (PID=29827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:05:56.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:05:56.138+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:05:56.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:05:56.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:05:56.196+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:05:56.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:05:56.209+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:05:56.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:05:56.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-10T04:06:26.436+0000] {processor.py:157} INFO - Started process (PID=29837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:06:26.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:06:26.438+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:06:26.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:06:26.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:06:26.468+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:06:26.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:06:26.479+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:06:26.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:06:26.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T04:06:56.862+0000] {processor.py:157} INFO - Started process (PID=29847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:06:56.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:06:56.866+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:06:56.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:06:56.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:06:56.902+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:06:56.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:06:56.914+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:06:56.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:06:56.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T04:07:27.202+0000] {processor.py:157} INFO - Started process (PID=29857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:07:27.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:07:27.211+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:07:27.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:07:27.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:07:27.240+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:07:27.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:07:27.253+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:07:27.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:07:27.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T04:07:57.563+0000] {processor.py:157} INFO - Started process (PID=29867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:07:57.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:07:57.567+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:07:57.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:07:57.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:07:57.593+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:07:57.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:07:57.608+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:07:57.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:07:57.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T04:08:27.973+0000] {processor.py:157} INFO - Started process (PID=29877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:08:27.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:08:27.979+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:08:27.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:08:27.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:08:28.017+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:08:28.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:08:28.029+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:08:28.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:08:28.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T04:08:58.406+0000] {processor.py:157} INFO - Started process (PID=29887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:08:58.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:08:58.412+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:08:58.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:08:58.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:08:58.466+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:08:58.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:08:58.479+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:08:58.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:08:58.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-10T04:09:28.771+0000] {processor.py:157} INFO - Started process (PID=29896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:09:28.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:09:28.776+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:09:28.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:09:28.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:09:28.819+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:09:28.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:09:28.832+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:09:28.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:09:28.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-10T04:09:59.136+0000] {processor.py:157} INFO - Started process (PID=29907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:09:59.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:09:59.140+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:09:59.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:09:59.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:09:59.169+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:09:59.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:09:59.179+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:09:59.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:09:59.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T04:10:29.561+0000] {processor.py:157} INFO - Started process (PID=29917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:10:29.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:10:29.571+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:10:29.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:10:29.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:10:29.626+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:10:29.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:10:29.641+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:10:29.641+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:10:29.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-10T04:10:59.908+0000] {processor.py:157} INFO - Started process (PID=29927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:10:59.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:10:59.916+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:10:59.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:10:59.928+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:10:59.950+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:10:59.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:10:59.963+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:10:59.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:10:59.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T04:11:30.232+0000] {processor.py:157} INFO - Started process (PID=29937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:11:30.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:11:30.236+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:11:30.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:11:30.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:11:30.263+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:11:30.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:11:30.276+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:11:30.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:11:30.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T04:12:00.607+0000] {processor.py:157} INFO - Started process (PID=29947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:12:00.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:12:00.610+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:12:00.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:12:00.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:12:00.642+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:12:00.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:12:00.654+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:12:00.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:12:00.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T04:12:31.078+0000] {processor.py:157} INFO - Started process (PID=29957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:12:31.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:12:31.081+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:12:31.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:12:31.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:12:31.105+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:12:31.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:12:31.116+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:12:31.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:12:31.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T04:13:01.386+0000] {processor.py:157} INFO - Started process (PID=29967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:13:01.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:13:01.388+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:13:01.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:13:01.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:13:01.413+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:13:01.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:13:01.424+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:13:01.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:13:01.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T04:13:31.788+0000] {processor.py:157} INFO - Started process (PID=29977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:13:31.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:13:31.793+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:13:31.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:13:31.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:13:31.831+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:13:31.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:13:31.846+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:13:31.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:13:31.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-10T04:14:02.237+0000] {processor.py:157} INFO - Started process (PID=29987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:14:02.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:14:02.240+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:14:02.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:14:02.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:14:02.265+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:14:02.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:14:02.275+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:14:02.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:14:02.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T04:14:32.623+0000] {processor.py:157} INFO - Started process (PID=29997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:14:32.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:14:32.625+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:14:32.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:14:32.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:14:32.652+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:14:32.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:14:32.666+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:14:32.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:14:32.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T04:15:03.024+0000] {processor.py:157} INFO - Started process (PID=30007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:15:03.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:15:03.028+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:15:03.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:15:03.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:15:03.055+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:15:03.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:15:03.068+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:15:03.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:15:03.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T04:15:33.461+0000] {processor.py:157} INFO - Started process (PID=30017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:15:33.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:15:33.466+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:15:33.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:15:33.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:15:33.502+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:15:33.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:15:33.514+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:15:33.514+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:15:33.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T04:16:03.847+0000] {processor.py:157} INFO - Started process (PID=30027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:16:03.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:16:03.850+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:16:03.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:16:03.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:16:03.875+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:16:03.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:16:03.888+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:16:03.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:16:03.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T04:16:34.191+0000] {processor.py:157} INFO - Started process (PID=30037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:16:34.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:16:34.194+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:16:34.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:16:34.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:16:34.224+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:16:34.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:16:34.236+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:16:34.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:16:34.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T04:17:04.600+0000] {processor.py:157} INFO - Started process (PID=30047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:17:04.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:17:04.602+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:17:04.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:17:04.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:17:04.627+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:17:04.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:17:04.639+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:17:04.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:17:04.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T04:17:35.035+0000] {processor.py:157} INFO - Started process (PID=30057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:17:35.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:17:35.041+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:17:35.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:17:35.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:17:35.075+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:17:35.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:17:35.088+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:17:35.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:17:35.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T04:18:05.365+0000] {processor.py:157} INFO - Started process (PID=30067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:18:05.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:18:05.368+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:18:05.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:18:05.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:18:05.397+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:18:05.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:18:05.410+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:18:05.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:18:05.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T04:18:35.734+0000] {processor.py:157} INFO - Started process (PID=30077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:18:35.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:18:35.738+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:18:35.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:18:35.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:18:35.768+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:18:35.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:18:35.779+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:18:35.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:18:35.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T04:19:06.159+0000] {processor.py:157} INFO - Started process (PID=30087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:19:06.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:19:06.164+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:19:06.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:19:06.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:19:06.189+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:19:06.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:19:06.199+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:19:06.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:19:06.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T04:19:36.597+0000] {processor.py:157} INFO - Started process (PID=30097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:19:36.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:19:36.602+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:19:36.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:19:36.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:19:36.637+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:19:36.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:19:36.649+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:19:36.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:19:36.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T04:20:06.994+0000] {processor.py:157} INFO - Started process (PID=30107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:20:06.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:20:06.996+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:20:06.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:20:07.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:20:07.021+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:20:07.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:20:07.032+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:20:07.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:20:07.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T04:20:37.362+0000] {processor.py:157} INFO - Started process (PID=30117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:20:37.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:20:37.366+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:20:37.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:20:37.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:20:37.437+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:20:37.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:20:37.451+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:20:37.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:20:37.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-10T04:21:07.709+0000] {processor.py:157} INFO - Started process (PID=30127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:21:07.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:21:07.712+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:21:07.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:21:07.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:21:07.740+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:21:07.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:21:07.753+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:21:07.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:21:07.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T04:21:38.190+0000] {processor.py:157} INFO - Started process (PID=30136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:21:38.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:21:38.194+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:21:38.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:21:38.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:21:38.239+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:21:38.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:21:38.252+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:21:38.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:21:38.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-10T04:22:08.593+0000] {processor.py:157} INFO - Started process (PID=30147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:22:08.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:22:08.597+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:22:08.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:22:08.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:22:08.625+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:22:08.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:22:08.634+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:22:08.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:22:08.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T04:22:39.040+0000] {processor.py:157} INFO - Started process (PID=30157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:22:39.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:22:39.044+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:22:39.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:22:39.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:22:39.078+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:22:39.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:22:39.090+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:22:39.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:22:39.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T04:23:09.348+0000] {processor.py:157} INFO - Started process (PID=30166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:23:09.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:23:09.351+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:23:09.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:23:09.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:23:09.380+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:23:09.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:23:09.390+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:23:09.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:23:09.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T04:23:39.760+0000] {processor.py:157} INFO - Started process (PID=30177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:23:39.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:23:39.781+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:23:39.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:23:39.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:23:39.824+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:23:39.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:23:39.837+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:23:39.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:23:39.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-10T04:24:10.084+0000] {processor.py:157} INFO - Started process (PID=30187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:24:10.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:24:10.087+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:24:10.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:24:10.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:24:10.118+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:24:10.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:24:10.128+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:24:10.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:24:10.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T04:24:40.399+0000] {processor.py:157} INFO - Started process (PID=30197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:24:40.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:24:40.405+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:24:40.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:24:40.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:24:40.459+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:24:40.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:24:40.472+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:24:40.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:24:40.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-10T04:25:10.685+0000] {processor.py:157} INFO - Started process (PID=30207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:25:10.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:25:10.688+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:25:10.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:25:10.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:25:10.715+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:25:10.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:25:10.726+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:25:10.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:25:10.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T04:25:40.991+0000] {processor.py:157} INFO - Started process (PID=30217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:25:40.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:25:40.997+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:25:40.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:25:41.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:25:41.030+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:25:41.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:25:41.045+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:25:41.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:25:41.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T04:26:11.369+0000] {processor.py:157} INFO - Started process (PID=30227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:26:11.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:26:11.372+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:26:11.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:26:11.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:26:11.402+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:26:11.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:26:11.413+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:26:11.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:26:11.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T04:26:41.820+0000] {processor.py:157} INFO - Started process (PID=30237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:26:41.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:26:41.824+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:26:41.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:26:41.832+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:26:41.848+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:26:41.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:26:41.859+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:26:41.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:26:41.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T04:27:12.303+0000] {processor.py:157} INFO - Started process (PID=30247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:27:12.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:27:12.308+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:27:12.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:27:12.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:27:12.344+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:27:12.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:27:12.356+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:27:12.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:27:12.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T04:27:42.599+0000] {processor.py:157} INFO - Started process (PID=30257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:27:42.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:27:42.602+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:27:42.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:27:42.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:27:42.631+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:27:42.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:27:42.642+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:27:42.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:27:42.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T04:28:13.079+0000] {processor.py:157} INFO - Started process (PID=30267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:28:13.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:28:13.087+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:28:13.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:28:13.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:28:13.121+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:28:13.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:28:13.134+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:28:13.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:28:13.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T04:28:43.442+0000] {processor.py:157} INFO - Started process (PID=30277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:28:43.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:28:43.446+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:28:43.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:28:43.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:28:43.474+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:28:43.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:28:43.491+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:28:43.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:28:43.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T04:29:13.840+0000] {processor.py:157} INFO - Started process (PID=30286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:29:13.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:29:13.845+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:29:13.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:29:13.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:29:13.879+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:29:13.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:29:13.905+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:29:13.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:29:13.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-10T04:29:44.190+0000] {processor.py:157} INFO - Started process (PID=30297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:29:44.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:29:44.195+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:29:44.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:29:44.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:29:44.222+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:29:44.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:29:44.233+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:29:44.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:29:44.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T04:30:14.607+0000] {processor.py:157} INFO - Started process (PID=30307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:30:14.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:30:14.610+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:30:14.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:30:14.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:30:14.635+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:30:14.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:30:14.645+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:30:14.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:30:14.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T04:30:45.005+0000] {processor.py:157} INFO - Started process (PID=30316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:30:45.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:30:45.025+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:30:45.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:30:45.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:30:45.067+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:30:45.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:30:45.080+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:30:45.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:30:45.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-10T04:31:15.410+0000] {processor.py:157} INFO - Started process (PID=30327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:31:15.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:31:15.413+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:31:15.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:31:15.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:31:15.439+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:31:15.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:31:15.450+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:31:15.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:31:15.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T04:31:45.761+0000] {processor.py:157} INFO - Started process (PID=30337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:31:45.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:31:45.766+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:31:45.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:31:45.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:31:45.800+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:31:45.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:31:45.813+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:31:45.813+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:31:45.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T04:32:16.096+0000] {processor.py:157} INFO - Started process (PID=30347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:32:16.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:32:16.099+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:32:16.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:32:16.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:32:16.129+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:32:16.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:32:16.142+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:32:16.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:32:16.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T04:32:46.499+0000] {processor.py:157} INFO - Started process (PID=30357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:32:46.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:32:46.503+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:32:46.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:32:46.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:32:46.530+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:32:46.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:32:46.540+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:32:46.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:32:46.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T04:33:16.982+0000] {processor.py:157} INFO - Started process (PID=30365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:33:16.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:33:16.986+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:33:16.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:33:17.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:33:17.023+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:33:17.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:33:17.036+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:33:17.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:33:17.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T04:33:47.291+0000] {processor.py:157} INFO - Started process (PID=30377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:33:47.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:33:47.294+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:33:47.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:33:47.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:33:47.321+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:33:47.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:33:47.330+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:33:47.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:33:47.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T04:34:17.663+0000] {processor.py:157} INFO - Started process (PID=30387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:34:17.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:34:17.668+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:34:17.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:34:17.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:34:17.704+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:34:17.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:34:17.719+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:34:17.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:34:17.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T04:34:48.144+0000] {processor.py:157} INFO - Started process (PID=30397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:34:48.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:34:48.149+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:34:48.149+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:34:48.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:34:48.173+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:34:48.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:34:48.182+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:34:48.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:34:48.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T04:35:18.645+0000] {processor.py:157} INFO - Started process (PID=30406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:35:18.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:35:18.650+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:35:18.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:35:18.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:35:18.708+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:35:18.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:35:18.724+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:35:18.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:35:18.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-10T04:35:49.062+0000] {processor.py:157} INFO - Started process (PID=30417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:35:49.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:35:49.068+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:35:49.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:35:49.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:35:49.094+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:35:49.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:35:49.106+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:35:49.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:35:49.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T04:36:19.432+0000] {processor.py:157} INFO - Started process (PID=30426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:36:19.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:36:19.442+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:36:19.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:36:19.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:36:19.500+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:36:19.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:36:19.513+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:36:19.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:36:19.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-10T04:36:49.769+0000] {processor.py:157} INFO - Started process (PID=30437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:36:49.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:36:49.771+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:36:49.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:36:49.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:36:49.798+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:36:49.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:36:49.816+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:36:49.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:36:49.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T04:37:20.118+0000] {processor.py:157} INFO - Started process (PID=30447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:37:20.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:37:20.122+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:37:20.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:37:20.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:37:20.160+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:37:20.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:37:20.173+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:37:20.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:37:20.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T04:37:50.534+0000] {processor.py:157} INFO - Started process (PID=30457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:37:50.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:37:50.538+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:37:50.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:37:50.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:37:50.567+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:37:50.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:37:50.578+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:37:50.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:37:50.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T04:38:20.992+0000] {processor.py:157} INFO - Started process (PID=30467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:38:20.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:38:20.996+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:38:20.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:38:21.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:38:21.031+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:38:21.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:38:21.044+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:38:21.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:38:21.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T04:38:51.396+0000] {processor.py:157} INFO - Started process (PID=30477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:38:51.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:38:51.400+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:38:51.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:38:51.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:38:51.429+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:38:51.429+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:38:51.441+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:38:51.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:38:51.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T04:39:21.889+0000] {processor.py:157} INFO - Started process (PID=30487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:39:21.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:39:21.897+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:39:21.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:39:21.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:39:21.952+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:39:21.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:39:21.966+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:39:21.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:39:21.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-10T04:39:52.219+0000] {processor.py:157} INFO - Started process (PID=30497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:39:52.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:39:52.222+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:39:52.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:39:52.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:39:52.246+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:39:52.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:39:52.255+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:39:52.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:39:52.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T04:40:22.646+0000] {processor.py:157} INFO - Started process (PID=30507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:40:22.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:40:22.651+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:40:22.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:40:22.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:40:22.713+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:40:22.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:40:22.727+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:40:22.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:40:22.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-10T04:40:53.069+0000] {processor.py:157} INFO - Started process (PID=30517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:40:53.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:40:53.081+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:40:53.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:40:53.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:40:53.138+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:40:53.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:40:53.153+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:40:53.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:40:53.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-10T04:41:23.475+0000] {processor.py:157} INFO - Started process (PID=30526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:41:23.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:41:23.481+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:41:23.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:41:23.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:41:23.542+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:41:23.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:41:23.557+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:41:23.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:41:23.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-10T04:41:53.897+0000] {processor.py:157} INFO - Started process (PID=30536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:41:53.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:41:53.902+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:41:53.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:41:53.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:41:53.950+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:41:53.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:41:53.963+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:41:53.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:41:53.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-10T04:42:24.225+0000] {processor.py:157} INFO - Started process (PID=30547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:42:24.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:42:24.227+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:42:24.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:42:24.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:42:24.257+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:42:24.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:42:24.267+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:42:24.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:42:24.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T04:42:54.665+0000] {processor.py:157} INFO - Started process (PID=30556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:42:54.668+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:42:54.672+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:42:54.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:42:54.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:42:54.739+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:42:54.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:42:54.751+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:42:54.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:42:54.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-10T04:43:25.030+0000] {processor.py:157} INFO - Started process (PID=30567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:43:25.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:43:25.033+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:43:25.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:43:25.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:43:25.062+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:43:25.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:43:25.072+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:43:25.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:43:25.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T04:43:55.425+0000] {processor.py:157} INFO - Started process (PID=30577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:43:55.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:43:55.430+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:43:55.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:43:55.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:43:55.467+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:43:55.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:43:55.479+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:43:55.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:43:55.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T04:44:25.814+0000] {processor.py:157} INFO - Started process (PID=30587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:44:25.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:44:25.816+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:44:25.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:44:25.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:44:25.848+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:44:25.848+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:44:25.858+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:44:25.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:44:25.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T04:44:56.235+0000] {processor.py:157} INFO - Started process (PID=30597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:44:56.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:44:56.238+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:44:56.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:44:56.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:44:56.265+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:44:56.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:44:56.275+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:44:56.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:44:56.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T04:45:26.620+0000] {processor.py:157} INFO - Started process (PID=30606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:45:26.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:45:26.625+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:45:26.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:45:26.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:45:26.663+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:45:26.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:45:26.678+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:45:26.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:45:26.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-10T04:45:56.991+0000] {processor.py:157} INFO - Started process (PID=30617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:45:56.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:45:56.995+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:45:56.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:45:57.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:45:57.020+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:45:57.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:45:57.030+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:45:57.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:45:57.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T04:46:27.394+0000] {processor.py:157} INFO - Started process (PID=30627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:46:27.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:46:27.400+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:46:27.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:46:27.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:46:27.435+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:46:27.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:46:27.448+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:46:27.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:46:27.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T04:46:57.780+0000] {processor.py:157} INFO - Started process (PID=30637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:46:57.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:46:57.785+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:46:57.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:46:57.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:46:57.815+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:46:57.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:46:57.826+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:46:57.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:46:57.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T04:47:28.138+0000] {processor.py:157} INFO - Started process (PID=30647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:47:28.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:47:28.140+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:47:28.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:47:28.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:47:28.168+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:47:28.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:47:28.180+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:47:28.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:47:28.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T04:47:58.545+0000] {processor.py:157} INFO - Started process (PID=30656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:47:58.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:47:58.548+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:47:58.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:47:58.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:47:58.574+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:47:58.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:47:58.585+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:47:58.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:47:58.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T04:48:28.955+0000] {processor.py:157} INFO - Started process (PID=30666) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:48:28.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:48:28.960+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:48:28.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:48:28.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:48:29.018+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:48:29.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:48:29.031+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:48:29.031+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:48:29.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-10T04:48:59.298+0000] {processor.py:157} INFO - Started process (PID=30676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:48:59.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:48:59.303+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:48:59.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:48:59.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:48:59.338+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:48:59.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:48:59.353+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:48:59.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:48:59.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T04:49:29.667+0000] {processor.py:157} INFO - Started process (PID=30687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:49:29.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:49:29.670+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:49:29.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:49:29.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:49:29.696+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:49:29.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:49:29.708+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:49:29.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:49:29.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T04:49:59.990+0000] {processor.py:157} INFO - Started process (PID=30697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:49:59.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:49:59.993+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:49:59.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:50:00.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:50:00.022+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:50:00.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:50:00.033+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:50:00.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:50:00.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T04:50:30.347+0000] {processor.py:157} INFO - Started process (PID=30706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:50:30.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:50:30.351+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:50:30.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:50:30.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:50:30.387+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:50:30.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:50:30.399+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:50:30.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:50:30.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T04:51:00.755+0000] {processor.py:157} INFO - Started process (PID=30717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:51:00.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:51:00.758+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:51:00.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:51:00.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:51:00.788+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:51:00.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:51:00.800+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:51:00.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:51:00.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T04:51:31.217+0000] {processor.py:157} INFO - Started process (PID=30727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:51:31.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:51:31.226+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:51:31.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:51:31.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:51:31.274+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:51:31.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:51:31.285+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:51:31.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:51:31.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-10T04:52:01.665+0000] {processor.py:157} INFO - Started process (PID=30736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:52:01.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:52:01.671+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:52:01.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:52:01.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:52:01.708+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:52:01.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:52:01.721+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:52:01.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:52:01.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T04:52:32.077+0000] {processor.py:157} INFO - Started process (PID=30747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:52:32.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:52:32.081+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:52:32.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:52:32.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:52:32.144+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:52:32.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:52:32.160+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:52:32.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:52:32.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T04:53:02.530+0000] {processor.py:157} INFO - Started process (PID=30757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:53:02.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:53:02.536+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:53:02.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:53:02.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:53:02.580+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:53:02.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:53:02.592+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:53:02.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:53:02.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T04:53:32.999+0000] {processor.py:157} INFO - Started process (PID=30767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:53:33.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:53:33.004+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:53:33.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:53:33.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:53:33.054+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:53:33.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:53:33.067+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:53:33.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:53:33.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-10T04:54:03.337+0000] {processor.py:157} INFO - Started process (PID=30777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:54:03.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:54:03.340+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:54:03.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:54:03.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:54:03.373+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:54:03.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:54:03.396+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:54:03.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:54:03.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T04:54:33.780+0000] {processor.py:157} INFO - Started process (PID=30787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:54:33.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:54:33.785+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:54:33.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:54:33.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:54:33.819+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:54:33.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:54:33.830+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:54:33.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:54:33.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T04:55:04.236+0000] {processor.py:157} INFO - Started process (PID=30797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:55:04.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:55:04.241+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:55:04.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:55:04.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:55:04.273+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:55:04.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:55:04.285+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:55:04.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:55:04.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T04:55:34.660+0000] {processor.py:157} INFO - Started process (PID=30807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:55:34.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:55:34.666+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:55:34.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:55:34.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:55:34.698+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:55:34.698+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:55:34.709+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:55:34.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:55:34.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T04:56:05.089+0000] {processor.py:157} INFO - Started process (PID=30817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:56:05.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:56:05.094+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:56:05.093+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:56:05.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:56:05.131+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:56:05.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:56:05.142+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:56:05.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:56:05.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T04:56:35.489+0000] {processor.py:157} INFO - Started process (PID=30826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:56:35.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:56:35.517+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:56:35.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:56:35.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:56:35.561+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:56:35.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:56:35.576+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:56:35.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:56:35.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-10T04:57:05.841+0000] {processor.py:157} INFO - Started process (PID=30837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:57:05.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:57:05.844+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:57:05.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:57:05.862+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:57:05.879+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:57:05.879+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:57:05.892+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:57:05.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:57:05.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T04:57:36.270+0000] {processor.py:157} INFO - Started process (PID=30847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:57:36.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:57:36.275+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:57:36.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:57:36.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:57:36.305+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:57:36.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:57:36.314+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:57:36.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:57:36.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T04:58:06.646+0000] {processor.py:157} INFO - Started process (PID=30857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:58:06.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:58:06.651+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:58:06.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:58:06.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:58:06.689+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:58:06.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:58:06.702+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:58:06.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:58:06.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-10T04:58:37.020+0000] {processor.py:157} INFO - Started process (PID=30865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:58:37.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:58:37.024+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:58:37.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:58:37.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:58:37.079+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:58:37.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:58:37.090+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:58:37.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:58:37.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T04:59:07.424+0000] {processor.py:157} INFO - Started process (PID=30877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:59:07.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:59:07.427+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:59:07.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:59:07.439+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:59:07.470+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:59:07.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:59:07.489+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:59:07.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:59:07.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-10T04:59:37.795+0000] {processor.py:157} INFO - Started process (PID=30886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:59:37.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T04:59:37.811+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:59:37.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:59:37.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T04:59:37.843+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:59:37.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T04:59:37.853+0000] {logging_mixin.py:151} INFO - [2024-09-10T04:59:37.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T04:59:37.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T05:00:08.123+0000] {processor.py:157} INFO - Started process (PID=30897) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:00:08.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:00:08.126+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:00:08.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:00:08.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:00:08.173+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:00:08.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:00:08.185+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:00:08.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:00:08.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-10T05:00:38.441+0000] {processor.py:157} INFO - Started process (PID=30907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:00:38.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:00:38.448+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:00:38.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:00:38.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:00:38.502+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:00:38.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:00:38.519+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:00:38.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:00:38.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T05:01:08.817+0000] {processor.py:157} INFO - Started process (PID=30917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:01:08.819+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:01:08.820+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:01:08.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:01:08.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:01:08.845+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:01:08.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:01:08.855+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:01:08.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:01:08.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T05:01:39.192+0000] {processor.py:157} INFO - Started process (PID=30927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:01:39.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:01:39.195+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:01:39.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:01:39.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:01:39.226+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:01:39.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:01:39.239+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:01:39.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:01:39.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T05:02:09.506+0000] {processor.py:157} INFO - Started process (PID=30937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:02:09.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:02:09.509+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:02:09.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:02:09.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:02:09.536+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:02:09.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:02:09.548+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:02:09.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:02:09.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T05:02:39.923+0000] {processor.py:157} INFO - Started process (PID=30947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:02:39.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:02:39.929+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:02:39.929+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:02:39.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:02:39.967+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:02:39.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:02:39.979+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:02:39.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:02:39.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T05:03:10.355+0000] {processor.py:157} INFO - Started process (PID=30957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:03:10.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:03:10.358+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:03:10.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:03:10.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:03:10.386+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:03:10.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:03:10.398+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:03:10.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:03:10.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T05:03:40.775+0000] {processor.py:157} INFO - Started process (PID=30967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:03:40.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:03:40.786+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:03:40.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:03:40.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:03:40.825+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:03:40.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:03:40.838+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:03:40.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:03:40.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-10T05:04:11.220+0000] {processor.py:157} INFO - Started process (PID=30977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:04:11.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:04:11.223+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:04:11.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:04:11.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:04:11.251+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:04:11.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:04:11.263+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:04:11.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:04:11.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T05:04:41.631+0000] {processor.py:157} INFO - Started process (PID=30987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:04:41.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:04:41.647+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:04:41.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:04:41.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:04:41.685+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:04:41.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:04:41.698+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:04:41.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:04:41.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-10T05:05:12.042+0000] {processor.py:157} INFO - Started process (PID=30997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:05:12.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:05:12.045+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:05:12.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:05:12.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:05:12.071+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:05:12.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:05:12.082+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:05:12.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:05:12.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T05:05:42.431+0000] {processor.py:157} INFO - Started process (PID=31007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:05:42.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:05:42.434+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:05:42.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:05:42.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:05:42.501+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:05:42.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:05:42.515+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:05:42.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:05:42.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-10T05:06:12.779+0000] {processor.py:157} INFO - Started process (PID=31017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:06:12.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:06:12.783+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:06:12.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:06:12.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:06:12.809+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:06:12.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:06:12.821+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:06:12.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:06:12.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T05:06:43.193+0000] {processor.py:157} INFO - Started process (PID=31026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:06:43.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:06:43.203+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:06:43.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:06:43.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:06:43.241+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:06:43.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:06:43.267+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:06:43.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:06:43.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-10T05:07:13.657+0000] {processor.py:157} INFO - Started process (PID=31037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:07:13.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:07:13.659+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:07:13.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:07:13.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:07:13.687+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:07:13.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:07:13.700+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:07:13.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:07:13.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T05:07:44.043+0000] {processor.py:157} INFO - Started process (PID=31047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:07:44.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:07:44.048+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:07:44.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:07:44.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:07:44.084+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:07:44.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:07:44.097+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:07:44.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:07:44.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T05:08:14.458+0000] {processor.py:157} INFO - Started process (PID=31057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:08:14.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:08:14.461+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:08:14.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:08:14.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:08:14.489+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:08:14.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:08:14.503+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:08:14.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:08:14.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T05:08:44.897+0000] {processor.py:157} INFO - Started process (PID=31066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:08:44.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:08:44.905+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:08:44.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:08:44.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:08:44.982+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:08:44.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:08:45.002+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:08:45.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:08:45.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-10T05:09:15.290+0000] {processor.py:157} INFO - Started process (PID=31077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:09:15.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:09:15.299+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:09:15.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:09:15.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:09:15.356+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:09:15.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:09:15.371+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:09:15.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:09:15.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-10T05:09:45.641+0000] {processor.py:157} INFO - Started process (PID=31087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:09:45.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:09:45.644+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:09:45.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:09:45.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:09:45.677+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:09:45.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:09:45.689+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:09:45.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:09:45.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T05:10:16.044+0000] {processor.py:157} INFO - Started process (PID=31097) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:10:16.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:10:16.048+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:10:16.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:10:16.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:10:16.078+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:10:16.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:10:16.089+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:10:16.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:10:16.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T05:10:46.513+0000] {processor.py:157} INFO - Started process (PID=31107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:10:46.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:10:46.518+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:10:46.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:10:46.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:10:46.568+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:10:46.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:10:46.581+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:10:46.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:10:46.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-10T05:11:16.989+0000] {processor.py:157} INFO - Started process (PID=31117) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:11:16.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:11:16.994+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:11:16.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:11:17.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:11:17.040+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:11:17.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:11:17.060+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:11:17.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:11:17.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-10T05:11:47.359+0000] {processor.py:157} INFO - Started process (PID=31127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:11:47.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:11:47.365+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:11:47.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:11:47.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:11:47.401+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:11:47.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:11:47.416+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:11:47.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:11:47.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T05:12:17.679+0000] {processor.py:157} INFO - Started process (PID=31137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:12:17.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:12:17.682+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:12:17.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:12:17.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:12:17.714+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:12:17.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:12:17.733+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:12:17.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:12:17.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T05:12:48.030+0000] {processor.py:157} INFO - Started process (PID=31147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:12:48.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:12:48.036+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:12:48.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:12:48.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:12:48.070+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:12:48.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:12:48.080+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:12:48.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:12:48.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T05:13:18.412+0000] {processor.py:157} INFO - Started process (PID=31157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:13:18.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:13:18.415+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:13:18.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:13:18.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:13:18.445+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:13:18.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:13:18.456+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:13:18.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:13:18.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T05:13:48.809+0000] {processor.py:157} INFO - Started process (PID=31167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:13:48.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:13:48.815+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:13:48.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:13:48.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:13:48.846+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:13:48.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:13:48.858+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:13:48.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:13:48.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T05:14:19.159+0000] {processor.py:157} INFO - Started process (PID=31177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:14:19.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:14:19.165+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:14:19.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:14:19.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:14:19.194+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:14:19.194+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:14:19.207+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:14:19.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:14:19.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T05:14:49.577+0000] {processor.py:157} INFO - Started process (PID=31187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:14:49.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:14:49.581+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:14:49.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:14:49.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:14:49.622+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:14:49.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:14:49.632+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:14:49.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:14:49.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T05:15:19.940+0000] {processor.py:157} INFO - Started process (PID=31197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:15:19.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:15:19.942+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:15:19.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:15:19.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:15:19.968+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:15:19.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:15:19.981+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:15:19.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:15:19.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T05:15:50.403+0000] {processor.py:157} INFO - Started process (PID=31207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:15:50.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:15:50.408+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:15:50.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:15:50.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:15:50.434+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:15:50.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:15:50.445+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:15:50.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:15:50.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T05:16:20.856+0000] {processor.py:157} INFO - Started process (PID=31217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:16:20.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:16:20.859+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:16:20.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:16:20.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:16:20.904+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:16:20.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:16:20.920+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:16:20.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:16:20.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-10T05:16:51.230+0000] {processor.py:157} INFO - Started process (PID=31227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:16:51.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:16:51.234+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:16:51.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:16:51.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:16:51.266+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:16:51.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:16:51.278+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:16:51.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:16:51.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T05:17:21.657+0000] {processor.py:157} INFO - Started process (PID=31237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:17:21.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:17:21.661+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:17:21.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:17:21.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:17:21.694+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:17:21.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:17:21.705+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:17:21.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:17:21.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T05:17:52.026+0000] {processor.py:157} INFO - Started process (PID=31247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:17:52.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:17:52.029+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:17:52.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:17:52.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:17:52.051+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:17:52.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:17:52.063+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:17:52.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:17:52.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T05:18:22.370+0000] {processor.py:157} INFO - Started process (PID=31257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:18:22.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:18:22.374+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:18:22.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:18:22.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:18:22.411+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:18:22.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:18:22.421+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:18:22.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:18:22.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T05:18:52.875+0000] {processor.py:157} INFO - Started process (PID=31267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:18:52.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:18:52.878+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:18:52.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:18:52.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:18:52.905+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:18:52.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:18:52.918+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:18:52.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:18:52.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T05:19:23.199+0000] {processor.py:157} INFO - Started process (PID=31277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:19:23.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:19:23.210+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:19:23.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:19:23.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:19:23.247+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:19:23.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:19:23.261+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:19:23.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:19:23.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T05:19:53.692+0000] {processor.py:157} INFO - Started process (PID=31287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:19:53.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:19:53.695+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:19:53.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:19:53.704+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:19:53.719+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:19:53.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:19:53.748+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:19:53.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:19:53.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T05:20:23.981+0000] {processor.py:157} INFO - Started process (PID=31296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:20:23.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:20:23.985+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:20:23.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:20:24.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:20:24.043+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:20:24.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:20:24.056+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:20:24.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:20:24.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T05:20:54.425+0000] {processor.py:157} INFO - Started process (PID=31307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:20:54.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:20:54.429+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:20:54.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:20:54.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:20:54.456+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:20:54.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:20:54.467+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:20:54.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:20:54.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T05:21:24.850+0000] {processor.py:157} INFO - Started process (PID=31316) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:21:24.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:21:24.855+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:21:24.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:21:24.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:21:24.904+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:21:24.904+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:21:24.925+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:21:24.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:21:24.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-10T05:21:55.203+0000] {processor.py:157} INFO - Started process (PID=31327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:21:55.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:21:55.206+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:21:55.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:21:55.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:21:55.234+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:21:55.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:21:55.245+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:21:55.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:21:55.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T05:22:25.647+0000] {processor.py:157} INFO - Started process (PID=31337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:22:25.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:22:25.651+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:22:25.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:22:25.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:22:25.690+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:22:25.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:22:25.703+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:22:25.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:22:25.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-10T05:22:56.047+0000] {processor.py:157} INFO - Started process (PID=31347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:22:56.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:22:56.051+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:22:56.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:22:56.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:22:56.077+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:22:56.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:22:56.088+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:22:56.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:22:56.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T05:23:26.414+0000] {processor.py:157} INFO - Started process (PID=31357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:23:26.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:23:26.419+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:23:26.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:23:26.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:23:26.479+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:23:26.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:23:26.492+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:23:26.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:23:26.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-10T05:23:56.769+0000] {processor.py:157} INFO - Started process (PID=31367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:23:56.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:23:56.772+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:23:56.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:23:56.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:23:56.805+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:23:56.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:23:56.816+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:23:56.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:23:56.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T05:24:27.150+0000] {processor.py:157} INFO - Started process (PID=31377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:24:27.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:24:27.156+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:24:27.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:24:27.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:24:27.192+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:24:27.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:24:27.207+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:24:27.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:24:27.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T05:24:57.513+0000] {processor.py:157} INFO - Started process (PID=31387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:24:57.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:24:57.516+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:24:57.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:24:57.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:24:57.545+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:24:57.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:24:57.556+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:24:57.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:24:57.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T05:25:27.905+0000] {processor.py:157} INFO - Started process (PID=31397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:25:27.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:25:27.910+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:25:27.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:25:27.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:25:27.945+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:25:27.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:25:27.961+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:25:27.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:25:27.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T05:25:58.288+0000] {processor.py:157} INFO - Started process (PID=31407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:25:58.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:25:58.290+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:25:58.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:25:58.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:25:58.318+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:25:58.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:25:58.328+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:25:58.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:25:58.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T05:26:28.661+0000] {processor.py:157} INFO - Started process (PID=31417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:26:28.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:26:28.665+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:26:28.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:26:28.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:26:28.697+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:26:28.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:26:28.714+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:26:28.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:26:28.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T05:26:59.010+0000] {processor.py:157} INFO - Started process (PID=31427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:26:59.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:26:59.014+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:26:59.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:26:59.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:26:59.049+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:26:59.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:26:59.060+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:26:59.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:26:59.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T05:27:29.413+0000] {processor.py:157} INFO - Started process (PID=31437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:27:29.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:27:29.418+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:27:29.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:27:29.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:27:29.447+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:27:29.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:27:29.459+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:27:29.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:27:29.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T05:27:59.843+0000] {processor.py:157} INFO - Started process (PID=31447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:27:59.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:27:59.849+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:27:59.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:27:59.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:27:59.884+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:27:59.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:27:59.895+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:27:59.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:27:59.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T05:28:30.249+0000] {processor.py:157} INFO - Started process (PID=31457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:28:30.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:28:30.252+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:28:30.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:28:30.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:28:30.284+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:28:30.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:28:30.306+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:28:30.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:28:30.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T05:29:00.620+0000] {processor.py:157} INFO - Started process (PID=31467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:29:00.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:29:00.625+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:29:00.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:29:00.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:29:00.660+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:29:00.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:29:00.672+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:29:00.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:29:00.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-10T05:29:30.934+0000] {processor.py:157} INFO - Started process (PID=31477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:29:30.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:29:30.940+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:29:30.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:29:30.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:29:30.980+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:29:30.980+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:29:30.997+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:29:30.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:29:31.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-10T05:30:01.345+0000] {processor.py:157} INFO - Started process (PID=31487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:30:01.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:30:01.348+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:30:01.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:30:01.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:30:01.373+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:30:01.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:30:01.383+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:30:01.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:30:01.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T05:30:31.726+0000] {processor.py:157} INFO - Started process (PID=31497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:30:31.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:30:31.730+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:30:31.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:30:31.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:30:31.761+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:30:31.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:30:31.774+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:30:31.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:30:31.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T05:31:02.126+0000] {processor.py:157} INFO - Started process (PID=31506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:31:02.128+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:31:02.132+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:31:02.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:31:02.147+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:31:02.184+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:31:02.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:31:02.196+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:31:02.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:31:02.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-10T05:31:32.597+0000] {processor.py:157} INFO - Started process (PID=31517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:31:32.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:31:32.603+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:31:32.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:31:32.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:31:32.634+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:31:32.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:31:32.646+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:31:32.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:31:32.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T05:32:02.973+0000] {processor.py:157} INFO - Started process (PID=31527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:32:02.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:32:02.979+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:32:02.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:32:02.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:32:03.011+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:32:03.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:32:03.022+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:32:03.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:32:03.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T05:32:33.349+0000] {processor.py:157} INFO - Started process (PID=31537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:32:33.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:32:33.354+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:32:33.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:32:33.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:32:33.383+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:32:33.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:32:33.394+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:32:33.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:32:33.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T05:33:03.791+0000] {processor.py:157} INFO - Started process (PID=31547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:33:03.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:33:03.795+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:33:03.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:33:03.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:33:03.823+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:33:03.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:33:03.834+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:33:03.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:33:03.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T05:33:34.188+0000] {processor.py:157} INFO - Started process (PID=31557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:33:34.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:33:34.195+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:33:34.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:33:34.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:33:34.246+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:33:34.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:33:34.260+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:33:34.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:33:34.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-10T05:34:04.635+0000] {processor.py:157} INFO - Started process (PID=31567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:34:04.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:34:04.639+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:34:04.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:34:04.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:34:04.671+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:34:04.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:34:04.682+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:34:04.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:34:04.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T05:34:35.075+0000] {processor.py:157} INFO - Started process (PID=31577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:34:35.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:34:35.080+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:34:35.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:34:35.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:34:35.117+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:34:35.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:34:35.129+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:34:35.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:34:35.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T05:35:05.515+0000] {processor.py:157} INFO - Started process (PID=31587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:35:05.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:35:05.520+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:35:05.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:35:05.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:35:05.552+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:35:05.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:35:05.565+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:35:05.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:35:05.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T05:35:35.968+0000] {processor.py:157} INFO - Started process (PID=31597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:35:35.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:35:35.974+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:35:35.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:35:35.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:35:36.005+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:35:36.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:35:36.015+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:35:36.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:35:36.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T05:36:06.352+0000] {processor.py:157} INFO - Started process (PID=31606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:36:06.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:36:06.357+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:36:06.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:36:06.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:36:06.416+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:36:06.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:36:06.428+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:36:06.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:36:06.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-10T05:36:36.700+0000] {processor.py:157} INFO - Started process (PID=31617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:36:36.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:36:36.703+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:36:36.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:36:36.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:36:36.731+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:36:36.731+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:36:36.741+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:36:36.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:36:36.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T05:37:07.117+0000] {processor.py:157} INFO - Started process (PID=31627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:37:07.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:37:07.130+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:37:07.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:37:07.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:37:07.174+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:37:07.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:37:07.186+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:37:07.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:37:07.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-10T05:37:37.467+0000] {processor.py:157} INFO - Started process (PID=31637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:37:37.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:37:37.471+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:37:37.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:37:37.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:37:37.498+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:37:37.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:37:37.510+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:37:37.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:37:37.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T05:38:07.914+0000] {processor.py:157} INFO - Started process (PID=31647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:38:07.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:38:07.917+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:38:07.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:38:07.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:38:07.944+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:38:07.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:38:07.955+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:38:07.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:38:07.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T05:38:38.306+0000] {processor.py:157} INFO - Started process (PID=31656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:38:38.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:38:38.312+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:38:38.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:38:38.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:38:38.373+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:38:38.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:38:38.387+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:38:38.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:38:38.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-10T05:39:08.730+0000] {processor.py:157} INFO - Started process (PID=31667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:39:08.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:39:08.734+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:39:08.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:39:08.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:39:08.763+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:39:08.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:39:08.775+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:39:08.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:39:08.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T05:39:39.174+0000] {processor.py:157} INFO - Started process (PID=31676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:39:39.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:39:39.180+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:39:39.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:39:39.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:39:39.219+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:39:39.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:39:39.234+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:39:39.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:39:39.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-10T05:40:09.448+0000] {processor.py:157} INFO - Started process (PID=31687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:40:09.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:40:09.452+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:40:09.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:40:09.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:40:09.486+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:40:09.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:40:09.498+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:40:09.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:40:09.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T05:40:39.886+0000] {processor.py:157} INFO - Started process (PID=31696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:40:39.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:40:39.893+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:40:39.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:40:39.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:40:39.937+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:40:39.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:40:39.952+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:40:39.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:40:39.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T05:41:10.283+0000] {processor.py:157} INFO - Started process (PID=31706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:41:10.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:41:10.288+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:41:10.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:41:10.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:41:10.342+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:41:10.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:41:10.354+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:41:10.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:41:10.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-10T05:41:40.656+0000] {processor.py:157} INFO - Started process (PID=31716) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:41:40.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:41:40.662+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:41:40.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:41:40.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:41:40.704+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:41:40.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:41:40.717+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:41:40.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:41:40.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-10T05:42:11.006+0000] {processor.py:157} INFO - Started process (PID=31727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:42:11.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:42:11.009+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:42:11.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:42:11.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:42:11.037+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:42:11.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:42:11.048+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:42:11.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:42:11.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T05:42:41.428+0000] {processor.py:157} INFO - Started process (PID=31737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:42:41.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:42:41.433+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:42:41.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:42:41.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:42:41.473+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:42:41.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:42:41.486+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:42:41.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:42:41.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T05:43:11.840+0000] {processor.py:157} INFO - Started process (PID=31747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:43:11.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:43:11.843+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:43:11.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:43:11.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:43:11.870+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:43:11.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:43:11.883+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:43:11.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:43:11.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T05:43:42.264+0000] {processor.py:157} INFO - Started process (PID=31757) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:43:42.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:43:42.274+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:43:42.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:43:42.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:43:42.314+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:43:42.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:43:42.327+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:43:42.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:43:42.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T05:44:12.578+0000] {processor.py:157} INFO - Started process (PID=31767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:44:12.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:44:12.585+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:44:12.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:44:12.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:44:12.607+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:44:12.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:44:12.615+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:44:12.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:44:12.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T05:44:42.981+0000] {processor.py:157} INFO - Started process (PID=31777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:44:42.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:44:42.987+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:44:42.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:44:43.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:44:43.023+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:44:43.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:44:43.036+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:44:43.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:44:43.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T05:45:13.377+0000] {processor.py:157} INFO - Started process (PID=31787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:45:13.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:45:13.380+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:45:13.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:45:13.388+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:45:13.403+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:45:13.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:45:13.413+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:45:13.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:45:13.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-10T05:45:43.806+0000] {processor.py:157} INFO - Started process (PID=31797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:45:43.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:45:43.809+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:45:43.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:45:43.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:45:43.835+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:45:43.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:45:43.845+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:45:43.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:45:43.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T05:46:14.199+0000] {processor.py:157} INFO - Started process (PID=31807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:46:14.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:46:14.206+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:46:14.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:46:14.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:46:14.241+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:46:14.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:46:14.252+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:46:14.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:46:14.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T05:46:44.616+0000] {processor.py:157} INFO - Started process (PID=31817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:46:44.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:46:44.619+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:46:44.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:46:44.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:46:44.644+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:46:44.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:46:44.658+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:46:44.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:46:44.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T05:47:15.031+0000] {processor.py:157} INFO - Started process (PID=31827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:47:15.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:47:15.036+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:47:15.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:47:15.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:47:15.073+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:47:15.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:47:15.084+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:47:15.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:47:15.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T05:47:45.460+0000] {processor.py:157} INFO - Started process (PID=31837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:47:45.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:47:45.464+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:47:45.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:47:45.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:47:45.496+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:47:45.496+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:47:45.507+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:47:45.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:47:45.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T05:48:15.821+0000] {processor.py:157} INFO - Started process (PID=31847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:48:15.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:48:15.824+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:48:15.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:48:15.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:48:15.851+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:48:15.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:48:15.863+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:48:15.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:48:15.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T05:48:46.189+0000] {processor.py:157} INFO - Started process (PID=31857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:48:46.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:48:46.194+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:48:46.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:48:46.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:48:46.229+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:48:46.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:48:46.241+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:48:46.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:48:46.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T05:49:16.616+0000] {processor.py:157} INFO - Started process (PID=31867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:49:16.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:49:16.621+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:49:16.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:49:16.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:49:16.649+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:49:16.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:49:16.661+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:49:16.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:49:16.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T05:49:46.952+0000] {processor.py:157} INFO - Started process (PID=31877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:49:46.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:49:46.958+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:49:46.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:49:46.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:49:46.998+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:49:46.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:49:47.010+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:49:47.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:49:47.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-10T05:50:17.342+0000] {processor.py:157} INFO - Started process (PID=31887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:50:17.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:50:17.345+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:50:17.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:50:17.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:50:17.376+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:50:17.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:50:17.396+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:50:17.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:50:17.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T05:50:47.682+0000] {processor.py:157} INFO - Started process (PID=31896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:50:47.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:50:47.687+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:50:47.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:50:47.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:50:47.750+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:50:47.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:50:47.762+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:50:47.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:50:47.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-10T05:51:18.125+0000] {processor.py:157} INFO - Started process (PID=31907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:51:18.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:51:18.129+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:51:18.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:51:18.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:51:18.157+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:51:18.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:51:18.176+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:51:18.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:51:18.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-10T05:51:48.498+0000] {processor.py:157} INFO - Started process (PID=31917) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:51:48.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:51:48.502+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:51:48.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:51:48.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:51:48.556+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:51:48.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:51:48.571+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:51:48.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:51:48.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-10T05:52:18.926+0000] {processor.py:157} INFO - Started process (PID=31927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:52:18.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:52:18.930+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:52:18.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:52:18.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:52:18.963+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:52:18.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:52:18.974+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:52:18.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:52:18.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T05:52:49.274+0000] {processor.py:157} INFO - Started process (PID=31937) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:52:49.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:52:49.279+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:52:49.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:52:49.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:52:49.315+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:52:49.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:52:49.326+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:52:49.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:52:49.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T05:53:19.554+0000] {processor.py:157} INFO - Started process (PID=31947) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:53:19.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:53:19.557+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:53:19.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:53:19.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:53:19.586+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:53:19.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:53:19.599+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:53:19.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:53:19.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T05:53:50.028+0000] {processor.py:157} INFO - Started process (PID=31957) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:53:50.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:53:50.033+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:53:50.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:53:50.050+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:53:50.069+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:53:50.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:53:50.079+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:53:50.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:53:50.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T05:54:20.460+0000] {processor.py:157} INFO - Started process (PID=31967) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:54:20.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:54:20.463+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:54:20.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:54:20.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:54:20.492+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:54:20.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:54:20.515+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:54:20.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:54:20.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-10T05:54:50.847+0000] {processor.py:157} INFO - Started process (PID=31976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:54:50.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:54:50.851+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:54:50.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:54:50.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:54:50.898+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:54:50.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:54:50.908+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:54:50.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:54:50.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-10T05:55:21.265+0000] {processor.py:157} INFO - Started process (PID=31987) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:55:21.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:55:21.268+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:55:21.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:55:21.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:55:21.316+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:55:21.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:55:21.330+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:55:21.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:55:21.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-10T05:55:51.609+0000] {processor.py:157} INFO - Started process (PID=31997) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:55:51.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:55:51.615+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:55:51.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:55:51.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:55:51.649+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:55:51.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:55:51.660+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:55:51.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:55:51.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T05:56:22.045+0000] {processor.py:157} INFO - Started process (PID=32007) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:56:22.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:56:22.049+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:56:22.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:56:22.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:56:22.077+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:56:22.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:56:22.089+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:56:22.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:56:22.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T05:56:52.380+0000] {processor.py:157} INFO - Started process (PID=32017) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:56:52.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:56:52.386+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:56:52.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:56:52.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:56:52.447+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:56:52.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:56:52.459+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:56:52.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:56:52.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-10T05:57:22.662+0000] {processor.py:157} INFO - Started process (PID=32027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:57:22.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:57:22.666+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:57:22.666+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:57:22.677+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:57:22.695+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:57:22.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:57:22.707+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:57:22.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:57:22.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T05:57:53.005+0000] {processor.py:157} INFO - Started process (PID=32037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:57:53.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:57:53.026+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:57:53.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:57:53.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:57:53.079+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:57:53.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:57:53.090+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:57:53.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:57:53.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-10T05:58:23.352+0000] {processor.py:157} INFO - Started process (PID=32047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:58:23.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:58:23.359+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:58:23.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:58:23.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:58:23.398+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:58:23.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:58:23.412+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:58:23.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:58:23.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T05:58:53.786+0000] {processor.py:157} INFO - Started process (PID=32057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:58:53.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:58:53.791+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:58:53.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:58:53.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:58:53.814+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:58:53.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:58:53.824+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:58:53.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:58:53.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T05:59:24.162+0000] {processor.py:157} INFO - Started process (PID=32066) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:59:24.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:59:24.167+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:59:24.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:59:24.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:59:24.200+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:59:24.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:59:24.211+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:59:24.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:59:24.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T05:59:54.575+0000] {processor.py:157} INFO - Started process (PID=32077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:59:54.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T05:59:54.578+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:59:54.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:59:54.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T05:59:54.637+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:59:54.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T05:59:54.649+0000] {logging_mixin.py:151} INFO - [2024-09-10T05:59:54.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T05:59:54.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-10T06:00:24.994+0000] {processor.py:157} INFO - Started process (PID=32087) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:00:24.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:00:24.998+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:00:24.998+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:00:25.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:00:25.027+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:00:25.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:00:25.039+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:00:25.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:00:25.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T06:00:55.371+0000] {processor.py:157} INFO - Started process (PID=32096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:00:55.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:00:55.393+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:00:55.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:00:55.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:00:55.428+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:00:55.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:00:55.439+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:00:55.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:00:55.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-10T06:01:25.785+0000] {processor.py:157} INFO - Started process (PID=32107) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:01:25.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:01:25.789+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:01:25.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:01:25.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:01:25.814+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:01:25.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:01:25.824+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:01:25.824+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:01:25.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T06:01:56.238+0000] {processor.py:157} INFO - Started process (PID=32116) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:01:56.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:01:56.254+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:01:56.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:01:56.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:01:56.318+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:01:56.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:01:56.335+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:01:56.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:01:56.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-10T06:02:26.604+0000] {processor.py:157} INFO - Started process (PID=32126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:02:26.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:02:26.610+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:02:26.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:02:26.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:02:26.654+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:02:26.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:02:26.666+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:02:26.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:02:26.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-10T06:02:56.943+0000] {processor.py:157} INFO - Started process (PID=32137) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:02:56.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:02:56.947+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:02:56.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:02:56.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:02:56.977+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:02:56.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:02:56.988+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:02:56.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:02:56.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T06:03:27.351+0000] {processor.py:157} INFO - Started process (PID=32147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:03:27.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:03:27.357+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:03:27.357+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:03:27.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:03:27.392+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:03:27.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:03:27.404+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:03:27.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:03:27.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T06:03:57.770+0000] {processor.py:157} INFO - Started process (PID=32157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:03:57.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:03:57.772+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:03:57.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:03:57.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:03:57.801+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:03:57.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:03:57.811+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:03:57.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:03:57.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T06:04:28.145+0000] {processor.py:157} INFO - Started process (PID=32167) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:04:28.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:04:28.149+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:04:28.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:04:28.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:04:28.174+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:04:28.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:04:28.186+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:04:28.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:04:28.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T06:04:58.627+0000] {processor.py:157} INFO - Started process (PID=32176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:04:58.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:04:58.652+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:04:58.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:04:58.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:04:58.689+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:04:58.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:04:58.701+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:04:58.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:04:58.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-10T06:05:29.056+0000] {processor.py:157} INFO - Started process (PID=32187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:05:29.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:05:29.061+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:05:29.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:05:29.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:05:29.097+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:05:29.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:05:29.109+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:05:29.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:05:29.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T06:05:59.490+0000] {processor.py:157} INFO - Started process (PID=32197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:05:59.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:05:59.494+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:05:59.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:05:59.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:05:59.519+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:05:59.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:05:59.528+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:05:59.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:05:59.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T06:06:29.883+0000] {processor.py:157} INFO - Started process (PID=32207) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:06:29.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:06:29.887+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:06:29.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:06:29.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:06:29.912+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:06:29.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:06:29.921+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:06:29.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:06:29.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T06:07:00.358+0000] {processor.py:157} INFO - Started process (PID=32217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:07:00.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:07:00.363+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:07:00.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:07:00.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:07:00.418+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:07:00.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:07:00.431+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:07:00.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:07:00.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T06:07:30.692+0000] {processor.py:157} INFO - Started process (PID=32227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:07:30.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:07:30.694+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:07:30.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:07:30.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:07:30.720+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:07:30.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:07:30.733+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:07:30.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:07:30.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T06:08:01.088+0000] {processor.py:157} INFO - Started process (PID=32237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:08:01.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:08:01.091+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:08:01.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:08:01.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:08:01.118+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:08:01.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:08:01.131+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:08:01.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:08:01.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T06:08:31.525+0000] {processor.py:157} INFO - Started process (PID=32247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:08:31.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:08:31.531+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:08:31.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:08:31.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:08:31.596+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:08:31.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:08:31.609+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:08:31.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:08:31.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-10T06:09:01.856+0000] {processor.py:157} INFO - Started process (PID=32256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:09:01.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:09:01.866+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:09:01.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:09:01.879+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:09:01.900+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:09:01.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:09:01.912+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:09:01.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:09:01.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-10T06:09:32.204+0000] {processor.py:157} INFO - Started process (PID=32267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:09:32.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:09:32.212+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:09:32.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:09:32.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:09:32.261+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:09:32.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:09:32.280+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:09:32.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:09:32.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-10T06:10:02.628+0000] {processor.py:157} INFO - Started process (PID=32277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:10:02.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:10:02.630+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:10:02.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:10:02.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:10:02.657+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:10:02.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:10:02.670+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:10:02.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:10:02.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T06:10:32.988+0000] {processor.py:157} INFO - Started process (PID=32287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:10:32.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:10:32.993+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:10:32.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:10:33.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:10:33.030+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:10:33.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:10:33.042+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:10:33.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:10:33.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T06:11:03.389+0000] {processor.py:157} INFO - Started process (PID=32297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:11:03.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:11:03.393+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:11:03.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:11:03.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:11:03.420+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:11:03.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:11:03.430+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:11:03.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:11:03.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T06:11:33.806+0000] {processor.py:157} INFO - Started process (PID=32307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:11:33.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:11:33.817+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:11:33.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:11:33.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:11:33.863+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:11:33.863+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:11:33.875+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:11:33.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:11:33.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-10T06:12:04.156+0000] {processor.py:157} INFO - Started process (PID=32317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:12:04.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:12:04.159+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:12:04.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:12:04.167+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:12:04.184+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:12:04.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:12:04.194+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:12:04.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:12:04.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T06:12:34.544+0000] {processor.py:157} INFO - Started process (PID=32327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:12:34.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:12:34.549+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:12:34.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:12:34.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:12:34.586+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:12:34.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:12:34.598+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:12:34.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:12:34.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T06:13:04.854+0000] {processor.py:157} INFO - Started process (PID=32337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:13:04.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:13:04.856+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:13:04.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:13:04.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:13:04.882+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:13:04.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:13:04.892+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:13:04.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:13:04.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T06:13:35.284+0000] {processor.py:157} INFO - Started process (PID=32347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:13:35.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:13:35.288+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:13:35.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:13:35.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:13:35.317+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:13:35.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:13:35.328+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:13:35.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:13:35.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T06:14:05.719+0000] {processor.py:157} INFO - Started process (PID=32357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:14:05.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:14:05.723+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:14:05.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:14:05.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:14:05.748+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:14:05.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:14:05.758+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:14:05.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:14:05.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T06:14:36.139+0000] {processor.py:157} INFO - Started process (PID=32367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:14:36.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:14:36.142+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:14:36.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:14:36.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:14:36.170+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:14:36.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:14:36.179+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:14:36.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:14:36.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T06:15:06.566+0000] {processor.py:157} INFO - Started process (PID=32377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:15:06.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:15:06.573+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:15:06.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:15:06.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:15:06.607+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:15:06.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:15:06.620+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:15:06.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:15:06.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T06:15:36.964+0000] {processor.py:157} INFO - Started process (PID=32387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:15:36.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:15:36.967+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:15:36.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:15:36.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:15:36.993+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:15:36.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:15:37.002+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:15:37.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:15:37.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T06:16:07.342+0000] {processor.py:157} INFO - Started process (PID=32397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:16:07.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:16:07.346+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:16:07.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:16:07.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:16:07.374+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:16:07.374+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:16:07.385+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:16:07.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:16:07.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T06:16:37.724+0000] {processor.py:157} INFO - Started process (PID=32407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:16:37.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:16:37.728+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:16:37.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:16:37.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:16:37.756+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:16:37.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:16:37.769+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:16:37.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:16:37.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T06:17:08.087+0000] {processor.py:157} INFO - Started process (PID=32417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:17:08.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:17:08.090+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:17:08.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:17:08.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:17:08.114+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:17:08.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:17:08.124+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:17:08.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:17:08.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T06:17:38.455+0000] {processor.py:157} INFO - Started process (PID=32427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:17:38.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:17:38.457+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:17:38.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:17:38.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:17:38.483+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:17:38.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:17:38.495+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:17:38.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:17:38.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T06:18:08.870+0000] {processor.py:157} INFO - Started process (PID=32437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:18:08.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:18:08.876+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:18:08.876+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:18:08.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:18:08.903+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:18:08.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:18:08.912+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:18:08.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:18:08.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T06:18:39.220+0000] {processor.py:157} INFO - Started process (PID=32447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:18:39.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:18:39.224+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:18:39.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:18:39.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:18:39.260+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:18:39.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:18:39.273+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:18:39.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:18:39.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T06:19:09.518+0000] {processor.py:157} INFO - Started process (PID=32457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:19:09.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:19:09.522+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:19:09.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:19:09.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:19:09.550+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:19:09.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:19:09.560+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:19:09.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:19:09.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T06:19:39.925+0000] {processor.py:157} INFO - Started process (PID=32467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:19:39.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:19:39.927+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:19:39.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:19:39.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:19:39.958+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:19:39.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:19:39.967+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:19:39.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:19:39.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T06:20:10.360+0000] {processor.py:157} INFO - Started process (PID=32477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:20:10.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:20:10.364+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:20:10.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:20:10.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:20:10.393+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:20:10.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:20:10.405+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:20:10.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:20:10.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T06:20:40.822+0000] {processor.py:157} INFO - Started process (PID=32487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:20:40.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:20:40.828+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:20:40.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:20:40.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:20:40.862+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:20:40.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:20:40.874+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:20:40.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:20:40.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T06:21:11.200+0000] {processor.py:157} INFO - Started process (PID=32497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:21:11.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:21:11.202+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:21:11.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:21:11.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:21:11.232+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:21:11.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:21:11.243+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:21:11.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:21:11.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T06:21:41.523+0000] {processor.py:157} INFO - Started process (PID=32507) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:21:41.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:21:41.527+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:21:41.527+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:21:41.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:21:41.551+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:21:41.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:21:41.560+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:21:41.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:21:41.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T06:22:11.925+0000] {processor.py:157} INFO - Started process (PID=32517) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:22:11.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:22:11.928+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:22:11.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:22:11.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:22:11.958+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:22:11.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:22:11.969+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:22:11.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:22:11.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T06:22:42.350+0000] {processor.py:157} INFO - Started process (PID=32527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:22:42.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:22:42.355+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:22:42.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:22:42.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:22:42.391+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:22:42.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:22:42.405+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:22:42.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:22:42.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T06:23:12.823+0000] {processor.py:157} INFO - Started process (PID=32537) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:23:12.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:23:12.828+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:23:12.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:23:12.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:23:12.882+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:23:12.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:23:12.895+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:23:12.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:23:12.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-10T06:23:43.244+0000] {processor.py:157} INFO - Started process (PID=32547) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:23:43.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:23:43.247+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:23:43.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:23:43.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:23:43.272+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:23:43.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:23:43.281+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:23:43.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:23:43.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T06:24:13.549+0000] {processor.py:157} INFO - Started process (PID=32557) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:24:13.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:24:13.553+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:24:13.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:24:13.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:24:13.589+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:24:13.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:24:13.604+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:24:13.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:24:13.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T06:24:43.970+0000] {processor.py:157} INFO - Started process (PID=32567) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:24:43.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:24:43.974+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:24:43.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:24:43.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:24:43.999+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:24:43.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:24:44.011+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:24:44.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:24:44.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T06:25:14.305+0000] {processor.py:157} INFO - Started process (PID=32577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:25:14.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:25:14.311+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:25:14.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:25:14.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:25:14.346+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:25:14.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:25:14.358+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:25:14.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:25:14.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T06:25:44.568+0000] {processor.py:157} INFO - Started process (PID=32587) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:25:44.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:25:44.570+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:25:44.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:25:44.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:25:44.594+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:25:44.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:25:44.604+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:25:44.604+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:25:44.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T06:26:14.925+0000] {processor.py:157} INFO - Started process (PID=32597) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:26:14.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:26:14.929+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:26:14.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:26:14.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:26:14.956+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:26:14.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:26:14.965+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:26:14.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:26:14.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T06:26:45.359+0000] {processor.py:157} INFO - Started process (PID=32607) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:26:45.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:26:45.363+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:26:45.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:26:45.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:26:45.399+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:26:45.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:26:45.410+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:26:45.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:26:45.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T06:27:15.769+0000] {processor.py:157} INFO - Started process (PID=32617) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:27:15.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:27:15.771+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:27:15.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:27:15.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:27:15.799+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:27:15.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:27:15.811+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:27:15.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:27:15.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T06:27:46.148+0000] {processor.py:157} INFO - Started process (PID=32627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:27:46.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:27:46.152+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:27:46.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:27:46.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:27:46.177+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:27:46.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:27:46.188+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:27:46.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:27:46.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T06:28:16.557+0000] {processor.py:157} INFO - Started process (PID=32637) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:28:16.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:28:16.563+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:28:16.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:28:16.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:28:16.599+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:28:16.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:28:16.612+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:28:16.612+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:28:16.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T06:28:47.003+0000] {processor.py:157} INFO - Started process (PID=32647) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:28:47.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:28:47.007+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:28:47.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:28:47.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:28:47.033+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:28:47.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:28:47.046+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:28:47.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:28:47.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T06:29:17.431+0000] {processor.py:157} INFO - Started process (PID=32656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:29:17.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:29:17.434+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:29:17.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:29:17.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:29:17.459+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:29:17.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:29:17.469+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:29:17.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:29:17.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T06:29:47.854+0000] {processor.py:157} INFO - Started process (PID=32667) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:29:47.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:29:47.858+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:29:47.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:29:47.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:29:47.895+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:29:47.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:29:47.907+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:29:47.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:29:47.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T06:30:18.326+0000] {processor.py:157} INFO - Started process (PID=32677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:30:18.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:30:18.329+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:30:18.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:30:18.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:30:18.356+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:30:18.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:30:18.365+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:30:18.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:30:18.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T06:30:48.756+0000] {processor.py:157} INFO - Started process (PID=32687) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:30:48.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:30:48.759+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:30:48.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:30:48.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:30:48.787+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:30:48.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:30:48.799+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:30:48.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:30:48.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T06:31:19.111+0000] {processor.py:157} INFO - Started process (PID=32697) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:31:19.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:31:19.117+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:31:19.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:31:19.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:31:19.154+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:31:19.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:31:19.165+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:31:19.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:31:19.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T06:31:49.476+0000] {processor.py:157} INFO - Started process (PID=32707) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:31:49.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:31:49.479+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:31:49.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:31:49.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:31:49.504+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:31:49.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:31:49.514+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:31:49.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:31:49.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T06:32:19.887+0000] {processor.py:157} INFO - Started process (PID=32717) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:32:19.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:32:19.890+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:32:19.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:32:19.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:32:19.913+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:32:19.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:32:19.923+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:32:19.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:32:19.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T06:32:50.276+0000] {processor.py:157} INFO - Started process (PID=32727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:32:50.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:32:50.281+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:32:50.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:32:50.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:32:50.311+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:32:50.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:32:50.320+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:32:50.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:32:50.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T06:33:20.640+0000] {processor.py:157} INFO - Started process (PID=32737) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:33:20.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:33:20.643+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:33:20.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:33:20.654+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:33:20.678+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:33:20.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:33:20.692+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:33:20.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:33:20.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T06:33:51.003+0000] {processor.py:157} INFO - Started process (PID=32747) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:33:51.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:33:51.007+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:33:51.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:33:51.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:33:51.033+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:33:51.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:33:51.046+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:33:51.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:33:51.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T06:34:21.422+0000] {processor.py:157} INFO - Started process (PID=32756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:34:21.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:34:21.425+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:34:21.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:34:21.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:34:21.450+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:34:21.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:34:21.460+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:34:21.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:34:21.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T06:34:51.816+0000] {processor.py:157} INFO - Started process (PID=32767) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:34:51.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:34:51.824+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:34:51.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:34:51.835+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:34:51.855+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:34:51.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:34:51.867+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:34:51.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:34:51.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T06:35:22.122+0000] {processor.py:157} INFO - Started process (PID=32777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:35:22.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:35:22.124+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:35:22.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:35:22.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:35:22.153+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:35:22.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:35:22.163+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:35:22.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:35:22.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T06:35:52.543+0000] {processor.py:157} INFO - Started process (PID=32787) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:35:52.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:35:52.547+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:35:52.546+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:35:52.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:35:52.574+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:35:52.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:35:52.584+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:35:52.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:35:52.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T06:36:22.890+0000] {processor.py:157} INFO - Started process (PID=32797) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:36:22.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:36:22.895+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:36:22.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:36:22.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:36:22.927+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:36:22.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:36:22.937+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:36:22.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:36:22.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T06:36:53.251+0000] {processor.py:157} INFO - Started process (PID=32807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:36:53.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:36:53.253+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:36:53.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:36:53.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:36:53.284+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:36:53.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:36:53.297+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:36:53.297+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:36:53.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T06:37:23.628+0000] {processor.py:157} INFO - Started process (PID=32817) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:37:23.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:37:23.630+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:37:23.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:37:23.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:37:23.658+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:37:23.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:37:23.671+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:37:23.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:37:23.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T06:37:54.009+0000] {processor.py:157} INFO - Started process (PID=32827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:37:54.011+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:37:54.013+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:37:54.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:37:54.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:37:54.041+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:37:54.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:37:54.050+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:37:54.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:37:54.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T06:38:24.314+0000] {processor.py:157} INFO - Started process (PID=32837) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:38:24.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:38:24.318+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:38:24.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:38:24.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:38:24.344+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:38:24.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:38:24.355+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:38:24.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:38:24.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T06:38:54.767+0000] {processor.py:157} INFO - Started process (PID=32847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:38:54.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:38:54.771+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:38:54.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:38:54.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:38:54.806+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:38:54.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:38:54.817+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:38:54.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:38:54.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T06:39:25.219+0000] {processor.py:157} INFO - Started process (PID=32857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:39:25.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:39:25.240+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:39:25.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:39:25.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:39:25.272+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:39:25.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:39:25.284+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:39:25.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:39:25.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-10T06:39:55.539+0000] {processor.py:157} INFO - Started process (PID=32867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:39:55.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:39:55.544+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:39:55.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:39:55.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:39:55.586+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:39:55.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:39:55.617+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:39:55.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:39:55.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-10T06:40:25.903+0000] {processor.py:157} INFO - Started process (PID=32877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:40:25.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:40:25.924+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:40:25.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:40:25.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:40:25.973+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:40:25.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:40:25.987+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:40:25.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:40:25.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-10T06:56:18.951+0000] {processor.py:157} INFO - Started process (PID=32887) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:56:18.955+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:56:18.958+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:56:18.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:56:18.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:56:19.009+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:56:19.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:56:19.028+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:56:19.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:56:19.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T06:56:49.387+0000] {processor.py:157} INFO - Started process (PID=32899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:56:49.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:56:49.393+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:56:49.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:56:49.405+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:56:49.430+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:56:49.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:56:49.442+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:56:49.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:56:49.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-10T06:57:19.681+0000] {processor.py:157} INFO - Started process (PID=32909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:57:19.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:57:19.688+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:57:19.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:57:19.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:57:19.751+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:57:19.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:57:19.763+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:57:19.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:57:19.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-10T06:57:49.971+0000] {processor.py:157} INFO - Started process (PID=32919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:57:49.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:57:49.974+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:57:49.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:57:49.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:57:49.998+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:57:49.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:57:50.010+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:57:50.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:57:50.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T06:58:20.357+0000] {processor.py:157} INFO - Started process (PID=32929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:58:20.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:58:20.363+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:58:20.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:58:20.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:58:20.418+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:58:20.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:58:20.431+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:58:20.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:58:20.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T06:58:50.649+0000] {processor.py:157} INFO - Started process (PID=32939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:58:50.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:58:50.651+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:58:50.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:58:50.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:58:50.674+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:58:50.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:58:50.685+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:58:50.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:58:50.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-10T06:59:20.957+0000] {processor.py:157} INFO - Started process (PID=32949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:59:20.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T06:59:20.963+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:59:20.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:59:20.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T06:59:20.986+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:59:20.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T06:59:20.995+0000] {logging_mixin.py:151} INFO - [2024-09-10T06:59:20.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T06:59:21.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T07:01:29.916+0000] {processor.py:157} INFO - Started process (PID=32961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:01:29.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T07:01:29.926+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:01:29.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:01:29.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:01:29.999+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:01:29.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T07:01:30.026+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:01:30.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T07:01:30.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-09-10T07:17:18.279+0000] {processor.py:157} INFO - Started process (PID=32971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:17:18.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T07:17:18.301+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:17:18.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:17:18.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:17:18.359+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:17:18.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T07:17:18.384+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:17:18.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T07:17:18.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-10T07:17:48.641+0000] {processor.py:157} INFO - Started process (PID=32979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:17:48.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T07:17:48.650+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:17:48.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:17:48.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:17:48.696+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:17:48.696+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T07:17:48.709+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:17:48.709+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T07:17:48.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-10T07:18:18.915+0000] {processor.py:157} INFO - Started process (PID=32991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:18:18.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T07:18:18.917+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:18:18.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:18:18.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:18:18.946+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:18:18.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T07:18:18.957+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:18:18.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T07:18:18.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T07:34:31.301+0000] {processor.py:157} INFO - Started process (PID=33002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:34:31.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T07:34:31.305+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:34:31.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:34:31.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:34:31.350+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:34:31.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T07:34:31.362+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:34:31.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T07:34:31.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T07:50:28.679+0000] {processor.py:157} INFO - Started process (PID=33012) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:50:28.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T07:50:28.686+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:50:28.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:50:28.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:50:28.755+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:50:28.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T07:50:28.777+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:50:28.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T07:50:28.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-10T07:50:59.025+0000] {processor.py:157} INFO - Started process (PID=33023) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:50:59.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T07:50:59.036+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:50:59.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:50:59.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:50:59.084+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:50:59.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T07:50:59.099+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:50:59.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T07:50:59.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-10T07:51:29.419+0000] {processor.py:157} INFO - Started process (PID=33033) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:51:29.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T07:51:29.424+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:51:29.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:51:29.436+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:51:29.459+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:51:29.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T07:51:29.475+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:51:29.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T07:51:29.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T07:51:59.776+0000] {processor.py:157} INFO - Started process (PID=33043) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:51:59.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T07:51:59.784+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:51:59.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:51:59.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:51:59.815+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:51:59.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T07:51:59.826+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:51:59.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T07:51:59.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T07:52:30.198+0000] {processor.py:157} INFO - Started process (PID=33053) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:52:30.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T07:52:30.208+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:52:30.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:52:30.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:52:30.249+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:52:30.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T07:52:30.262+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:52:30.261+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T07:52:30.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-10T07:53:00.571+0000] {processor.py:157} INFO - Started process (PID=33063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:53:00.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T07:53:00.573+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:53:00.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:53:00.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T07:53:00.904+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:53:00.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T07:53:00.922+0000] {logging_mixin.py:151} INFO - [2024-09-10T07:53:00.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T07:53:00.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.400 seconds
[2024-09-10T08:09:40.019+0000] {processor.py:157} INFO - Started process (PID=33073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:09:40.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:09:40.027+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:09:40.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:09:40.059+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:09:40.117+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:09:40.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:09:40.158+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:09:40.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:09:40.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-09-10T08:10:10.567+0000] {processor.py:157} INFO - Started process (PID=33085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:10:10.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:10:10.576+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:10:10.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:10:10.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:10:10.617+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:10:10.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:10:10.629+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:10:10.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:10:10.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-10T08:10:40.926+0000] {processor.py:157} INFO - Started process (PID=33095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:10:40.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:10:40.931+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:10:40.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:10:40.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:10:40.955+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:10:40.955+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:10:40.968+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:10:40.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:10:40.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T08:11:11.290+0000] {processor.py:157} INFO - Started process (PID=33105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:11:11.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:11:11.295+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:11:11.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:11:11.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:11:11.321+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:11:11.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:11:11.331+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:11:11.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:11:11.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T08:11:41.651+0000] {processor.py:157} INFO - Started process (PID=33115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:11:41.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:11:41.653+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:11:41.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:11:41.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:11:41.681+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:11:41.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:11:41.691+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:11:41.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:11:41.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T08:12:11.968+0000] {processor.py:157} INFO - Started process (PID=33125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:12:11.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:12:11.974+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:12:11.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:12:11.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:12:12.009+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:12:12.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:12:12.021+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:12:12.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:12:12.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T08:12:42.346+0000] {processor.py:157} INFO - Started process (PID=33135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:12:42.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:12:42.350+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:12:42.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:12:42.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:12:42.376+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:12:42.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:12:42.386+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:12:42.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:12:42.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T08:13:12.686+0000] {processor.py:157} INFO - Started process (PID=33145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:13:12.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:13:12.689+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:13:12.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:13:12.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:13:12.714+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:13:12.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:13:12.726+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:13:12.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:13:12.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T08:13:43.081+0000] {processor.py:157} INFO - Started process (PID=33155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:13:43.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:13:43.083+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:13:43.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:13:43.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:13:43.110+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:13:43.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:13:43.120+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:13:43.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:13:43.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T08:14:13.462+0000] {processor.py:157} INFO - Started process (PID=33165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:14:13.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:14:13.466+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:14:13.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:14:13.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:14:13.504+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:14:13.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:14:13.518+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:14:13.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:14:13.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T08:14:43.766+0000] {processor.py:157} INFO - Started process (PID=33175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:14:43.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:14:43.769+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:14:43.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:14:43.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:14:43.795+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:14:43.795+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:14:43.806+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:14:43.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:14:43.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T08:15:14.087+0000] {processor.py:157} INFO - Started process (PID=33185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:15:14.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:15:14.091+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:15:14.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:15:14.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:15:14.117+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:15:14.117+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:15:14.129+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:15:14.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:15:14.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T08:15:44.520+0000] {processor.py:157} INFO - Started process (PID=33195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:15:44.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:15:44.522+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:15:44.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:15:44.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:15:44.548+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:15:44.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:15:44.559+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:15:44.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:15:44.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T08:16:14.894+0000] {processor.py:157} INFO - Started process (PID=33205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:16:14.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:16:14.898+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:16:14.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:16:14.913+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:16:14.935+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:16:14.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:16:14.950+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:16:14.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:16:14.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T08:16:45.302+0000] {processor.py:157} INFO - Started process (PID=33215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:16:45.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:16:45.305+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:16:45.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:16:45.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:16:45.336+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:16:45.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:16:45.345+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:16:45.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:16:45.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T08:17:15.731+0000] {processor.py:157} INFO - Started process (PID=33225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:17:15.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:17:15.734+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:17:15.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:17:15.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:17:15.760+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:17:15.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:17:15.770+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:17:15.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:17:15.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T08:17:46.118+0000] {processor.py:157} INFO - Started process (PID=33235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:17:46.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:17:46.121+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:17:46.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:17:46.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:17:46.147+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:17:46.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:17:46.157+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:17:46.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:17:46.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T08:18:16.428+0000] {processor.py:157} INFO - Started process (PID=33245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:18:16.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:18:16.431+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:18:16.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:18:16.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:18:16.457+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:18:16.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:18:16.466+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:18:16.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:18:16.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T08:18:46.802+0000] {processor.py:157} INFO - Started process (PID=33255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:18:46.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:18:46.809+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:18:46.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:18:46.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:18:46.841+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:18:46.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:18:46.855+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:18:46.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:18:46.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T08:19:17.096+0000] {processor.py:157} INFO - Started process (PID=33265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:19:17.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:19:17.099+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:19:17.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:19:17.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:19:17.119+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:19:17.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:19:17.130+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:19:17.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:19:17.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-09-10T08:19:47.509+0000] {processor.py:157} INFO - Started process (PID=33275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:19:47.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:19:47.513+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:19:47.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:19:47.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:19:47.546+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:19:47.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:19:47.559+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:19:47.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:19:47.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T08:20:17.875+0000] {processor.py:157} INFO - Started process (PID=33285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:20:17.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:20:17.878+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:20:17.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:20:17.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:20:17.905+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:20:17.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:20:17.915+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:20:17.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:20:17.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T08:20:48.184+0000] {processor.py:157} INFO - Started process (PID=33295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:20:48.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:20:48.191+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:20:48.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:20:48.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:20:48.219+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:20:48.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:20:48.228+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:20:48.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:20:48.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T08:21:18.544+0000] {processor.py:157} INFO - Started process (PID=33305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:21:18.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:21:18.547+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:21:18.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:21:18.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:21:18.575+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:21:18.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:21:18.585+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:21:18.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:21:18.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T08:21:48.944+0000] {processor.py:157} INFO - Started process (PID=33315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:21:48.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:21:48.946+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:21:48.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:21:48.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:21:48.974+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:21:48.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:21:48.985+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:21:48.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:21:48.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T08:22:19.308+0000] {processor.py:157} INFO - Started process (PID=33325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:22:19.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:22:19.314+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:22:19.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:22:19.326+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:22:19.342+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:22:19.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:22:19.351+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:22:19.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:22:19.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T08:22:49.696+0000] {processor.py:157} INFO - Started process (PID=33335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:22:49.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:22:49.702+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:22:49.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:22:49.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:22:49.737+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:22:49.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:22:49.750+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:22:49.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:22:49.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T08:23:20.143+0000] {processor.py:157} INFO - Started process (PID=33345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:23:20.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:23:20.146+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:23:20.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:23:20.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:23:20.172+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:23:20.171+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:23:20.182+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:23:20.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:23:20.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T08:23:50.484+0000] {processor.py:157} INFO - Started process (PID=33355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:23:50.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:23:50.488+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:23:50.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:23:50.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:23:50.513+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:23:50.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:23:50.523+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:23:50.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:23:50.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T08:24:20.882+0000] {processor.py:157} INFO - Started process (PID=33365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:24:20.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:24:20.888+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:24:20.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:24:20.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:24:20.930+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:24:20.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:24:20.944+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:24:20.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:24:20.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-10T08:24:51.187+0000] {processor.py:157} INFO - Started process (PID=33375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:24:51.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:24:51.192+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:24:51.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:24:51.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:24:51.218+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:24:51.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:24:51.229+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:24:51.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:24:51.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T08:25:21.537+0000] {processor.py:157} INFO - Started process (PID=33385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:25:21.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:25:21.541+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:25:21.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:25:21.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:25:21.568+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:25:21.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:25:21.577+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:25:21.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:25:21.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T08:25:51.935+0000] {processor.py:157} INFO - Started process (PID=33395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:25:51.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:25:51.949+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:25:51.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:25:51.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:25:52.006+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:25:52.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:25:52.020+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:25:52.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:25:52.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-10T08:26:22.291+0000] {processor.py:157} INFO - Started process (PID=33405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:26:22.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:26:22.295+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:26:22.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:26:22.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:26:22.321+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:26:22.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:26:22.331+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:26:22.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:26:22.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T08:26:52.604+0000] {processor.py:157} INFO - Started process (PID=33415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:26:52.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:26:52.609+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:26:52.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:26:52.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:26:52.645+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:26:52.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:26:52.657+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:26:52.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:26:52.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T08:27:22.917+0000] {processor.py:157} INFO - Started process (PID=33425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:27:22.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:27:22.921+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:27:22.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:27:22.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:27:22.949+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:27:22.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:27:22.959+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:27:22.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:27:22.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T08:27:53.371+0000] {processor.py:157} INFO - Started process (PID=33435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:27:53.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:27:53.377+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:27:53.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:27:53.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:27:53.415+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:27:53.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:27:53.428+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:27:53.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:27:53.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T08:28:23.636+0000] {processor.py:157} INFO - Started process (PID=33445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:28:23.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:28:23.641+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:28:23.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:28:23.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:28:23.690+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:28:23.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:28:23.702+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:28:23.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:28:23.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T08:28:54.077+0000] {processor.py:157} INFO - Started process (PID=33455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:28:54.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:28:54.080+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:28:54.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:28:54.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:28:54.107+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:28:54.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:28:54.118+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:28:54.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:28:54.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T08:29:24.490+0000] {processor.py:157} INFO - Started process (PID=33465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:29:24.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:29:24.500+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:29:24.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:29:24.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:29:24.541+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:29:24.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:29:24.561+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:29:24.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:29:24.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-10T08:29:54.840+0000] {processor.py:157} INFO - Started process (PID=33475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:29:54.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:29:54.842+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:29:54.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:29:54.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:29:54.871+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:29:54.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:29:54.881+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:29:54.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:29:54.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T08:30:25.257+0000] {processor.py:157} INFO - Started process (PID=33484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:30:25.258+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:30:25.262+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:30:25.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:30:25.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:30:25.310+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:30:25.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:30:25.323+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:30:25.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:30:25.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-10T08:30:55.562+0000] {processor.py:157} INFO - Started process (PID=33495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:30:55.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:30:55.564+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:30:55.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:30:55.573+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:30:55.590+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:30:55.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:30:55.601+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:30:55.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:30:55.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T08:31:25.896+0000] {processor.py:157} INFO - Started process (PID=33505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:31:25.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:31:25.909+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:31:25.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:31:25.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:31:25.959+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:31:25.959+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:31:25.978+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:31:25.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:31:25.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-10T08:31:56.260+0000] {processor.py:157} INFO - Started process (PID=33515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:31:56.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:31:56.263+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:31:56.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:31:56.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:31:56.288+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:31:56.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:31:56.298+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:31:56.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:31:56.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T08:32:26.699+0000] {processor.py:157} INFO - Started process (PID=33525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:32:26.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:32:26.716+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:32:26.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:32:26.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:32:26.761+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:32:26.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:32:26.784+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:32:26.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:32:26.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-10T08:32:57.027+0000] {processor.py:157} INFO - Started process (PID=33535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:32:57.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:32:57.031+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:32:57.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:32:57.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:32:57.057+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:32:57.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:32:57.066+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:32:57.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:32:57.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T08:33:27.452+0000] {processor.py:157} INFO - Started process (PID=33545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:33:27.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:33:27.457+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:33:27.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:33:27.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:33:27.484+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:33:27.484+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:33:27.495+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:33:27.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:33:27.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T08:33:57.809+0000] {processor.py:157} INFO - Started process (PID=33555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:33:57.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:33:57.814+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:33:57.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:33:57.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:33:57.850+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:33:57.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:33:57.862+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:33:57.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:33:57.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T08:34:28.236+0000] {processor.py:157} INFO - Started process (PID=33565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:34:28.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:34:28.240+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:34:28.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:34:28.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:34:28.267+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:34:28.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:34:28.276+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:34:28.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:34:28.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T08:34:58.652+0000] {processor.py:157} INFO - Started process (PID=33575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:34:58.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:34:58.660+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:34:58.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:34:58.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:34:58.715+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:34:58.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:34:58.730+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:34:58.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:34:58.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-10T08:35:28.980+0000] {processor.py:157} INFO - Started process (PID=33585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:35:28.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:35:28.989+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:35:28.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:35:29.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:35:29.030+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:35:29.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:35:29.054+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:35:29.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:35:29.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T08:35:59.335+0000] {processor.py:157} INFO - Started process (PID=33595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:35:59.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:35:59.339+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:35:59.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:35:59.347+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:35:59.364+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:35:59.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:35:59.377+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:35:59.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:35:59.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T08:36:29.757+0000] {processor.py:157} INFO - Started process (PID=33605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:36:29.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:36:29.768+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:36:29.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:36:29.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:36:29.825+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:36:29.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:36:29.838+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:36:29.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:36:29.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-10T08:37:00.072+0000] {processor.py:157} INFO - Started process (PID=33615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:37:00.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:37:00.076+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:37:00.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:37:00.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:37:00.103+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:37:00.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:37:00.115+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:37:00.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:37:00.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T08:37:30.499+0000] {processor.py:157} INFO - Started process (PID=33625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:37:30.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:37:30.504+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:37:30.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:37:30.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:37:30.544+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:37:30.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:37:30.557+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:37:30.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:37:30.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T08:38:00.889+0000] {processor.py:157} INFO - Started process (PID=33635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:38:00.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:38:00.892+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:38:00.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:38:00.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:38:00.918+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:38:00.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:38:00.931+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:38:00.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:38:00.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T08:38:31.277+0000] {processor.py:157} INFO - Started process (PID=33645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:38:31.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:38:31.283+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:38:31.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:38:31.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:38:31.319+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:38:31.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:38:31.335+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:38:31.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:38:31.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-10T08:39:01.638+0000] {processor.py:157} INFO - Started process (PID=33655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:39:01.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:39:01.641+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:39:01.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:39:01.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:39:01.668+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:39:01.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:39:01.679+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:39:01.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:39:01.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T08:39:32.073+0000] {processor.py:157} INFO - Started process (PID=33665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:39:32.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:39:32.079+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:39:32.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:39:32.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:39:32.115+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:39:32.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:39:32.127+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:39:32.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:39:32.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T08:40:02.483+0000] {processor.py:157} INFO - Started process (PID=33675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:40:02.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:40:02.486+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:40:02.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:40:02.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:40:02.513+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:40:02.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:40:02.526+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:40:02.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:40:02.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T08:40:32.898+0000] {processor.py:157} INFO - Started process (PID=33685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:40:32.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:40:32.901+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:40:32.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:40:32.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:40:32.930+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:40:32.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:40:32.942+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:40:32.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:40:32.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T08:41:03.287+0000] {processor.py:157} INFO - Started process (PID=33695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:41:03.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:41:03.293+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:41:03.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:41:03.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:41:03.329+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:41:03.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:41:03.342+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:41:03.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:41:03.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T08:41:33.679+0000] {processor.py:157} INFO - Started process (PID=33705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:41:33.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:41:33.682+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:41:33.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:41:33.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:41:33.710+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:41:33.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:41:33.721+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:41:33.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:41:33.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T08:42:04.047+0000] {processor.py:157} INFO - Started process (PID=33715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:42:04.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:42:04.049+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:42:04.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:42:04.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:42:04.077+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:42:04.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:42:04.087+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:42:04.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:42:04.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T08:42:34.411+0000] {processor.py:157} INFO - Started process (PID=33725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:42:34.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:42:34.415+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:42:34.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:42:34.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:42:34.440+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:42:34.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:42:34.451+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:42:34.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:42:34.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T08:43:04.797+0000] {processor.py:157} INFO - Started process (PID=33735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:43:04.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:43:04.803+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:43:04.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:43:04.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:43:04.838+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:43:04.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:43:04.851+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:43:04.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:43:04.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T08:43:35.128+0000] {processor.py:157} INFO - Started process (PID=33745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:43:35.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:43:35.133+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:43:35.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:43:35.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:43:35.161+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:43:35.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:43:35.172+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:43:35.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:43:35.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T08:44:05.484+0000] {processor.py:157} INFO - Started process (PID=33755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:44:05.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:44:05.487+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:44:05.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:44:05.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:44:05.513+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:44:05.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:44:05.526+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:44:05.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:44:05.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T08:44:35.832+0000] {processor.py:157} INFO - Started process (PID=33765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:44:35.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:44:35.836+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:44:35.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:44:35.847+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:44:35.864+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:44:35.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:44:35.876+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:44:35.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:44:35.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T08:45:06.205+0000] {processor.py:157} INFO - Started process (PID=33775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:45:06.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:45:06.207+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:45:06.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:45:06.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:45:06.234+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:45:06.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:45:06.246+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:45:06.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:45:06.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T08:45:36.564+0000] {processor.py:157} INFO - Started process (PID=33785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:45:36.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:45:36.566+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:45:36.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:45:36.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:45:36.592+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:45:36.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:45:36.601+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:45:36.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:45:36.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T08:46:06.983+0000] {processor.py:157} INFO - Started process (PID=33795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:46:06.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:46:06.987+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:46:06.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:46:06.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:46:07.013+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:46:07.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:46:07.022+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:46:07.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:46:07.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T08:46:37.345+0000] {processor.py:157} INFO - Started process (PID=33805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:46:37.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:46:37.347+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:46:37.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:46:37.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:46:37.374+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:46:37.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:46:37.385+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:46:37.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:46:37.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T08:47:07.632+0000] {processor.py:157} INFO - Started process (PID=33815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:47:07.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:47:07.635+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:47:07.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:47:07.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:47:07.662+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:47:07.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:47:07.672+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:47:07.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:47:07.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T08:47:38.049+0000] {processor.py:157} INFO - Started process (PID=33825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:47:38.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:47:38.051+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:47:38.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:47:38.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:47:38.080+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:47:38.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:47:38.092+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:47:38.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:47:38.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T08:48:08.458+0000] {processor.py:157} INFO - Started process (PID=33835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:48:08.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:48:08.460+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:48:08.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:48:08.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:48:08.490+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:48:08.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:48:08.499+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:48:08.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:48:08.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T08:48:38.819+0000] {processor.py:157} INFO - Started process (PID=33845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:48:38.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:48:38.822+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:48:38.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:48:38.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:48:38.849+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:48:38.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:48:38.859+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:48:38.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:48:38.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T08:49:09.157+0000] {processor.py:157} INFO - Started process (PID=33855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:49:09.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:49:09.160+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:49:09.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:49:09.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:49:09.186+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:49:09.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:49:09.197+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:49:09.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:49:09.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T08:49:39.505+0000] {processor.py:157} INFO - Started process (PID=33865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:49:39.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:49:39.510+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:49:39.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:49:39.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:49:39.546+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:49:39.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:49:39.558+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:49:39.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:49:39.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T08:50:09.805+0000] {processor.py:157} INFO - Started process (PID=33875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:50:09.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:50:09.808+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:50:09.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:50:09.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:50:09.838+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:50:09.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:50:09.847+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:50:09.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:50:09.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T08:50:40.264+0000] {processor.py:157} INFO - Started process (PID=33885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:50:40.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:50:40.268+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:50:40.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:50:40.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:50:40.294+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:50:40.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:50:40.304+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:50:40.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:50:40.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T08:51:10.630+0000] {processor.py:157} INFO - Started process (PID=33895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:51:10.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:51:10.633+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:51:10.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:51:10.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:51:10.656+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:51:10.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:51:10.667+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:51:10.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:51:10.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T08:51:41.040+0000] {processor.py:157} INFO - Started process (PID=33905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:51:41.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:51:41.044+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:51:41.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:51:41.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:51:41.073+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:51:41.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:51:41.084+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:51:41.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:51:41.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T08:52:11.445+0000] {processor.py:157} INFO - Started process (PID=33915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:52:11.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:52:11.448+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:52:11.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:52:11.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:52:11.475+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:52:11.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:52:11.485+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:52:11.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:52:11.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T08:52:41.828+0000] {processor.py:157} INFO - Started process (PID=33925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:52:41.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:52:41.833+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:52:41.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:52:41.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:52:41.858+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:52:41.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:52:41.868+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:52:41.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:52:41.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T08:53:12.160+0000] {processor.py:157} INFO - Started process (PID=33935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:53:12.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:53:12.165+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:53:12.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:53:12.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:53:12.191+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:53:12.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:53:12.200+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:53:12.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:53:12.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T08:53:42.502+0000] {processor.py:157} INFO - Started process (PID=33945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:53:42.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:53:42.506+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:53:42.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:53:42.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:53:42.530+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:53:42.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:53:42.540+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:53:42.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:53:42.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T08:54:12.853+0000] {processor.py:157} INFO - Started process (PID=33955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:54:12.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:54:12.857+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:54:12.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:54:12.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:54:12.895+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:54:12.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:54:12.908+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:54:12.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:54:12.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T08:54:43.180+0000] {processor.py:157} INFO - Started process (PID=33965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:54:43.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:54:43.184+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:54:43.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:54:43.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:54:43.208+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:54:43.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:54:43.218+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:54:43.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:54:43.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T08:55:13.583+0000] {processor.py:157} INFO - Started process (PID=33975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:55:13.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:55:13.586+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:55:13.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:55:13.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:55:13.613+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:55:13.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:55:13.625+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:55:13.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:55:13.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T08:55:43.944+0000] {processor.py:157} INFO - Started process (PID=33985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:55:43.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:55:43.946+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:55:43.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:55:43.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:55:43.974+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:55:43.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:55:43.985+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:55:43.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:55:43.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T08:56:14.336+0000] {processor.py:157} INFO - Started process (PID=33995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:56:14.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:56:14.338+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:56:14.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:56:14.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:56:14.361+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:56:14.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:56:14.371+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:56:14.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:56:14.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-10T08:56:44.720+0000] {processor.py:157} INFO - Started process (PID=34005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:56:44.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:56:44.723+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:56:44.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:56:44.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:56:44.752+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:56:44.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:56:44.761+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:56:44.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:56:44.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T08:57:15.098+0000] {processor.py:157} INFO - Started process (PID=34015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:57:15.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:57:15.101+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:57:15.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:57:15.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:57:15.132+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:57:15.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:57:15.143+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:57:15.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:57:15.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T08:57:45.468+0000] {processor.py:157} INFO - Started process (PID=34025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:57:45.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:57:45.472+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:57:45.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:57:45.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:57:45.500+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:57:45.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:57:45.510+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:57:45.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:57:45.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T08:58:15.801+0000] {processor.py:157} INFO - Started process (PID=34035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:58:15.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:58:15.804+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:58:15.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:58:15.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:58:15.830+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:58:15.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:58:15.844+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:58:15.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:58:15.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T08:58:46.133+0000] {processor.py:157} INFO - Started process (PID=34045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:58:46.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:58:46.137+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:58:46.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:58:46.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:58:46.162+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:58:46.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:58:46.172+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:58:46.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:58:46.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T08:59:16.442+0000] {processor.py:157} INFO - Started process (PID=34055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:59:16.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:59:16.446+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:59:16.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:59:16.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:59:16.471+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:59:16.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:59:16.481+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:59:16.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:59:16.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T08:59:46.849+0000] {processor.py:157} INFO - Started process (PID=34065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:59:46.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T08:59:46.854+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:59:46.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:59:46.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T08:59:46.887+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:59:46.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T08:59:46.899+0000] {logging_mixin.py:151} INFO - [2024-09-10T08:59:46.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T08:59:46.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T09:00:17.182+0000] {processor.py:157} INFO - Started process (PID=34075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:00:17.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:00:17.186+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:00:17.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:00:17.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:00:17.210+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:00:17.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:00:17.219+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:00:17.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:00:17.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T09:00:47.618+0000] {processor.py:157} INFO - Started process (PID=34085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:00:47.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:00:47.624+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:00:47.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:00:47.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:00:47.661+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:00:47.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:00:47.676+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:00:47.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:00:47.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-10T09:01:17.941+0000] {processor.py:157} INFO - Started process (PID=34095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:01:17.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:01:17.945+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:01:17.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:01:17.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:01:17.969+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:01:17.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:01:17.979+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:01:17.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:01:17.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T09:01:48.348+0000] {processor.py:157} INFO - Started process (PID=34105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:01:48.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:01:48.355+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:01:48.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:01:48.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:01:48.389+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:01:48.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:01:48.399+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:01:48.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:01:48.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T09:02:18.729+0000] {processor.py:157} INFO - Started process (PID=34115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:02:18.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:02:18.731+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:02:18.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:02:18.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:02:18.761+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:02:18.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:02:18.775+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:02:18.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:02:18.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T09:02:49.052+0000] {processor.py:157} INFO - Started process (PID=34125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:02:49.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:02:49.054+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:02:49.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:02:49.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:02:49.083+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:02:49.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:02:49.093+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:02:49.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:02:49.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T09:03:19.450+0000] {processor.py:157} INFO - Started process (PID=34135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:03:19.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:03:19.452+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:03:19.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:03:19.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:03:19.479+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:03:19.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:03:19.489+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:03:19.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:03:19.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T09:03:49.838+0000] {processor.py:157} INFO - Started process (PID=34145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:03:49.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:03:49.841+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:03:49.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:03:49.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:03:49.866+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:03:49.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:03:49.876+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:03:49.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:03:49.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T09:04:20.135+0000] {processor.py:157} INFO - Started process (PID=34155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:04:20.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:04:20.137+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:04:20.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:04:20.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:04:20.169+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:04:20.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:04:20.183+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:04:20.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:04:20.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T09:04:50.492+0000] {processor.py:157} INFO - Started process (PID=34165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:04:50.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:04:50.496+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:04:50.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:04:50.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:04:50.520+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:04:50.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:04:50.531+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:04:50.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:04:50.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T09:05:20.890+0000] {processor.py:157} INFO - Started process (PID=34175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:05:20.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:05:20.894+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:05:20.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:05:20.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:05:20.919+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:05:20.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:05:20.929+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:05:20.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:05:20.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T09:05:51.314+0000] {processor.py:157} INFO - Started process (PID=34185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:05:51.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:05:51.318+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:05:51.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:05:51.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:05:51.352+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:05:51.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:05:51.363+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:05:51.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:05:51.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T09:06:21.729+0000] {processor.py:157} INFO - Started process (PID=34195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:06:21.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:06:21.731+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:06:21.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:06:21.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:06:21.762+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:06:21.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:06:21.773+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:06:21.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:06:21.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T09:06:52.093+0000] {processor.py:157} INFO - Started process (PID=34205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:06:52.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:06:52.097+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:06:52.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:06:52.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:06:52.129+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:06:52.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:06:52.140+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:06:52.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:06:52.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T09:07:22.438+0000] {processor.py:157} INFO - Started process (PID=34215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:07:22.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:07:22.441+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:07:22.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:07:22.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:07:22.465+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:07:22.465+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:07:22.479+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:07:22.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:07:22.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T09:07:52.810+0000] {processor.py:157} INFO - Started process (PID=34225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:07:52.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:07:52.815+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:07:52.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:07:52.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:07:52.841+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:07:52.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:07:52.850+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:07:52.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:07:52.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T09:08:23.233+0000] {processor.py:157} INFO - Started process (PID=34235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:08:23.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:08:23.237+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:08:23.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:08:23.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:08:23.262+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:08:23.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:08:23.276+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:08:23.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:08:23.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T09:08:53.572+0000] {processor.py:157} INFO - Started process (PID=34245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:08:53.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:08:53.576+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:08:53.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:08:53.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:08:53.605+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:08:53.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:08:53.616+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:08:53.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:08:53.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T09:09:23.933+0000] {processor.py:157} INFO - Started process (PID=34255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:09:23.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:09:23.937+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:09:23.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:09:23.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:09:23.964+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:09:23.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:09:23.974+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:09:23.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:09:23.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T09:09:54.311+0000] {processor.py:157} INFO - Started process (PID=34264) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:09:54.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:09:54.325+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:09:54.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:09:54.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:09:54.381+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:09:54.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:09:54.394+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:09:54.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:09:54.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-10T09:25:47.365+0000] {processor.py:157} INFO - Started process (PID=34275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:25:47.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:25:47.367+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:25:47.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:25:47.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:25:47.393+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:25:47.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:25:47.403+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:25:47.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:25:47.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T09:42:02.738+0000] {processor.py:157} INFO - Started process (PID=34286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:42:02.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:42:02.748+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:42:02.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:42:02.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:42:02.826+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:42:02.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:42:02.859+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:42:02.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:42:02.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-10T09:42:33.218+0000] {processor.py:157} INFO - Started process (PID=34297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:42:33.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:42:33.225+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:42:33.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:42:33.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:42:33.261+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:42:33.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:42:33.272+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:42:33.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:42:33.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T09:43:03.520+0000] {processor.py:157} INFO - Started process (PID=34307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:43:03.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T09:43:03.523+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:43:03.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:43:03.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T09:43:03.547+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:43:03.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T09:43:03.557+0000] {logging_mixin.py:151} INFO - [2024-09-10T09:43:03.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T09:43:03.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T10:00:25.148+0000] {processor.py:157} INFO - Started process (PID=34317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:00:25.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:00:25.156+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:00:25.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:00:25.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:00:25.195+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:00:25.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:00:25.208+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:00:25.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:00:25.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-10T10:00:55.484+0000] {processor.py:157} INFO - Started process (PID=34329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:00:55.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:00:55.490+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:00:55.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:00:55.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:00:55.529+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:00:55.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:00:55.541+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:00:55.541+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:00:55.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T10:01:25.798+0000] {processor.py:157} INFO - Started process (PID=34339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:01:25.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:01:25.801+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:01:25.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:01:25.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:01:25.825+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:01:25.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:01:25.835+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:01:25.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:01:25.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T10:01:56.173+0000] {processor.py:157} INFO - Started process (PID=34349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:01:56.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:01:56.182+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:01:56.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:01:56.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:01:56.203+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:01:56.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:01:56.211+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:01:56.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:01:56.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T10:02:26.555+0000] {processor.py:157} INFO - Started process (PID=34359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:02:26.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:02:26.558+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:02:26.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:02:26.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:02:26.580+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:02:26.580+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:02:26.591+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:02:26.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:02:26.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-09-10T10:02:56.979+0000] {processor.py:157} INFO - Started process (PID=34369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:02:56.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:02:56.983+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:02:56.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:02:56.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:02:57.008+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:02:57.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:02:57.019+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:02:57.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:02:57.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T10:03:27.444+0000] {processor.py:157} INFO - Started process (PID=34379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:03:27.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:03:27.450+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:03:27.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:03:27.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:03:27.483+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:03:27.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:03:27.494+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:03:27.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:03:27.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T10:03:57.906+0000] {processor.py:157} INFO - Started process (PID=34389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:03:57.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:03:57.911+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:03:57.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:03:57.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:03:57.939+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:03:57.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:03:57.951+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:03:57.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:03:57.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T10:04:28.339+0000] {processor.py:157} INFO - Started process (PID=34399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:04:28.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:04:28.341+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:04:28.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:04:28.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:04:28.367+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:04:28.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:04:28.379+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:04:28.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:04:28.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T10:04:58.751+0000] {processor.py:157} INFO - Started process (PID=34409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:04:58.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:04:58.753+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:04:58.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:04:58.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:04:58.783+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:04:58.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:04:58.793+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:04:58.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:04:58.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T10:05:29.190+0000] {processor.py:157} INFO - Started process (PID=34419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:05:29.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:05:29.194+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:05:29.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:05:29.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:05:29.221+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:05:29.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:05:29.230+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:05:29.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:05:29.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T10:05:59.587+0000] {processor.py:157} INFO - Started process (PID=34429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:05:59.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:05:59.590+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:05:59.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:05:59.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:05:59.620+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:05:59.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:05:59.630+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:05:59.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:05:59.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T10:06:29.927+0000] {processor.py:157} INFO - Started process (PID=34439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:06:29.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:06:29.930+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:06:29.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:06:29.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:06:29.958+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:06:29.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:06:29.969+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:06:29.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:06:29.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T10:07:00.386+0000] {processor.py:157} INFO - Started process (PID=34449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:07:00.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:07:00.389+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:07:00.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:07:00.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:07:00.422+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:07:00.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:07:00.435+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:07:00.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:07:00.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T10:07:30.880+0000] {processor.py:157} INFO - Started process (PID=34459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:07:30.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:07:30.884+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:07:30.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:07:30.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:07:30.911+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:07:30.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:07:30.921+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:07:30.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:07:30.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T10:08:01.375+0000] {processor.py:157} INFO - Started process (PID=34469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:08:01.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:08:01.379+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:08:01.379+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:08:01.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:08:01.408+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:08:01.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:08:01.419+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:08:01.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:08:01.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T10:08:31.850+0000] {processor.py:157} INFO - Started process (PID=34479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:08:31.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:08:31.857+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:08:31.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:08:31.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:08:31.877+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:08:31.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:08:31.887+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:08:31.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:08:31.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T10:09:02.151+0000] {processor.py:157} INFO - Started process (PID=34489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:09:02.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:09:02.155+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:09:02.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:09:02.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:09:02.187+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:09:02.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:09:02.198+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:09:02.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:09:02.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T10:09:32.633+0000] {processor.py:157} INFO - Started process (PID=34499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:09:32.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:09:32.636+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:09:32.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:09:32.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:09:32.660+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:09:32.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:09:32.669+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:09:32.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:09:32.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T10:10:02.994+0000] {processor.py:157} INFO - Started process (PID=34509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:10:02.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:10:02.996+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:10:02.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:10:03.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:10:03.018+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:10:03.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:10:03.028+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:10:03.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:10:03.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-09-10T10:10:33.412+0000] {processor.py:157} INFO - Started process (PID=34519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:10:33.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:10:33.416+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:10:33.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:10:33.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:10:33.448+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:10:33.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:10:33.461+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:10:33.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:10:33.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T10:11:03.770+0000] {processor.py:157} INFO - Started process (PID=34529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:11:03.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:11:03.772+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:11:03.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:11:03.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:11:03.802+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:11:03.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:11:03.812+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:11:03.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:11:03.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T10:11:34.166+0000] {processor.py:157} INFO - Started process (PID=34539) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:11:34.167+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:11:34.168+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:11:34.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:11:34.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:11:34.193+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:11:34.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:11:34.202+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:11:34.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:11:34.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T10:12:04.574+0000] {processor.py:157} INFO - Started process (PID=34549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:12:04.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:12:04.581+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:12:04.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:12:04.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:12:04.604+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:12:04.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:12:04.613+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:12:04.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:12:04.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T10:12:34.949+0000] {processor.py:157} INFO - Started process (PID=34559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:12:34.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:12:34.952+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:12:34.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:12:34.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:12:34.978+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:12:34.978+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:12:34.988+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:12:34.987+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:12:34.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T10:13:05.309+0000] {processor.py:157} INFO - Started process (PID=34569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:13:05.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:13:05.312+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:13:05.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:13:05.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:13:05.339+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:13:05.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:13:05.351+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:13:05.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:13:05.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T10:13:35.691+0000] {processor.py:157} INFO - Started process (PID=34579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:13:35.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:13:35.693+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:13:35.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:13:35.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:13:35.725+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:13:35.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:13:35.737+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:13:35.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:13:35.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T10:14:06.085+0000] {processor.py:157} INFO - Started process (PID=34589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:14:06.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:14:06.088+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:14:06.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:14:06.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:14:06.116+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:14:06.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:14:06.127+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:14:06.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:14:06.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T10:14:36.445+0000] {processor.py:157} INFO - Started process (PID=34599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:14:36.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:14:36.447+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:14:36.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:14:36.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:14:36.471+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:14:36.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:14:36.481+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:14:36.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:14:36.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T10:15:06.758+0000] {processor.py:157} INFO - Started process (PID=34609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:15:06.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:15:06.762+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:15:06.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:15:06.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:15:06.795+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:15:06.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:15:06.807+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:15:06.807+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:15:06.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T10:15:37.203+0000] {processor.py:157} INFO - Started process (PID=34619) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:15:37.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:15:37.206+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:15:37.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:15:37.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:15:37.234+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:15:37.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:15:37.245+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:15:37.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:15:37.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T10:16:07.594+0000] {processor.py:157} INFO - Started process (PID=34629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:16:07.597+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:16:07.599+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:16:07.599+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:16:07.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:16:07.624+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:16:07.624+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:16:07.635+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:16:07.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:16:07.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T10:16:37.913+0000] {processor.py:157} INFO - Started process (PID=34639) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:16:37.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:16:37.918+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:16:37.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:16:37.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:16:37.945+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:16:37.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:16:37.955+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:16:37.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:16:37.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T10:17:08.277+0000] {processor.py:157} INFO - Started process (PID=34649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:17:08.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:17:08.281+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:17:08.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:17:08.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:17:08.307+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:17:08.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:17:08.317+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:17:08.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:17:08.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T10:17:38.665+0000] {processor.py:157} INFO - Started process (PID=34659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:17:38.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:17:38.684+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:17:38.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:17:38.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:17:38.749+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:17:38.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:17:38.771+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:17:38.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:17:38.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-10T10:18:09.088+0000] {processor.py:157} INFO - Started process (PID=34669) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:18:09.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:18:09.097+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:18:09.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:18:09.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:18:09.119+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:18:09.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:18:09.128+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:18:09.128+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:18:09.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T10:18:39.452+0000] {processor.py:157} INFO - Started process (PID=34679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:18:39.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:18:39.456+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:18:39.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:18:39.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:18:39.487+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:18:39.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:18:39.500+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:18:39.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:18:39.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T10:19:09.964+0000] {processor.py:157} INFO - Started process (PID=34689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:19:09.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:19:09.968+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:19:09.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:19:09.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:19:09.998+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:19:09.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:19:10.008+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:19:10.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:19:10.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T10:19:40.352+0000] {processor.py:157} INFO - Started process (PID=34699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:19:40.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:19:40.356+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:19:40.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:19:40.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:19:40.385+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:19:40.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:19:40.394+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:19:40.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:19:40.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T10:20:10.760+0000] {processor.py:157} INFO - Started process (PID=34709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:20:10.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:20:10.765+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:20:10.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:20:10.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:20:10.799+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:20:10.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:20:10.811+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:20:10.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:20:10.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T10:20:41.157+0000] {processor.py:157} INFO - Started process (PID=34719) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:20:41.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:20:41.160+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:20:41.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:20:41.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:20:41.185+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:20:41.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:20:41.196+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:20:41.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:20:41.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T10:21:11.515+0000] {processor.py:157} INFO - Started process (PID=34729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:21:11.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:21:11.524+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:21:11.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:21:11.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:21:11.543+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:21:11.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:21:11.553+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:21:11.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:21:11.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T10:21:41.799+0000] {processor.py:157} INFO - Started process (PID=34739) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:21:41.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:21:41.807+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:21:41.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:21:41.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:21:41.827+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:21:41.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:21:41.838+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:21:41.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:21:41.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T10:22:12.296+0000] {processor.py:157} INFO - Started process (PID=34749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:22:12.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:22:12.299+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:22:12.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:22:12.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:22:12.330+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:22:12.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:22:12.343+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:22:12.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:22:12.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T10:22:42.723+0000] {processor.py:157} INFO - Started process (PID=34759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:22:42.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:22:42.729+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:22:42.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:22:42.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:22:42.750+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:22:42.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:22:42.760+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:22:42.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:22:42.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T10:23:13.119+0000] {processor.py:157} INFO - Started process (PID=34769) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:23:13.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:23:13.123+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:23:13.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:23:13.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:23:13.153+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:23:13.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:23:13.165+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:23:13.165+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:23:13.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T10:23:43.487+0000] {processor.py:157} INFO - Started process (PID=34779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:23:43.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:23:43.489+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:23:43.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:23:43.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:23:43.515+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:23:43.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:23:43.526+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:23:43.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:23:43.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T10:24:13.851+0000] {processor.py:157} INFO - Started process (PID=34789) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:24:13.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:24:13.854+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:24:13.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:24:13.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:24:13.882+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:24:13.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:24:13.891+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:24:13.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:24:13.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T10:24:44.241+0000] {processor.py:157} INFO - Started process (PID=34799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:24:44.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:24:44.248+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:24:44.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:24:44.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:24:44.269+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:24:44.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:24:44.279+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:24:44.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:24:44.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T10:25:14.651+0000] {processor.py:157} INFO - Started process (PID=34809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:25:14.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:25:14.654+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:25:14.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:25:14.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:25:14.684+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:25:14.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:25:14.694+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:25:14.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:25:14.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T10:25:45.003+0000] {processor.py:157} INFO - Started process (PID=34819) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:25:45.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:25:45.012+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:25:45.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:25:45.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:25:45.032+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:25:45.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:25:45.042+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:25:45.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:25:45.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T10:26:15.436+0000] {processor.py:157} INFO - Started process (PID=34829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:26:15.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:26:15.439+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:26:15.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:26:15.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:26:15.466+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:26:15.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:26:15.477+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:26:15.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:26:15.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T10:26:45.758+0000] {processor.py:157} INFO - Started process (PID=34839) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:26:45.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:26:45.763+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:26:45.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:26:45.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:26:45.791+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:26:45.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:26:45.802+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:26:45.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:26:45.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T10:27:16.121+0000] {processor.py:157} INFO - Started process (PID=34849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:27:16.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:27:16.126+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:27:16.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:27:16.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:27:16.154+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:27:16.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:27:16.166+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:27:16.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:27:16.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T10:27:46.537+0000] {processor.py:157} INFO - Started process (PID=34859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:27:46.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:27:46.542+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:27:46.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:27:46.554+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:27:46.574+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:27:46.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:27:46.586+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:27:46.586+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:27:46.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T10:28:16.980+0000] {processor.py:157} INFO - Started process (PID=34869) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:28:16.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:28:16.985+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:28:16.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:28:16.996+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:28:17.015+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:28:17.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:28:17.029+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:28:17.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:28:17.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T10:28:47.388+0000] {processor.py:157} INFO - Started process (PID=34879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:28:47.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:28:47.390+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:28:47.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:28:47.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:28:47.416+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:28:47.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:28:47.429+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:28:47.429+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:28:47.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T10:29:17.849+0000] {processor.py:157} INFO - Started process (PID=34889) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:29:17.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:29:17.857+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:29:17.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:29:17.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:29:17.877+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:29:17.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:29:17.887+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:29:17.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:29:17.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T10:29:48.206+0000] {processor.py:157} INFO - Started process (PID=34899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:29:48.207+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:29:48.209+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:29:48.209+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:29:48.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:29:48.235+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:29:48.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:29:48.245+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:29:48.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:29:48.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T10:30:18.561+0000] {processor.py:157} INFO - Started process (PID=34909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:30:18.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:30:18.565+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:30:18.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:30:18.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:30:18.592+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:30:18.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:30:18.601+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:30:18.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:30:18.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T10:30:48.967+0000] {processor.py:157} INFO - Started process (PID=34919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:30:48.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:30:48.970+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:30:48.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:30:48.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:30:49.000+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:30:49.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:30:49.013+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:30:49.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:30:49.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T10:31:19.251+0000] {processor.py:157} INFO - Started process (PID=34929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:31:19.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:31:19.254+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:31:19.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:31:19.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:31:19.282+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:31:19.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:31:19.293+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:31:19.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:31:19.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T10:31:49.725+0000] {processor.py:157} INFO - Started process (PID=34939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:31:49.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:31:49.729+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:31:49.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:31:49.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:31:49.762+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:31:49.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:31:49.772+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:31:49.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:31:49.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T10:32:20.190+0000] {processor.py:157} INFO - Started process (PID=34949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:32:20.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:32:20.193+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:32:20.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:32:20.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:32:20.219+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:32:20.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:32:20.229+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:32:20.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:32:20.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T10:32:50.475+0000] {processor.py:157} INFO - Started process (PID=34959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:32:50.476+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:32:50.478+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:32:50.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:32:50.489+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:32:50.507+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:32:50.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:32:50.518+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:32:50.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:32:50.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T10:33:20.800+0000] {processor.py:157} INFO - Started process (PID=34969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:33:20.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:33:20.802+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:33:20.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:33:20.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:33:20.826+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:33:20.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:33:20.836+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:33:20.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:33:20.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T10:33:51.295+0000] {processor.py:157} INFO - Started process (PID=34979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:33:51.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:33:51.300+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:33:51.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:33:51.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:33:51.330+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:33:51.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:33:51.345+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:33:51.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:33:51.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T10:34:21.773+0000] {processor.py:157} INFO - Started process (PID=34989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:34:21.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:34:21.779+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:34:21.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:34:21.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:34:21.801+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:34:21.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:34:21.811+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:34:21.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:34:21.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T10:34:52.171+0000] {processor.py:157} INFO - Started process (PID=34999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:34:52.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:34:52.176+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:34:52.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:34:52.191+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:34:52.207+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:34:52.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:34:52.219+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:34:52.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:34:52.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T10:35:22.583+0000] {processor.py:157} INFO - Started process (PID=35009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:35:22.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:35:22.585+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:35:22.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:35:22.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:35:22.610+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:35:22.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:35:22.619+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:35:22.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:35:22.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T10:35:52.972+0000] {processor.py:157} INFO - Started process (PID=35019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:35:52.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:35:52.976+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:35:52.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:35:52.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:35:53.004+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:35:53.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:35:53.014+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:35:53.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:35:53.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T10:36:23.398+0000] {processor.py:157} INFO - Started process (PID=35029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:36:23.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:36:23.402+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:36:23.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:36:23.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:36:23.427+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:36:23.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:36:23.438+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:36:23.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:36:23.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T10:36:53.739+0000] {processor.py:157} INFO - Started process (PID=35039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:36:53.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:36:53.743+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:36:53.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:36:53.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:36:53.774+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:36:53.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:36:53.786+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:36:53.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:36:53.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T10:37:24.003+0000] {processor.py:157} INFO - Started process (PID=35049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:37:24.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:37:24.005+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:37:24.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:37:24.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:37:24.028+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:37:24.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:37:24.041+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:37:24.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:37:24.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T10:37:54.382+0000] {processor.py:157} INFO - Started process (PID=35059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:37:54.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:37:54.386+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:37:54.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:37:54.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:37:54.417+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:37:54.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:37:54.428+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:37:54.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:37:54.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T10:38:24.720+0000] {processor.py:157} INFO - Started process (PID=35069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:38:24.727+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:38:24.730+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:38:24.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:38:24.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:38:24.750+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:38:24.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:38:24.759+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:38:24.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:38:24.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T10:38:55.103+0000] {processor.py:157} INFO - Started process (PID=35079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:38:55.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:38:55.106+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:38:55.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:38:55.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:38:55.136+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:38:55.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:38:55.146+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:38:55.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:38:55.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T10:39:25.562+0000] {processor.py:157} INFO - Started process (PID=35089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:39:25.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:39:25.570+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:39:25.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:39:25.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:39:25.589+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:39:25.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:39:25.598+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:39:25.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:39:25.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-09-10T10:39:55.921+0000] {processor.py:157} INFO - Started process (PID=35099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:39:55.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:39:55.924+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:39:55.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:39:55.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:39:55.952+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:39:55.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:39:55.963+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:39:55.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:39:55.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T10:40:26.305+0000] {processor.py:157} INFO - Started process (PID=35109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:40:26.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:40:26.309+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:40:26.309+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:40:26.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:40:26.338+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:40:26.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:40:26.348+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:40:26.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:40:26.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T10:40:56.697+0000] {processor.py:157} INFO - Started process (PID=35119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:40:56.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:40:56.702+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:40:56.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:40:56.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:40:56.742+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:40:56.742+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:40:56.754+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:40:56.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:40:56.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T10:41:27.039+0000] {processor.py:157} INFO - Started process (PID=35129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:41:27.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:41:27.041+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:41:27.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:41:27.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:41:27.068+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:41:27.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:41:27.080+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:41:27.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:41:27.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T10:41:57.515+0000] {processor.py:157} INFO - Started process (PID=35139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:41:57.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:41:57.518+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:41:57.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:41:57.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:41:57.547+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:41:57.547+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:41:57.559+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:41:57.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:41:57.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T10:42:27.887+0000] {processor.py:157} INFO - Started process (PID=35149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:42:27.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:42:27.890+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:42:27.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:42:27.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:42:27.921+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:42:27.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:42:27.933+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:42:27.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:42:27.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T10:42:58.240+0000] {processor.py:157} INFO - Started process (PID=35159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:42:58.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:42:58.244+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:42:58.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:42:58.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:42:58.276+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:42:58.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:42:58.289+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:42:58.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:42:58.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T10:43:28.691+0000] {processor.py:157} INFO - Started process (PID=35169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:43:28.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:43:28.698+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:43:28.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:43:28.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:43:28.723+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:43:28.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:43:28.732+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:43:28.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:43:28.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T10:43:59.125+0000] {processor.py:157} INFO - Started process (PID=35179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:43:59.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:43:59.130+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:43:59.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:43:59.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:43:59.155+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:43:59.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:43:59.166+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:43:59.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:43:59.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T10:44:29.525+0000] {processor.py:157} INFO - Started process (PID=35189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:44:29.525+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:44:29.533+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:44:29.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:44:29.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:44:29.555+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:44:29.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:44:29.565+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:44:29.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:44:29.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T10:44:59.910+0000] {processor.py:157} INFO - Started process (PID=35199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:44:59.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:44:59.917+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:44:59.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:44:59.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:44:59.953+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:44:59.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:44:59.966+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:44:59.966+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:44:59.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T10:45:30.279+0000] {processor.py:157} INFO - Started process (PID=35209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:45:30.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:45:30.284+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:45:30.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:45:30.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:45:30.319+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:45:30.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:45:30.332+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:45:30.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:45:30.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T10:46:00.594+0000] {processor.py:157} INFO - Started process (PID=35219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:46:00.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:46:00.596+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:46:00.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:46:00.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:46:00.623+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:46:00.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:46:00.635+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:46:00.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:46:00.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T10:46:30.932+0000] {processor.py:157} INFO - Started process (PID=35229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:46:30.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:46:30.934+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:46:30.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:46:30.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:46:30.962+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:46:30.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:46:30.972+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:46:30.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:46:30.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T10:47:01.365+0000] {processor.py:157} INFO - Started process (PID=35239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:47:01.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:47:01.368+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:47:01.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:47:01.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:47:01.404+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:47:01.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:47:01.419+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:47:01.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:47:01.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T10:47:31.887+0000] {processor.py:157} INFO - Started process (PID=35249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:47:31.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:47:31.893+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:47:31.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:47:31.912+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:47:31.944+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:47:31.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:47:31.956+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:47:31.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:47:31.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T10:48:02.230+0000] {processor.py:157} INFO - Started process (PID=35259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:48:02.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:48:02.237+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:48:02.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:48:02.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:48:02.281+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:48:02.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:48:02.293+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:48:02.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:48:02.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-10T10:48:32.669+0000] {processor.py:157} INFO - Started process (PID=35269) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:48:32.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:48:32.678+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:48:32.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:48:32.687+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:48:32.708+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:48:32.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:48:32.721+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:48:32.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:48:32.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T10:49:03.021+0000] {processor.py:157} INFO - Started process (PID=35279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:49:03.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:49:03.025+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:49:03.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:49:03.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:49:03.058+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:49:03.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:49:03.073+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:49:03.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:49:03.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T10:49:33.484+0000] {processor.py:157} INFO - Started process (PID=35289) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:49:33.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:49:33.487+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:49:33.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:49:33.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:49:33.517+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:49:33.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:49:33.528+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:49:33.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:49:33.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T10:50:03.885+0000] {processor.py:157} INFO - Started process (PID=35299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:50:03.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:50:03.888+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:50:03.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:50:03.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:50:03.916+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:50:03.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:50:03.929+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:50:03.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:50:03.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T10:50:34.231+0000] {processor.py:157} INFO - Started process (PID=35309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:50:34.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:50:34.236+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:50:34.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:50:34.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:50:34.262+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:50:34.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:50:34.274+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:50:34.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:50:34.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T10:51:04.641+0000] {processor.py:157} INFO - Started process (PID=35319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:51:04.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:51:04.646+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:51:04.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:51:04.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:51:04.678+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:51:04.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:51:04.689+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:51:04.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:51:04.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T10:51:35.135+0000] {processor.py:157} INFO - Started process (PID=35329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:51:35.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:51:35.138+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:51:35.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:51:35.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:51:35.164+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:51:35.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:51:35.175+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:51:35.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:51:35.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T10:52:05.560+0000] {processor.py:157} INFO - Started process (PID=35339) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:52:05.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:52:05.565+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:52:05.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:52:05.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:52:05.592+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:52:05.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:52:05.601+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:52:05.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:52:05.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T10:52:35.961+0000] {processor.py:157} INFO - Started process (PID=35349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:52:35.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:52:35.963+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:52:35.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:52:35.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:52:35.994+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:52:35.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:52:36.004+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:52:36.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:52:36.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T10:53:06.350+0000] {processor.py:157} INFO - Started process (PID=35359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:53:06.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:53:06.353+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:53:06.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:53:06.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:53:06.381+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:53:06.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:53:06.396+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:53:06.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:53:06.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T10:53:36.735+0000] {processor.py:157} INFO - Started process (PID=35369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:53:36.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:53:36.737+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:53:36.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:53:36.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:53:36.765+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:53:36.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:53:36.776+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:53:36.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:53:36.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T10:54:07.121+0000] {processor.py:157} INFO - Started process (PID=35379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:54:07.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:54:07.128+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:54:07.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:54:07.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:54:07.150+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:54:07.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:54:07.160+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:54:07.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:54:07.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T10:54:37.417+0000] {processor.py:157} INFO - Started process (PID=35389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:54:37.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:54:37.423+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:54:37.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:54:37.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:54:37.450+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:54:37.450+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:54:37.461+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:54:37.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:54:37.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T10:55:07.872+0000] {processor.py:157} INFO - Started process (PID=35399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:55:07.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:55:07.874+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:55:07.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:55:07.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:55:07.901+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:55:07.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:55:07.913+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:55:07.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:55:07.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T10:55:38.296+0000] {processor.py:157} INFO - Started process (PID=35409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:55:38.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:55:38.299+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:55:38.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:55:38.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:55:38.326+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:55:38.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:55:38.339+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:55:38.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:55:38.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T10:56:08.704+0000] {processor.py:157} INFO - Started process (PID=35419) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:56:08.705+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:56:08.711+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:56:08.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:56:08.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:56:08.732+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:56:08.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:56:08.741+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:56:08.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:56:08.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T10:56:39.036+0000] {processor.py:157} INFO - Started process (PID=35429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:56:39.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:56:39.039+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:56:39.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:56:39.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:56:39.063+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:56:39.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:56:39.073+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:56:39.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:56:39.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T10:57:09.449+0000] {processor.py:157} INFO - Started process (PID=35439) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:57:09.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:57:09.453+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:57:09.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:57:09.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:57:09.482+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:57:09.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:57:09.493+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:57:09.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:57:09.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T10:57:39.857+0000] {processor.py:157} INFO - Started process (PID=35449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:57:39.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:57:39.860+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:57:39.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:57:39.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:57:39.892+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:57:39.892+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:57:39.905+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:57:39.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:57:39.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T10:58:10.288+0000] {processor.py:157} INFO - Started process (PID=35459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:58:10.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:58:10.294+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:58:10.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:58:10.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:58:10.318+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:58:10.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:58:10.328+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:58:10.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:58:10.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T10:58:40.633+0000] {processor.py:157} INFO - Started process (PID=35469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:58:40.633+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:58:40.642+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:58:40.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:58:40.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:58:40.662+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:58:40.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:58:40.672+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:58:40.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:58:40.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T10:59:11.015+0000] {processor.py:157} INFO - Started process (PID=35479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:59:11.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:59:11.024+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:59:11.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:59:11.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:59:11.045+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:59:11.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:59:11.056+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:59:11.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:59:11.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T10:59:41.429+0000] {processor.py:157} INFO - Started process (PID=35489) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:59:41.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T10:59:41.437+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:59:41.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:59:41.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T10:59:41.458+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:59:41.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T10:59:41.467+0000] {logging_mixin.py:151} INFO - [2024-09-10T10:59:41.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T10:59:41.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T11:00:11.782+0000] {processor.py:157} INFO - Started process (PID=35499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:00:11.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T11:00:11.785+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:00:11.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:00:11.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:00:11.810+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:00:11.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T11:00:11.820+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:00:11.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T11:00:11.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T11:00:42.296+0000] {processor.py:157} INFO - Started process (PID=35509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:00:42.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T11:00:42.302+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:00:42.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:00:42.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:00:42.372+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:00:42.371+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T11:00:42.385+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:00:42.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T11:00:42.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-10T11:17:56.491+0000] {processor.py:157} INFO - Started process (PID=35521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:17:56.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T11:17:56.495+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:17:56.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:17:56.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:17:56.551+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:17:56.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T11:17:56.571+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:17:56.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T11:17:56.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-10T11:18:26.805+0000] {processor.py:157} INFO - Started process (PID=35531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:18:26.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T11:18:26.807+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:18:26.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:18:26.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:18:26.848+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:18:26.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T11:18:26.860+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:18:26.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T11:18:26.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T11:18:57.197+0000] {processor.py:157} INFO - Started process (PID=35540) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:18:57.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T11:18:57.202+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:18:57.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:18:57.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:18:57.241+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:18:57.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T11:18:57.251+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:18:57.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T11:18:57.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T11:36:33.617+0000] {processor.py:157} INFO - Started process (PID=35553) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:36:33.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T11:36:33.623+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:36:33.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:36:33.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:36:33.680+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:36:33.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T11:36:33.694+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:36:33.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T11:36:33.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-10T11:52:06.916+0000] {processor.py:157} INFO - Started process (PID=35563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:52:06.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T11:52:06.920+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:52:06.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:52:06.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:52:06.963+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:52:06.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T11:52:06.976+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:52:06.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T11:52:06.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-10T11:52:37.323+0000] {processor.py:157} INFO - Started process (PID=35573) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:52:37.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T11:52:37.327+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:52:37.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:52:37.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T11:52:37.370+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:52:37.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T11:52:37.380+0000] {logging_mixin.py:151} INFO - [2024-09-10T11:52:37.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T11:52:37.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-10T12:09:06.872+0000] {processor.py:157} INFO - Started process (PID=35582) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:09:06.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:09:06.880+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:09:06.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:09:06.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:09:06.941+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:09:06.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:09:06.971+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:09:06.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:09:06.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-10T12:09:37.255+0000] {processor.py:157} INFO - Started process (PID=35592) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:09:37.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:09:37.261+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:09:37.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:09:37.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:09:37.312+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:09:37.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:09:37.325+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:09:37.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:09:37.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-10T12:10:07.658+0000] {processor.py:157} INFO - Started process (PID=35603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:10:07.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:10:07.662+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:10:07.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:10:07.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:10:07.686+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:10:07.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:10:07.696+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:10:07.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:10:07.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T12:12:16.142+0000] {processor.py:157} INFO - Started process (PID=35614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:12:16.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:12:16.152+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:12:16.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:12:16.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:12:16.221+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:12:16.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:12:16.248+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:12:16.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:12:16.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-09-10T12:12:46.608+0000] {processor.py:157} INFO - Started process (PID=35625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:12:46.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:12:46.610+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:12:46.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:12:46.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:12:46.635+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:12:46.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:12:46.647+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:12:46.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:12:46.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T12:28:20.973+0000] {processor.py:157} INFO - Started process (PID=35635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:28:20.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:28:21.018+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:28:21.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:28:21.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:28:21.092+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:28:21.092+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:28:21.104+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:28:21.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:28:21.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-09-10T12:28:51.449+0000] {processor.py:157} INFO - Started process (PID=35645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:28:51.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:28:51.452+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:28:51.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:28:51.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:28:51.478+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:28:51.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:28:51.493+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:28:51.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:28:51.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T12:29:21.792+0000] {processor.py:157} INFO - Started process (PID=35655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:29:21.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:29:21.796+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:29:21.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:29:21.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:29:21.826+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:29:21.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:29:21.836+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:29:21.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:29:21.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T12:29:52.193+0000] {processor.py:157} INFO - Started process (PID=35665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:29:52.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:29:52.197+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:29:52.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:29:52.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:29:52.227+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:29:52.227+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:29:52.240+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:29:52.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:29:52.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T12:30:22.535+0000] {processor.py:157} INFO - Started process (PID=35675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:30:22.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:30:22.539+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:30:22.539+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:30:22.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:30:22.564+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:30:22.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:30:22.576+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:30:22.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:30:22.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T12:30:52.970+0000] {processor.py:157} INFO - Started process (PID=35685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:30:52.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:30:52.973+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:30:52.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:30:52.982+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:30:52.998+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:30:52.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:30:53.008+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:30:53.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:30:53.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T12:31:23.389+0000] {processor.py:157} INFO - Started process (PID=35695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:31:23.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:31:23.392+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:31:23.392+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:31:23.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:31:23.418+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:31:23.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:31:23.430+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:31:23.430+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:31:23.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T12:31:53.789+0000] {processor.py:157} INFO - Started process (PID=35705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:31:53.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:31:53.792+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:31:53.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:31:53.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:31:53.820+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:31:53.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:31:53.829+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:31:53.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:31:53.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T12:32:24.209+0000] {processor.py:157} INFO - Started process (PID=35715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:32:24.210+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:32:24.212+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:32:24.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:32:24.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:32:24.237+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:32:24.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:32:24.246+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:32:24.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:32:24.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T12:32:54.561+0000] {processor.py:157} INFO - Started process (PID=35725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:32:54.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:32:54.564+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:32:54.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:32:54.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:32:54.586+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:32:54.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:32:54.595+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:32:54.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:32:54.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-09-10T12:33:24.982+0000] {processor.py:157} INFO - Started process (PID=35735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:33:24.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:33:24.984+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:33:24.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:33:24.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:33:25.013+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:33:25.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:33:25.024+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:33:25.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:33:25.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T12:33:55.366+0000] {processor.py:157} INFO - Started process (PID=35745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:33:55.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:33:55.369+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:33:55.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:33:55.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:33:55.399+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:33:55.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:33:55.410+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:33:55.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:33:55.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T12:34:25.774+0000] {processor.py:157} INFO - Started process (PID=35755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:34:25.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:34:25.777+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:34:25.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:34:25.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:34:25.805+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:34:25.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:34:25.815+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:34:25.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:34:25.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T12:34:56.050+0000] {processor.py:157} INFO - Started process (PID=35765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:34:56.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:34:56.053+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:34:56.053+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:34:56.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:34:56.081+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:34:56.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:34:56.091+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:34:56.091+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:34:56.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T12:35:26.416+0000] {processor.py:157} INFO - Started process (PID=35775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:35:26.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:35:26.418+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:35:26.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:35:26.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:35:26.443+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:35:26.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:35:26.452+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:35:26.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:35:26.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T12:35:56.756+0000] {processor.py:157} INFO - Started process (PID=35785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:35:56.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:35:56.759+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:35:56.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:35:56.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:35:56.784+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:35:56.784+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:35:56.794+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:35:56.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:35:56.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T12:36:27.143+0000] {processor.py:157} INFO - Started process (PID=35795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:36:27.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:36:27.146+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:36:27.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:36:27.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:36:27.176+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:36:27.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:36:27.185+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:36:27.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:36:27.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T12:36:57.523+0000] {processor.py:157} INFO - Started process (PID=35805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:36:57.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:36:57.526+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:36:57.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:36:57.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:36:57.553+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:36:57.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:36:57.565+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:36:57.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:36:57.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T12:37:27.877+0000] {processor.py:157} INFO - Started process (PID=35815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:37:27.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:37:27.880+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:37:27.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:37:27.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:37:27.908+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:37:27.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:37:27.917+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:37:27.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:37:27.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T12:37:58.250+0000] {processor.py:157} INFO - Started process (PID=35825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:37:58.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:37:58.256+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:37:58.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:37:58.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:37:58.286+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:37:58.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:37:58.299+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:37:58.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:37:58.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T12:38:28.670+0000] {processor.py:157} INFO - Started process (PID=35835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:38:28.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:38:28.674+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:38:28.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:38:28.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:38:28.701+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:38:28.701+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:38:28.714+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:38:28.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:38:28.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T12:38:59.016+0000] {processor.py:157} INFO - Started process (PID=35845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:38:59.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:38:59.020+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:38:59.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:38:59.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:38:59.048+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:38:59.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:38:59.057+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:38:59.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:38:59.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T12:39:29.417+0000] {processor.py:157} INFO - Started process (PID=35855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:39:29.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:39:29.420+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:39:29.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:39:29.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:39:29.449+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:39:29.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:39:29.462+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:39:29.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:39:29.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T12:39:59.803+0000] {processor.py:157} INFO - Started process (PID=35865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:39:59.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:39:59.807+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:39:59.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:39:59.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:39:59.837+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:39:59.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:39:59.850+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:39:59.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:39:59.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T12:40:30.109+0000] {processor.py:157} INFO - Started process (PID=35875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:40:30.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:40:30.111+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:40:30.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:40:30.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:40:30.138+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:40:30.138+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:40:30.150+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:40:30.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:40:30.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T12:41:00.516+0000] {processor.py:157} INFO - Started process (PID=35885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:41:00.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:41:00.518+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:41:00.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:41:00.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:41:00.545+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:41:00.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:41:00.555+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:41:00.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:41:00.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T12:41:30.909+0000] {processor.py:157} INFO - Started process (PID=35895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:41:30.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:41:30.912+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:41:30.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:41:30.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:41:30.939+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:41:30.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:41:30.951+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:41:30.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:41:30.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T12:42:01.287+0000] {processor.py:157} INFO - Started process (PID=35905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:42:01.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:42:01.293+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:42:01.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:42:01.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:42:01.328+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:42:01.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:42:01.340+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:42:01.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:42:01.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T12:42:31.698+0000] {processor.py:157} INFO - Started process (PID=35915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:42:31.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:42:31.701+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:42:31.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:42:31.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:42:31.725+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:42:31.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:42:31.736+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:42:31.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:42:31.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T12:43:02.079+0000] {processor.py:157} INFO - Started process (PID=35925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:43:02.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:43:02.082+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:43:02.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:43:02.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:43:02.109+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:43:02.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:43:02.122+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:43:02.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:43:02.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T12:43:32.495+0000] {processor.py:157} INFO - Started process (PID=35935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:43:32.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:43:32.499+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:43:32.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:43:32.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:43:32.524+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:43:32.524+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:43:32.536+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:43:32.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:43:32.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T12:44:02.835+0000] {processor.py:157} INFO - Started process (PID=35945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:44:02.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:44:02.839+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:44:02.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:44:02.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:44:02.869+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:44:02.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:44:02.878+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:44:02.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:44:02.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T12:44:33.232+0000] {processor.py:157} INFO - Started process (PID=35955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:44:33.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:44:33.235+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:44:33.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:44:33.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:44:33.261+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:44:33.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:44:33.270+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:44:33.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:44:33.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T12:45:03.647+0000] {processor.py:157} INFO - Started process (PID=35965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:45:03.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:45:03.652+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:45:03.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:45:03.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:45:03.684+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:45:03.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:45:03.695+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:45:03.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:45:03.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T12:45:34.096+0000] {processor.py:157} INFO - Started process (PID=35975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:45:34.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:45:34.099+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:45:34.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:45:34.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:45:34.121+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:45:34.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:45:34.132+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:45:34.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:45:34.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-10T12:46:04.482+0000] {processor.py:157} INFO - Started process (PID=35985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:46:04.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:46:04.484+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:46:04.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:46:04.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:46:04.507+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:46:04.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:46:04.517+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:46:04.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:46:04.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-10T12:46:34.859+0000] {processor.py:157} INFO - Started process (PID=35995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:46:34.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:46:34.861+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:46:34.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:46:34.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:46:34.891+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:46:34.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:46:34.903+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:46:34.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:46:34.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T12:47:05.298+0000] {processor.py:157} INFO - Started process (PID=36005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:47:05.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:47:05.302+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:47:05.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:47:05.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:47:05.331+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:47:05.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:47:05.343+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:47:05.343+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:47:05.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T12:47:35.745+0000] {processor.py:157} INFO - Started process (PID=36015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:47:35.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:47:35.747+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:47:35.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:47:35.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:47:35.777+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:47:35.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:47:35.788+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:47:35.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:47:35.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T12:48:06.169+0000] {processor.py:157} INFO - Started process (PID=36025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:48:06.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:48:06.172+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:48:06.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:48:06.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:48:06.198+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:48:06.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:48:06.212+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:48:06.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:48:06.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T12:48:36.505+0000] {processor.py:157} INFO - Started process (PID=36035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:48:36.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:48:36.507+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:48:36.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:48:36.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:48:36.535+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:48:36.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:48:36.548+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:48:36.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:48:36.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T12:49:06.871+0000] {processor.py:157} INFO - Started process (PID=36045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:49:06.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:49:06.877+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:49:06.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:49:06.892+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:49:06.913+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:49:06.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:49:06.925+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:49:06.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:49:06.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T12:49:37.229+0000] {processor.py:157} INFO - Started process (PID=36055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:49:37.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:49:37.232+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:49:37.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:49:37.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:49:37.257+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:49:37.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:49:37.270+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:49:37.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:49:37.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T12:50:07.570+0000] {processor.py:157} INFO - Started process (PID=36065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:50:07.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:50:07.573+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:50:07.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:50:07.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:50:07.604+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:50:07.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:50:07.616+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:50:07.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:50:07.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T12:50:37.931+0000] {processor.py:157} INFO - Started process (PID=36075) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:50:37.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:50:37.936+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:50:37.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:50:37.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:50:37.973+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:50:37.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:50:37.983+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:50:37.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:50:37.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T12:51:08.308+0000] {processor.py:157} INFO - Started process (PID=36085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:51:08.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:51:08.311+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:51:08.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:51:08.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:51:08.343+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:51:08.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:51:08.353+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:51:08.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:51:08.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T12:51:38.767+0000] {processor.py:157} INFO - Started process (PID=36095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:51:38.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:51:38.770+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:51:38.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:51:38.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:51:38.796+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:51:38.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:51:38.808+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:51:38.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:51:38.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T12:52:09.188+0000] {processor.py:157} INFO - Started process (PID=36105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:52:09.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:52:09.192+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:52:09.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:52:09.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:52:09.222+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:52:09.222+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:52:09.231+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:52:09.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:52:09.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T12:52:39.586+0000] {processor.py:157} INFO - Started process (PID=36115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:52:39.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:52:39.593+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:52:39.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:52:39.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:52:39.616+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:52:39.616+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:52:39.626+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:52:39.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:52:39.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T12:53:09.858+0000] {processor.py:157} INFO - Started process (PID=36125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:53:09.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:53:09.861+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:53:09.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:53:09.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:53:09.886+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:53:09.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:53:09.896+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:53:09.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:53:09.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-10T12:53:40.265+0000] {processor.py:157} INFO - Started process (PID=36135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:53:40.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:53:40.269+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:53:40.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:53:40.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:53:40.293+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:53:40.293+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:53:40.302+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:53:40.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:53:40.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T12:54:10.628+0000] {processor.py:157} INFO - Started process (PID=36145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:54:10.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:54:10.630+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:54:10.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:54:10.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:54:10.655+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:54:10.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:54:10.664+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:54:10.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:54:10.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T12:54:40.999+0000] {processor.py:157} INFO - Started process (PID=36155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:54:41.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:54:41.002+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:54:41.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:54:41.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:54:41.032+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:54:41.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:54:41.043+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:54:41.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:54:41.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T12:55:11.420+0000] {processor.py:157} INFO - Started process (PID=36165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:55:11.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:55:11.424+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:55:11.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:55:11.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:55:11.458+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:55:11.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:55:11.471+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:55:11.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:55:11.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T12:55:41.852+0000] {processor.py:157} INFO - Started process (PID=36175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:55:41.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:55:41.855+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:55:41.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:55:41.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:55:41.882+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:55:41.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:55:41.892+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:55:41.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:55:41.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T12:56:12.223+0000] {processor.py:157} INFO - Started process (PID=36185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:56:12.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:56:12.228+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:56:12.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:56:12.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:56:12.263+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:56:12.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:56:12.274+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:56:12.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:56:12.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T12:56:42.556+0000] {processor.py:157} INFO - Started process (PID=36195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:56:42.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:56:42.560+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:56:42.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:56:42.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:56:42.587+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:56:42.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:56:42.599+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:56:42.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:56:42.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T12:57:12.945+0000] {processor.py:157} INFO - Started process (PID=36205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:57:12.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:57:12.949+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:57:12.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:57:12.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:57:12.975+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:57:12.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:57:12.988+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:57:12.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:57:12.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T12:57:43.265+0000] {processor.py:157} INFO - Started process (PID=36215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:57:43.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:57:43.268+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:57:43.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:57:43.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:57:43.296+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:57:43.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:57:43.306+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:57:43.306+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:57:43.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T12:58:13.702+0000] {processor.py:157} INFO - Started process (PID=36225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:58:13.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:58:13.705+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:58:13.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:58:13.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:58:13.729+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:58:13.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:58:13.738+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:58:13.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:58:13.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T12:58:44.062+0000] {processor.py:157} INFO - Started process (PID=36235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:58:44.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:58:44.067+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:58:44.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:58:44.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:58:44.098+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:58:44.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:58:44.110+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:58:44.110+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:58:44.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T12:59:14.392+0000] {processor.py:157} INFO - Started process (PID=36245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:59:14.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:59:14.398+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:59:14.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:59:14.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:59:14.431+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:59:14.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:59:14.440+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:59:14.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:59:14.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T12:59:44.794+0000] {processor.py:157} INFO - Started process (PID=36255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:59:44.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T12:59:44.798+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:59:44.798+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:59:44.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T12:59:44.823+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:59:44.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T12:59:44.832+0000] {logging_mixin.py:151} INFO - [2024-09-10T12:59:44.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T12:59:44.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T13:00:15.168+0000] {processor.py:157} INFO - Started process (PID=36265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:00:15.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:00:15.174+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:00:15.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:00:15.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:00:15.205+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:00:15.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:00:15.220+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:00:15.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:00:15.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T13:00:45.590+0000] {processor.py:157} INFO - Started process (PID=36274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:00:45.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:00:45.595+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:00:45.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:00:45.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:00:45.631+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:00:45.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:00:45.645+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:00:45.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:00:45.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T13:01:15.934+0000] {processor.py:157} INFO - Started process (PID=36285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:01:15.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:01:15.937+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:01:15.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:01:15.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:01:15.964+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:01:15.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:01:15.977+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:01:15.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:01:15.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T13:01:46.403+0000] {processor.py:157} INFO - Started process (PID=36295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:01:46.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:01:46.406+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:01:46.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:01:46.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:01:46.434+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:01:46.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:01:46.443+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:01:46.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:01:46.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T13:02:16.811+0000] {processor.py:157} INFO - Started process (PID=36305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:02:16.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:02:16.817+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:02:16.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:02:16.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:02:16.848+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:02:16.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:02:16.858+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:02:16.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:02:16.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T13:02:47.233+0000] {processor.py:157} INFO - Started process (PID=36315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:02:47.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:02:47.237+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:02:47.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:02:47.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:02:47.263+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:02:47.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:02:47.272+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:02:47.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:02:47.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T13:03:17.643+0000] {processor.py:157} INFO - Started process (PID=36324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:03:17.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:03:17.648+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:03:17.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:03:17.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:03:17.686+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:03:17.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:03:17.698+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:03:17.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:03:17.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T13:03:47.989+0000] {processor.py:157} INFO - Started process (PID=36335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:03:47.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:03:47.992+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:03:47.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:03:48.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:03:48.021+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:03:48.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:03:48.033+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:03:48.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:03:48.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T13:04:18.420+0000] {processor.py:157} INFO - Started process (PID=36345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:04:18.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:04:18.423+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:04:18.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:04:18.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:04:18.451+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:04:18.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:04:18.463+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:04:18.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:04:18.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T13:04:48.784+0000] {processor.py:157} INFO - Started process (PID=36355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:04:48.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:04:48.787+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:04:48.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:04:48.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:04:48.812+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:04:48.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:04:48.821+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:04:48.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:04:48.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T13:05:19.174+0000] {processor.py:157} INFO - Started process (PID=36365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:05:19.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:05:19.176+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:05:19.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:05:19.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:05:19.207+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:05:19.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:05:19.219+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:05:19.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:05:19.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T13:05:49.544+0000] {processor.py:157} INFO - Started process (PID=36375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:05:49.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:05:49.550+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:05:49.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:05:49.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:05:49.583+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:05:49.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:05:49.595+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:05:49.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:05:49.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T13:06:19.890+0000] {processor.py:157} INFO - Started process (PID=36385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:06:19.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:06:19.893+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:06:19.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:06:19.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:06:19.920+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:06:19.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:06:19.933+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:06:19.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:06:19.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T13:06:50.277+0000] {processor.py:157} INFO - Started process (PID=36395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:06:50.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:06:50.279+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:06:50.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:06:50.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:06:50.306+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:06:50.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:06:50.315+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:06:50.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:06:50.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T13:07:20.696+0000] {processor.py:157} INFO - Started process (PID=36405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:07:20.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:07:20.699+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:07:20.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:07:20.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:07:20.726+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:07:20.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:07:20.739+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:07:20.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:07:20.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T13:07:51.069+0000] {processor.py:157} INFO - Started process (PID=36415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:07:51.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:07:51.072+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:07:51.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:07:51.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:07:51.097+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:07:51.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:07:51.117+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:07:51.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:07:51.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T13:08:21.464+0000] {processor.py:157} INFO - Started process (PID=36425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:08:21.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:08:21.467+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:08:21.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:08:21.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:08:21.494+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:08:21.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:08:21.505+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:08:21.505+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:08:21.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T13:08:51.854+0000] {processor.py:157} INFO - Started process (PID=36435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:08:51.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:08:51.858+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:08:51.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:08:51.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:08:51.887+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:08:51.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:08:51.899+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:08:51.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:08:51.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T13:09:22.271+0000] {processor.py:157} INFO - Started process (PID=36445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:09:22.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:09:22.275+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:09:22.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:09:22.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:09:22.305+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:09:22.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:09:22.317+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:09:22.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:09:22.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T13:09:52.740+0000] {processor.py:157} INFO - Started process (PID=36455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:09:52.741+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:09:52.742+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:09:52.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:09:52.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:09:52.775+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:09:52.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:09:52.788+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:09:52.788+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:09:52.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T13:10:23.106+0000] {processor.py:157} INFO - Started process (PID=36465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:10:23.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:10:23.111+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:10:23.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:10:23.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:10:23.145+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:10:23.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:10:23.160+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:10:23.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:10:23.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T13:10:53.486+0000] {processor.py:157} INFO - Started process (PID=36475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:10:53.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:10:53.488+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:10:53.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:10:53.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:10:53.518+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:10:53.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:10:53.528+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:10:53.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:10:53.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T13:11:23.917+0000] {processor.py:157} INFO - Started process (PID=36485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:11:23.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:11:23.921+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:11:23.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:11:23.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:11:23.952+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:11:23.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:11:23.963+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:11:23.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:11:23.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T13:11:54.261+0000] {processor.py:157} INFO - Started process (PID=36495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:11:54.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:11:54.269+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:11:54.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:11:54.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:11:54.314+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:11:54.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:11:54.326+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:11:54.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:11:54.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-10T13:12:24.615+0000] {processor.py:157} INFO - Started process (PID=36505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:12:24.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:12:24.624+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:12:24.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:12:24.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:12:24.649+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:12:24.649+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:12:24.659+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:12:24.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:12:24.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T13:12:55.055+0000] {processor.py:157} INFO - Started process (PID=36515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:12:55.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:12:55.058+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:12:55.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:12:55.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:12:55.093+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:12:55.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:12:55.104+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:12:55.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:12:55.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T13:13:25.472+0000] {processor.py:157} INFO - Started process (PID=36525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:13:25.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:13:25.475+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:13:25.475+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:13:25.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:13:25.500+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:13:25.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:13:25.513+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:13:25.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:13:25.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T13:13:55.877+0000] {processor.py:157} INFO - Started process (PID=36534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:13:55.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:13:55.882+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:13:55.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:13:55.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:13:55.938+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:13:55.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:13:55.951+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:13:55.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:13:55.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-10T13:14:26.183+0000] {processor.py:157} INFO - Started process (PID=36545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:14:26.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:14:26.186+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:14:26.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:14:26.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:14:26.211+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:14:26.211+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:14:26.221+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:14:26.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:14:26.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T13:14:56.576+0000] {processor.py:157} INFO - Started process (PID=36555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:14:56.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:14:56.579+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:14:56.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:14:56.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:14:56.608+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:14:56.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:14:56.619+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:14:56.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:14:56.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T13:15:26.936+0000] {processor.py:157} INFO - Started process (PID=36565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:15:26.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:15:26.941+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:15:26.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:15:26.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:15:26.969+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:15:26.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:15:26.980+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:15:26.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:15:26.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T13:15:57.271+0000] {processor.py:157} INFO - Started process (PID=36575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:15:57.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:15:57.276+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:15:57.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:15:57.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:15:57.305+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:15:57.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:15:57.316+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:15:57.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:15:57.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T13:16:27.690+0000] {processor.py:157} INFO - Started process (PID=36585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:16:27.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:16:27.693+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:16:27.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:16:27.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:16:27.719+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:16:27.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:16:27.729+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:16:27.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:16:27.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T13:16:58.099+0000] {processor.py:157} INFO - Started process (PID=36595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:16:58.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:16:58.104+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:16:58.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:16:58.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:16:58.130+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:16:58.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:16:58.141+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:16:58.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:16:58.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T13:17:28.504+0000] {processor.py:157} INFO - Started process (PID=36605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:17:28.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:17:28.510+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:17:28.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:17:28.522+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:17:28.542+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:17:28.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:17:28.552+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:17:28.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:17:28.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T13:17:58.883+0000] {processor.py:157} INFO - Started process (PID=36614) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:17:58.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:17:58.889+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:17:58.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:17:58.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:17:58.913+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:17:58.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:17:58.924+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:17:58.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:17:58.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T13:18:29.273+0000] {processor.py:157} INFO - Started process (PID=36625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:18:29.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:18:29.277+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:18:29.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:18:29.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:18:29.304+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:18:29.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:18:29.316+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:18:29.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:18:29.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T13:18:59.646+0000] {processor.py:157} INFO - Started process (PID=36635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:18:59.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:18:59.648+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:18:59.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:18:59.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:18:59.678+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:18:59.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:18:59.690+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:18:59.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:18:59.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T13:19:30.067+0000] {processor.py:157} INFO - Started process (PID=36645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:19:30.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:19:30.071+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:19:30.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:19:30.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:19:30.099+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:19:30.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:19:30.109+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:19:30.109+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:19:30.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T13:20:00.513+0000] {processor.py:157} INFO - Started process (PID=36655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:20:00.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:20:00.517+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:20:00.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:20:00.527+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:20:00.546+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:20:00.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:20:00.561+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:20:00.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:20:00.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T13:20:30.907+0000] {processor.py:157} INFO - Started process (PID=36665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:20:30.909+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:20:30.912+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:20:30.911+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:20:30.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:20:30.940+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:20:30.940+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:20:30.951+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:20:30.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:20:30.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T13:21:01.332+0000] {processor.py:157} INFO - Started process (PID=36675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:21:01.333+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:21:01.335+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:21:01.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:21:01.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:21:01.359+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:21:01.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:21:01.370+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:21:01.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:21:01.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T13:21:31.739+0000] {processor.py:157} INFO - Started process (PID=36685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:21:31.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:21:31.745+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:21:31.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:21:31.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:21:31.781+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:21:31.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:21:31.793+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:21:31.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:21:31.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T13:22:02.060+0000] {processor.py:157} INFO - Started process (PID=36695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:22:02.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:22:02.062+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:22:02.062+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:22:02.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:22:02.088+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:22:02.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:22:02.099+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:22:02.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:22:02.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T13:22:32.486+0000] {processor.py:157} INFO - Started process (PID=36705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:22:32.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:22:32.489+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:22:32.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:22:32.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:22:32.516+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:22:32.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:22:32.525+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:22:32.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:22:32.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T13:23:02.838+0000] {processor.py:157} INFO - Started process (PID=36715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:23:02.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:23:02.840+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:23:02.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:23:02.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:23:02.866+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:23:02.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:23:02.877+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:23:02.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:23:02.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T13:23:33.252+0000] {processor.py:157} INFO - Started process (PID=36725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:23:33.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:23:33.258+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:23:33.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:23:33.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:23:33.285+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:23:33.285+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:23:33.296+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:23:33.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:23:33.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T13:24:03.714+0000] {processor.py:157} INFO - Started process (PID=36735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:24:03.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:24:03.719+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:24:03.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:24:03.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:24:03.750+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:24:03.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:24:03.763+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:24:03.763+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:24:03.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T13:24:34.078+0000] {processor.py:157} INFO - Started process (PID=36745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:24:34.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:24:34.083+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:24:34.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:24:34.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:24:34.108+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:24:34.108+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:24:34.118+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:24:34.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:24:34.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T13:25:04.451+0000] {processor.py:157} INFO - Started process (PID=36755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:25:04.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:25:04.455+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:25:04.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:25:04.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:25:04.481+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:25:04.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:25:04.491+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:25:04.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:25:04.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T13:25:34.827+0000] {processor.py:157} INFO - Started process (PID=36765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:25:34.829+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:25:34.832+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:25:34.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:25:34.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:25:34.865+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:25:34.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:25:34.876+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:25:34.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:25:34.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T13:26:05.239+0000] {processor.py:157} INFO - Started process (PID=36775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:26:05.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:26:05.242+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:26:05.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:26:05.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:26:05.267+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:26:05.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:26:05.277+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:26:05.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:26:05.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T13:26:35.616+0000] {processor.py:157} INFO - Started process (PID=36785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:26:35.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:26:35.618+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:26:35.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:26:35.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:26:35.642+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:26:35.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:26:35.653+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:26:35.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:26:35.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T13:27:06.025+0000] {processor.py:157} INFO - Started process (PID=36795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:27:06.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:27:06.028+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:27:06.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:27:06.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:27:06.055+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:27:06.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:27:06.065+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:27:06.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:27:06.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T13:27:36.429+0000] {processor.py:157} INFO - Started process (PID=36805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:27:36.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:27:36.430+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:27:36.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:27:36.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:27:36.461+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:27:36.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:27:36.471+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:27:36.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:27:36.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T13:28:06.827+0000] {processor.py:157} INFO - Started process (PID=36815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:28:06.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:28:06.830+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:28:06.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:28:06.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:28:06.858+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:28:06.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:28:06.868+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:28:06.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:28:06.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T13:28:37.262+0000] {processor.py:157} INFO - Started process (PID=36825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:28:37.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:28:37.265+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:28:37.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:28:37.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:28:37.294+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:28:37.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:28:37.304+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:28:37.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:28:37.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T13:30:03.094+0000] {processor.py:157} INFO - Started process (PID=36835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:30:03.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:30:03.107+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:30:03.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:30:03.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:30:03.160+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:30:03.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:30:03.174+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:30:03.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:30:03.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-09-10T13:30:33.389+0000] {processor.py:157} INFO - Started process (PID=36847) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:30:33.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:30:33.394+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:30:33.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:30:33.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:30:33.442+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:30:33.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:30:33.453+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:30:33.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:30:33.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-10T13:31:46.329+0000] {processor.py:157} INFO - Started process (PID=36857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:31:46.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:31:46.334+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:31:46.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:31:46.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:31:46.362+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:31:46.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:31:46.373+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:31:46.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:31:46.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T13:32:16.673+0000] {processor.py:157} INFO - Started process (PID=36867) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:32:16.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:32:16.676+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:32:16.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:32:16.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:32:16.704+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:32:16.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:32:16.714+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:32:16.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:32:16.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T13:39:57.361+0000] {processor.py:157} INFO - Started process (PID=36878) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:39:57.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:39:57.373+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:39:57.367+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:39:57.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:39:57.438+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:39:57.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:39:57.461+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:39:57.461+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:39:57.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-10T13:46:52.327+0000] {processor.py:157} INFO - Started process (PID=36888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:46:52.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:46:52.336+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:46:52.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:46:52.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:46:52.391+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:46:52.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:46:52.408+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:46:52.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:46:52.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-10T13:47:22.809+0000] {processor.py:157} INFO - Started process (PID=36898) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:47:22.812+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T13:47:22.817+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:47:22.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:47:22.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T13:47:22.872+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:47:22.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T13:47:22.884+0000] {logging_mixin.py:151} INFO - [2024-09-10T13:47:22.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T13:47:22.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-10T14:04:09.563+0000] {processor.py:157} INFO - Started process (PID=36907) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:04:09.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:04:09.571+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:04:09.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:04:09.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:04:09.628+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:04:09.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:04:09.653+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:04:09.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:04:09.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-10T14:04:39.872+0000] {processor.py:157} INFO - Started process (PID=36919) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:04:39.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:04:39.878+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:04:39.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:04:39.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:04:39.938+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:04:39.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:04:39.952+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:04:39.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:04:39.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-10T14:05:10.176+0000] {processor.py:157} INFO - Started process (PID=36929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:05:10.176+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:05:10.178+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:05:10.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:05:10.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:05:10.208+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:05:10.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:05:10.217+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:05:10.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:05:10.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T14:05:40.591+0000] {processor.py:157} INFO - Started process (PID=36939) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:05:40.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:05:40.596+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:05:40.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:05:40.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:05:40.637+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:05:40.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:05:40.650+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:05:40.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:05:40.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-10T14:06:10.991+0000] {processor.py:157} INFO - Started process (PID=36949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:06:10.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:06:10.994+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:06:10.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:06:11.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:06:11.019+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:06:11.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:06:11.029+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:06:11.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:06:11.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T14:06:41.359+0000] {processor.py:157} INFO - Started process (PID=36959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:06:41.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:06:41.362+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:06:41.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:06:41.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:06:41.397+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:06:41.397+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:06:41.408+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:06:41.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:06:41.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T14:07:11.703+0000] {processor.py:157} INFO - Started process (PID=36969) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:07:11.706+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:07:11.708+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:07:11.707+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:07:11.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:07:11.741+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:07:11.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:07:11.755+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:07:11.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:07:11.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T14:07:42.013+0000] {processor.py:157} INFO - Started process (PID=36979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:07:42.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:07:42.015+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:07:42.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:07:42.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:07:42.045+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:07:42.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:07:42.059+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:07:42.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:07:42.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T14:08:12.395+0000] {processor.py:157} INFO - Started process (PID=36989) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:08:12.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:08:12.397+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:08:12.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:08:12.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:08:12.423+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:08:12.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:08:12.433+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:08:12.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:08:12.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T14:08:42.755+0000] {processor.py:157} INFO - Started process (PID=36999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:08:42.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:08:42.757+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:08:42.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:08:42.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:08:42.787+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:08:42.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:08:42.799+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:08:42.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:08:42.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T14:09:13.150+0000] {processor.py:157} INFO - Started process (PID=37009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:09:13.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:09:13.159+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:09:13.159+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:09:13.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:09:13.208+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:09:13.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:09:13.220+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:09:13.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:09:13.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T14:09:43.485+0000] {processor.py:157} INFO - Started process (PID=37019) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:09:43.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:09:43.489+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:09:43.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:09:43.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:09:43.518+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:09:43.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:09:43.530+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:09:43.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:09:43.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T14:10:13.895+0000] {processor.py:157} INFO - Started process (PID=37029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:10:13.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:10:13.897+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:10:13.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:10:13.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:10:13.923+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:10:13.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:10:13.933+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:10:13.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:10:13.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T14:10:44.252+0000] {processor.py:157} INFO - Started process (PID=37039) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:10:44.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:10:44.259+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:10:44.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:10:44.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:10:44.297+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:10:44.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:10:44.310+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:10:44.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:10:44.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-10T14:11:14.612+0000] {processor.py:157} INFO - Started process (PID=37049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:11:14.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:11:14.615+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:11:14.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:11:14.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:11:14.640+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:11:14.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:11:14.650+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:11:14.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:11:14.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T14:11:45.040+0000] {processor.py:157} INFO - Started process (PID=37059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:11:45.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:11:45.044+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:11:45.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:11:45.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:11:45.072+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:11:45.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:11:45.082+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:11:45.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:11:45.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T14:12:15.452+0000] {processor.py:157} INFO - Started process (PID=37069) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:12:15.453+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:12:15.454+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:12:15.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:12:15.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:12:15.482+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:12:15.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:12:15.495+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:12:15.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:12:15.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T14:12:45.853+0000] {processor.py:157} INFO - Started process (PID=37079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:12:45.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:12:45.859+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:12:45.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:12:45.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:12:45.896+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:12:45.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:12:45.909+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:12:45.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:12:45.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T14:13:16.200+0000] {processor.py:157} INFO - Started process (PID=37089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:13:16.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:13:16.218+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:13:16.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:13:16.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:13:16.248+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:13:16.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:13:16.260+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:13:16.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:13:16.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-10T14:13:46.620+0000] {processor.py:157} INFO - Started process (PID=37099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:13:46.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:13:46.623+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:13:46.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:13:46.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:13:46.651+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:13:46.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:13:46.660+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:13:46.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:13:46.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T14:14:17.061+0000] {processor.py:157} INFO - Started process (PID=37109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:14:17.062+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:14:17.064+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:14:17.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:14:17.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:14:17.102+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:14:17.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:14:17.114+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:14:17.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:14:17.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T14:14:47.368+0000] {processor.py:157} INFO - Started process (PID=37119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:14:47.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:14:47.372+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:14:47.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:14:47.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:14:47.401+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:14:47.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:14:47.414+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:14:47.414+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:14:47.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T14:15:17.742+0000] {processor.py:157} INFO - Started process (PID=37129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:15:17.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:15:17.745+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:15:17.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:15:17.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:15:17.770+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:15:17.770+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:15:17.780+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:15:17.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:15:17.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T14:15:48.071+0000] {processor.py:157} INFO - Started process (PID=37139) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:15:48.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:15:48.074+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:15:48.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:15:48.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:15:48.102+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:15:48.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:15:48.113+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:15:48.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:15:48.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T14:16:18.375+0000] {processor.py:157} INFO - Started process (PID=37149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:16:18.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:16:18.378+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:16:18.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:16:18.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:16:18.407+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:16:18.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:16:18.418+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:16:18.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:16:18.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T14:16:48.772+0000] {processor.py:157} INFO - Started process (PID=37159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:16:48.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:16:48.776+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:16:48.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:16:48.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:16:48.804+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:16:48.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:16:48.816+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:16:48.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:16:48.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T14:17:19.148+0000] {processor.py:157} INFO - Started process (PID=37169) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:17:19.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:17:19.151+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:17:19.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:17:19.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:17:19.179+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:17:19.178+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:17:19.189+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:17:19.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:17:19.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T14:17:49.458+0000] {processor.py:157} INFO - Started process (PID=37179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:17:49.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:17:49.460+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:17:49.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:17:49.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:17:49.488+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:17:49.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:17:49.498+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:17:49.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:17:49.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T14:18:19.843+0000] {processor.py:157} INFO - Started process (PID=37189) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:18:19.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:18:19.847+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:18:19.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:18:19.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:18:19.872+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:18:19.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:18:19.883+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:18:19.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:18:19.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T14:18:50.219+0000] {processor.py:157} INFO - Started process (PID=37199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:18:50.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:18:50.222+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:18:50.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:18:50.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:18:50.249+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:18:50.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:18:50.258+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:18:50.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:18:50.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T14:19:20.608+0000] {processor.py:157} INFO - Started process (PID=37209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:19:20.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:19:20.613+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:19:20.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:19:20.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:19:20.640+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:19:20.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:19:20.651+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:19:20.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:19:20.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T14:19:50.984+0000] {processor.py:157} INFO - Started process (PID=37219) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:19:50.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:19:50.990+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:19:50.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:19:51.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:19:51.024+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:19:51.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:19:51.036+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:19:51.036+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:19:51.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T14:20:21.306+0000] {processor.py:157} INFO - Started process (PID=37229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:20:21.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:20:21.310+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:20:21.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:20:21.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:20:21.337+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:20:21.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:20:21.348+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:20:21.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:20:21.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T14:29:55.267+0000] {processor.py:157} INFO - Started process (PID=37239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:29:55.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:29:55.273+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:29:55.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:29:55.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:29:55.342+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:29:55.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:29:55.368+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:29:55.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:29:55.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-10T14:30:25.714+0000] {processor.py:157} INFO - Started process (PID=37249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:30:25.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:30:25.718+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:30:25.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:30:25.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:30:25.748+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:30:25.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:30:25.759+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:30:25.759+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:30:25.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T14:30:56.205+0000] {processor.py:157} INFO - Started process (PID=37261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:30:56.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:30:56.207+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:30:56.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:30:56.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:30:56.237+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:30:56.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:30:56.247+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:30:56.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:30:56.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T14:31:26.621+0000] {processor.py:157} INFO - Started process (PID=37271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:31:26.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:31:26.625+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:31:26.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:31:26.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:31:26.654+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:31:26.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:31:26.665+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:31:26.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:31:26.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T14:31:57.026+0000] {processor.py:157} INFO - Started process (PID=37281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:31:57.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:31:57.029+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:31:57.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:31:57.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:31:57.059+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:31:57.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:31:57.070+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:31:57.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:31:57.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T14:32:27.433+0000] {processor.py:157} INFO - Started process (PID=37290) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:32:27.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:32:27.437+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:32:27.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:32:27.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:32:27.469+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:32:27.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:32:27.481+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:32:27.480+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:32:27.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T14:32:57.919+0000] {processor.py:157} INFO - Started process (PID=37301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:32:57.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:32:57.924+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:32:57.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:32:57.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:32:57.952+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:32:57.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:32:57.965+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:32:57.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:32:57.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T14:33:28.344+0000] {processor.py:157} INFO - Started process (PID=37311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:33:28.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:33:28.349+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:33:28.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:33:28.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:33:28.377+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:33:28.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:33:28.387+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:33:28.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:33:28.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T14:33:58.724+0000] {processor.py:157} INFO - Started process (PID=37321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:33:58.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:33:58.732+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:33:58.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:33:58.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:33:58.760+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:33:58.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:33:58.770+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:33:58.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:33:58.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T14:34:29.152+0000] {processor.py:157} INFO - Started process (PID=37331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:34:29.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:34:29.157+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:34:29.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:34:29.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:34:29.191+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:34:29.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:34:29.204+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:34:29.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:34:29.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T14:34:59.494+0000] {processor.py:157} INFO - Started process (PID=37341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:34:59.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:34:59.497+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:34:59.497+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:34:59.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:34:59.519+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:34:59.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:34:59.529+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:34:59.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:34:59.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-10T14:35:29.931+0000] {processor.py:157} INFO - Started process (PID=37351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:35:29.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:35:29.936+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:35:29.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:35:29.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:35:29.962+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:35:29.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:35:29.973+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:35:29.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:35:29.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T14:36:00.370+0000] {processor.py:157} INFO - Started process (PID=37361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:36:00.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:36:00.372+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:36:00.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:36:00.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:36:00.396+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:36:00.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:36:00.406+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:36:00.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:36:00.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T14:36:30.652+0000] {processor.py:157} INFO - Started process (PID=37371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:36:30.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:36:30.654+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:36:30.654+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:36:30.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:36:30.681+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:36:30.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:36:30.690+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:36:30.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:36:30.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T14:37:01.052+0000] {processor.py:157} INFO - Started process (PID=37381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:37:01.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:37:01.055+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:37:01.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:37:01.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:37:01.082+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:37:01.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:37:01.093+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:37:01.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:37:01.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T14:37:31.408+0000] {processor.py:157} INFO - Started process (PID=37391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:37:31.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:37:31.411+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:37:31.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:37:31.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:37:31.437+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:37:31.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:37:31.447+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:37:31.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:37:31.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T14:38:01.798+0000] {processor.py:157} INFO - Started process (PID=37401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:38:01.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:38:01.802+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:38:01.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:38:01.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:38:01.830+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:38:01.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:38:01.840+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:38:01.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:38:01.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T14:38:32.148+0000] {processor.py:157} INFO - Started process (PID=37411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:38:32.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:38:32.151+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:38:32.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:38:32.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:38:32.182+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:38:32.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:38:32.193+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:38:32.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:38:32.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T14:39:02.570+0000] {processor.py:157} INFO - Started process (PID=37421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:39:02.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:39:02.575+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:39:02.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:39:02.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:39:02.609+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:39:02.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:39:02.620+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:39:02.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:39:02.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T14:39:32.965+0000] {processor.py:157} INFO - Started process (PID=37431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:39:32.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:39:32.969+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:39:32.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:39:32.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:39:32.995+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:39:32.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:39:33.005+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:39:33.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:39:33.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T14:40:03.328+0000] {processor.py:157} INFO - Started process (PID=37441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:40:03.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:40:03.332+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:40:03.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:40:03.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:40:03.356+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:40:03.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:40:03.367+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:40:03.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:40:03.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T14:40:33.674+0000] {processor.py:157} INFO - Started process (PID=37451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:40:33.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:40:33.679+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:40:33.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:40:33.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:40:33.708+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:40:33.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:40:33.721+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:40:33.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:40:33.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T14:41:04.069+0000] {processor.py:157} INFO - Started process (PID=37461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:41:04.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:41:04.073+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:41:04.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:41:04.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:41:04.101+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:41:04.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:41:04.111+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:41:04.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:41:04.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T14:41:34.463+0000] {processor.py:157} INFO - Started process (PID=37471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:41:34.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:41:34.466+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:41:34.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:41:34.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:41:34.495+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:41:34.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:41:34.506+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:41:34.506+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:41:34.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T14:42:04.800+0000] {processor.py:157} INFO - Started process (PID=37481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:42:04.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:42:04.803+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:42:04.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:42:04.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:42:04.830+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:42:04.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:42:04.842+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:42:04.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:42:04.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T14:42:35.088+0000] {processor.py:157} INFO - Started process (PID=37491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:42:35.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:42:35.092+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:42:35.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:42:35.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:42:35.116+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:42:35.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:42:35.129+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:42:35.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:42:35.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T14:43:05.546+0000] {processor.py:157} INFO - Started process (PID=37501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:43:05.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:43:05.549+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:43:05.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:43:05.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:43:05.574+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:43:05.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:43:05.584+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:43:05.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:43:05.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T14:43:35.824+0000] {processor.py:157} INFO - Started process (PID=37511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:43:35.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:43:35.831+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:43:35.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:43:35.859+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:43:35.909+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:43:35.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:43:35.931+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:43:35.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:43:35.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-09-10T14:44:06.190+0000] {processor.py:157} INFO - Started process (PID=37521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:44:06.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:44:06.198+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:44:06.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:44:06.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:44:06.339+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:44:06.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:44:06.383+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:44:06.383+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:44:06.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.233 seconds
[2024-09-10T14:44:36.661+0000] {processor.py:157} INFO - Started process (PID=37531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:44:36.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:44:36.668+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:44:36.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:44:36.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:44:36.714+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:44:36.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:44:36.730+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:44:36.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:44:36.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-10T14:45:06.995+0000] {processor.py:157} INFO - Started process (PID=37541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:45:06.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:45:07.000+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:45:07.000+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:45:07.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:45:07.039+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:45:07.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:45:07.053+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:45:07.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:45:07.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-10T14:45:37.459+0000] {processor.py:157} INFO - Started process (PID=37551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:45:37.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:45:37.467+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:45:37.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:45:37.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:45:37.528+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:45:37.528+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:45:37.544+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:45:37.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:45:37.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-10T14:46:07.778+0000] {processor.py:157} INFO - Started process (PID=37561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:46:07.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:46:07.790+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:46:07.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:46:07.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:46:07.832+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:46:07.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:46:07.845+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:46:07.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:46:07.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T14:46:38.116+0000] {processor.py:157} INFO - Started process (PID=37571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:46:38.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:46:38.123+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:46:38.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:46:38.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:46:38.174+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:46:38.174+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:46:38.187+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:46:38.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:46:38.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-10T14:47:08.465+0000] {processor.py:157} INFO - Started process (PID=37581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:47:08.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:47:08.470+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:47:08.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:47:08.487+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:47:08.510+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:47:08.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:47:08.530+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:47:08.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:47:08.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-10T14:47:38.835+0000] {processor.py:157} INFO - Started process (PID=37591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:47:38.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:47:38.848+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:47:38.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:47:38.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:47:38.974+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:47:38.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:47:39.008+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:47:39.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:47:39.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.218 seconds
[2024-09-10T14:48:09.384+0000] {processor.py:157} INFO - Started process (PID=37601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:48:09.391+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:48:09.399+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:48:09.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:48:09.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:48:09.457+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:48:09.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:48:09.479+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:48:09.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:48:09.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-10T14:48:39.671+0000] {processor.py:157} INFO - Started process (PID=37611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:48:39.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:48:39.679+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:48:39.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:48:39.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:48:39.716+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:48:39.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:48:39.732+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:48:39.731+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:48:39.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T14:49:10.133+0000] {processor.py:157} INFO - Started process (PID=37621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:49:10.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:49:10.141+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:49:10.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:49:10.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:49:10.183+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:49:10.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:49:10.200+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:49:10.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:49:10.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T14:49:40.565+0000] {processor.py:157} INFO - Started process (PID=37631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:49:40.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:49:40.579+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:49:40.578+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:49:40.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:49:40.626+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:49:40.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:49:40.642+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:49:40.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:49:40.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-10T14:50:11.012+0000] {processor.py:157} INFO - Started process (PID=37641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:50:11.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:50:11.036+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:50:11.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:50:11.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:50:11.088+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:50:11.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:50:11.102+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:50:11.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:50:11.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-10T14:50:41.341+0000] {processor.py:157} INFO - Started process (PID=37651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:50:41.342+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:50:41.345+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:50:41.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:50:41.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:50:41.402+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:50:41.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:50:41.415+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:50:41.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:50:41.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-10T14:51:11.717+0000] {processor.py:157} INFO - Started process (PID=37661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:51:11.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:51:11.737+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:51:11.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:51:11.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:51:11.816+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:51:11.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:51:11.834+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:51:11.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:51:11.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.154 seconds
[2024-09-10T14:51:42.055+0000] {processor.py:157} INFO - Started process (PID=37671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:51:42.060+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:51:42.064+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:51:42.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:51:42.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:51:42.105+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:51:42.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:51:42.119+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:51:42.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:51:42.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-10T14:52:12.518+0000] {processor.py:157} INFO - Started process (PID=37681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:52:12.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:52:12.524+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:52:12.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:52:12.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:52:12.574+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:52:12.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:52:12.592+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:52:12.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:52:12.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-10T14:52:42.914+0000] {processor.py:157} INFO - Started process (PID=37691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:52:42.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:52:42.927+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:52:42.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:52:42.942+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:52:42.968+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:52:42.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:52:42.982+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:52:42.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:52:42.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T14:53:13.214+0000] {processor.py:157} INFO - Started process (PID=37701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:53:13.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:53:13.219+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:53:13.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:53:13.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:53:13.257+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:53:13.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:53:13.270+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:53:13.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:53:13.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-10T14:53:43.556+0000] {processor.py:157} INFO - Started process (PID=37711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:53:43.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:53:43.562+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:53:43.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:53:43.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:53:43.620+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:53:43.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:53:43.635+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:53:43.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:53:43.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-10T14:54:13.980+0000] {processor.py:157} INFO - Started process (PID=37721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:54:13.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:54:13.986+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:54:13.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:54:14.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:54:14.028+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:54:14.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:54:14.044+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:54:14.044+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:54:14.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-10T14:54:44.456+0000] {processor.py:157} INFO - Started process (PID=37731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:54:44.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:54:44.471+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:54:44.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:54:44.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:54:44.518+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:54:44.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:54:44.533+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:54:44.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:54:44.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-10T14:55:14.931+0000] {processor.py:157} INFO - Started process (PID=37740) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:55:14.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:55:14.936+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:55:14.936+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:55:14.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:55:14.981+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:55:14.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:55:14.993+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:55:14.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:55:15.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-10T14:55:45.494+0000] {processor.py:157} INFO - Started process (PID=37751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:55:45.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:55:45.513+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:55:45.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:55:45.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:55:45.555+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:55:45.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:55:45.577+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:55:45.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:55:45.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-10T14:56:15.823+0000] {processor.py:157} INFO - Started process (PID=37761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:56:15.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:56:15.833+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:56:15.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:56:15.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:56:15.881+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:56:15.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:56:15.902+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:56:15.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:56:15.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-09-10T14:56:46.233+0000] {processor.py:157} INFO - Started process (PID=37771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:56:46.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:56:46.239+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:56:46.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:56:46.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:56:46.281+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:56:46.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:56:46.294+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:56:46.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:56:46.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-10T14:57:16.941+0000] {processor.py:157} INFO - Started process (PID=37781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:57:16.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:57:16.948+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:57:16.947+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:57:16.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:57:16.994+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:57:16.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:57:17.007+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:57:17.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:57:17.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-10T14:58:01.811+0000] {processor.py:157} INFO - Started process (PID=37791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:58:01.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:58:01.816+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:58:01.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:58:01.826+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:58:01.843+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:58:01.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:58:01.853+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:58:01.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:58:01.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T14:58:32.223+0000] {processor.py:157} INFO - Started process (PID=37803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:58:32.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T14:58:32.228+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:58:32.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:58:32.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T14:58:32.254+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:58:32.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T14:58:32.269+0000] {logging_mixin.py:151} INFO - [2024-09-10T14:58:32.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T14:58:32.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T15:16:07.565+0000] {processor.py:157} INFO - Started process (PID=37813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:16:07.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:16:07.575+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:16:07.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:16:07.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:16:07.648+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:16:07.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:16:07.703+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:16:07.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:16:07.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-09-10T15:16:37.858+0000] {processor.py:157} INFO - Started process (PID=37825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:16:37.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:16:37.874+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:16:37.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:16:37.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:16:37.932+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:16:37.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:16:37.947+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:16:37.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:16:37.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-09-10T15:17:08.290+0000] {processor.py:157} INFO - Started process (PID=37835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:17:08.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:17:08.293+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:17:08.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:17:08.303+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:17:08.319+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:17:08.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:17:08.329+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:17:08.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:17:08.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T15:17:38.723+0000] {processor.py:157} INFO - Started process (PID=37845) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:17:38.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:17:38.729+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:17:38.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:17:38.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:17:38.766+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:17:38.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:17:38.779+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:17:38.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:17:38.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T15:18:09.091+0000] {processor.py:157} INFO - Started process (PID=37855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:18:09.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:18:09.095+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:18:09.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:18:09.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:18:09.121+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:18:09.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:18:09.132+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:18:09.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:18:09.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T15:18:39.417+0000] {processor.py:157} INFO - Started process (PID=37865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:18:39.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:18:39.424+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:18:39.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:18:39.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:18:39.447+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:18:39.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:18:39.457+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:18:39.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:18:39.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T15:19:09.841+0000] {processor.py:157} INFO - Started process (PID=37875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:19:09.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:19:09.847+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:19:09.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:19:09.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:19:09.885+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:19:09.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:19:09.897+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:19:09.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:19:09.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T15:19:40.293+0000] {processor.py:157} INFO - Started process (PID=37885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:19:40.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:19:40.296+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:19:40.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:19:40.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:19:40.325+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:19:40.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:19:40.337+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:19:40.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:19:40.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T15:20:10.712+0000] {processor.py:157} INFO - Started process (PID=37895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:20:10.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:20:10.716+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:20:10.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:20:10.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:20:10.741+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:20:10.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:20:10.753+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:20:10.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:20:10.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T15:20:41.088+0000] {processor.py:157} INFO - Started process (PID=37905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:20:41.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:20:41.091+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:20:41.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:20:41.100+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:20:41.116+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:20:41.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:20:41.129+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:20:41.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:20:41.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T15:21:11.514+0000] {processor.py:157} INFO - Started process (PID=37915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:21:11.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:21:11.521+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:21:11.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:21:11.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:21:11.555+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:21:11.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:21:11.569+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:21:11.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:21:11.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T15:21:41.936+0000] {processor.py:157} INFO - Started process (PID=37925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:21:41.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:21:41.940+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:21:41.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:21:41.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:21:41.981+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:21:41.981+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:21:41.995+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:21:41.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:21:42.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T15:22:12.365+0000] {processor.py:157} INFO - Started process (PID=37935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:22:12.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:22:12.372+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:22:12.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:22:12.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:22:12.405+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:22:12.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:22:12.419+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:22:12.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:22:12.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T15:22:42.791+0000] {processor.py:157} INFO - Started process (PID=37945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:22:42.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:22:42.796+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:22:42.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:22:42.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:22:42.825+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:22:42.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:22:42.836+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:22:42.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:22:42.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T15:23:13.141+0000] {processor.py:157} INFO - Started process (PID=37955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:23:13.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:23:13.146+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:23:13.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:23:13.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:23:13.170+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:23:13.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:23:13.181+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:23:13.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:23:13.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T15:23:43.550+0000] {processor.py:157} INFO - Started process (PID=37965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:23:43.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:23:43.559+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:23:43.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:23:43.586+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:23:43.608+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:23:43.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:23:43.620+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:23:43.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:23:43.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T15:24:13.922+0000] {processor.py:157} INFO - Started process (PID=37975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:24:13.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:24:13.927+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:24:13.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:24:13.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:24:13.954+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:24:13.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:24:13.965+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:24:13.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:24:13.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T15:24:44.220+0000] {processor.py:157} INFO - Started process (PID=37985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:24:44.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:24:44.222+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:24:44.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:24:44.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:24:44.245+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:24:44.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:24:44.258+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:24:44.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:24:44.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T15:25:14.536+0000] {processor.py:157} INFO - Started process (PID=37995) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:25:14.538+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:25:14.540+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:25:14.540+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:25:14.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:25:14.565+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:25:14.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:25:14.574+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:25:14.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:25:14.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T15:25:44.876+0000] {processor.py:157} INFO - Started process (PID=38005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:25:44.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:25:44.879+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:25:44.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:25:44.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:25:44.910+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:25:44.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:25:44.921+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:25:44.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:25:44.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T15:26:15.308+0000] {processor.py:157} INFO - Started process (PID=38015) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:26:15.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:26:15.315+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:26:15.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:26:15.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:26:15.350+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:26:15.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:26:15.363+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:26:15.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:26:15.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T15:26:45.642+0000] {processor.py:157} INFO - Started process (PID=38025) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:26:45.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:26:45.645+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:26:45.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:26:45.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:26:45.669+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:26:45.669+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:26:45.679+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:26:45.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:26:45.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T15:27:16.086+0000] {processor.py:157} INFO - Started process (PID=38035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:27:16.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:27:16.088+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:27:16.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:27:16.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:27:16.116+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:27:16.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:27:16.126+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:27:16.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:27:16.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T15:27:46.417+0000] {processor.py:157} INFO - Started process (PID=38045) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:27:46.425+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:27:46.426+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:27:46.426+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:27:46.437+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:27:46.454+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:27:46.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:27:46.465+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:27:46.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:27:46.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T15:28:16.854+0000] {processor.py:157} INFO - Started process (PID=38055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:28:16.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:28:16.856+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:28:16.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:28:16.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:28:16.887+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:28:16.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:28:16.897+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:28:16.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:28:16.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T15:28:47.228+0000] {processor.py:157} INFO - Started process (PID=38065) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:28:47.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:28:47.231+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:28:47.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:28:47.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:28:47.257+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:28:47.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:28:47.269+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:28:47.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:28:47.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T15:29:17.604+0000] {processor.py:157} INFO - Started process (PID=38074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:29:17.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:29:17.610+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:29:17.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:29:17.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:29:17.647+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:29:17.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:29:17.659+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:29:17.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:29:17.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T15:29:48.030+0000] {processor.py:157} INFO - Started process (PID=38085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:29:48.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:29:48.034+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:29:48.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:29:48.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:29:48.061+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:29:48.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:29:48.073+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:29:48.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:29:48.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T15:30:18.329+0000] {processor.py:157} INFO - Started process (PID=38095) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:30:18.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:30:18.332+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:30:18.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:30:18.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:30:18.356+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:30:18.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:30:18.367+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:30:18.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:30:18.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T15:30:48.706+0000] {processor.py:157} INFO - Started process (PID=38105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:30:48.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:30:48.709+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:30:48.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:30:48.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:30:48.736+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:30:48.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:30:48.746+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:30:48.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:30:48.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T15:31:19.131+0000] {processor.py:157} INFO - Started process (PID=38115) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:31:19.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:31:19.135+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:31:19.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:31:19.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:31:19.161+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:31:19.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:31:19.172+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:31:19.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:31:19.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T15:31:49.525+0000] {processor.py:157} INFO - Started process (PID=38125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:31:49.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:31:49.530+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:31:49.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:31:49.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:31:49.560+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:31:49.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:31:49.571+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:31:49.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:31:49.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T15:32:19.925+0000] {processor.py:157} INFO - Started process (PID=38135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:32:19.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:32:19.928+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:32:19.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:32:19.939+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:32:19.954+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:32:19.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:32:19.964+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:32:19.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:32:19.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T15:32:50.373+0000] {processor.py:157} INFO - Started process (PID=38145) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:32:50.374+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:32:50.377+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:32:50.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:32:50.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:32:50.402+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:32:50.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:32:50.413+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:32:50.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:32:50.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T15:33:20.780+0000] {processor.py:157} INFO - Started process (PID=38155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:33:20.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:33:20.784+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:33:20.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:33:20.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:33:20.810+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:33:20.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:33:20.821+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:33:20.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:33:20.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T15:33:51.196+0000] {processor.py:157} INFO - Started process (PID=38165) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:33:51.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:33:51.198+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:33:51.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:33:51.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:33:51.226+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:33:51.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:33:51.238+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:33:51.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:33:51.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T15:34:21.555+0000] {processor.py:157} INFO - Started process (PID=38175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:34:21.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:34:21.559+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:34:21.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:34:21.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:34:21.585+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:34:21.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:34:21.595+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:34:21.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:34:21.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T15:34:51.920+0000] {processor.py:157} INFO - Started process (PID=38185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:34:51.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:34:51.923+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:34:51.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:34:51.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:34:51.949+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:34:51.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:34:51.960+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:34:51.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:34:51.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T15:35:22.288+0000] {processor.py:157} INFO - Started process (PID=38195) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:35:22.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:35:22.292+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:35:22.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:35:22.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:35:22.327+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:35:22.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:35:22.339+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:35:22.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:35:22.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T15:35:52.615+0000] {processor.py:157} INFO - Started process (PID=38205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:35:52.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:35:52.618+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:35:52.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:35:52.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:35:52.648+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:35:52.648+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:35:52.659+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:35:52.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:35:52.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T15:36:23.040+0000] {processor.py:157} INFO - Started process (PID=38215) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:36:23.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:36:23.044+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:36:23.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:36:23.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:36:23.067+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:36:23.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:36:23.078+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:36:23.078+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:36:23.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T15:36:53.429+0000] {processor.py:157} INFO - Started process (PID=38225) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:36:53.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:36:53.433+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:36:53.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:36:53.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:36:53.459+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:36:53.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:36:53.470+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:36:53.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:36:53.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T15:37:23.832+0000] {processor.py:157} INFO - Started process (PID=38235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:37:23.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:37:23.835+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:37:23.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:37:23.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:37:23.864+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:37:23.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:37:23.873+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:37:23.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:37:23.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T15:37:54.222+0000] {processor.py:157} INFO - Started process (PID=38245) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:37:54.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:37:54.225+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:37:54.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:37:54.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:37:54.254+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:37:54.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:37:54.263+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:37:54.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:37:54.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T15:38:24.604+0000] {processor.py:157} INFO - Started process (PID=38254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:38:24.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:38:24.609+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:38:24.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:38:24.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:38:24.667+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:38:24.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:38:24.680+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:38:24.680+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:38:24.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-10T15:38:54.922+0000] {processor.py:157} INFO - Started process (PID=38265) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:38:54.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:38:54.926+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:38:54.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:38:54.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:38:54.951+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:38:54.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:38:54.961+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:38:54.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:38:54.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T15:39:25.367+0000] {processor.py:157} INFO - Started process (PID=38275) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:39:25.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:39:25.373+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:39:25.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:39:25.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:39:25.408+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:39:25.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:39:25.422+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:39:25.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:39:25.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T15:39:55.756+0000] {processor.py:157} INFO - Started process (PID=38285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:39:55.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:39:55.759+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:39:55.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:39:55.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:39:55.786+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:39:55.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:39:55.797+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:39:55.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:39:55.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T15:40:26.170+0000] {processor.py:157} INFO - Started process (PID=38295) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:40:26.174+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:40:26.180+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:40:26.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:40:26.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:40:26.231+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:40:26.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:40:26.246+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:40:26.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:40:26.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-10T15:40:56.521+0000] {processor.py:157} INFO - Started process (PID=38305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:40:56.523+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:40:56.526+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:40:56.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:40:56.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:40:56.552+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:40:56.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:40:56.565+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:40:56.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:40:56.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T15:41:26.946+0000] {processor.py:157} INFO - Started process (PID=38315) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:41:26.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:41:26.951+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:41:26.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:41:26.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:41:27.015+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:41:27.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:41:27.028+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:41:27.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:41:27.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T15:41:57.288+0000] {processor.py:157} INFO - Started process (PID=38325) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:41:57.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:41:57.291+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:41:57.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:41:57.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:41:57.317+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:41:57.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:41:57.328+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:41:57.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:41:57.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T15:42:27.644+0000] {processor.py:157} INFO - Started process (PID=38335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:42:27.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:42:27.647+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:42:27.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:42:27.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:42:27.676+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:42:27.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:42:27.687+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:42:27.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:42:27.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T15:42:57.981+0000] {processor.py:157} INFO - Started process (PID=38345) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:42:57.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:42:57.986+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:42:57.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:42:58.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:42:58.020+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:42:58.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:42:58.030+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:42:58.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:42:58.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T15:43:28.314+0000] {processor.py:157} INFO - Started process (PID=38355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:43:28.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:43:28.316+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:43:28.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:43:28.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:43:28.347+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:43:28.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:43:28.361+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:43:28.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:43:28.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T15:43:58.732+0000] {processor.py:157} INFO - Started process (PID=38365) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:43:58.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:43:58.735+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:43:58.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:43:58.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:43:58.761+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:43:58.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:43:58.771+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:43:58.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:43:58.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T15:44:29.117+0000] {processor.py:157} INFO - Started process (PID=38375) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:44:29.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:44:29.121+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:44:29.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:44:29.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:44:29.149+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:44:29.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:44:29.159+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:44:29.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:44:29.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T15:44:59.540+0000] {processor.py:157} INFO - Started process (PID=38385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:44:59.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:44:59.544+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:44:59.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:44:59.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:44:59.573+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:44:59.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:44:59.584+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:44:59.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:44:59.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T15:45:29.913+0000] {processor.py:157} INFO - Started process (PID=38395) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:45:29.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:45:29.915+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:45:29.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:45:29.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:45:29.946+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:45:29.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:45:29.957+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:45:29.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:45:29.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T15:46:00.277+0000] {processor.py:157} INFO - Started process (PID=38405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:46:00.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:46:00.281+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:46:00.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:46:00.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:46:00.318+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:46:00.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:46:00.330+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:46:00.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:46:00.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T15:46:30.636+0000] {processor.py:157} INFO - Started process (PID=38415) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:46:30.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:46:30.639+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:46:30.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:46:30.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:46:30.663+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:46:30.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:46:30.674+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:46:30.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:46:30.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T15:47:01.057+0000] {processor.py:157} INFO - Started process (PID=38425) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:47:01.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:47:01.060+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:47:01.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:47:01.070+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:47:01.089+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:47:01.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:47:01.098+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:47:01.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:47:01.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T15:47:31.474+0000] {processor.py:157} INFO - Started process (PID=38435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:47:31.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:47:31.477+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:47:31.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:47:31.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:47:31.503+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:47:31.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:47:31.512+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:47:31.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:47:31.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T15:48:01.853+0000] {processor.py:157} INFO - Started process (PID=38445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:48:01.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:48:01.858+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:48:01.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:48:01.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:48:01.890+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:48:01.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:48:01.902+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:48:01.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:48:01.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T15:48:32.220+0000] {processor.py:157} INFO - Started process (PID=38455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:48:32.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:48:32.226+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:48:32.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:48:32.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:48:32.253+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:48:32.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:48:32.264+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:48:32.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:48:32.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T15:49:02.617+0000] {processor.py:157} INFO - Started process (PID=38465) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:49:02.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:49:02.622+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:49:02.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:49:02.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:49:02.661+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:49:02.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:49:02.674+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:49:02.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:49:02.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T15:49:33.081+0000] {processor.py:157} INFO - Started process (PID=38475) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:49:33.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:49:33.087+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:49:33.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:49:33.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:49:33.111+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:49:33.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:49:33.121+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:49:33.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:49:33.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T15:50:03.428+0000] {processor.py:157} INFO - Started process (PID=38485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:50:03.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:50:03.432+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:50:03.432+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:50:03.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:50:03.456+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:50:03.456+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:50:03.466+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:50:03.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:50:03.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T15:50:33.884+0000] {processor.py:157} INFO - Started process (PID=38495) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:50:33.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:50:33.888+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:50:33.888+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:50:33.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:50:33.916+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:50:33.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:50:33.925+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:50:33.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:50:33.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T15:51:04.302+0000] {processor.py:157} INFO - Started process (PID=38505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:51:04.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:51:04.307+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:51:04.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:51:04.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:51:04.343+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:51:04.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:51:04.356+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:51:04.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:51:04.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T15:51:34.631+0000] {processor.py:157} INFO - Started process (PID=38515) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:51:34.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:51:34.638+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:51:34.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:51:34.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:51:34.659+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:51:34.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:51:34.669+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:51:34.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:51:34.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T15:52:04.915+0000] {processor.py:157} INFO - Started process (PID=38525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:52:04.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:52:04.919+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:52:04.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:52:04.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:52:04.950+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:52:04.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:52:04.961+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:52:04.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:52:04.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T15:52:35.282+0000] {processor.py:157} INFO - Started process (PID=38535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:52:35.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:52:35.285+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:52:35.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:52:35.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:52:35.313+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:52:35.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:52:35.323+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:52:35.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:52:35.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T15:53:05.708+0000] {processor.py:157} INFO - Started process (PID=38545) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:53:05.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:53:05.711+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:53:05.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:53:05.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:53:05.740+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:53:05.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:53:05.750+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:53:05.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:53:05.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T15:53:36.150+0000] {processor.py:157} INFO - Started process (PID=38555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:53:36.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:53:36.155+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:53:36.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:53:36.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:53:36.189+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:53:36.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:53:36.202+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:53:36.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:53:36.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T15:54:06.467+0000] {processor.py:157} INFO - Started process (PID=38565) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:54:06.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:54:06.470+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:54:06.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:54:06.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:54:06.500+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:54:06.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:54:06.511+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:54:06.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:54:06.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T15:54:36.864+0000] {processor.py:157} INFO - Started process (PID=38575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:54:36.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:54:36.868+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:54:36.867+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:54:36.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:54:36.896+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:54:36.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:54:36.908+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:54:36.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:54:36.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T15:55:07.282+0000] {processor.py:157} INFO - Started process (PID=38585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:55:07.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:55:07.287+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:55:07.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:55:07.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:55:07.316+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:55:07.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:55:07.328+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:55:07.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:55:07.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T15:55:37.687+0000] {processor.py:157} INFO - Started process (PID=38595) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:55:37.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:55:37.693+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:55:37.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:55:37.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:55:37.728+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:55:37.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:55:37.740+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:55:37.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:55:37.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T15:56:08.084+0000] {processor.py:157} INFO - Started process (PID=38605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:56:08.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:56:08.088+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:56:08.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:56:08.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:56:08.114+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:56:08.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:56:08.124+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:56:08.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:56:08.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T15:56:38.464+0000] {processor.py:157} INFO - Started process (PID=38615) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:56:38.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:56:38.468+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:56:38.468+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:56:38.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:56:38.492+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:56:38.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:56:38.503+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:56:38.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:56:38.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T15:57:08.757+0000] {processor.py:157} INFO - Started process (PID=38625) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:57:08.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:57:08.760+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:57:08.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:57:08.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:57:08.790+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:57:08.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:57:08.803+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:57:08.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:57:08.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T15:57:39.195+0000] {processor.py:157} INFO - Started process (PID=38635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:57:39.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:57:39.202+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:57:39.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:57:39.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:57:39.234+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:57:39.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:57:39.243+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:57:39.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:57:39.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T15:58:09.563+0000] {processor.py:157} INFO - Started process (PID=38645) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:58:09.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:58:09.567+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:58:09.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:58:09.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:58:09.614+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:58:09.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:58:09.627+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:58:09.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:58:09.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-10T15:58:39.895+0000] {processor.py:157} INFO - Started process (PID=38655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:58:39.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:58:39.896+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:58:39.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:58:39.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:58:39.923+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:58:39.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:58:39.933+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:58:39.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:58:39.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T15:59:10.329+0000] {processor.py:157} INFO - Started process (PID=38665) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:59:10.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:59:10.333+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:59:10.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:59:10.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:59:10.362+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:59:10.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:59:10.373+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:59:10.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:59:10.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T15:59:40.733+0000] {processor.py:157} INFO - Started process (PID=38675) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:59:40.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T15:59:40.739+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:59:40.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:59:40.752+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T15:59:40.773+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:59:40.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T15:59:40.785+0000] {logging_mixin.py:151} INFO - [2024-09-10T15:59:40.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T15:59:40.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T16:00:11.162+0000] {processor.py:157} INFO - Started process (PID=38685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:00:11.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:00:11.165+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:00:11.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:00:11.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:00:11.191+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:00:11.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:00:11.204+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:00:11.204+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:00:11.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T16:00:41.517+0000] {processor.py:157} INFO - Started process (PID=38695) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:00:41.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:00:41.521+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:00:41.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:00:41.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:00:41.555+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:00:41.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:00:41.566+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:00:41.566+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:00:41.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T16:01:11.848+0000] {processor.py:157} INFO - Started process (PID=38705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:01:11.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:01:11.854+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:01:11.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:01:11.873+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:01:11.898+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:01:11.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:01:11.911+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:01:11.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:01:11.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-10T16:01:42.122+0000] {processor.py:157} INFO - Started process (PID=38715) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:01:42.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:01:42.125+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:01:42.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:01:42.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:01:42.152+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:01:42.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:01:42.161+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:01:42.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:01:42.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T16:02:12.462+0000] {processor.py:157} INFO - Started process (PID=38725) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:02:12.463+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:02:12.464+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:02:12.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:02:12.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:02:12.492+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:02:12.492+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:02:12.501+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:02:12.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:02:12.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T16:02:42.836+0000] {processor.py:157} INFO - Started process (PID=38735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:02:42.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:02:42.839+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:02:42.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:02:42.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:02:42.866+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:02:42.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:02:42.875+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:02:42.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:02:42.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T16:03:13.154+0000] {processor.py:157} INFO - Started process (PID=38745) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:03:13.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:03:13.157+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:03:13.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:03:13.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:03:13.182+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:03:13.181+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:03:13.191+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:03:13.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:03:13.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T16:03:43.457+0000] {processor.py:157} INFO - Started process (PID=38755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:03:43.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:03:43.461+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:03:43.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:03:43.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:03:43.487+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:03:43.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:03:43.497+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:03:43.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:03:43.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T16:04:13.845+0000] {processor.py:157} INFO - Started process (PID=38765) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:04:13.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:04:13.849+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:04:13.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:04:13.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:04:13.884+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:04:13.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:04:13.896+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:04:13.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:04:13.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T16:04:44.184+0000] {processor.py:157} INFO - Started process (PID=38775) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:04:44.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:04:44.187+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:04:44.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:04:44.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:04:44.210+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:04:44.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:04:44.220+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:04:44.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:04:44.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T16:05:14.543+0000] {processor.py:157} INFO - Started process (PID=38785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:05:14.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:05:14.546+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:05:14.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:05:14.555+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:05:14.570+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:05:14.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:05:14.582+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:05:14.582+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:05:14.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T16:05:44.976+0000] {processor.py:157} INFO - Started process (PID=38795) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:05:44.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:05:44.980+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:05:44.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:05:44.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:05:45.009+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:05:45.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:05:45.019+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:05:45.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:05:45.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T16:06:15.317+0000] {processor.py:157} INFO - Started process (PID=38805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:06:15.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:06:15.319+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:06:15.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:06:15.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:06:15.344+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:06:15.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:06:15.356+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:06:15.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:06:15.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T16:06:45.724+0000] {processor.py:157} INFO - Started process (PID=38815) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:06:45.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:06:45.728+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:06:45.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:06:45.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:06:45.753+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:06:45.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:06:45.762+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:06:45.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:06:45.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T16:07:16.076+0000] {processor.py:157} INFO - Started process (PID=38825) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:07:16.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:07:16.079+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:07:16.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:07:16.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:07:16.104+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:07:16.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:07:16.116+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:07:16.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:07:16.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T16:07:46.499+0000] {processor.py:157} INFO - Started process (PID=38835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:07:46.500+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:07:46.502+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:07:46.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:07:46.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:07:46.540+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:07:46.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:07:46.553+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:07:46.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:07:46.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T16:08:16.851+0000] {processor.py:157} INFO - Started process (PID=38844) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:08:16.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:08:16.855+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:08:16.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:08:16.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:08:16.882+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:08:16.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:08:16.893+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:08:16.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:08:16.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T16:08:47.301+0000] {processor.py:157} INFO - Started process (PID=38855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:08:47.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:08:47.305+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:08:47.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:08:47.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:08:47.331+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:08:47.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:08:47.344+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:08:47.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:08:47.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T16:09:17.628+0000] {processor.py:157} INFO - Started process (PID=38865) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:09:17.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:09:17.634+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:09:17.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:09:17.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:09:17.672+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:09:17.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:09:17.686+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:09:17.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:09:17.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T16:09:47.955+0000] {processor.py:157} INFO - Started process (PID=38875) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:09:47.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:09:47.959+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:09:47.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:09:47.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:09:47.987+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:09:47.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:09:47.999+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:09:47.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:09:48.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T16:10:18.397+0000] {processor.py:157} INFO - Started process (PID=38885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:10:18.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:10:18.402+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:10:18.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:10:18.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:10:18.434+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:10:18.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:10:18.444+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:10:18.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:10:18.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T16:10:48.808+0000] {processor.py:157} INFO - Started process (PID=38895) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:10:48.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:10:48.811+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:10:48.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:10:48.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:10:48.843+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:10:48.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:10:48.855+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:10:48.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:10:48.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T16:11:19.254+0000] {processor.py:157} INFO - Started process (PID=38905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:11:19.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:11:19.257+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:11:19.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:11:19.268+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:11:19.284+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:11:19.284+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:11:19.293+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:11:19.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:11:19.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T16:11:49.662+0000] {processor.py:157} INFO - Started process (PID=38915) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:11:49.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:11:49.665+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:11:49.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:11:49.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:11:49.693+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:11:49.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:11:49.703+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:11:49.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:11:49.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T16:12:20.051+0000] {processor.py:157} INFO - Started process (PID=38925) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:12:20.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:12:20.054+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:12:20.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:12:20.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:12:20.080+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:12:20.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:12:20.091+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:12:20.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:12:20.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T16:12:50.506+0000] {processor.py:157} INFO - Started process (PID=38935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:12:50.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:12:50.512+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:12:50.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:12:50.528+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:12:50.550+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:12:50.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:12:50.562+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:12:50.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:12:50.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T16:13:20.893+0000] {processor.py:157} INFO - Started process (PID=38945) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:13:20.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:13:20.900+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:13:20.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:13:20.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:13:20.927+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:13:20.927+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:13:20.936+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:13:20.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:13:20.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T16:13:51.259+0000] {processor.py:157} INFO - Started process (PID=38955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:13:51.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:13:51.265+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:13:51.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:13:51.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:13:51.289+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:13:51.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:13:51.299+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:13:51.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:13:51.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T16:14:21.644+0000] {processor.py:157} INFO - Started process (PID=38965) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:14:21.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:14:21.647+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:14:21.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:14:21.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:14:21.676+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:14:21.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:14:21.686+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:14:21.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:14:21.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T16:14:51.987+0000] {processor.py:157} INFO - Started process (PID=38975) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:14:51.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:14:51.990+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:14:51.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:14:52.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:14:52.016+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:14:52.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:14:52.026+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:14:52.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:14:52.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T16:15:22.387+0000] {processor.py:157} INFO - Started process (PID=38985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:15:22.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:15:22.390+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:15:22.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:15:22.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:15:22.416+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:15:22.416+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:15:22.426+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:15:22.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:15:22.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T16:15:52.807+0000] {processor.py:157} INFO - Started process (PID=38994) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:15:52.809+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:15:52.813+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:15:52.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:15:52.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:15:52.873+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:15:52.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:15:52.886+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:15:52.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:15:52.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-10T16:31:21.242+0000] {processor.py:157} INFO - Started process (PID=39005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:31:21.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:31:21.246+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:31:21.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:31:21.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:31:21.268+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:31:21.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:31:21.278+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:31:21.278+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:31:21.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T16:46:58.660+0000] {processor.py:157} INFO - Started process (PID=39016) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:46:58.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:46:58.664+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:46:58.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:46:58.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:46:58.727+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:46:58.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:46:58.751+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:46:58.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:46:58.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-10T16:47:29.101+0000] {processor.py:157} INFO - Started process (PID=39027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:47:29.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:47:29.106+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:47:29.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:47:29.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:47:29.141+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:47:29.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:47:29.153+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:47:29.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:47:29.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T16:47:59.470+0000] {processor.py:157} INFO - Started process (PID=39037) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:47:59.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:47:59.477+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:47:59.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:47:59.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:47:59.505+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:47:59.505+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:47:59.516+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:47:59.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:47:59.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T16:48:29.842+0000] {processor.py:157} INFO - Started process (PID=39047) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:48:29.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:48:29.845+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:48:29.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:48:29.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:48:29.872+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:48:29.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:48:29.881+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:48:29.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:48:29.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T16:49:00.299+0000] {processor.py:157} INFO - Started process (PID=39057) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:49:00.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:49:00.301+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:49:00.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:49:00.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:49:00.325+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:49:00.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:49:00.334+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:49:00.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:49:00.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-10T16:49:30.685+0000] {processor.py:157} INFO - Started process (PID=39067) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:49:30.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:49:30.688+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:49:30.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:49:30.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:49:30.719+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:49:30.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:49:30.729+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:49:30.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:49:30.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T16:58:27.030+0000] {processor.py:157} INFO - Started process (PID=39077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:58:27.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:58:27.032+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:58:27.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:58:27.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:58:27.061+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:58:27.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:58:27.084+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:58:27.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:58:27.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T16:58:57.366+0000] {processor.py:157} INFO - Started process (PID=39089) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:58:57.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:58:57.371+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:58:57.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:58:57.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:58:57.408+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:58:57.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:58:57.420+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:58:57.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:58:57.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T16:59:27.770+0000] {processor.py:157} INFO - Started process (PID=39099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:59:27.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:59:27.776+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:59:27.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:59:27.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:59:27.800+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:59:27.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:59:27.811+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:59:27.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:59:27.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T16:59:58.096+0000] {processor.py:157} INFO - Started process (PID=39109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:59:58.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T16:59:58.100+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:59:58.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:59:58.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T16:59:58.131+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:59:58.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T16:59:58.143+0000] {logging_mixin.py:151} INFO - [2024-09-10T16:59:58.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T16:59:58.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T17:16:30.907+0000] {processor.py:157} INFO - Started process (PID=39119) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:16:30.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:16:30.912+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:16:30.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:16:30.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:16:30.954+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:16:30.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:16:30.965+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:16:30.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:16:30.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-10T17:17:01.281+0000] {processor.py:157} INFO - Started process (PID=39131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:17:01.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:17:01.299+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:17:01.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:17:01.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:17:01.362+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:17:01.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:17:01.392+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:17:01.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:17:01.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-10T17:17:31.560+0000] {processor.py:157} INFO - Started process (PID=39141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:17:31.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:17:31.564+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:17:31.564+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:17:31.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:17:31.591+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:17:31.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:17:31.602+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:17:31.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:17:31.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T17:18:01.942+0000] {processor.py:157} INFO - Started process (PID=39151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:18:01.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:18:01.945+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:18:01.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:18:01.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:18:01.971+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:18:01.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:18:01.983+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:18:01.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:18:01.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T17:18:32.304+0000] {processor.py:157} INFO - Started process (PID=39161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:18:32.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:18:32.308+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:18:32.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:18:32.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:18:32.341+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:18:32.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:18:32.354+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:18:32.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:18:32.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T17:19:02.592+0000] {processor.py:157} INFO - Started process (PID=39171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:19:02.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:19:02.595+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:19:02.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:19:02.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:19:02.620+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:19:02.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:19:02.630+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:19:02.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:19:02.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T17:37:21.172+0000] {processor.py:157} INFO - Started process (PID=39181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:37:21.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:37:21.185+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:37:21.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:37:21.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:37:21.228+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:37:21.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:37:21.254+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:37:21.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:37:21.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-10T17:37:51.537+0000] {processor.py:157} INFO - Started process (PID=39190) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:37:51.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:37:51.557+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:37:51.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:37:51.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:37:51.599+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:37:51.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:37:51.613+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:37:51.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:37:51.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-10T17:38:21.842+0000] {processor.py:157} INFO - Started process (PID=39201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:38:21.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:38:21.845+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:38:21.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:38:21.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:38:21.871+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:38:21.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:38:21.883+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:38:21.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:38:21.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T17:38:52.220+0000] {processor.py:157} INFO - Started process (PID=39211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:38:52.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:38:52.224+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:38:52.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:38:52.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:38:52.261+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:38:52.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:38:52.274+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:38:52.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:38:52.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T17:39:22.638+0000] {processor.py:157} INFO - Started process (PID=39221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:39:22.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:39:22.640+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:39:22.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:39:22.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:39:22.670+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:39:22.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:39:22.683+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:39:22.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:39:22.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T17:39:52.965+0000] {processor.py:157} INFO - Started process (PID=39231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:39:52.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:39:52.967+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:39:52.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:39:52.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:39:52.997+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:39:52.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:39:53.013+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:39:53.012+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:39:53.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T17:40:23.357+0000] {processor.py:157} INFO - Started process (PID=39241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:40:23.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:40:23.361+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:40:23.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:40:23.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:40:23.395+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:40:23.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:40:23.409+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:40:23.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:40:23.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T17:40:53.782+0000] {processor.py:157} INFO - Started process (PID=39251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:40:53.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:40:53.785+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:40:53.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:40:53.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:40:53.813+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:40:53.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:40:53.823+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:40:53.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:40:53.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T17:41:24.125+0000] {processor.py:157} INFO - Started process (PID=39261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:41:24.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:41:24.128+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:41:24.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:41:24.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:41:24.154+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:41:24.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:41:24.164+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:41:24.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:41:24.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T17:41:54.490+0000] {processor.py:157} INFO - Started process (PID=39271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:41:54.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:41:54.493+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:41:54.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:41:54.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:41:54.519+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:41:54.519+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:41:54.529+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:41:54.529+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:41:54.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T17:42:24.876+0000] {processor.py:157} INFO - Started process (PID=39281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:42:24.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:42:24.884+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:42:24.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:42:24.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:42:24.913+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:42:24.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:42:24.925+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:42:24.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:42:24.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T17:42:55.186+0000] {processor.py:157} INFO - Started process (PID=39291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:42:55.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:42:55.189+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:42:55.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:42:55.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:42:55.215+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:42:55.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:42:55.224+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:42:55.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:42:55.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T17:43:25.602+0000] {processor.py:157} INFO - Started process (PID=39301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:43:25.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:43:25.604+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:43:25.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:43:25.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:43:25.630+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:43:25.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:43:25.643+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:43:25.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:43:25.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T17:43:55.990+0000] {processor.py:157} INFO - Started process (PID=39311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:43:55.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:43:55.994+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:43:55.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:43:56.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:43:56.018+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:43:56.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:43:56.030+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:43:56.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:43:56.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T17:44:26.290+0000] {processor.py:157} INFO - Started process (PID=39321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:44:26.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:44:26.295+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:44:26.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:44:26.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:44:26.322+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:44:26.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:44:26.333+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:44:26.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:44:26.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T17:44:56.668+0000] {processor.py:157} INFO - Started process (PID=39331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:44:56.670+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:44:56.672+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:44:56.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:44:56.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:44:56.700+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:44:56.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:44:56.712+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:44:56.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:44:56.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T17:45:27.013+0000] {processor.py:157} INFO - Started process (PID=39341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:45:27.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:45:27.018+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:45:27.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:45:27.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:45:27.054+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:45:27.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:45:27.066+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:45:27.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:45:27.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T17:45:57.327+0000] {processor.py:157} INFO - Started process (PID=39351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:45:57.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:45:57.329+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:45:57.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:45:57.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:45:57.359+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:45:57.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:45:57.369+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:45:57.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:45:57.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T17:46:27.679+0000] {processor.py:157} INFO - Started process (PID=39361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:46:27.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:46:27.681+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:46:27.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:46:27.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:46:27.706+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:46:27.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:46:27.715+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:46:27.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:46:27.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T17:46:58.056+0000] {processor.py:157} INFO - Started process (PID=39371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:46:58.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:46:58.060+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:46:58.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:46:58.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:46:58.090+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:46:58.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:46:58.102+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:46:58.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:46:58.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T17:47:28.437+0000] {processor.py:157} INFO - Started process (PID=39381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:47:28.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:47:28.440+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:47:28.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:47:28.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:47:28.468+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:47:28.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:47:28.477+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:47:28.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:47:28.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T17:47:58.844+0000] {processor.py:157} INFO - Started process (PID=39390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:47:58.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:47:58.848+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:47:58.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:47:58.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:47:58.874+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:47:58.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:47:58.885+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:47:58.885+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:47:58.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T17:48:29.259+0000] {processor.py:157} INFO - Started process (PID=39401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:48:29.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:48:29.264+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:48:29.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:48:29.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:48:29.299+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:48:29.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:48:29.311+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:48:29.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:48:29.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T17:48:59.551+0000] {processor.py:157} INFO - Started process (PID=39411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:48:59.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:48:59.554+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:48:59.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:48:59.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:48:59.582+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:48:59.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:48:59.592+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:48:59.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:48:59.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T17:49:29.903+0000] {processor.py:157} INFO - Started process (PID=39421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:49:29.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:49:29.907+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:49:29.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:49:29.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:49:29.936+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:49:29.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:49:29.947+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:49:29.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:49:29.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T17:50:00.293+0000] {processor.py:157} INFO - Started process (PID=39431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:50:00.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:50:00.296+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:50:00.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:50:00.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:50:00.326+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:50:00.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:50:00.337+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:50:00.337+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:50:00.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T17:50:30.640+0000] {processor.py:157} INFO - Started process (PID=39441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:50:30.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:50:30.643+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:50:30.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:50:30.653+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:50:30.667+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:50:30.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:50:30.679+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:50:30.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:50:30.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T17:51:01.013+0000] {processor.py:157} INFO - Started process (PID=39451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:51:01.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:51:01.015+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:51:01.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:51:01.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:51:01.042+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:51:01.042+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:51:01.053+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:51:01.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:51:01.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T17:51:31.372+0000] {processor.py:157} INFO - Started process (PID=39461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:51:31.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:51:31.378+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:51:31.377+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:51:31.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:51:31.414+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:51:31.414+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:51:31.426+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:51:31.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:51:31.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T17:52:01.692+0000] {processor.py:157} INFO - Started process (PID=39471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:52:01.693+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:52:01.695+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:52:01.695+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:52:01.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:52:01.724+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:52:01.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:52:01.734+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:52:01.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:52:01.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T17:52:32.140+0000] {processor.py:157} INFO - Started process (PID=39481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:52:32.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:52:32.145+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:52:32.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:52:32.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:52:32.183+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:52:32.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:52:32.197+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:52:32.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:52:32.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-10T17:53:02.579+0000] {processor.py:157} INFO - Started process (PID=39491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:53:02.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:53:02.609+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:53:02.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:53:02.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:53:02.652+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:53:02.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:53:02.683+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:53:02.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:53:02.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-09-10T17:53:32.907+0000] {processor.py:157} INFO - Started process (PID=39501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:53:32.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:53:32.910+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:53:32.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:53:32.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:53:32.937+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:53:32.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:53:32.948+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:53:32.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:53:32.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T17:54:03.288+0000] {processor.py:157} INFO - Started process (PID=39511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:54:03.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:54:03.295+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:54:03.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:54:03.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:54:03.330+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:54:03.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:54:03.345+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:54:03.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:54:03.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T17:54:33.603+0000] {processor.py:157} INFO - Started process (PID=39521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:54:33.604+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:54:33.605+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:54:33.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:54:33.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:54:33.630+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:54:33.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:54:33.640+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:54:33.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:54:33.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T17:55:03.957+0000] {processor.py:157} INFO - Started process (PID=39531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:55:03.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:55:03.961+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:55:03.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:55:03.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:55:03.987+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:55:03.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:55:03.999+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:55:03.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:55:04.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T17:55:34.350+0000] {processor.py:157} INFO - Started process (PID=39541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:55:34.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:55:34.352+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:55:34.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:55:34.362+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:55:34.382+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:55:34.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:55:34.391+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:55:34.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:55:34.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T17:56:04.719+0000] {processor.py:157} INFO - Started process (PID=39551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:56:04.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:56:04.726+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:56:04.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:56:04.740+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:56:04.761+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:56:04.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:56:04.772+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:56:04.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:56:04.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T17:56:35.040+0000] {processor.py:157} INFO - Started process (PID=39561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:56:35.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:56:35.044+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:56:35.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:56:35.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:56:35.074+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:56:35.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:56:35.089+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:56:35.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:56:35.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T17:57:05.404+0000] {processor.py:157} INFO - Started process (PID=39571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:57:05.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:57:05.406+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:57:05.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:57:05.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:57:05.438+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:57:05.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:57:05.451+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:57:05.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:57:05.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T17:57:35.797+0000] {processor.py:157} INFO - Started process (PID=39581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:57:35.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:57:35.799+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:57:35.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:57:35.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:57:35.827+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:57:35.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:57:35.837+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:57:35.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:57:35.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T17:58:06.125+0000] {processor.py:157} INFO - Started process (PID=39591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:58:06.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:58:06.128+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:58:06.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:58:06.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:58:06.157+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:58:06.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:58:06.167+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:58:06.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:58:06.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T17:58:36.511+0000] {processor.py:157} INFO - Started process (PID=39601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:58:36.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:58:36.515+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:58:36.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:58:36.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:58:36.544+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:58:36.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:58:36.553+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:58:36.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:58:36.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T17:59:06.869+0000] {processor.py:157} INFO - Started process (PID=39611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:59:06.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:59:06.873+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:59:06.873+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:59:06.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:59:06.909+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:59:06.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:59:06.921+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:59:06.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:59:06.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T17:59:37.244+0000] {processor.py:157} INFO - Started process (PID=39621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:59:37.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T17:59:37.247+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:59:37.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:59:37.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T17:59:37.274+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:59:37.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T17:59:37.285+0000] {logging_mixin.py:151} INFO - [2024-09-10T17:59:37.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T17:59:37.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T18:00:07.574+0000] {processor.py:157} INFO - Started process (PID=39631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:00:07.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:00:07.577+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:00:07.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:00:07.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:00:07.604+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:00:07.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:00:07.614+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:00:07.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:00:07.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T18:00:37.961+0000] {processor.py:157} INFO - Started process (PID=39641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:00:37.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:00:37.964+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:00:37.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:00:37.978+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:00:37.993+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:00:37.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:00:38.004+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:00:38.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:00:38.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T18:01:08.300+0000] {processor.py:157} INFO - Started process (PID=39651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:01:08.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:01:08.305+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:01:08.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:01:08.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:01:08.332+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:01:08.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:01:08.341+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:01:08.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:01:08.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T18:01:38.665+0000] {processor.py:157} INFO - Started process (PID=39661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:01:38.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:01:38.671+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:01:38.671+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:01:38.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:01:38.709+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:01:38.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:01:38.721+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:01:38.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:01:38.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T18:02:08.971+0000] {processor.py:157} INFO - Started process (PID=39671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:02:08.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:02:08.976+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:02:08.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:02:08.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:02:09.000+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:02:09.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:02:09.010+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:02:09.010+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:02:09.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T18:02:39.378+0000] {processor.py:157} INFO - Started process (PID=39681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:02:39.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:02:39.381+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:02:39.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:02:39.393+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:02:39.409+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:02:39.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:02:39.420+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:02:39.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:02:39.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T18:03:09.748+0000] {processor.py:157} INFO - Started process (PID=39691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:03:09.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:03:09.754+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:03:09.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:03:09.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:03:09.790+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:03:09.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:03:09.806+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:03:09.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:03:09.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T18:03:40.117+0000] {processor.py:157} INFO - Started process (PID=39701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:03:40.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:03:40.119+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:03:40.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:03:40.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:03:40.147+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:03:40.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:03:40.156+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:03:40.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:03:40.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T18:04:10.498+0000] {processor.py:157} INFO - Started process (PID=39711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:04:10.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:04:10.501+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:04:10.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:04:10.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:04:10.527+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:04:10.527+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:04:10.537+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:04:10.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:04:10.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T18:04:40.869+0000] {processor.py:157} INFO - Started process (PID=39721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:04:40.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:04:40.872+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:04:40.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:04:40.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:04:40.897+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:04:40.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:04:40.906+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:04:40.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:04:40.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T18:05:11.176+0000] {processor.py:157} INFO - Started process (PID=39731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:05:11.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:05:11.178+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:05:11.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:05:11.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:05:11.204+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:05:11.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:05:11.214+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:05:11.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:05:11.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T18:05:41.530+0000] {processor.py:157} INFO - Started process (PID=39741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:05:41.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:05:41.536+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:05:41.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:05:41.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:05:41.563+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:05:41.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:05:41.573+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:05:41.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:05:41.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T18:06:11.892+0000] {processor.py:157} INFO - Started process (PID=39751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:06:11.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:06:11.894+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:06:11.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:06:11.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:06:11.919+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:06:11.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:06:11.929+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:06:11.929+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:06:11.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T18:06:42.205+0000] {processor.py:157} INFO - Started process (PID=39761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:06:42.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:06:42.208+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:06:42.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:06:42.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:06:42.244+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:06:42.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:06:42.258+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:06:42.258+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:06:42.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T18:07:12.605+0000] {processor.py:157} INFO - Started process (PID=39771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:07:12.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:07:12.610+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:07:12.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:07:12.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:07:12.635+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:07:12.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:07:12.647+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:07:12.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:07:12.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T18:07:42.945+0000] {processor.py:157} INFO - Started process (PID=39781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:07:42.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:07:42.949+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:07:42.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:07:42.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:07:42.975+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:07:42.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:07:42.985+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:07:42.985+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:07:42.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T18:08:13.302+0000] {processor.py:157} INFO - Started process (PID=39791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:08:13.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:08:13.305+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:08:13.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:08:13.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:08:13.329+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:08:13.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:08:13.338+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:08:13.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:08:13.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-09-10T18:08:43.674+0000] {processor.py:157} INFO - Started process (PID=39801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:08:43.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:08:43.677+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:08:43.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:08:43.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:08:43.704+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:08:43.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:08:43.718+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:08:43.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:08:43.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T18:09:14.073+0000] {processor.py:157} INFO - Started process (PID=39811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:09:14.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:09:14.079+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:09:14.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:09:14.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:09:14.114+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:09:14.114+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:09:14.126+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:09:14.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:09:14.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T18:09:44.460+0000] {processor.py:157} INFO - Started process (PID=39821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:09:44.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:09:44.462+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:09:44.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:09:44.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:09:44.490+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:09:44.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:09:44.502+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:09:44.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:09:44.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T18:10:14.813+0000] {processor.py:157} INFO - Started process (PID=39831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:10:14.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:10:14.815+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:10:14.815+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:10:14.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:10:14.847+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:10:14.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:10:14.858+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:10:14.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:10:14.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T18:10:45.157+0000] {processor.py:157} INFO - Started process (PID=39841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:10:45.158+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:10:45.160+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:10:45.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:10:45.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:10:45.185+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:10:45.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:10:45.199+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:10:45.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:10:45.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T18:11:15.516+0000] {processor.py:157} INFO - Started process (PID=39851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:11:15.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:11:15.520+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:11:15.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:11:15.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:11:15.553+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:11:15.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:11:15.565+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:11:15.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:11:15.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T18:11:45.905+0000] {processor.py:157} INFO - Started process (PID=39861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:11:45.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:11:45.908+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:11:45.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:11:45.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:11:45.934+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:11:45.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:11:45.946+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:11:45.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:11:45.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T18:12:16.267+0000] {processor.py:157} INFO - Started process (PID=39871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:12:16.269+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:12:16.272+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:12:16.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:12:16.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:12:16.312+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:12:16.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:12:16.324+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:12:16.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:12:16.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T18:12:46.661+0000] {processor.py:157} INFO - Started process (PID=39881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:12:46.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:12:46.664+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:12:46.664+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:12:46.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:12:46.695+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:12:46.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:12:46.705+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:12:46.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:12:46.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T18:13:17.055+0000] {processor.py:157} INFO - Started process (PID=39891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:13:17.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:13:17.058+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:13:17.058+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:13:17.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:13:17.085+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:13:17.085+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:13:17.097+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:13:17.097+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:13:17.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T18:13:47.453+0000] {processor.py:157} INFO - Started process (PID=39901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:13:47.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:13:47.456+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:13:47.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:13:47.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:13:47.486+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:13:47.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:13:47.497+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:13:47.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:13:47.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T18:14:17.782+0000] {processor.py:157} INFO - Started process (PID=39911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:14:17.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:14:17.785+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:14:17.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:14:17.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:14:17.810+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:14:17.810+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:14:17.820+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:14:17.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:14:17.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T18:14:48.147+0000] {processor.py:157} INFO - Started process (PID=39921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:14:48.148+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:14:48.150+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:14:48.150+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:14:48.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:14:48.179+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:14:48.179+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:14:48.188+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:14:48.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:14:48.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T18:15:18.517+0000] {processor.py:157} INFO - Started process (PID=39931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:15:18.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:15:18.522+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:15:18.522+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:15:18.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:15:18.559+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:15:18.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:15:18.571+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:15:18.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:15:18.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T18:15:48.779+0000] {processor.py:157} INFO - Started process (PID=39941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:15:48.781+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:15:48.782+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:15:48.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:15:48.796+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:15:48.811+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:15:48.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:15:48.820+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:15:48.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:15:48.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T18:16:19.139+0000] {processor.py:157} INFO - Started process (PID=39951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:16:19.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:16:19.143+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:16:19.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:16:19.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:16:19.170+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:16:19.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:16:19.181+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:16:19.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:16:19.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T18:16:49.547+0000] {processor.py:157} INFO - Started process (PID=39961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:16:49.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:16:49.551+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:16:49.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:16:49.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:16:49.578+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:16:49.578+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:16:49.588+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:16:49.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:16:49.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T18:17:19.886+0000] {processor.py:157} INFO - Started process (PID=39971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:17:19.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:17:19.892+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:17:19.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:17:19.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:17:19.925+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:17:19.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:17:19.938+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:17:19.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:17:19.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T18:17:50.298+0000] {processor.py:157} INFO - Started process (PID=39981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:17:50.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:17:50.300+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:17:50.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:17:50.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:17:50.325+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:17:50.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:17:50.338+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:17:50.338+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:17:50.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T18:18:20.676+0000] {processor.py:157} INFO - Started process (PID=39991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:18:20.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:18:20.679+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:18:20.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:18:20.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:18:20.707+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:18:20.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:18:20.719+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:18:20.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:18:20.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T18:18:51.052+0000] {processor.py:157} INFO - Started process (PID=40001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:18:51.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:18:51.054+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:18:51.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:18:51.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:18:51.084+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:18:51.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:18:51.094+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:18:51.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:18:51.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T18:19:21.435+0000] {processor.py:157} INFO - Started process (PID=40011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:19:21.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:19:21.440+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:19:21.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:19:21.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:19:21.471+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:19:21.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:19:21.482+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:19:21.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:19:21.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T18:19:51.866+0000] {processor.py:157} INFO - Started process (PID=40021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:19:51.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:19:51.870+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:19:51.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:19:51.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:19:51.905+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:19:51.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:19:51.916+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:19:51.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:19:51.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T18:20:22.142+0000] {processor.py:157} INFO - Started process (PID=40031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:20:22.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:20:22.145+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:20:22.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:20:22.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:20:22.172+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:20:22.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:20:22.182+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:20:22.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:20:22.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T18:20:52.434+0000] {processor.py:157} INFO - Started process (PID=40041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:20:52.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:20:52.436+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:20:52.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:20:52.445+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:20:52.464+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:20:52.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:20:52.475+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:20:52.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:20:52.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T18:21:22.777+0000] {processor.py:157} INFO - Started process (PID=40049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:21:22.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:21:22.781+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:21:22.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:21:22.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:21:22.818+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:21:22.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:21:22.830+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:21:22.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:21:22.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T18:26:28.096+0000] {processor.py:157} INFO - Started process (PID=40062) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:26:28.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:26:28.106+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:26:28.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:26:28.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:26:28.214+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:26:28.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:26:28.239+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:26:28.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:26:28.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.172 seconds
[2024-09-10T18:26:58.603+0000] {processor.py:157} INFO - Started process (PID=40073) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:26:58.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:26:58.608+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:26:58.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:26:58.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:26:58.656+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:26:58.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:26:58.670+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:26:58.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:26:58.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-10T18:27:28.913+0000] {processor.py:157} INFO - Started process (PID=40082) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:27:28.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:27:28.918+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:27:28.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:27:28.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:27:28.962+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:27:28.962+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:27:28.975+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:27:28.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:27:28.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-10T18:27:59.229+0000] {processor.py:157} INFO - Started process (PID=40093) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:27:59.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:27:59.232+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:27:59.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:27:59.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:27:59.277+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:27:59.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:27:59.291+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:27:59.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:27:59.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T18:28:29.565+0000] {processor.py:157} INFO - Started process (PID=40103) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:28:29.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:28:29.567+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:28:29.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:28:29.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:28:29.598+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:28:29.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:28:29.608+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:28:29.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:28:29.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T18:29:26.652+0000] {processor.py:157} INFO - Started process (PID=40114) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:29:26.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:29:26.667+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:29:26.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:29:26.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:29:26.710+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:29:26.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:29:26.723+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:29:26.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:29:26.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T18:29:58.498+0000] {processor.py:157} INFO - Started process (PID=40125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:29:58.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:29:58.501+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:29:58.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:29:58.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:29:58.531+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:29:58.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:29:58.540+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:29:58.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:29:58.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T18:30:28.876+0000] {processor.py:157} INFO - Started process (PID=40135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:30:28.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:30:28.879+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:30:28.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:30:28.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:30:28.908+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:30:28.907+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:30:28.917+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:30:28.917+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:30:28.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T18:46:04.002+0000] {processor.py:157} INFO - Started process (PID=40147) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:46:04.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:46:04.011+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:46:04.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:46:04.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:46:04.062+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:46:04.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:46:04.085+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:46:04.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:46:04.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-09-10T18:46:34.452+0000] {processor.py:157} INFO - Started process (PID=40157) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:46:34.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T18:46:34.456+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:46:34.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:46:34.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T18:46:34.481+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:46:34.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T18:46:34.491+0000] {logging_mixin.py:151} INFO - [2024-09-10T18:46:34.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T18:46:34.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T19:02:07.922+0000] {processor.py:157} INFO - Started process (PID=40166) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:02:07.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:02:07.932+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:02:07.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:02:07.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:02:07.989+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:02:07.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:02:08.019+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:02:08.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:02:08.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-10T19:02:38.218+0000] {processor.py:157} INFO - Started process (PID=40177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:02:38.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:02:38.224+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:02:38.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:02:38.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:02:38.258+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:02:38.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:02:38.269+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:02:38.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:02:38.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T19:03:08.599+0000] {processor.py:157} INFO - Started process (PID=40187) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:03:08.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:03:08.602+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:03:08.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:03:08.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:03:08.632+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:03:08.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:03:08.643+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:03:08.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:03:08.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T19:03:39.025+0000] {processor.py:157} INFO - Started process (PID=40197) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:03:39.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:03:39.029+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:03:39.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:03:39.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:03:39.057+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:03:39.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:03:39.069+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:03:39.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:03:39.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T19:04:09.398+0000] {processor.py:157} INFO - Started process (PID=40206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:04:09.399+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:04:09.401+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:04:09.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:04:09.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:04:09.426+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:04:09.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:04:09.436+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:04:09.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:04:09.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T19:04:39.760+0000] {processor.py:157} INFO - Started process (PID=40217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:04:39.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:04:39.762+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:04:39.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:04:39.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:04:39.792+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:04:39.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:04:39.802+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:04:39.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:04:39.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T19:05:10.082+0000] {processor.py:157} INFO - Started process (PID=40227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:05:10.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:05:10.085+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:05:10.085+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:05:10.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:05:10.109+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:05:10.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:05:10.120+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:05:10.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:05:10.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T19:05:40.455+0000] {processor.py:157} INFO - Started process (PID=40237) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:05:40.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:05:40.457+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:05:40.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:05:40.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:05:40.485+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:05:40.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:05:40.494+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:05:40.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:05:40.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T19:06:10.847+0000] {processor.py:157} INFO - Started process (PID=40247) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:06:10.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:06:10.851+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:06:10.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:06:10.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:06:10.886+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:06:10.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:06:10.897+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:06:10.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:06:10.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T19:06:41.140+0000] {processor.py:157} INFO - Started process (PID=40257) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:06:41.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:06:41.143+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:06:41.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:06:41.151+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:06:41.166+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:06:41.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:06:41.176+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:06:41.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:06:41.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T19:07:11.574+0000] {processor.py:157} INFO - Started process (PID=40267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:07:11.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:07:11.577+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:07:11.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:07:11.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:07:11.607+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:07:11.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:07:11.619+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:07:11.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:07:11.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T19:07:41.956+0000] {processor.py:157} INFO - Started process (PID=40277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:07:41.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:07:41.959+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:07:41.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:07:41.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:07:41.987+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:07:41.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:07:42.000+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:07:42.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:07:42.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T19:08:12.325+0000] {processor.py:157} INFO - Started process (PID=40287) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:08:12.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:08:12.328+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:08:12.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:08:12.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:08:12.355+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:08:12.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:08:12.365+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:08:12.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:08:12.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T19:08:42.685+0000] {processor.py:157} INFO - Started process (PID=40297) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:08:42.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:08:42.692+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:08:42.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:08:42.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:08:42.729+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:08:42.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:08:42.741+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:08:42.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:08:42.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T19:09:13.035+0000] {processor.py:157} INFO - Started process (PID=40307) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:09:13.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:09:13.037+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:09:13.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:09:13.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:09:13.058+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:09:13.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:09:13.067+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:09:13.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:09:13.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-09-10T19:09:43.443+0000] {processor.py:157} INFO - Started process (PID=40317) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:09:43.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:09:43.445+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:09:43.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:09:43.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:09:43.471+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:09:43.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:09:43.481+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:09:43.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:09:43.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T19:10:13.780+0000] {processor.py:157} INFO - Started process (PID=40327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:10:13.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:10:13.783+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:10:13.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:10:13.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:10:13.809+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:10:13.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:10:13.823+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:10:13.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:10:13.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T19:10:44.133+0000] {processor.py:157} INFO - Started process (PID=40337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:10:44.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:10:44.137+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:10:44.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:10:44.148+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:10:44.162+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:10:44.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:10:44.176+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:10:44.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:10:44.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T19:11:14.485+0000] {processor.py:157} INFO - Started process (PID=40347) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:11:14.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:11:14.487+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:11:14.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:11:14.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:11:14.515+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:11:14.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:11:14.526+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:11:14.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:11:14.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T19:11:44.911+0000] {processor.py:157} INFO - Started process (PID=40357) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:11:44.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:11:44.914+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:11:44.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:11:44.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:11:44.941+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:11:44.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:11:44.955+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:11:44.954+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:11:44.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T19:12:15.280+0000] {processor.py:157} INFO - Started process (PID=40367) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:12:15.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:12:15.282+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:12:15.282+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:12:15.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:12:15.310+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:12:15.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:12:15.321+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:12:15.321+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:12:15.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T19:12:45.697+0000] {processor.py:157} INFO - Started process (PID=40377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:12:45.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:12:45.699+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:12:45.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:12:45.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:12:45.729+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:12:45.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:12:45.739+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:12:45.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:12:45.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T19:13:16.095+0000] {processor.py:157} INFO - Started process (PID=40387) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:13:16.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:13:16.098+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:13:16.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:13:16.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:13:16.124+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:13:16.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:13:16.136+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:13:16.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:13:16.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T19:13:46.413+0000] {processor.py:157} INFO - Started process (PID=40397) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:13:46.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:13:46.416+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:13:46.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:13:46.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:13:46.454+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:13:46.454+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:13:46.466+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:13:46.466+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:13:46.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T19:14:16.767+0000] {processor.py:157} INFO - Started process (PID=40407) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:14:16.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:14:16.769+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:14:16.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:14:16.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:14:16.797+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:14:16.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:14:16.806+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:14:16.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:14:16.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T19:14:47.154+0000] {processor.py:157} INFO - Started process (PID=40417) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:14:47.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:14:47.162+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:14:47.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:14:47.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:14:47.183+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:14:47.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:14:47.191+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:14:47.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:14:47.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T19:15:17.446+0000] {processor.py:157} INFO - Started process (PID=40427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:15:17.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:15:17.449+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:15:17.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:15:17.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:15:17.479+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:15:17.479+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:15:17.491+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:15:17.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:15:17.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T19:15:47.816+0000] {processor.py:157} INFO - Started process (PID=40437) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:15:47.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:15:47.819+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:15:47.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:15:47.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:15:47.847+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:15:47.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:15:47.856+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:15:47.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:15:47.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T19:16:18.243+0000] {processor.py:157} INFO - Started process (PID=40447) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:16:18.244+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:16:18.246+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:16:18.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:16:18.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:16:18.272+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:16:18.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:16:18.282+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:16:18.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:16:18.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T19:16:48.629+0000] {processor.py:157} INFO - Started process (PID=40457) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:16:48.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:16:48.633+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:16:48.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:16:48.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:16:48.660+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:16:48.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:16:48.671+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:16:48.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:16:48.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T19:17:19.069+0000] {processor.py:157} INFO - Started process (PID=40467) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:17:19.073+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:17:19.075+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:17:19.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:17:19.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:17:19.111+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:17:19.111+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:17:19.123+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:17:19.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:17:19.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T19:17:49.435+0000] {processor.py:157} INFO - Started process (PID=40477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:17:49.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:17:49.438+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:17:49.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:17:49.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:17:49.461+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:17:49.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:17:49.470+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:17:49.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:17:49.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-10T19:18:19.809+0000] {processor.py:157} INFO - Started process (PID=40487) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:18:19.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:18:19.814+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:18:19.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:18:19.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:18:19.839+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:18:19.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:18:19.850+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:18:19.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:18:19.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T19:20:17.195+0000] {processor.py:157} INFO - Started process (PID=40497) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:20:17.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:20:17.200+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:20:17.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:20:17.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:20:17.260+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:20:17.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:20:17.280+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:20:17.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:20:17.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-09-10T19:20:47.623+0000] {processor.py:157} INFO - Started process (PID=40509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:20:47.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:20:47.627+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:20:47.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:20:47.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:20:47.654+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:20:47.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:20:47.668+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:20:47.668+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:20:47.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T19:38:17.894+0000] {processor.py:157} INFO - Started process (PID=40519) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:38:17.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:38:17.899+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:38:17.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:38:17.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:38:17.942+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:38:17.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:38:17.958+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:38:17.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:38:17.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-10T19:54:35.151+0000] {processor.py:157} INFO - Started process (PID=40529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:54:35.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:54:35.158+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:54:35.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:54:35.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:54:35.228+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:54:35.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:54:35.251+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:54:35.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:54:35.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-09-10T19:55:05.689+0000] {processor.py:157} INFO - Started process (PID=40538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:55:05.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:55:05.695+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:55:05.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:55:05.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:55:05.740+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:55:05.740+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:55:05.754+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:55:05.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:55:05.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T19:55:35.991+0000] {processor.py:157} INFO - Started process (PID=40549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:55:35.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:55:35.994+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:55:35.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:55:36.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:55:36.026+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:55:36.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:55:36.037+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:55:36.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:55:36.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T19:56:06.392+0000] {processor.py:157} INFO - Started process (PID=40559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:56:06.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:56:06.395+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:56:06.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:56:06.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:56:06.422+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:56:06.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:56:06.432+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:56:06.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:56:06.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T19:56:36.748+0000] {processor.py:157} INFO - Started process (PID=40569) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:56:36.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T19:56:36.751+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:56:36.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:56:36.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T19:56:36.777+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:56:36.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T19:56:36.789+0000] {logging_mixin.py:151} INFO - [2024-09-10T19:56:36.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T19:56:36.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T20:12:03.765+0000] {processor.py:157} INFO - Started process (PID=40579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:12:03.769+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:12:03.774+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:12:03.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:12:03.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:12:03.848+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:12:03.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:12:03.873+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:12:03.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:12:03.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-10T20:16:21.354+0000] {processor.py:157} INFO - Started process (PID=40589) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:16:21.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:16:21.358+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:16:21.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:16:21.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:16:21.402+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:16:21.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:16:21.428+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:16:21.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:16:21.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T20:16:51.769+0000] {processor.py:157} INFO - Started process (PID=40599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:16:51.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:16:51.774+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:16:51.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:16:51.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:16:51.816+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:16:51.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:16:51.830+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:16:51.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:16:51.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-10T20:18:16.472+0000] {processor.py:157} INFO - Started process (PID=40610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:18:16.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:18:16.483+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:18:16.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:18:16.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:18:16.543+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:18:16.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:18:16.558+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:18:16.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:18:16.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-10T20:18:46.766+0000] {processor.py:157} INFO - Started process (PID=40621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:18:46.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:18:46.770+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:18:46.770+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:18:46.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:18:46.802+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:18:46.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:18:46.812+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:18:46.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:18:46.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T20:19:17.115+0000] {processor.py:157} INFO - Started process (PID=40631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:19:17.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:19:17.117+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:19:17.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:19:17.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:19:17.142+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:19:17.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:19:17.152+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:19:17.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:19:17.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T20:19:47.467+0000] {processor.py:157} INFO - Started process (PID=40641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:19:47.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:19:47.470+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:19:47.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:19:47.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:19:47.503+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:19:47.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:19:47.515+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:19:47.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:19:47.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T20:20:17.743+0000] {processor.py:157} INFO - Started process (PID=40651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:20:17.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:20:17.750+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:20:17.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:20:17.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:20:17.774+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:20:17.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:20:17.784+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:20:17.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:20:17.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T20:20:48.038+0000] {processor.py:157} INFO - Started process (PID=40661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:20:48.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:20:48.041+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:20:48.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:20:48.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:20:48.069+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:20:48.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:20:48.080+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:20:48.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:20:48.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T20:21:18.374+0000] {processor.py:157} INFO - Started process (PID=40671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:21:18.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:21:18.376+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:21:18.376+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:21:18.385+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:21:18.400+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:21:18.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:21:18.409+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:21:18.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:21:18.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T20:21:48.724+0000] {processor.py:157} INFO - Started process (PID=40681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:21:48.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:21:48.729+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:21:48.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:21:48.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:21:48.764+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:21:48.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:21:48.778+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:21:48.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:21:48.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T20:22:19.052+0000] {processor.py:157} INFO - Started process (PID=40691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:22:19.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:22:19.056+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:22:19.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:22:19.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:22:19.082+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:22:19.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:22:19.093+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:22:19.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:22:19.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T20:22:49.417+0000] {processor.py:157} INFO - Started process (PID=40701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:22:49.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:22:49.420+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:22:49.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:22:49.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:22:49.453+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:22:49.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:22:49.463+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:22:49.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:22:49.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T20:23:19.728+0000] {processor.py:157} INFO - Started process (PID=40711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:23:19.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:23:19.731+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:23:19.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:23:19.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:23:19.762+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:23:19.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:23:19.776+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:23:19.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:23:19.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T20:23:50.089+0000] {processor.py:157} INFO - Started process (PID=40721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:23:50.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:23:50.092+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:23:50.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:23:50.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:23:50.118+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:23:50.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:23:50.128+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:23:50.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:23:50.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T20:24:20.531+0000] {processor.py:157} INFO - Started process (PID=40731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:24:20.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:24:20.548+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:24:20.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:24:20.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:24:20.613+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:24:20.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:24:20.632+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:24:20.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:24:20.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-10T20:24:50.831+0000] {processor.py:157} INFO - Started process (PID=40741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:24:50.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:24:50.838+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:24:50.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:24:50.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:24:50.892+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:24:50.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:24:50.905+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:24:50.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:24:50.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-10T20:25:21.298+0000] {processor.py:157} INFO - Started process (PID=40750) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:25:21.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:25:21.304+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:25:21.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:25:21.319+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:25:21.344+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:25:21.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:25:21.367+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:25:21.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:25:21.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-10T20:25:51.688+0000] {processor.py:157} INFO - Started process (PID=40761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:25:51.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:25:51.693+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:25:51.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:25:51.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:25:51.717+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:25:51.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:25:51.726+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:25:51.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:25:51.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T20:26:22.084+0000] {processor.py:157} INFO - Started process (PID=40771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:26:22.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:26:22.088+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:26:22.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:26:22.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:26:22.126+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:26:22.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:26:22.141+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:26:22.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:26:22.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T20:26:52.560+0000] {processor.py:157} INFO - Started process (PID=40780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:26:52.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:26:52.569+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:26:52.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:26:52.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:26:52.657+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:26:52.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:26:52.675+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:26:52.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:26:52.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-10T20:27:22.880+0000] {processor.py:157} INFO - Started process (PID=40790) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:27:22.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:27:22.888+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:27:22.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:27:22.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:27:22.929+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:27:22.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:27:22.942+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:27:22.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:27:22.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-10T20:27:53.266+0000] {processor.py:157} INFO - Started process (PID=40801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:27:53.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:27:53.274+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:27:53.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:27:53.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:27:53.345+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:27:53.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:27:53.368+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:27:53.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:27:53.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-09-10T20:28:23.579+0000] {processor.py:157} INFO - Started process (PID=40811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:28:23.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:28:23.583+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:28:23.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:28:23.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:28:23.614+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:28:23.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:28:23.624+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:28:23.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:28:23.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T20:28:53.925+0000] {processor.py:157} INFO - Started process (PID=40821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:28:53.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:28:53.928+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:28:53.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:28:53.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:28:53.968+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:28:53.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:28:53.981+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:28:53.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:28:53.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T20:29:24.270+0000] {processor.py:157} INFO - Started process (PID=40831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:29:24.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:29:24.272+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:29:24.272+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:29:24.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:29:24.299+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:29:24.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:29:24.309+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:29:24.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:29:24.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T20:29:54.709+0000] {processor.py:157} INFO - Started process (PID=40841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:29:54.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:29:54.715+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:29:54.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:29:54.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:29:54.768+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:29:54.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:29:54.785+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:29:54.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:29:54.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-10T20:30:25.185+0000] {processor.py:157} INFO - Started process (PID=40850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:30:25.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:30:25.198+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:30:25.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:30:25.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:30:25.260+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:30:25.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:30:25.291+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:30:25.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:30:25.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.162 seconds
[2024-09-10T20:30:55.544+0000] {processor.py:157} INFO - Started process (PID=40861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:30:55.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:30:55.555+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:30:55.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:30:55.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:30:55.636+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:30:55.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:30:55.657+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:30:55.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:30:55.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.136 seconds
[2024-09-10T20:31:25.855+0000] {processor.py:157} INFO - Started process (PID=40871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:31:25.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:31:25.861+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:31:25.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:31:25.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:31:25.898+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:31:25.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:31:25.913+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:31:25.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:31:25.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-10T20:31:56.234+0000] {processor.py:157} INFO - Started process (PID=40881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:31:56.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:31:56.258+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:31:56.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:31:56.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:31:56.350+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:31:56.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:31:56.377+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:31:56.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:31:56.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.173 seconds
[2024-09-10T20:32:26.622+0000] {processor.py:157} INFO - Started process (PID=40891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:32:26.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:32:26.645+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:32:26.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:32:26.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:32:26.732+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:32:26.732+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:32:26.754+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:32:26.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:32:26.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-09-10T20:32:56.969+0000] {processor.py:157} INFO - Started process (PID=40901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:32:56.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:32:56.980+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:32:56.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:32:56.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:32:57.024+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:32:57.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:32:57.053+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:32:57.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:32:57.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-09-10T20:33:27.314+0000] {processor.py:157} INFO - Started process (PID=40911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:33:27.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:33:27.324+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:33:27.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:33:27.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:33:27.389+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:33:27.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:33:27.412+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:33:27.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:33:27.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-10T20:33:57.680+0000] {processor.py:157} INFO - Started process (PID=40921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:33:57.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:33:57.690+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:33:57.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:33:57.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:33:57.781+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:33:57.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:33:57.804+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:33:57.804+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:33:57.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-10T20:34:28.022+0000] {processor.py:157} INFO - Started process (PID=40931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:34:28.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:34:28.028+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:34:28.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:34:28.046+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:34:28.073+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:34:28.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:34:28.092+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:34:28.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:34:28.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-10T20:34:58.350+0000] {processor.py:157} INFO - Started process (PID=40941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:34:58.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:34:58.354+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:34:58.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:34:58.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:34:58.392+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:34:58.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:34:58.404+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:34:58.404+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:34:58.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T20:35:28.739+0000] {processor.py:157} INFO - Started process (PID=40950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:35:28.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:35:28.748+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:35:28.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:35:28.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:35:28.828+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:35:28.828+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:35:28.850+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:35:28.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:35:28.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-09-10T20:35:59.006+0000] {processor.py:157} INFO - Started process (PID=40961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:35:59.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:35:59.011+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:35:59.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:35:59.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:35:59.053+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:35:59.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:35:59.071+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:35:59.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:35:59.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T20:36:29.416+0000] {processor.py:157} INFO - Started process (PID=40971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:36:29.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:36:29.433+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:36:29.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:36:29.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:36:29.496+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:36:29.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:36:29.524+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:36:29.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:36:29.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-10T20:36:59.742+0000] {processor.py:157} INFO - Started process (PID=40981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:36:59.745+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:36:59.747+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:36:59.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:36:59.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:36:59.845+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:36:59.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:36:59.866+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:36:59.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:36:59.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.145 seconds
[2024-09-10T20:37:30.133+0000] {processor.py:157} INFO - Started process (PID=40991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:37:30.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:37:30.153+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:37:30.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:37:30.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:37:30.217+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:37:30.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:37:30.237+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:37:30.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:37:30.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-10T20:38:00.465+0000] {processor.py:157} INFO - Started process (PID=41001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:38:00.482+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:38:00.496+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:38:00.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:38:00.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:38:00.586+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:38:00.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:38:00.605+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:38:00.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:38:00.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.170 seconds
[2024-09-10T20:38:30.832+0000] {processor.py:157} INFO - Started process (PID=41011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:38:30.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:38:30.838+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:38:30.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:38:30.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:38:30.883+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:38:30.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:38:30.898+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:38:30.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:38:30.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-10T20:39:01.312+0000] {processor.py:157} INFO - Started process (PID=41021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:39:01.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:39:01.321+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:39:01.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:39:01.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:39:01.410+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:39:01.410+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:39:01.431+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:39:01.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:39:01.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-09-10T20:39:31.588+0000] {processor.py:157} INFO - Started process (PID=41031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:39:31.589+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:39:31.593+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:39:31.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:39:31.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:39:31.625+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:39:31.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:39:31.639+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:39:31.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:39:31.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T20:40:02.028+0000] {processor.py:157} INFO - Started process (PID=41041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:40:02.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:40:02.038+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:40:02.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:40:02.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:40:02.104+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:40:02.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:40:02.126+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:40:02.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:40:02.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-09-10T20:40:32.318+0000] {processor.py:157} INFO - Started process (PID=41051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:40:32.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:40:32.326+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:40:32.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:40:32.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:40:32.366+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:40:32.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:40:32.378+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:40:32.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:40:32.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-10T20:41:02.660+0000] {processor.py:157} INFO - Started process (PID=41061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:41:02.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:41:02.669+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:41:02.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:41:02.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:41:02.728+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:41:02.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:41:02.749+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:41:02.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:41:02.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-10T20:41:32.977+0000] {processor.py:157} INFO - Started process (PID=41071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:41:32.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:41:32.988+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:41:32.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:41:33.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:41:33.037+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:41:33.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:41:33.057+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:41:33.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:41:33.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-10T20:42:03.607+0000] {processor.py:157} INFO - Started process (PID=41081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:42:03.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:42:03.618+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:42:03.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:42:03.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:42:03.688+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:42:03.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:42:03.708+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:42:03.708+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:42:03.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-09-10T20:42:34.036+0000] {processor.py:157} INFO - Started process (PID=41090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:42:34.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:42:34.055+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:42:34.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:42:34.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:42:34.104+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:42:34.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:42:34.127+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:42:34.127+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:42:34.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-09-10T20:43:04.353+0000] {processor.py:157} INFO - Started process (PID=41101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:43:04.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:43:04.363+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:43:04.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:43:04.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:43:04.459+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:43:04.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:43:04.482+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:43:04.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:43:04.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-09-10T20:43:34.717+0000] {processor.py:157} INFO - Started process (PID=41111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:43:34.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:43:34.726+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:43:34.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:43:34.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:43:34.815+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:43:34.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:43:34.831+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:43:34.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:43:34.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-09-10T20:44:05.104+0000] {processor.py:157} INFO - Started process (PID=41121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:44:05.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:44:05.106+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:44:05.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:44:05.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:44:05.137+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:44:05.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:44:05.148+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:44:05.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:44:05.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T20:44:35.497+0000] {processor.py:157} INFO - Started process (PID=41131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:44:35.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:44:35.502+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:44:35.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:44:35.516+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:44:35.539+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:44:35.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:44:35.553+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:44:35.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:44:35.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-10T20:45:05.964+0000] {processor.py:157} INFO - Started process (PID=41141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:45:05.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:45:05.969+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:45:05.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:45:05.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:45:06.052+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:45:06.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:45:06.068+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:45:06.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:45:06.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-10T20:45:36.277+0000] {processor.py:157} INFO - Started process (PID=41151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:45:36.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:45:36.281+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:45:36.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:45:36.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:45:36.313+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:45:36.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:45:36.325+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:45:36.325+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:45:36.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T20:46:06.642+0000] {processor.py:157} INFO - Started process (PID=41161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:46:06.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:46:06.647+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:46:06.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:46:06.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:46:06.687+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:46:06.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:46:06.701+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:46:06.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:46:06.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T20:46:37.021+0000] {processor.py:157} INFO - Started process (PID=41171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:46:37.023+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:46:37.024+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:46:37.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:46:37.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:46:37.053+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:46:37.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:46:37.065+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:46:37.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:46:37.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T20:47:07.383+0000] {processor.py:157} INFO - Started process (PID=41181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:47:07.386+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:47:07.388+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:47:07.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:47:07.399+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:47:07.414+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:47:07.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:47:07.424+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:47:07.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:47:07.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T20:47:37.734+0000] {processor.py:157} INFO - Started process (PID=41191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:47:37.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:47:37.741+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:47:37.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:47:37.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:47:37.777+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:47:37.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:47:37.790+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:47:37.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:47:37.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T20:48:08.071+0000] {processor.py:157} INFO - Started process (PID=41201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:48:08.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:48:08.074+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:48:08.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:48:08.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:48:08.101+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:48:08.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:48:08.113+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:48:08.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:48:08.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T20:48:38.415+0000] {processor.py:157} INFO - Started process (PID=41211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:48:38.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:48:38.421+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:48:38.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:48:38.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:48:38.455+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:48:38.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:48:38.467+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:48:38.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:48:38.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T20:49:08.729+0000] {processor.py:157} INFO - Started process (PID=41221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:49:08.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:49:08.733+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:49:08.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:49:08.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:49:08.761+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:49:08.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:49:08.771+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:49:08.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:49:08.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T20:49:39.134+0000] {processor.py:157} INFO - Started process (PID=41231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:49:39.134+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:49:39.137+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:49:39.136+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:49:39.146+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:49:39.163+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:49:39.163+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:49:39.175+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:49:39.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:49:39.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T20:50:09.496+0000] {processor.py:157} INFO - Started process (PID=41241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:50:09.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:50:09.501+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:50:09.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:50:09.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:50:09.526+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:50:09.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:50:09.536+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:50:09.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:50:09.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T20:50:39.857+0000] {processor.py:157} INFO - Started process (PID=41251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:50:39.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:50:39.861+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:50:39.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:50:39.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:50:39.889+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:50:39.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:50:39.902+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:50:39.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:50:39.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T20:51:10.251+0000] {processor.py:157} INFO - Started process (PID=41261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:51:10.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:51:10.258+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:51:10.258+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:51:10.272+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:51:10.294+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:51:10.294+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:51:10.307+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:51:10.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:51:10.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T20:51:40.545+0000] {processor.py:157} INFO - Started process (PID=41271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:51:40.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:51:40.547+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:51:40.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:51:40.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:51:40.576+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:51:40.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:51:40.585+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:51:40.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:51:40.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T20:52:10.932+0000] {processor.py:157} INFO - Started process (PID=41281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:52:10.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:52:10.935+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:52:10.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:52:10.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:52:10.960+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:52:10.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:52:10.970+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:52:10.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:52:10.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T20:52:41.316+0000] {processor.py:157} INFO - Started process (PID=41291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:52:41.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:52:41.321+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:52:41.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:52:41.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:52:41.364+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:52:41.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:52:41.377+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:52:41.377+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:52:41.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-10T20:53:11.571+0000] {processor.py:157} INFO - Started process (PID=41301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:53:11.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:53:11.573+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:53:11.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:53:11.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:53:11.599+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:53:11.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:53:11.608+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:53:11.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:53:11.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T20:53:41.938+0000] {processor.py:157} INFO - Started process (PID=41311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:53:41.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:53:41.942+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:53:41.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:53:41.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:53:41.973+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:53:41.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:53:41.983+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:53:41.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:53:41.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T20:54:12.314+0000] {processor.py:157} INFO - Started process (PID=41321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:54:12.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:54:12.319+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:54:12.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:54:12.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:54:12.349+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:54:12.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:54:12.360+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:54:12.360+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:54:12.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T20:54:42.622+0000] {processor.py:157} INFO - Started process (PID=41331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:54:42.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:54:42.627+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:54:42.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:54:42.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:54:42.664+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:54:42.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:54:42.678+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:54:42.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:54:42.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T20:55:12.998+0000] {processor.py:157} INFO - Started process (PID=41341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:55:13.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:55:13.002+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:55:13.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:55:13.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:55:13.032+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:55:13.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:55:13.045+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:55:13.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:55:13.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T20:55:43.408+0000] {processor.py:157} INFO - Started process (PID=41351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:55:43.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:55:43.411+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:55:43.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:55:43.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:55:43.444+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:55:43.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:55:43.453+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:55:43.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:55:43.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T20:56:13.756+0000] {processor.py:157} INFO - Started process (PID=41361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:56:13.758+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:56:13.760+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:56:13.760+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:56:13.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:56:13.787+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:56:13.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:56:13.797+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:56:13.797+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:56:13.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T20:56:44.161+0000] {processor.py:157} INFO - Started process (PID=41371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:56:44.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:56:44.163+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:56:44.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:56:44.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:56:44.189+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:56:44.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:56:44.199+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:56:44.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:56:44.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T20:57:14.582+0000] {processor.py:157} INFO - Started process (PID=41381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:57:14.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:57:14.587+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:57:14.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:57:14.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:57:14.622+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:57:14.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:57:14.638+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:57:14.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:57:14.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T20:57:44.924+0000] {processor.py:157} INFO - Started process (PID=41391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:57:44.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:57:44.928+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:57:44.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:57:44.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:57:44.952+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:57:44.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:57:44.963+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:57:44.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:57:44.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T20:58:15.236+0000] {processor.py:157} INFO - Started process (PID=41401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:58:15.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:58:15.238+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:58:15.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:58:15.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:58:15.266+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:58:15.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:58:15.276+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:58:15.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:58:15.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T20:58:45.609+0000] {processor.py:157} INFO - Started process (PID=41411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:58:45.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:58:45.612+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:58:45.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:58:45.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:58:45.638+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:58:45.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:58:45.650+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:58:45.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:58:45.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T20:59:15.990+0000] {processor.py:157} INFO - Started process (PID=41421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:59:15.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:59:15.994+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:59:15.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:59:16.007+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:59:16.021+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:59:16.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:59:16.034+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:59:16.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:59:16.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T20:59:46.401+0000] {processor.py:157} INFO - Started process (PID=41431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:59:46.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T20:59:46.405+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:59:46.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:59:46.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T20:59:46.436+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:59:46.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T20:59:46.445+0000] {logging_mixin.py:151} INFO - [2024-09-10T20:59:46.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T20:59:46.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T21:00:16.804+0000] {processor.py:157} INFO - Started process (PID=41441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:00:16.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:00:16.807+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:00:16.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:00:16.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:00:16.840+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:00:16.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:00:16.855+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:00:16.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:00:16.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T21:00:47.316+0000] {processor.py:157} INFO - Started process (PID=41450) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:00:47.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:00:47.318+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:00:47.318+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:00:47.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:00:47.347+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:00:47.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:00:47.356+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:00:47.356+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:00:47.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T21:01:17.683+0000] {processor.py:157} INFO - Started process (PID=41461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:01:17.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:01:17.686+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:01:17.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:01:17.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:01:17.716+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:01:17.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:01:17.727+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:01:17.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:01:17.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T21:01:48.027+0000] {processor.py:157} INFO - Started process (PID=41471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:01:48.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:01:48.029+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:01:48.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:01:48.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:01:48.051+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:01:48.051+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:01:48.061+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:01:48.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:01:48.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-10T21:02:18.418+0000] {processor.py:157} INFO - Started process (PID=41481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:02:18.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:02:18.422+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:02:18.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:02:18.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:02:18.447+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:02:18.447+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:02:18.457+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:02:18.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:02:18.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T21:02:48.805+0000] {processor.py:157} INFO - Started process (PID=41491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:02:48.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:02:48.809+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:02:48.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:02:48.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:02:48.846+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:02:48.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:02:48.858+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:02:48.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:02:48.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T21:03:19.218+0000] {processor.py:157} INFO - Started process (PID=41501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:03:19.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:03:19.222+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:03:19.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:03:19.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:03:19.247+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:03:19.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:03:19.257+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:03:19.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:03:19.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T21:03:49.598+0000] {processor.py:157} INFO - Started process (PID=41511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:03:49.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:03:49.602+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:03:49.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:03:49.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:03:49.627+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:03:49.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:03:49.637+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:03:49.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:03:49.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T21:04:19.917+0000] {processor.py:157} INFO - Started process (PID=41521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:04:19.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:04:19.922+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:04:19.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:04:19.932+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:04:19.949+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:04:19.949+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:04:19.959+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:04:19.959+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:04:19.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T21:04:50.253+0000] {processor.py:157} INFO - Started process (PID=41531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:04:50.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:04:50.257+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:04:50.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:04:50.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:04:50.281+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:04:50.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:04:50.290+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:04:50.290+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:04:50.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T21:05:20.725+0000] {processor.py:157} INFO - Started process (PID=41541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:05:20.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:05:20.728+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:05:20.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:05:20.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:05:20.753+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:05:20.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:05:20.763+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:05:20.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:05:20.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T21:05:51.171+0000] {processor.py:157} INFO - Started process (PID=41551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:05:51.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:05:51.174+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:05:51.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:05:51.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:05:51.195+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:05:51.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:05:51.207+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:05:51.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:05:51.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-10T21:06:21.500+0000] {processor.py:157} INFO - Started process (PID=41561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:06:21.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:06:21.506+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:06:21.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:06:21.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:06:21.540+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:06:21.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:06:21.552+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:06:21.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:06:21.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T21:06:51.784+0000] {processor.py:157} INFO - Started process (PID=41571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:06:51.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:06:51.789+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:06:51.789+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:06:51.799+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:06:51.817+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:06:51.817+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:06:51.827+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:06:51.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:06:51.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T21:07:22.139+0000] {processor.py:157} INFO - Started process (PID=41581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:07:22.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:07:22.142+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:07:22.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:07:22.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:07:22.170+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:07:22.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:07:22.181+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:07:22.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:07:22.189+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T21:07:52.561+0000] {processor.py:157} INFO - Started process (PID=41591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:07:52.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:07:52.565+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:07:52.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:07:52.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:07:52.602+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:07:52.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:07:52.616+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:07:52.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:07:52.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T21:08:22.905+0000] {processor.py:157} INFO - Started process (PID=41601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:08:22.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:08:22.909+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:08:22.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:08:22.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:08:22.939+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:08:22.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:08:22.951+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:08:22.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:08:22.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T21:08:53.300+0000] {processor.py:157} INFO - Started process (PID=41611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:08:53.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:08:53.303+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:08:53.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:08:53.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:08:53.330+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:08:53.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:08:53.340+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:08:53.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:08:53.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T21:09:23.678+0000] {processor.py:157} INFO - Started process (PID=41621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:09:23.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:09:23.682+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:09:23.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:09:23.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:09:23.707+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:09:23.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:09:23.718+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:09:23.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:09:23.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T21:09:54.019+0000] {processor.py:157} INFO - Started process (PID=41631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:09:54.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:09:54.023+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:09:54.023+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:09:54.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:09:54.058+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:09:54.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:09:54.071+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:09:54.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:09:54.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T21:10:24.377+0000] {processor.py:157} INFO - Started process (PID=41640) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:10:24.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:10:24.381+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:10:24.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:10:24.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:10:24.417+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:10:24.417+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:10:24.428+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:10:24.428+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:10:24.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T21:10:54.726+0000] {processor.py:157} INFO - Started process (PID=41651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:10:54.726+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:10:54.728+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:10:54.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:10:54.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:10:54.753+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:10:54.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:10:54.764+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:10:54.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:10:54.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T21:11:25.100+0000] {processor.py:157} INFO - Started process (PID=41661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:11:25.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:11:25.103+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:11:25.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:11:25.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:11:25.126+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:11:25.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:11:25.136+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:11:25.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:11:25.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T21:11:55.586+0000] {processor.py:157} INFO - Started process (PID=41671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:11:55.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:11:55.592+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:11:55.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:11:55.610+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:11:55.636+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:11:55.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:11:55.655+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:11:55.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:11:55.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-10T21:12:25.871+0000] {processor.py:157} INFO - Started process (PID=41681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:12:25.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:12:25.873+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:12:25.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:12:25.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:12:25.899+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:12:25.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:12:25.911+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:12:25.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:12:25.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T21:12:56.382+0000] {processor.py:157} INFO - Started process (PID=41690) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:12:56.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:12:56.386+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:12:56.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:12:56.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:12:56.425+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:12:56.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:12:56.444+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:12:56.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:12:56.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T21:13:26.701+0000] {processor.py:157} INFO - Started process (PID=41701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:13:26.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:13:26.705+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:13:26.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:13:26.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:13:26.730+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:13:26.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:13:26.742+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:13:26.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:13:26.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T21:13:57.074+0000] {processor.py:157} INFO - Started process (PID=41711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:13:57.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:13:57.077+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:13:57.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:13:57.086+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:13:57.101+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:13:57.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:13:57.111+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:13:57.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:13:57.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T21:14:27.561+0000] {processor.py:157} INFO - Started process (PID=41721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:14:27.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:14:27.565+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:14:27.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:14:27.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:14:27.595+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:14:27.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:14:27.607+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:14:27.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:14:27.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T21:14:58.010+0000] {processor.py:157} INFO - Started process (PID=41731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:14:58.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:14:58.016+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:14:58.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:14:58.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:14:58.055+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:14:58.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:14:58.068+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:14:58.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:14:58.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-10T21:15:28.469+0000] {processor.py:157} INFO - Started process (PID=41741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:15:28.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:15:28.472+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:15:28.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:15:28.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:15:28.500+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:15:28.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:15:28.510+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:15:28.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:15:28.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T21:15:58.828+0000] {processor.py:157} INFO - Started process (PID=41751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:15:58.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:15:58.830+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:15:58.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:15:58.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:15:58.855+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:15:58.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:15:58.866+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:15:58.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:15:58.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T21:16:29.200+0000] {processor.py:157} INFO - Started process (PID=41761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:16:29.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:16:29.203+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:16:29.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:16:29.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:16:29.228+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:16:29.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:16:29.238+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:16:29.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:16:29.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T21:16:59.729+0000] {processor.py:157} INFO - Started process (PID=41771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:16:59.732+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:16:59.735+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:16:59.734+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:16:59.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:16:59.786+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:16:59.786+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:16:59.799+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:16:59.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:16:59.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T21:17:30.045+0000] {processor.py:157} INFO - Started process (PID=41781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:17:30.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:17:30.049+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:17:30.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:17:30.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:17:30.076+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:17:30.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:17:30.087+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:17:30.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:17:30.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T21:18:00.463+0000] {processor.py:157} INFO - Started process (PID=41791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:18:00.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:18:00.465+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:18:00.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:18:00.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:18:00.501+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:18:00.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:18:00.513+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:18:00.513+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:18:00.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T21:18:30.918+0000] {processor.py:157} INFO - Started process (PID=41801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:18:30.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:18:30.920+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:18:30.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:18:30.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:18:30.946+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:18:30.946+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:18:30.956+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:18:30.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:18:30.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T21:19:01.320+0000] {processor.py:157} INFO - Started process (PID=41811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:19:01.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:19:01.323+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:19:01.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:19:01.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:19:01.350+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:19:01.349+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:19:01.363+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:19:01.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:19:01.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T21:19:31.751+0000] {processor.py:157} INFO - Started process (PID=41821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:19:31.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:19:31.755+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:19:31.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:19:31.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:19:31.790+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:19:31.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:19:31.802+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:19:31.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:19:31.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T21:20:02.057+0000] {processor.py:157} INFO - Started process (PID=41831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:20:02.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:20:02.060+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:20:02.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:20:02.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:20:02.086+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:20:02.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:20:02.096+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:20:02.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:20:02.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T21:20:32.397+0000] {processor.py:157} INFO - Started process (PID=41841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:20:32.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:20:32.399+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:20:32.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:20:32.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:20:32.427+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:20:32.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:20:32.439+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:20:32.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:20:32.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T21:21:02.833+0000] {processor.py:157} INFO - Started process (PID=41851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:21:02.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:21:02.839+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:21:02.839+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:21:02.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:21:02.881+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:21:02.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:21:02.893+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:21:02.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:21:02.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-10T21:21:33.160+0000] {processor.py:157} INFO - Started process (PID=41861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:21:33.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:21:33.163+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:21:33.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:21:33.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:21:33.190+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:21:33.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:21:33.200+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:21:33.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:21:33.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T21:22:03.571+0000] {processor.py:157} INFO - Started process (PID=41871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:22:03.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:22:03.576+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:22:03.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:22:03.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:22:03.627+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:22:03.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:22:03.640+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:22:03.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:22:03.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-10T21:22:33.953+0000] {processor.py:157} INFO - Started process (PID=41881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:22:33.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:22:33.960+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:22:33.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:22:33.974+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:22:33.997+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:22:33.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:22:34.009+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:22:34.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:22:34.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T21:23:04.281+0000] {processor.py:157} INFO - Started process (PID=41891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:23:04.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:23:04.284+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:23:04.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:23:04.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:23:04.310+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:23:04.310+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:23:04.319+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:23:04.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:23:04.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T21:23:34.713+0000] {processor.py:157} INFO - Started process (PID=41901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:23:34.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:23:34.719+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:23:34.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:23:34.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:23:34.760+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:23:34.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:23:34.773+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:23:34.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:23:34.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-09-10T21:24:05.101+0000] {processor.py:157} INFO - Started process (PID=41911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:24:05.102+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:24:05.103+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:24:05.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:24:05.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:24:05.128+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:24:05.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:24:05.139+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:24:05.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:24:05.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T21:24:35.508+0000] {processor.py:157} INFO - Started process (PID=41921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:24:35.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:24:35.514+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:24:35.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:24:35.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:24:35.548+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:24:35.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:24:35.560+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:24:35.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:24:35.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T21:25:06.005+0000] {processor.py:157} INFO - Started process (PID=41931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:25:06.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:25:06.009+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:25:06.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:25:06.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:25:06.035+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:25:06.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:25:06.045+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:25:06.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:25:06.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T21:25:36.367+0000] {processor.py:157} INFO - Started process (PID=41941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:25:36.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:25:36.369+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:25:36.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:25:36.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:25:36.396+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:25:36.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:25:36.405+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:25:36.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:25:36.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T21:26:06.826+0000] {processor.py:157} INFO - Started process (PID=41951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:26:06.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:26:06.831+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:26:06.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:26:06.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:26:06.866+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:26:06.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:26:06.877+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:26:06.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:26:06.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T21:26:37.227+0000] {processor.py:157} INFO - Started process (PID=41961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:26:37.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:26:37.229+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:26:37.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:26:37.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:26:37.251+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:26:37.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:26:37.259+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:26:37.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:26:37.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.041 seconds
[2024-09-10T21:27:07.686+0000] {processor.py:157} INFO - Started process (PID=41971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:27:07.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:27:07.689+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:27:07.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:27:07.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:27:07.723+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:27:07.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:27:07.735+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:27:07.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:27:07.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T21:27:38.019+0000] {processor.py:157} INFO - Started process (PID=41981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:27:38.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:27:38.024+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:27:38.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:27:38.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:27:38.048+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:27:38.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:27:38.059+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:27:38.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:27:38.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T21:28:08.501+0000] {processor.py:157} INFO - Started process (PID=41991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:28:08.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:28:08.504+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:28:08.503+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:28:08.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:28:08.531+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:28:08.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:28:08.543+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:28:08.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:28:08.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T21:28:38.966+0000] {processor.py:157} INFO - Started process (PID=42001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:28:38.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:28:38.970+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:28:38.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:28:38.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:28:39.007+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:28:39.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:28:39.019+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:28:39.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:28:39.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T21:29:09.292+0000] {processor.py:157} INFO - Started process (PID=42011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:29:09.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:29:09.295+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:29:09.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:29:09.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:29:09.322+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:29:09.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:29:09.335+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:29:09.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:29:09.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T21:29:39.687+0000] {processor.py:157} INFO - Started process (PID=42021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:29:39.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:29:39.692+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:29:39.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:29:39.709+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:29:39.745+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:29:39.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:29:39.760+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:29:39.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:29:39.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-10T21:30:10.028+0000] {processor.py:157} INFO - Started process (PID=42031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:30:10.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:30:10.033+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:30:10.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:30:10.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:30:10.059+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:30:10.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:30:10.070+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:30:10.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:30:10.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T21:30:40.392+0000] {processor.py:157} INFO - Started process (PID=42041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:30:40.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:30:40.398+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:30:40.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:30:40.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:30:40.502+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:30:40.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:30:40.523+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:30:40.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:30:40.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.147 seconds
[2024-09-10T21:31:10.729+0000] {processor.py:157} INFO - Started process (PID=42051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:31:10.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:31:10.736+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:31:10.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:31:10.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:31:10.805+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:31:10.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:31:10.826+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:31:10.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:31:10.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-10T21:31:41.091+0000] {processor.py:157} INFO - Started process (PID=42061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:31:41.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:31:41.097+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:31:41.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:31:41.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:31:41.129+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:31:41.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:31:41.139+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:31:41.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:31:41.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T21:32:11.483+0000] {processor.py:157} INFO - Started process (PID=42071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:32:11.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:32:11.489+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:32:11.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:32:11.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:32:11.531+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:32:11.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:32:11.545+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:32:11.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:32:11.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-10T21:32:41.780+0000] {processor.py:157} INFO - Started process (PID=42081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:32:41.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:32:41.784+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:32:41.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:32:41.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:32:41.811+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:32:41.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:32:41.825+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:32:41.825+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:32:41.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T21:33:12.149+0000] {processor.py:157} INFO - Started process (PID=42090) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:33:12.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:33:12.153+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:33:12.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:33:12.185+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:33:12.212+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:33:12.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:33:12.223+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:33:12.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:33:12.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T21:33:42.481+0000] {processor.py:157} INFO - Started process (PID=42101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:33:42.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:33:42.484+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:33:42.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:33:42.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:33:42.515+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:33:42.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:33:42.536+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:33:42.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:33:42.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-10T21:34:12.789+0000] {processor.py:157} INFO - Started process (PID=42111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:34:12.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:34:12.795+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:34:12.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:34:12.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:34:12.829+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:34:12.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:34:12.838+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:34:12.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:34:12.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T21:34:43.130+0000] {processor.py:157} INFO - Started process (PID=42121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:34:43.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:34:43.138+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:34:43.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:34:43.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:34:43.170+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:34:43.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:34:43.183+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:34:43.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:34:43.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T21:35:13.473+0000] {processor.py:157} INFO - Started process (PID=42131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:35:13.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:35:13.478+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:35:13.478+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:35:13.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:35:13.511+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:35:13.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:35:13.520+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:35:13.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:35:13.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T21:35:43.795+0000] {processor.py:157} INFO - Started process (PID=42141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:35:43.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:35:43.797+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:35:43.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:35:43.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:35:43.823+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:35:43.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:35:43.834+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:35:43.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:35:43.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T21:36:14.151+0000] {processor.py:157} INFO - Started process (PID=42151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:36:14.153+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:36:14.155+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:36:14.155+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:36:14.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:36:14.192+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:36:14.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:36:14.205+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:36:14.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:36:14.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T21:36:44.560+0000] {processor.py:157} INFO - Started process (PID=42161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:36:44.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:36:44.563+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:36:44.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:36:44.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:36:44.590+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:36:44.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:36:44.605+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:36:44.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:36:44.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T21:37:14.873+0000] {processor.py:157} INFO - Started process (PID=42171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:37:14.874+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:37:14.875+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:37:14.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:37:14.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:37:14.903+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:37:14.903+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:37:14.913+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:37:14.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:37:14.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T21:37:45.244+0000] {processor.py:157} INFO - Started process (PID=42181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:37:45.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:37:45.248+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:37:45.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:37:45.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:37:45.275+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:37:45.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:37:45.286+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:37:45.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:37:45.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T21:38:15.516+0000] {processor.py:157} INFO - Started process (PID=42191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:38:15.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:38:15.519+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:38:15.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:38:15.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:38:15.551+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:38:15.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:38:15.561+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:38:15.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:38:15.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T21:38:45.900+0000] {processor.py:157} INFO - Started process (PID=42201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:38:45.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:38:45.904+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:38:45.904+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:38:45.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:38:45.933+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:38:45.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:38:45.948+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:38:45.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:38:45.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T21:39:16.249+0000] {processor.py:157} INFO - Started process (PID=42211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:39:16.251+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:39:16.253+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:39:16.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:39:16.265+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:39:16.280+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:39:16.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:39:16.291+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:39:16.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:39:16.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T21:39:46.658+0000] {processor.py:157} INFO - Started process (PID=42221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:39:46.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:39:46.661+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:39:46.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:39:46.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:39:46.688+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:39:46.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:39:46.698+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:39:46.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:39:46.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T21:40:17.072+0000] {processor.py:157} INFO - Started process (PID=42230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:40:17.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:40:17.077+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:40:17.077+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:40:17.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:40:17.109+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:40:17.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:40:17.119+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:40:17.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:40:17.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T21:40:47.508+0000] {processor.py:157} INFO - Started process (PID=42241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:40:47.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:40:47.515+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:40:47.515+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:40:47.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:40:47.544+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:40:47.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:40:47.557+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:40:47.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:40:47.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T21:41:17.806+0000] {processor.py:157} INFO - Started process (PID=42251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:41:17.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:41:17.810+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:41:17.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:41:17.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:41:17.839+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:41:17.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:41:17.848+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:41:17.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:41:17.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T21:41:48.178+0000] {processor.py:157} INFO - Started process (PID=42261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:41:48.180+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:41:48.184+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:41:48.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:41:48.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:41:48.217+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:41:48.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:41:48.228+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:41:48.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:41:48.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T21:42:18.597+0000] {processor.py:157} INFO - Started process (PID=42271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:42:18.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:42:18.601+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:42:18.601+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:42:18.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:42:18.629+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:42:18.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:42:18.642+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:42:18.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:42:18.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T21:42:48.947+0000] {processor.py:157} INFO - Started process (PID=42279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:42:48.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:42:48.955+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:42:48.954+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:42:48.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:42:49.010+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:42:49.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:42:49.024+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:42:49.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:42:49.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-10T21:43:19.277+0000] {processor.py:157} INFO - Started process (PID=42291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:43:19.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:43:19.281+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:43:19.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:43:19.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:43:19.321+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:43:19.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:43:19.334+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:43:19.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:43:19.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T21:43:49.694+0000] {processor.py:157} INFO - Started process (PID=42301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:43:49.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:43:49.706+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:43:49.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:43:49.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:43:49.757+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:43:49.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:43:49.777+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:43:49.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:43:49.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-10T21:44:20.037+0000] {processor.py:157} INFO - Started process (PID=42311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:44:20.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:44:20.045+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:44:20.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:44:20.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:44:20.099+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:44:20.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:44:20.111+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:44:20.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:44:20.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-10T21:44:50.357+0000] {processor.py:157} INFO - Started process (PID=42321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:44:50.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:44:50.361+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:44:50.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:44:50.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:44:50.396+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:44:50.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:44:50.410+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:44:50.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:44:50.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T21:45:20.797+0000] {processor.py:157} INFO - Started process (PID=42331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:45:20.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:45:20.802+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:45:20.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:45:20.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:45:20.835+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:45:20.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:45:20.848+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:45:20.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:45:20.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T21:45:51.120+0000] {processor.py:157} INFO - Started process (PID=42341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:45:51.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:45:51.123+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:45:51.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:45:51.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:45:51.149+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:45:51.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:45:51.159+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:45:51.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:45:51.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T21:46:21.486+0000] {processor.py:157} INFO - Started process (PID=42351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:46:21.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:46:21.488+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:46:21.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:46:21.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:46:21.522+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:46:21.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:46:21.536+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:46:21.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:46:21.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T21:46:51.849+0000] {processor.py:157} INFO - Started process (PID=42361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:46:51.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:46:51.852+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:46:51.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:46:51.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:46:51.882+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:46:51.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:46:51.891+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:46:51.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:46:51.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T21:47:22.210+0000] {processor.py:157} INFO - Started process (PID=42371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:47:22.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:47:22.219+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:47:22.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:47:22.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:47:22.256+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:47:22.256+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:47:22.268+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:47:22.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:47:22.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-10T21:47:52.561+0000] {processor.py:157} INFO - Started process (PID=42381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:47:52.562+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:47:52.563+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:47:52.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:47:52.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:47:52.591+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:47:52.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:47:52.602+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:47:52.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:47:52.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T21:48:23.002+0000] {processor.py:157} INFO - Started process (PID=42390) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:48:23.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:48:23.007+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:48:23.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:48:23.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:48:23.072+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:48:23.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:48:23.084+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:48:23.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:48:23.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-10T21:48:53.317+0000] {processor.py:157} INFO - Started process (PID=42401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:48:53.318+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:48:53.320+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:48:53.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:48:53.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:48:53.352+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:48:53.351+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:48:53.362+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:48:53.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:48:53.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T21:49:23.796+0000] {processor.py:157} INFO - Started process (PID=42411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:49:23.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:49:23.801+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:49:23.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:49:23.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:49:23.833+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:49:23.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:49:23.844+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:49:23.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:49:23.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T21:49:54.165+0000] {processor.py:157} INFO - Started process (PID=42421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:49:54.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:49:54.169+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:49:54.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:49:54.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:49:54.204+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:49:54.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:49:54.217+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:49:54.217+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:49:54.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-10T21:50:24.577+0000] {processor.py:157} INFO - Started process (PID=42431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:50:24.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:50:24.582+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:50:24.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:50:24.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:50:24.620+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:50:24.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:50:24.631+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:50:24.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:50:24.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-10T21:50:54.862+0000] {processor.py:157} INFO - Started process (PID=42441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:50:54.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:50:54.865+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:50:54.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:50:54.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:50:54.898+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:50:54.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:50:54.911+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:50:54.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:50:54.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T21:51:25.223+0000] {processor.py:157} INFO - Started process (PID=42451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:51:25.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:51:25.230+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:51:25.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:51:25.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:51:25.272+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:51:25.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:51:25.284+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:51:25.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:51:25.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-10T21:51:55.571+0000] {processor.py:157} INFO - Started process (PID=42461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:51:55.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:51:55.575+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:51:55.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:51:55.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:51:55.602+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:51:55.602+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:51:55.614+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:51:55.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:51:55.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T21:52:26.026+0000] {processor.py:157} INFO - Started process (PID=42471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:52:26.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:52:26.032+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:52:26.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:52:26.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:52:26.070+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:52:26.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:52:26.085+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:52:26.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:52:26.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T21:52:56.391+0000] {processor.py:157} INFO - Started process (PID=42481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:52:56.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:52:56.401+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:52:56.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:52:56.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:52:56.445+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:52:56.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:52:56.458+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:52:56.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:52:56.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-10T21:53:26.806+0000] {processor.py:157} INFO - Started process (PID=42491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:53:26.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:53:26.810+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:53:26.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:53:26.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:53:26.833+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:53:26.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:53:26.843+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:53:26.843+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:53:26.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T21:53:57.269+0000] {processor.py:157} INFO - Started process (PID=42501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:53:57.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:53:57.284+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:53:57.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:53:57.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:53:57.330+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:53:57.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:53:57.344+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:53:57.344+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:53:57.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-10T21:54:27.634+0000] {processor.py:157} INFO - Started process (PID=42511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:54:27.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:54:27.637+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:54:27.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:54:27.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:54:27.664+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:54:27.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:54:27.675+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:54:27.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:54:27.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T21:54:58.078+0000] {processor.py:157} INFO - Started process (PID=42521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:54:58.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:54:58.082+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:54:58.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:54:58.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:54:58.137+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:54:58.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:54:58.150+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:54:58.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:54:58.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-10T21:55:28.471+0000] {processor.py:157} INFO - Started process (PID=42531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:55:28.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:55:28.473+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:55:28.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:55:28.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:55:28.501+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:55:28.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:55:28.509+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:55:28.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:55:28.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T21:55:58.852+0000] {processor.py:157} INFO - Started process (PID=42541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:55:58.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:55:58.858+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:55:58.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:55:58.871+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:55:58.895+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:55:58.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:55:58.907+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:55:58.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:55:58.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T21:56:29.278+0000] {processor.py:157} INFO - Started process (PID=42551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:56:29.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:56:29.281+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:56:29.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:56:29.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:56:29.314+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:56:29.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:56:29.328+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:56:29.328+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:56:29.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T21:56:59.744+0000] {processor.py:157} INFO - Started process (PID=42561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:56:59.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:56:59.749+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:56:59.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:56:59.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:56:59.783+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:56:59.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:56:59.795+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:56:59.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:56:59.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T21:57:30.078+0000] {processor.py:157} INFO - Started process (PID=42571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:57:30.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:57:30.082+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:57:30.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:57:30.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:57:30.107+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:57:30.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:57:30.117+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:57:30.117+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:57:30.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T21:58:00.488+0000] {processor.py:157} INFO - Started process (PID=42581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:58:00.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:58:00.494+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:58:00.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:58:00.509+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:58:00.544+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:58:00.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:58:00.558+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:58:00.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:58:00.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-10T21:58:30.774+0000] {processor.py:157} INFO - Started process (PID=42591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:58:30.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:58:30.777+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:58:30.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:58:30.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:58:30.802+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:58:30.802+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:58:30.812+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:58:30.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:58:30.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T21:59:01.285+0000] {processor.py:157} INFO - Started process (PID=42601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:59:01.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:59:01.291+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:59:01.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:59:01.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:59:01.337+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:59:01.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:59:01.365+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:59:01.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:59:01.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-09-10T21:59:31.610+0000] {processor.py:157} INFO - Started process (PID=42611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:59:31.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T21:59:31.613+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:59:31.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:59:31.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T21:59:31.639+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:59:31.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T21:59:31.654+0000] {logging_mixin.py:151} INFO - [2024-09-10T21:59:31.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T21:59:31.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T22:00:02.010+0000] {processor.py:157} INFO - Started process (PID=42621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:00:02.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:00:02.015+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:00:02.015+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:00:02.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:00:02.063+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:00:02.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:00:02.077+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:00:02.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:00:02.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-09-10T22:00:32.367+0000] {processor.py:157} INFO - Started process (PID=42631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:00:32.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:00:32.370+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:00:32.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:00:32.381+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:00:32.396+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:00:32.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:00:32.405+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:00:32.405+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:00:32.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T22:01:02.830+0000] {processor.py:157} INFO - Started process (PID=42641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:01:02.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:01:02.835+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:01:02.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:01:02.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:01:02.883+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:01:02.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:01:02.897+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:01:02.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:01:02.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T22:01:33.214+0000] {processor.py:157} INFO - Started process (PID=42651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:01:33.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:01:33.220+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:01:33.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:01:33.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:01:33.258+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:01:33.258+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:01:33.271+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:01:33.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:01:33.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T22:02:03.615+0000] {processor.py:157} INFO - Started process (PID=42661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:02:03.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:02:03.618+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:02:03.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:02:03.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:02:03.645+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:02:03.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:02:03.654+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:02:03.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:02:03.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T22:02:33.994+0000] {processor.py:157} INFO - Started process (PID=42670) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:02:33.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:02:33.999+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:02:33.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:02:34.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:02:34.039+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:02:34.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:02:34.062+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:02:34.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:02:34.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-10T22:03:04.347+0000] {processor.py:157} INFO - Started process (PID=42681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:03:04.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:03:04.351+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:03:04.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:03:04.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:03:04.380+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:03:04.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:03:04.390+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:03:04.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:03:04.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T22:03:34.843+0000] {processor.py:157} INFO - Started process (PID=42689) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:03:34.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:03:34.848+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:03:34.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:03:34.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:03:34.894+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:03:34.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:03:34.907+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:03:34.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:03:34.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-10T22:04:05.237+0000] {processor.py:157} INFO - Started process (PID=42701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:04:05.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:04:05.240+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:04:05.240+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:04:05.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:04:05.270+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:04:05.270+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:04:05.281+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:04:05.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:04:05.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T22:04:35.613+0000] {processor.py:157} INFO - Started process (PID=42711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:04:35.617+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:04:35.621+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:04:35.620+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:04:35.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:04:35.656+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:04:35.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:04:35.669+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:04:35.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:04:35.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T22:05:06.041+0000] {processor.py:157} INFO - Started process (PID=42721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:05:06.044+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:05:06.047+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:05:06.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:05:06.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:05:06.101+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:05:06.101+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:05:06.113+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:05:06.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:05:06.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-10T22:05:36.358+0000] {processor.py:157} INFO - Started process (PID=42731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:05:36.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:05:36.361+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:05:36.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:05:36.369+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:05:36.386+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:05:36.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:05:36.399+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:05:36.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:05:36.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T22:06:06.718+0000] {processor.py:157} INFO - Started process (PID=42741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:06:06.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:06:06.721+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:06:06.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:06:06.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:06:06.760+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:06:06.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:06:06.774+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:06:06.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:06:06.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T22:06:37.001+0000] {processor.py:157} INFO - Started process (PID=42751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:06:37.006+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:06:37.008+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:06:37.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:06:37.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:06:37.032+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:06:37.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:06:37.042+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:06:37.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:06:37.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T22:07:07.383+0000] {processor.py:157} INFO - Started process (PID=42761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:07:07.385+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:07:07.387+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:07:07.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:07:07.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:07:07.425+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:07:07.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:07:07.439+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:07:07.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:07:07.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T22:07:37.794+0000] {processor.py:157} INFO - Started process (PID=42771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:07:37.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:07:37.797+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:07:37.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:07:37.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:07:37.830+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:07:37.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:07:37.842+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:07:37.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:07:37.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T22:08:08.124+0000] {processor.py:157} INFO - Started process (PID=42781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:08:08.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:08:08.127+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:08:08.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:08:08.142+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:08:08.158+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:08:08.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:08:08.168+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:08:08.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:08:08.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T22:08:38.538+0000] {processor.py:157} INFO - Started process (PID=42791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:08:38.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:08:38.542+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:08:38.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:08:38.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:08:38.572+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:08:38.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:08:38.584+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:08:38.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:08:38.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T22:09:08.966+0000] {processor.py:157} INFO - Started process (PID=42801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:09:08.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:09:08.971+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:09:08.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:09:09.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:09:09.032+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:09:09.032+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:09:09.041+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:09:09.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:09:09.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-10T22:09:39.406+0000] {processor.py:157} INFO - Started process (PID=42811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:09:39.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:09:39.412+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:09:39.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:09:39.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:09:39.464+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:09:39.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:09:39.477+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:09:39.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:09:39.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-10T22:10:09.784+0000] {processor.py:157} INFO - Started process (PID=42821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:10:09.786+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:10:09.788+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:10:09.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:10:09.797+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:10:09.813+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:10:09.813+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:10:09.828+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:10:09.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:10:09.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T22:10:40.202+0000] {processor.py:157} INFO - Started process (PID=42830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:10:40.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:10:40.211+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:10:40.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:10:40.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:10:40.261+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:10:40.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:10:40.273+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:10:40.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:10:40.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-10T22:11:10.581+0000] {processor.py:157} INFO - Started process (PID=42841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:11:10.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:11:10.583+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:11:10.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:11:10.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:11:10.609+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:11:10.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:11:10.619+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:11:10.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:11:10.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T22:11:41.074+0000] {processor.py:157} INFO - Started process (PID=42851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:11:41.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:11:41.078+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:11:41.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:11:41.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:11:41.130+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:11:41.129+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:11:41.142+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:11:41.142+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:11:41.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-10T22:12:11.608+0000] {processor.py:157} INFO - Started process (PID=42861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:12:11.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:12:11.612+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:12:11.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:12:11.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:12:11.639+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:12:11.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:12:11.651+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:12:11.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:12:11.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T22:12:41.964+0000] {processor.py:157} INFO - Started process (PID=42870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:12:41.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:12:41.970+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:12:41.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:12:41.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:12:42.014+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:12:42.014+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:12:42.026+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:12:42.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:12:42.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-10T22:13:12.283+0000] {processor.py:157} INFO - Started process (PID=42881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:13:12.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:13:12.289+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:13:12.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:13:12.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:13:12.315+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:13:12.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:13:12.326+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:13:12.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:13:12.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T22:13:42.677+0000] {processor.py:157} INFO - Started process (PID=42890) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:13:42.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:13:42.684+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:13:42.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:13:42.700+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:13:42.724+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:13:42.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:13:42.739+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:13:42.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:13:42.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-10T22:14:13.046+0000] {processor.py:157} INFO - Started process (PID=42901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:14:13.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:14:13.049+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:14:13.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:14:13.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:14:13.077+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:14:13.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:14:13.089+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:14:13.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:14:13.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T22:14:43.505+0000] {processor.py:157} INFO - Started process (PID=42911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:14:43.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:14:43.512+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:14:43.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:14:43.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:14:43.546+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:14:43.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:14:43.559+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:14:43.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:14:43.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T22:15:13.830+0000] {processor.py:157} INFO - Started process (PID=42921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:15:13.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:15:13.833+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:15:13.832+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:15:13.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:15:13.861+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:15:13.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:15:13.873+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:15:13.873+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:15:13.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T22:15:44.228+0000] {processor.py:157} INFO - Started process (PID=42931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:15:44.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:15:44.233+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:15:44.232+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:15:44.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:15:44.269+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:15:44.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:15:44.282+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:15:44.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:15:44.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-10T22:16:14.590+0000] {processor.py:157} INFO - Started process (PID=42941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:16:14.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:16:14.592+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:16:14.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:16:14.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:16:14.619+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:16:14.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:16:14.630+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:16:14.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:16:14.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T22:16:45.082+0000] {processor.py:157} INFO - Started process (PID=42951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:16:45.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:16:45.087+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:16:45.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:16:45.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:16:45.142+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:16:45.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:16:45.154+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:16:45.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:16:45.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-10T22:17:15.389+0000] {processor.py:157} INFO - Started process (PID=42961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:17:15.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:17:15.391+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:17:15.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:17:15.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:17:15.415+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:17:15.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:17:15.423+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:17:15.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:17:15.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-09-10T22:17:45.713+0000] {processor.py:157} INFO - Started process (PID=42971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:17:45.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:17:45.739+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:17:45.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:17:45.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:17:45.779+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:17:45.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:17:45.792+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:17:45.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:17:45.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-10T22:18:16.103+0000] {processor.py:157} INFO - Started process (PID=42981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:18:16.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:18:16.107+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:18:16.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:18:16.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:18:16.134+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:18:16.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:18:16.144+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:18:16.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:18:16.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T22:18:46.588+0000] {processor.py:157} INFO - Started process (PID=42991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:18:46.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:18:46.592+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:18:46.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:18:46.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:18:46.631+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:18:46.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:18:46.644+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:18:46.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:18:46.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T22:19:16.946+0000] {processor.py:157} INFO - Started process (PID=43001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:19:16.947+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:19:16.949+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:19:16.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:19:16.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:19:16.976+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:19:16.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:19:16.989+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:19:16.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:19:16.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T22:19:47.359+0000] {processor.py:157} INFO - Started process (PID=43011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:19:47.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:19:47.374+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:19:47.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:19:47.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:19:47.420+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:19:47.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:19:47.432+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:19:47.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:19:47.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-10T22:20:17.797+0000] {processor.py:157} INFO - Started process (PID=43021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:20:17.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:20:17.800+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:20:17.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:20:17.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:20:17.834+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:20:17.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:20:17.846+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:20:17.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:20:17.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T22:20:48.322+0000] {processor.py:157} INFO - Started process (PID=43031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:20:48.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:20:48.327+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:20:48.327+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:20:48.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:20:48.379+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:20:48.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:20:48.392+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:20:48.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:20:48.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-10T22:21:18.648+0000] {processor.py:157} INFO - Started process (PID=43041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:21:18.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:21:18.651+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:21:18.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:21:18.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:21:18.691+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:21:18.691+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:21:18.702+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:21:18.702+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:21:18.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T22:21:49.119+0000] {processor.py:157} INFO - Started process (PID=43051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:21:49.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:21:49.128+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:21:49.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:21:49.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:21:49.169+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:21:49.169+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:21:49.194+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:21:49.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:21:49.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-10T22:22:19.463+0000] {processor.py:157} INFO - Started process (PID=43061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:22:19.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:22:19.485+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:22:19.483+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:22:19.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:22:19.531+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:22:19.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:22:19.544+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:22:19.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:22:19.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-10T22:22:49.847+0000] {processor.py:157} INFO - Started process (PID=43071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:22:49.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:22:49.853+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:22:49.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:22:49.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:22:49.891+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:22:49.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:22:49.903+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:22:49.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:22:49.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T22:23:20.186+0000] {processor.py:157} INFO - Started process (PID=43081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:23:20.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:23:20.190+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:23:20.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:23:20.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:23:20.218+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:23:20.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:23:20.229+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:23:20.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:23:20.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T22:23:50.497+0000] {processor.py:157} INFO - Started process (PID=43091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:23:50.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:23:50.505+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:23:50.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:23:50.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:23:50.553+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:23:50.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:23:50.564+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:23:50.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:23:50.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-10T22:24:20.770+0000] {processor.py:157} INFO - Started process (PID=43101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:24:20.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:24:20.772+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:24:20.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:24:20.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:24:20.801+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:24:20.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:24:20.811+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:24:20.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:24:20.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T22:24:51.299+0000] {processor.py:157} INFO - Started process (PID=43111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:24:51.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:24:51.306+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:24:51.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:24:51.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:24:51.343+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:24:51.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:24:51.355+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:24:51.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:24:51.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T22:25:21.751+0000] {processor.py:157} INFO - Started process (PID=43121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:25:21.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:25:21.756+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:25:21.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:25:21.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:25:21.793+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:25:21.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:25:21.805+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:25:21.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:25:21.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-10T22:25:52.083+0000] {processor.py:157} INFO - Started process (PID=43131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:25:52.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:25:52.087+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:25:52.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:25:52.099+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:25:52.113+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:25:52.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:25:52.124+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:25:52.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:25:52.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T22:26:22.517+0000] {processor.py:157} INFO - Started process (PID=43141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:26:22.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:26:22.530+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:26:22.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:26:22.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:26:22.588+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:26:22.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:26:22.601+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:26:22.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:26:22.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-09-10T22:26:52.793+0000] {processor.py:157} INFO - Started process (PID=43151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:26:52.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:26:52.796+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:26:52.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:26:52.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:26:52.825+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:26:52.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:26:52.835+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:26:52.835+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:26:52.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T22:27:23.302+0000] {processor.py:157} INFO - Started process (PID=43161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:27:23.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:27:23.305+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:27:23.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:27:23.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:27:23.340+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:27:23.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:27:23.355+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:27:23.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:27:23.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T22:27:53.680+0000] {processor.py:157} INFO - Started process (PID=43171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:27:53.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:27:53.684+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:27:53.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:27:53.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:27:53.711+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:27:53.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:27:53.722+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:27:53.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:27:53.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T22:28:24.074+0000] {processor.py:157} INFO - Started process (PID=43180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:28:24.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:28:24.079+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:28:24.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:28:24.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:28:24.113+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:28:24.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:28:24.125+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:28:24.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:28:24.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T22:28:54.467+0000] {processor.py:157} INFO - Started process (PID=43191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:28:54.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:28:54.469+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:28:54.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:28:54.478+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:28:54.493+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:28:54.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:28:54.503+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:28:54.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:28:54.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T22:29:24.932+0000] {processor.py:157} INFO - Started process (PID=43201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:29:24.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:29:24.937+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:29:24.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:29:24.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:29:24.972+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:29:24.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:29:24.984+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:29:24.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:29:24.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T22:29:55.294+0000] {processor.py:157} INFO - Started process (PID=43211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:29:55.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:29:55.297+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:29:55.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:29:55.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:29:55.322+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:29:55.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:29:55.332+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:29:55.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:29:55.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T22:30:25.681+0000] {processor.py:157} INFO - Started process (PID=43221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:30:25.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:30:25.684+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:30:25.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:30:25.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:30:25.711+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:30:25.711+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:30:25.722+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:30:25.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:30:25.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T22:30:56.059+0000] {processor.py:157} INFO - Started process (PID=43231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:30:56.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:30:56.066+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:30:56.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:30:56.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:30:56.104+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:30:56.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:30:56.116+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:30:56.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:30:56.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T22:31:26.416+0000] {processor.py:157} INFO - Started process (PID=43241) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:31:26.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:31:26.420+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:31:26.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:31:26.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:31:26.446+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:31:26.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:31:26.457+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:31:26.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:31:26.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T22:31:56.735+0000] {processor.py:157} INFO - Started process (PID=43251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:31:56.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:31:56.741+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:31:56.740+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:31:56.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:31:56.776+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:31:56.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:31:56.789+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:31:56.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:31:56.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T22:32:27.136+0000] {processor.py:157} INFO - Started process (PID=43261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:32:27.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:32:27.141+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:32:27.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:32:27.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:32:27.167+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:32:27.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:32:27.192+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:32:27.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:32:27.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T22:32:57.558+0000] {processor.py:157} INFO - Started process (PID=43271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:32:57.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:32:57.563+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:32:57.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:32:57.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:32:57.609+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:32:57.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:32:57.638+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:32:57.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:32:57.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-10T22:33:27.940+0000] {processor.py:157} INFO - Started process (PID=43281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:33:27.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:33:27.944+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:33:27.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:33:27.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:33:27.979+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:33:27.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:33:27.993+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:33:27.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:33:28.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T22:33:58.267+0000] {processor.py:157} INFO - Started process (PID=43291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:33:58.268+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:33:58.270+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:33:58.270+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:33:58.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:33:58.302+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:33:58.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:33:58.313+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:33:58.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:33:58.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T22:34:28.700+0000] {processor.py:157} INFO - Started process (PID=43301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:34:28.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:34:28.704+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:34:28.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:34:28.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:34:28.735+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:34:28.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:34:28.745+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:34:28.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:34:28.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T22:34:59.090+0000] {processor.py:157} INFO - Started process (PID=43311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:34:59.091+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:34:59.093+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:34:59.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:34:59.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:34:59.128+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:34:59.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:34:59.140+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:34:59.140+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:34:59.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T22:35:29.386+0000] {processor.py:157} INFO - Started process (PID=43321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:35:29.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:35:29.389+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:35:29.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:35:29.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:35:29.436+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:35:29.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:35:29.447+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:35:29.447+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:35:29.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-10T22:35:59.711+0000] {processor.py:157} INFO - Started process (PID=43331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:35:59.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:35:59.714+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:35:59.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:35:59.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:35:59.748+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:35:59.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:35:59.762+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:35:59.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:35:59.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-09-10T22:36:30.018+0000] {processor.py:157} INFO - Started process (PID=43341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:36:30.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:36:30.022+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:36:30.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:36:30.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:36:30.052+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:36:30.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:36:30.062+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:36:30.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:36:30.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T22:37:00.402+0000] {processor.py:157} INFO - Started process (PID=43351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:37:00.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:37:00.405+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:37:00.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:37:00.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:37:00.439+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:37:00.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:37:00.452+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:37:00.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:37:00.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T22:37:30.729+0000] {processor.py:157} INFO - Started process (PID=43361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:37:30.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:37:30.733+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:37:30.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:37:30.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:37:30.772+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:37:30.772+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:37:30.783+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:37:30.783+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:37:30.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T22:38:01.067+0000] {processor.py:157} INFO - Started process (PID=43371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:38:01.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:38:01.070+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:38:01.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:38:01.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:38:01.100+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:38:01.100+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:38:01.112+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:38:01.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:38:01.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T22:38:31.385+0000] {processor.py:157} INFO - Started process (PID=43381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:38:31.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:38:31.389+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:38:31.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:38:31.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:38:31.444+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:38:31.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:38:31.457+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:38:31.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:38:31.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-10T22:39:01.846+0000] {processor.py:157} INFO - Started process (PID=43389) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:39:01.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:39:01.850+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:39:01.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:39:01.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:39:01.900+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:39:01.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:39:01.912+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:39:01.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:39:01.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-10T22:39:32.185+0000] {processor.py:157} INFO - Started process (PID=43401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:39:32.187+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:39:32.189+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:39:32.189+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:39:32.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:39:32.216+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:39:32.216+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:39:32.228+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:39:32.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:39:32.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T22:40:02.580+0000] {processor.py:157} INFO - Started process (PID=43411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:40:02.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:40:02.588+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:40:02.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:40:02.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:40:02.622+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:40:02.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:40:02.634+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:40:02.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:40:02.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T22:40:32.972+0000] {processor.py:157} INFO - Started process (PID=43421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:40:32.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:40:32.974+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:40:32.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:40:32.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:40:33.004+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:40:33.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:40:33.013+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:40:33.013+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:40:33.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T22:41:03.356+0000] {processor.py:157} INFO - Started process (PID=43431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:41:03.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:41:03.358+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:41:03.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:41:03.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:41:03.383+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:41:03.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:41:03.393+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:41:03.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:41:03.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-09-10T22:41:33.651+0000] {processor.py:157} INFO - Started process (PID=43441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:41:33.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:41:33.659+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:41:33.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:41:33.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:41:33.693+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:41:33.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:41:33.707+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:41:33.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:41:33.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T22:42:03.990+0000] {processor.py:157} INFO - Started process (PID=43451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:42:03.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:42:03.994+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:42:03.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:42:04.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:42:04.026+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:42:04.026+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:42:04.041+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:42:04.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:42:04.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T22:42:34.321+0000] {processor.py:157} INFO - Started process (PID=43461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:42:34.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:42:34.328+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:42:34.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:42:34.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:42:34.359+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:42:34.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:42:34.368+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:42:34.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:42:34.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T22:43:04.627+0000] {processor.py:157} INFO - Started process (PID=43471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:43:04.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:43:04.630+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:43:04.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:43:04.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:43:04.655+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:43:04.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:43:04.667+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:43:04.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:43:04.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T22:43:34.961+0000] {processor.py:157} INFO - Started process (PID=43481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:43:34.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:43:34.967+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:43:34.967+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:43:34.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:43:34.993+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:43:34.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:43:35.005+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:43:35.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:43:35.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T22:44:05.364+0000] {processor.py:157} INFO - Started process (PID=43491) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:44:05.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:44:05.371+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:44:05.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:44:05.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:44:05.408+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:44:05.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:44:05.420+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:44:05.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:44:05.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T22:44:35.715+0000] {processor.py:157} INFO - Started process (PID=43501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:44:35.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:44:35.718+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:44:35.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:44:35.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:44:35.745+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:44:35.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:44:35.758+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:44:35.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:44:35.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T22:45:06.016+0000] {processor.py:157} INFO - Started process (PID=43511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:45:06.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:45:06.019+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:45:06.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:45:06.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:45:06.066+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:45:06.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:45:06.081+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:45:06.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:45:06.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-09-10T22:45:36.418+0000] {processor.py:157} INFO - Started process (PID=43521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:45:36.420+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:45:36.422+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:45:36.422+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:45:36.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:45:36.453+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:45:36.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:45:36.466+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:45:36.465+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:45:36.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-09-10T22:46:06.762+0000] {processor.py:157} INFO - Started process (PID=43531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:46:06.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:46:06.767+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:46:06.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:46:06.781+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:46:06.832+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:46:06.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:46:06.845+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:46:06.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:46:06.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-10T22:46:37.039+0000] {processor.py:157} INFO - Started process (PID=43541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:46:37.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:46:37.044+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:46:37.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:46:37.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:46:37.073+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:46:37.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:46:37.083+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:46:37.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:46:37.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-09-10T22:47:07.351+0000] {processor.py:157} INFO - Started process (PID=43550) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:47:07.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:47:07.356+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:47:07.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:47:07.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:47:07.393+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:47:07.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:47:07.406+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:47:07.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:47:07.415+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T22:47:37.781+0000] {processor.py:157} INFO - Started process (PID=43560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:47:37.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:47:37.785+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:47:37.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:47:37.800+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:47:37.826+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:47:37.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:47:37.839+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:47:37.839+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:47:37.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-10T22:48:08.082+0000] {processor.py:157} INFO - Started process (PID=43571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:48:08.083+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:48:08.084+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:48:08.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:48:08.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:48:08.112+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:48:08.112+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:48:08.121+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:48:08.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:48:08.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T22:48:38.435+0000] {processor.py:157} INFO - Started process (PID=43581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:48:38.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:48:38.437+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:48:38.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:48:38.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:48:38.462+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:48:38.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:48:38.472+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:48:38.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:48:38.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-09-10T22:49:08.768+0000] {processor.py:157} INFO - Started process (PID=43591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:49:08.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:49:08.774+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:49:08.774+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:49:08.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:49:08.818+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:49:08.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:49:08.833+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:49:08.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:49:08.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-09-10T22:49:39.125+0000] {processor.py:157} INFO - Started process (PID=43601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:49:39.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:49:39.139+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:49:39.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:49:39.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:49:39.182+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:49:39.182+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:49:39.195+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:49:39.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:49:39.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-10T22:50:09.461+0000] {processor.py:157} INFO - Started process (PID=43611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:50:09.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:50:09.465+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:50:09.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:50:09.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:50:09.499+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:50:09.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:50:09.512+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:50:09.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:50:09.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T22:50:39.856+0000] {processor.py:157} INFO - Started process (PID=43621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:50:39.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:50:39.858+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:50:39.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:50:39.869+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:50:39.888+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:50:39.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:50:39.900+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:50:39.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:50:39.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T22:51:10.229+0000] {processor.py:157} INFO - Started process (PID=43631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:51:10.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:51:10.235+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:51:10.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:51:10.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:51:10.274+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:51:10.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:51:10.288+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:51:10.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:51:10.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-10T22:51:40.597+0000] {processor.py:157} INFO - Started process (PID=43641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:51:40.600+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:51:40.613+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:51:40.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:51:40.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:51:40.675+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:51:40.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:51:40.691+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:51:40.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:51:40.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-10T22:52:10.962+0000] {processor.py:157} INFO - Started process (PID=43651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:52:10.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:52:10.966+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:52:10.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:52:10.987+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:52:11.023+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:52:11.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:52:11.041+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:52:11.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:52:11.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T22:52:41.296+0000] {processor.py:157} INFO - Started process (PID=43661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:52:41.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:52:41.301+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:52:41.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:52:41.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:52:41.338+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:52:41.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:52:41.352+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:52:41.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:52:41.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T22:53:11.719+0000] {processor.py:157} INFO - Started process (PID=43671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:53:11.721+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:53:11.723+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:53:11.723+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:53:11.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:53:11.755+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:53:11.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:53:11.767+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:53:11.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:53:11.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-09-10T22:53:42.196+0000] {processor.py:157} INFO - Started process (PID=43681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:53:42.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:53:42.200+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:53:42.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:53:42.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:53:42.252+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:53:42.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:53:42.266+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:53:42.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:53:42.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-10T22:54:12.589+0000] {processor.py:157} INFO - Started process (PID=43691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:54:12.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:54:12.597+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:54:12.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:54:12.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:54:12.640+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:54:12.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:54:12.655+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:54:12.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:54:12.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-10T22:54:42.949+0000] {processor.py:157} INFO - Started process (PID=43701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:54:42.951+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:54:42.957+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:54:42.956+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:54:42.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:54:42.996+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:54:42.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:54:43.008+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:54:43.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:54:43.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-10T22:55:13.352+0000] {processor.py:157} INFO - Started process (PID=43711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:55:13.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:55:13.359+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:55:13.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:55:13.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:55:13.409+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:55:13.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:55:13.427+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:55:13.427+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:55:13.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-10T22:55:43.760+0000] {processor.py:157} INFO - Started process (PID=43721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:55:43.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:55:43.768+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:55:43.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:55:43.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:55:43.815+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:55:43.815+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:55:43.838+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:55:43.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:55:43.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-09-10T22:56:14.105+0000] {processor.py:157} INFO - Started process (PID=43731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:56:14.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:56:14.115+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:56:14.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:56:14.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:56:14.159+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:56:14.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:56:14.173+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:56:14.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:56:14.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T22:56:44.465+0000] {processor.py:157} INFO - Started process (PID=43741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:56:44.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:56:44.469+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:56:44.469+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:56:44.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:56:44.500+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:56:44.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:56:44.509+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:56:44.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:56:44.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T22:57:14.869+0000] {processor.py:157} INFO - Started process (PID=43751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:57:14.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:57:14.872+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:57:14.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:57:14.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:57:14.911+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:57:14.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:57:14.931+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:57:14.931+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:57:14.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T22:57:45.213+0000] {processor.py:157} INFO - Started process (PID=43761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:57:45.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:57:45.221+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:57:45.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:57:45.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:57:45.260+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:57:45.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:57:45.270+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:57:45.269+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:57:45.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-10T22:58:15.501+0000] {processor.py:157} INFO - Started process (PID=43771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:58:15.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:58:15.506+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:58:15.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:58:15.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:58:15.545+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:58:15.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:58:15.559+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:58:15.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:58:15.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T22:58:45.799+0000] {processor.py:157} INFO - Started process (PID=43781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:58:45.801+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:58:45.804+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:58:45.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:58:45.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:58:45.836+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:58:45.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:58:45.847+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:58:45.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:58:45.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T22:59:16.155+0000] {processor.py:157} INFO - Started process (PID=43791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:59:16.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:59:16.160+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:59:16.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:59:16.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:59:16.208+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:59:16.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:59:16.221+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:59:16.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:59:16.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-10T22:59:46.568+0000] {processor.py:157} INFO - Started process (PID=43801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:59:46.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T22:59:46.573+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:59:46.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:59:46.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T22:59:46.607+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:59:46.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T22:59:46.619+0000] {logging_mixin.py:151} INFO - [2024-09-10T22:59:46.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T22:59:46.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T23:00:16.998+0000] {processor.py:157} INFO - Started process (PID=43811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:00:16.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:00:17.002+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:00:17.002+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:00:17.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:00:17.050+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:00:17.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:00:17.061+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:00:17.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:00:17.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-10T23:00:47.406+0000] {processor.py:157} INFO - Started process (PID=43821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:00:47.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:00:47.409+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:00:47.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:00:47.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:00:47.469+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:00:47.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:00:47.483+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:00:47.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:00:47.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-10T23:01:17.753+0000] {processor.py:157} INFO - Started process (PID=43831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:01:17.755+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:01:17.758+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:01:17.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:01:17.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:01:17.797+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:01:17.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:01:17.823+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:01:17.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:01:17.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-10T23:01:48.195+0000] {processor.py:157} INFO - Started process (PID=43841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:01:48.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:01:48.202+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:01:48.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:01:48.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:01:48.266+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:01:48.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:01:48.280+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:01:48.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:01:48.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-09-10T23:02:18.488+0000] {processor.py:157} INFO - Started process (PID=43851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:02:18.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:02:18.492+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:02:18.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:02:18.507+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:02:18.529+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:02:18.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:02:18.543+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:02:18.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:02:18.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T23:02:48.886+0000] {processor.py:157} INFO - Started process (PID=43861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:02:48.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:02:48.890+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:02:48.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:02:48.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:02:48.917+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:02:48.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:02:48.930+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:02:48.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:02:48.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T23:03:19.274+0000] {processor.py:157} INFO - Started process (PID=43870) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:03:19.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:03:19.279+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:03:19.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:03:19.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:03:19.333+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:03:19.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:03:19.345+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:03:19.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:03:19.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-10T23:03:49.497+0000] {processor.py:157} INFO - Started process (PID=43881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:03:49.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:03:49.500+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:03:49.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:03:49.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:03:49.529+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:03:49.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:03:49.540+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:03:49.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:03:49.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T23:04:19.850+0000] {processor.py:157} INFO - Started process (PID=43891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:04:19.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:04:19.856+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:04:19.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:04:19.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:04:19.888+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:04:19.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:04:19.900+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:04:19.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:04:19.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-09-10T23:04:50.226+0000] {processor.py:157} INFO - Started process (PID=43901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:04:50.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:04:50.232+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:04:50.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:04:50.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:04:50.263+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:04:50.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:04:50.273+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:04:50.272+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:04:50.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T23:05:20.622+0000] {processor.py:157} INFO - Started process (PID=43910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:05:20.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:05:20.627+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:05:20.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:05:20.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:05:20.686+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:05:20.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:05:20.698+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:05:20.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:05:20.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-10T23:05:50.993+0000] {processor.py:157} INFO - Started process (PID=43920) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:05:50.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:05:50.998+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:05:50.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:05:51.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:05:51.034+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:05:51.034+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:05:51.049+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:05:51.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:05:51.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-10T23:06:21.391+0000] {processor.py:157} INFO - Started process (PID=43931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:06:21.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:06:21.394+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:06:21.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:06:21.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:06:21.425+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:06:21.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:06:21.436+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:06:21.436+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:06:21.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T23:06:51.776+0000] {processor.py:157} INFO - Started process (PID=43941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:06:51.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:06:51.785+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:06:51.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:06:51.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:06:51.832+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:06:51.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:06:51.845+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:06:51.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:06:51.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-10T23:07:22.303+0000] {processor.py:157} INFO - Started process (PID=43950) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:07:22.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:07:22.308+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:07:22.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:07:22.322+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:07:22.347+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:07:22.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:07:22.367+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:07:22.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:07:22.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-10T23:07:52.714+0000] {processor.py:157} INFO - Started process (PID=43961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:07:52.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:07:52.718+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:07:52.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:07:52.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:07:52.755+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:07:52.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:07:52.768+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:07:52.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:07:52.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T23:08:23.047+0000] {processor.py:157} INFO - Started process (PID=43971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:08:23.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:08:23.051+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:08:23.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:08:23.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:08:23.086+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:08:23.086+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:08:23.100+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:08:23.100+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:08:23.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T23:08:53.493+0000] {processor.py:157} INFO - Started process (PID=43981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:08:53.494+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:08:53.496+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:08:53.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:08:53.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:08:53.522+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:08:53.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:08:53.532+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:08:53.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:08:53.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T23:09:23.859+0000] {processor.py:157} INFO - Started process (PID=43991) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:09:23.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:09:23.863+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:09:23.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:09:23.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:09:23.898+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:09:23.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:09:23.911+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:09:23.911+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:09:23.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T23:09:54.305+0000] {processor.py:157} INFO - Started process (PID=44001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:09:54.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:09:54.308+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:09:54.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:09:54.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:09:54.337+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:09:54.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:09:54.347+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:09:54.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:09:54.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T23:10:24.684+0000] {processor.py:157} INFO - Started process (PID=44011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:10:24.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:10:24.688+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:10:24.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:10:24.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:10:24.725+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:10:24.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:10:24.736+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:10:24.736+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:10:24.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-10T23:10:55.162+0000] {processor.py:157} INFO - Started process (PID=44021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:10:55.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:10:55.172+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:10:55.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:10:55.195+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:10:55.224+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:10:55.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:10:55.250+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:10:55.250+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:10:55.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-10T23:11:25.552+0000] {processor.py:157} INFO - Started process (PID=44031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:11:25.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:11:25.557+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:11:25.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:11:25.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:11:25.599+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:11:25.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:11:25.620+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:11:25.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:11:25.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.102 seconds
[2024-09-10T23:11:55.863+0000] {processor.py:157} INFO - Started process (PID=44041) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:11:55.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:11:55.866+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:11:55.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:11:55.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:11:55.896+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:11:55.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:11:55.907+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:11:55.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:11:55.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T23:12:26.251+0000] {processor.py:157} INFO - Started process (PID=44051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:12:26.254+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:12:26.262+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:12:26.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:12:26.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:12:26.303+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:12:26.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:12:26.320+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:12:26.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:12:26.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T23:12:56.698+0000] {processor.py:157} INFO - Started process (PID=44061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:12:56.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:12:56.704+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:12:56.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:12:56.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:12:56.764+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:12:56.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:12:56.778+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:12:56.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:12:56.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-10T23:13:27.015+0000] {processor.py:157} INFO - Started process (PID=44071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:13:27.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:13:27.018+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:13:27.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:13:27.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:13:27.043+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:13:27.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:13:27.055+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:13:27.055+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:13:27.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T23:13:57.436+0000] {processor.py:157} INFO - Started process (PID=44081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:13:57.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:13:57.442+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:13:57.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:13:57.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:13:57.516+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:13:57.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:13:57.531+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:13:57.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:13:57.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-09-10T23:14:27.747+0000] {processor.py:157} INFO - Started process (PID=44091) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:14:27.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:14:27.752+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:14:27.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:14:27.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:14:27.779+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:14:27.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:14:27.790+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:14:27.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:14:27.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T23:14:58.111+0000] {processor.py:157} INFO - Started process (PID=44101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:14:58.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:14:58.115+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:14:58.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:14:58.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:14:58.158+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:14:58.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:14:58.172+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:14:58.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:14:58.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-09-10T23:15:28.427+0000] {processor.py:157} INFO - Started process (PID=44111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:15:28.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:15:28.430+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:15:28.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:15:28.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:15:28.460+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:15:28.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:15:28.470+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:15:28.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:15:28.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T23:15:58.831+0000] {processor.py:157} INFO - Started process (PID=44121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:15:58.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:15:58.836+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:15:58.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:15:58.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:15:58.871+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:15:58.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:15:58.888+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:15:58.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:15:58.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-09-10T23:16:29.154+0000] {processor.py:157} INFO - Started process (PID=44131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:16:29.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:16:29.157+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:16:29.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:16:29.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:16:29.183+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:16:29.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:16:29.194+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:16:29.194+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:16:29.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T23:16:59.562+0000] {processor.py:157} INFO - Started process (PID=44141) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:16:59.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:16:59.567+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:16:59.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:16:59.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:16:59.627+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:16:59.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:16:59.650+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:16:59.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:16:59.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-10T23:17:29.978+0000] {processor.py:157} INFO - Started process (PID=44150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:17:29.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:17:29.984+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:17:29.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:17:30.000+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:17:30.031+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:17:30.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:17:30.047+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:17:30.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:17:30.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-09-10T23:18:00.319+0000] {processor.py:157} INFO - Started process (PID=44161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:18:00.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:18:00.324+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:18:00.324+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:18:00.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:18:00.385+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:18:00.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:18:00.403+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:18:00.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:18:00.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-09-10T23:18:30.716+0000] {processor.py:157} INFO - Started process (PID=44171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:18:30.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:18:30.724+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:18:30.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:18:30.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:18:30.775+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:18:30.775+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:18:30.791+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:18:30.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:18:30.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-10T23:19:01.221+0000] {processor.py:157} INFO - Started process (PID=44181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:19:01.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:19:01.227+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:19:01.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:19:01.245+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:19:01.274+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:19:01.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:19:01.289+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:19:01.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:19:01.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-09-10T23:19:31.545+0000] {processor.py:157} INFO - Started process (PID=44191) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:19:31.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:19:31.549+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:19:31.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:19:31.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:19:31.586+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:19:31.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:19:31.602+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:19:31.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:19:31.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-09-10T23:20:01.931+0000] {processor.py:157} INFO - Started process (PID=44201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:20:01.933+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:20:01.934+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:20:01.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:20:01.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:20:01.960+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:20:01.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:20:01.975+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:20:01.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:20:01.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T23:20:32.245+0000] {processor.py:157} INFO - Started process (PID=44211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:20:32.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:20:32.252+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:20:32.252+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:20:32.267+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:20:32.288+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:20:32.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:20:32.302+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:20:32.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:20:32.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T23:21:02.606+0000] {processor.py:157} INFO - Started process (PID=44220) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:21:02.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:21:02.612+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:21:02.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:21:02.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:21:02.670+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:21:02.670+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:21:02.683+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:21:02.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:21:02.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-09-10T23:21:32.972+0000] {processor.py:157} INFO - Started process (PID=44230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:21:32.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:21:32.982+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:21:32.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:21:33.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:21:33.072+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:21:33.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:21:33.092+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:21:33.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:21:33.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-09-10T23:22:03.305+0000] {processor.py:157} INFO - Started process (PID=44239) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:22:03.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:22:03.320+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:22:03.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:22:03.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:22:03.398+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:22:03.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:22:03.419+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:22:03.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:22:03.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-09-10T23:22:33.695+0000] {processor.py:157} INFO - Started process (PID=44251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:22:33.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:22:33.700+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:22:33.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:22:33.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:22:33.736+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:22:33.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:22:33.748+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:22:33.748+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:22:33.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T23:23:04.057+0000] {processor.py:157} INFO - Started process (PID=44261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:23:04.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:23:04.075+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:23:04.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:23:04.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:23:04.121+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:23:04.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:23:04.157+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:23:04.157+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:23:04.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-09-10T23:23:34.573+0000] {processor.py:157} INFO - Started process (PID=44271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:23:34.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:23:34.577+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:23:34.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:23:34.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:23:34.646+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:23:34.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:23:34.659+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:23:34.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:23:34.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-09-10T23:24:04.905+0000] {processor.py:157} INFO - Started process (PID=44281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:24:04.912+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:24:04.919+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:24:04.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:24:04.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:24:04.967+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:24:04.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:24:04.982+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:24:04.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:24:04.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-10T23:24:35.294+0000] {processor.py:157} INFO - Started process (PID=44291) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:24:35.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:24:35.299+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:24:35.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:24:35.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:24:35.337+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:24:35.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:24:35.352+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:24:35.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:24:35.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-09-10T23:25:05.742+0000] {processor.py:157} INFO - Started process (PID=44300) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:25:05.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:25:05.748+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:25:05.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:25:05.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:25:05.817+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:25:05.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:25:05.834+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:25:05.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:25:05.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-10T23:25:36.016+0000] {processor.py:157} INFO - Started process (PID=44311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:25:36.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:25:36.019+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:25:36.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:25:36.033+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:25:36.048+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:25:36.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:25:36.057+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:25:36.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:25:36.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T23:26:06.358+0000] {processor.py:157} INFO - Started process (PID=44321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:26:06.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:26:06.363+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:26:06.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:26:06.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:26:06.399+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:26:06.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:26:06.411+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:26:06.411+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:26:06.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T23:26:36.770+0000] {processor.py:157} INFO - Started process (PID=44331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:26:36.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:26:36.774+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:26:36.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:26:36.810+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:26:36.838+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:26:36.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:26:36.852+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:26:36.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:26:36.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-09-10T23:27:07.170+0000] {processor.py:157} INFO - Started process (PID=44341) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:27:07.172+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:27:07.177+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:27:07.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:27:07.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:27:07.251+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:27:07.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:27:07.266+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:27:07.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:27:07.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-09-10T23:27:37.562+0000] {processor.py:157} INFO - Started process (PID=44351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:27:37.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:27:37.570+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:27:37.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:27:37.592+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:27:37.646+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:27:37.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:27:37.665+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:27:37.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:27:37.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-10T23:28:08.001+0000] {processor.py:157} INFO - Started process (PID=44361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:28:08.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:28:08.004+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:28:08.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:28:08.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:28:08.031+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:28:08.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:28:08.040+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:28:08.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:28:08.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T23:28:38.379+0000] {processor.py:157} INFO - Started process (PID=44371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:28:38.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:28:38.382+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:28:38.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:28:38.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:28:38.408+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:28:38.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:28:38.418+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:28:38.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:28:38.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T23:29:08.713+0000] {processor.py:157} INFO - Started process (PID=44381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:29:08.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:29:08.718+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:29:08.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:29:08.734+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:29:08.754+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:29:08.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:29:08.766+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:29:08.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:29:08.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-09-10T23:29:39.141+0000] {processor.py:157} INFO - Started process (PID=44391) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:29:39.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:29:39.145+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:29:39.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:29:39.155+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:29:39.172+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:29:39.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:29:39.183+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:29:39.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:29:39.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T23:30:09.532+0000] {processor.py:157} INFO - Started process (PID=44401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:30:09.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:30:09.535+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:30:09.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:30:09.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:30:09.562+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:30:09.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:30:09.572+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:30:09.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:30:09.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T23:30:39.922+0000] {processor.py:157} INFO - Started process (PID=44411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:30:39.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:30:39.927+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:30:39.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:30:39.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:30:39.952+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:30:39.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:30:39.964+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:30:39.964+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:30:39.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T23:31:10.313+0000] {processor.py:157} INFO - Started process (PID=44421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:31:10.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:31:10.318+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:31:10.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:31:10.337+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:31:10.355+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:31:10.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:31:10.367+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:31:10.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:31:10.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-09-10T23:31:40.685+0000] {processor.py:157} INFO - Started process (PID=44431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:31:40.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:31:40.689+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:31:40.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:31:40.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:31:40.715+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:31:40.715+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:31:40.729+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:31:40.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:31:40.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T23:32:11.039+0000] {processor.py:157} INFO - Started process (PID=44441) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:32:11.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:32:11.044+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:32:11.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:32:11.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:32:11.072+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:32:11.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:32:11.084+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:32:11.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:32:11.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-09-10T23:32:41.392+0000] {processor.py:157} INFO - Started process (PID=44451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:32:41.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:32:41.401+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:32:41.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:32:41.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:32:41.446+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:32:41.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:32:41.457+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:32:41.457+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:32:41.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-09-10T23:33:11.800+0000] {processor.py:157} INFO - Started process (PID=44461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:33:11.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:33:11.802+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:33:11.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:33:11.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:33:11.831+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:33:11.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:33:11.841+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:33:11.841+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:33:11.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-09-10T23:33:42.139+0000] {processor.py:157} INFO - Started process (PID=44471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:33:42.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:33:42.142+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:33:42.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:33:42.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:33:42.170+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:33:42.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:33:42.180+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:33:42.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:33:42.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-09-10T23:34:12.604+0000] {processor.py:157} INFO - Started process (PID=44480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:34:12.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:34:12.611+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:34:12.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:34:12.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:34:12.679+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:34:12.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:34:12.703+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:34:12.703+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:34:12.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-09-10T23:34:42.944+0000] {processor.py:157} INFO - Started process (PID=44490) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:34:42.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:34:42.952+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:34:42.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:34:42.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:34:42.993+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:34:42.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:34:43.005+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:34:43.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:34:43.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-09-10T23:35:13.322+0000] {processor.py:157} INFO - Started process (PID=44501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:35:13.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:35:13.325+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:35:13.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:35:13.335+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:35:13.352+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:35:13.352+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:35:13.364+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:35:13.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:35:13.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T23:35:43.694+0000] {processor.py:157} INFO - Started process (PID=44511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:35:43.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:35:43.699+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:35:43.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:35:43.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:35:43.758+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:35:43.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:35:43.771+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:35:43.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:35:43.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-09-10T23:36:14.018+0000] {processor.py:157} INFO - Started process (PID=44521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:36:14.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:36:14.020+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:36:14.020+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:36:14.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:36:14.048+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:36:14.048+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:36:14.057+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:36:14.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:36:14.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T23:36:44.436+0000] {processor.py:157} INFO - Started process (PID=44531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:36:44.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:36:44.438+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:36:44.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:36:44.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:36:44.464+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:36:44.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:36:44.474+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:36:44.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:36:44.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-09-10T23:37:14.761+0000] {processor.py:157} INFO - Started process (PID=44541) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:37:14.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:37:14.764+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:37:14.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:37:14.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:37:14.809+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:37:14.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:37:14.823+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:37:14.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:37:14.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T23:37:45.104+0000] {processor.py:157} INFO - Started process (PID=44551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:37:45.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:37:45.110+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:37:45.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:37:45.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:37:45.150+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:37:45.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:37:45.162+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:37:45.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:37:45.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-09-10T23:38:15.389+0000] {processor.py:157} INFO - Started process (PID=44561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:38:15.389+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:38:15.391+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:38:15.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:38:15.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:38:15.415+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:38:15.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:38:15.424+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:38:15.424+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:38:15.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T23:38:45.772+0000] {processor.py:157} INFO - Started process (PID=44571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:38:45.775+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:38:45.778+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:38:45.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:38:45.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:38:45.811+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:38:45.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:38:45.822+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:38:45.822+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:38:45.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-09-10T23:39:16.106+0000] {processor.py:157} INFO - Started process (PID=44581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:39:16.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:39:16.109+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:39:16.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:39:16.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:39:16.147+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:39:16.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:39:16.160+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:39:16.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:39:16.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-09-10T23:39:46.529+0000] {processor.py:157} INFO - Started process (PID=44591) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:39:46.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:39:46.534+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:39:46.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:39:46.548+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:39:46.567+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:39:46.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:39:46.578+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:39:46.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:39:46.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T23:40:16.909+0000] {processor.py:157} INFO - Started process (PID=44600) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:40:16.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:40:16.913+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:40:16.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:40:16.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:40:16.987+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:40:16.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:40:17.001+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:40:17.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:40:17.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-09-10T23:40:47.353+0000] {processor.py:157} INFO - Started process (PID=44611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:40:47.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:40:47.358+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:40:47.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:40:47.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:40:47.383+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:40:47.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:40:47.392+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:40:47.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:40:47.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-09-10T23:41:17.713+0000] {processor.py:157} INFO - Started process (PID=44621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:41:17.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:41:17.716+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:41:17.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:41:17.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:41:17.746+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:41:17.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:41:17.757+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:41:17.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:41:17.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-09-10T23:41:48.056+0000] {processor.py:157} INFO - Started process (PID=44631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:41:48.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:41:48.061+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:41:48.060+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:41:48.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:41:48.104+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:41:48.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:41:48.116+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:41:48.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:41:48.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-09-10T23:42:18.506+0000] {processor.py:157} INFO - Started process (PID=44641) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:42:18.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:42:18.511+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:42:18.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:42:18.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:42:18.549+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:42:18.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:42:18.563+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:42:18.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:42:18.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-09-10T23:42:48.912+0000] {processor.py:157} INFO - Started process (PID=44651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:42:48.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:42:48.917+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:42:48.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:42:48.943+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:42:48.980+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:42:48.979+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:42:48.991+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:42:48.991+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:42:49.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-10T23:43:19.237+0000] {processor.py:157} INFO - Started process (PID=44661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:43:19.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:43:19.243+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:43:19.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:43:19.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:43:19.266+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:43:19.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:43:19.276+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:43:19.276+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:43:19.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-09-10T23:43:49.797+0000] {processor.py:157} INFO - Started process (PID=44671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:43:49.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:43:49.805+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:43:49.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:43:49.829+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:43:49.883+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:43:49.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:43:49.900+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:43:49.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:43:49.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-09-10T23:44:20.230+0000] {processor.py:157} INFO - Started process (PID=44681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:44:20.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:44:20.260+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:44:20.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:44:20.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:44:20.327+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:44:20.327+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:44:20.347+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:44:20.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:44:20.361+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-09-10T23:44:50.621+0000] {processor.py:157} INFO - Started process (PID=44691) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:44:50.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:44:50.629+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:44:50.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:44:50.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:44:50.730+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:44:50.730+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:44:50.749+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:44:50.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:44:50.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.153 seconds
[2024-09-10T23:45:20.982+0000] {processor.py:157} INFO - Started process (PID=44701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:45:20.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:45:20.991+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:45:20.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:45:21.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:45:21.077+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:45:21.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:45:21.098+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:45:21.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:45:21.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-09-10T23:45:51.292+0000] {processor.py:157} INFO - Started process (PID=44711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:45:51.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:45:51.297+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:45:51.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:45:51.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:45:51.339+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:45:51.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:45:51.352+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:45:51.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:45:51.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T23:46:21.659+0000] {processor.py:157} INFO - Started process (PID=44721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:46:21.660+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:46:21.664+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:46:21.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:46:21.686+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:46:21.705+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:46:21.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:46:21.717+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:46:21.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:46:21.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-09-10T23:46:52.096+0000] {processor.py:157} INFO - Started process (PID=44731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:46:52.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:46:52.100+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:46:52.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:46:52.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:46:52.156+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:46:52.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:46:52.173+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:46:52.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:46:52.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-09-10T23:47:22.415+0000] {processor.py:157} INFO - Started process (PID=44741) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:47:22.419+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:47:22.421+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:47:22.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:47:22.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:47:22.474+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:47:22.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:47:22.488+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:47:22.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:47:22.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T23:47:52.763+0000] {processor.py:157} INFO - Started process (PID=44751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:47:52.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:47:52.770+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:47:52.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:47:52.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:47:52.814+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:47:52.814+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:47:52.832+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:47:52.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:47:52.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-09-10T23:48:23.113+0000] {processor.py:157} INFO - Started process (PID=44761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:48:23.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:48:23.119+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:48:23.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:48:23.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:48:23.254+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:48:23.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:48:23.270+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:48:23.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:48:23.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.174 seconds
[2024-09-10T23:48:53.401+0000] {processor.py:157} INFO - Started process (PID=44771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:48:53.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:48:53.408+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:48:53.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:48:53.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:48:53.453+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:48:53.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:48:53.473+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:48:53.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:48:53.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-09-10T23:49:23.676+0000] {processor.py:157} INFO - Started process (PID=44781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:49:23.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:49:23.680+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:49:23.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:49:23.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:49:23.717+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:49:23.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:49:23.732+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:49:23.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:49:23.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-09-10T23:49:54.019+0000] {processor.py:157} INFO - Started process (PID=44791) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:49:54.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:49:54.022+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:49:54.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:49:54.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:49:54.052+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:49:54.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:49:54.061+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:49:54.061+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:49:54.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-09-10T23:50:24.383+0000] {processor.py:157} INFO - Started process (PID=44801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:50:24.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:50:24.388+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:50:24.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:50:24.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:50:24.428+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:50:24.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:50:24.443+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:50:24.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:50:24.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-10T23:50:54.706+0000] {processor.py:157} INFO - Started process (PID=44811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:50:54.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:50:54.709+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:50:54.709+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:50:54.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:50:54.739+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:50:54.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:50:54.752+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:50:54.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:50:54.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-09-10T23:51:25.155+0000] {processor.py:157} INFO - Started process (PID=44821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:51:25.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:51:25.161+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:51:25.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:51:25.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:51:25.236+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:51:25.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:51:25.260+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:51:25.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:51:25.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-09-10T23:51:55.498+0000] {processor.py:157} INFO - Started process (PID=44831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:51:55.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:51:55.505+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:51:55.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:51:55.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:51:55.558+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:51:55.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:51:55.571+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:51:55.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:51:55.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T23:52:25.881+0000] {processor.py:157} INFO - Started process (PID=44841) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:52:25.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:52:25.887+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:52:25.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:52:25.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:52:25.928+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:52:25.928+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:52:25.941+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:52:25.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:52:25.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-09-10T23:52:56.204+0000] {processor.py:157} INFO - Started process (PID=44851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:52:56.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:52:56.210+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:52:56.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:52:56.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:52:56.254+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:52:56.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:52:56.266+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:52:56.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:52:56.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-09-10T23:53:26.623+0000] {processor.py:157} INFO - Started process (PID=44861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:53:26.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:53:26.630+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:53:26.630+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:53:26.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:53:26.672+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:53:26.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:53:26.705+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:53:26.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:53:26.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-09-10T23:53:56.923+0000] {processor.py:157} INFO - Started process (PID=44871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:53:56.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:53:56.925+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:53:56.925+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:53:56.940+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:53:56.954+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:53:56.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:53:56.963+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:53:56.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:53:56.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-09-10T23:54:27.254+0000] {processor.py:157} INFO - Started process (PID=44880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:54:27.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:54:27.258+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:54:27.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:54:27.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:54:27.297+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:54:27.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:54:27.314+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:54:27.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:54:27.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-09-10T23:54:57.487+0000] {processor.py:157} INFO - Started process (PID=44891) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:54:57.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:54:57.490+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:54:57.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:54:57.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:54:57.520+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:54:57.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:54:57.532+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:54:57.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:54:57.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T23:55:27.857+0000] {processor.py:157} INFO - Started process (PID=44900) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:55:27.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:55:27.862+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:55:27.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:55:27.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:55:27.913+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:55:27.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:55:27.928+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:55:27.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:55:27.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-09-10T23:55:58.236+0000] {processor.py:157} INFO - Started process (PID=44911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:55:58.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:55:58.239+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:55:58.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:55:58.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:55:58.273+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:55:58.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:55:58.286+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:55:58.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:55:58.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-09-10T23:56:28.544+0000] {processor.py:157} INFO - Started process (PID=44921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:56:28.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:56:28.549+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:56:28.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:56:28.565+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:56:28.587+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:56:28.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:56:28.600+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:56:28.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:56:28.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-09-10T23:56:58.905+0000] {processor.py:157} INFO - Started process (PID=44931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:56:58.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:56:58.908+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:56:58.907+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:56:58.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:56:58.933+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:56:58.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:56:58.942+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:56:58.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:56:58.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-09-10T23:57:29.302+0000] {processor.py:157} INFO - Started process (PID=44941) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:57:29.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:57:29.314+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:57:29.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:57:29.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:57:29.369+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:57:29.369+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:57:29.382+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:57:29.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:57:29.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-09-10T23:57:59.588+0000] {processor.py:157} INFO - Started process (PID=44951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:57:59.590+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:57:59.592+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:57:59.592+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:57:59.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:57:59.631+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:57:59.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:57:59.644+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:57:59.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:57:59.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-09-10T23:58:30.030+0000] {processor.py:157} INFO - Started process (PID=44961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:58:30.032+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:58:30.037+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:58:30.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:58:30.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:58:30.106+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:58:30.106+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:58:30.125+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:58:30.125+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:58:30.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-09-10T23:59:00.356+0000] {processor.py:157} INFO - Started process (PID=44971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:59:00.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:59:00.361+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:59:00.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:59:00.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:59:00.404+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:59:00.404+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:59:00.416+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:59:00.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:59:00.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-09-10T23:59:30.676+0000] {processor.py:157} INFO - Started process (PID=44981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:59:30.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-09-10T23:59:30.684+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:59:30.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:59:30.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-09-10T23:59:30.741+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:59:30.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-09-10T23:59:30.784+0000] {logging_mixin.py:151} INFO - [2024-09-10T23:59:30.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-09-09T01:00:00+00:00, run_after=2024-09-10T01:00:00+00:00
[2024-09-10T23:59:30.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
