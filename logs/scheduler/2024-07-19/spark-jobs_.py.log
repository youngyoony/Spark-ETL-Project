[2024-07-19T00:01:54.939+0000] {processor.py:157} INFO - Started process (PID=36259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:01:54.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:01:54.944+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:01:54.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:01:54.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:01:55.024+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:01:55.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:01:55.048+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:01:55.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:01:55.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-19T00:02:25.782+0000] {processor.py:157} INFO - Started process (PID=36285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:02:25.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:02:25.785+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:02:25.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:02:25.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:02:25.816+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:02:25.816+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:02:25.828+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:02:25.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:02:25.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T00:18:55.444+0000] {processor.py:157} INFO - Started process (PID=36311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:18:55.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:18:55.449+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:18:55.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:18:55.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:18:55.490+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:18:55.490+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:18:55.502+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:18:55.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:18:55.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T00:19:25.962+0000] {processor.py:157} INFO - Started process (PID=36337) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:19:25.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:19:25.965+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:19:25.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:19:25.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:19:25.997+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:19:25.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:19:26.009+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:19:26.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:19:26.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T00:29:44.824+0000] {processor.py:157} INFO - Started process (PID=36361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:29:44.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:29:44.830+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:29:44.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:29:44.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:29:44.910+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:29:44.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:29:44.938+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:29:44.938+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:29:44.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-07-19T00:30:15.399+0000] {processor.py:157} INFO - Started process (PID=36780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:30:15.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:30:15.403+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:30:15.402+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:30:15.419+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:30:15.445+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:30:15.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:30:15.456+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:30:15.456+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:30:15.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T00:30:45.908+0000] {processor.py:157} INFO - Started process (PID=36806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:30:45.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:30:45.912+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:30:45.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:30:45.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:30:45.939+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:30:45.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:30:45.950+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:30:45.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:30:45.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T00:31:16.383+0000] {processor.py:157} INFO - Started process (PID=36831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:31:16.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:31:16.386+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:31:16.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:31:16.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:31:16.420+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:31:16.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:31:16.432+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:31:16.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:31:16.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T00:31:46.841+0000] {processor.py:157} INFO - Started process (PID=36856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:31:46.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:31:46.846+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:31:46.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:31:46.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:31:46.877+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:31:46.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:31:46.889+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:31:46.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:31:46.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T00:32:17.284+0000] {processor.py:157} INFO - Started process (PID=36884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:32:17.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:32:17.289+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:32:17.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:32:17.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:32:17.323+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:32:17.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:32:17.335+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:32:17.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:32:17.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T00:32:47.751+0000] {processor.py:157} INFO - Started process (PID=36909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:32:47.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:32:47.754+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:32:47.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:32:47.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:32:47.779+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:32:47.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:32:47.789+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:32:47.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:32:47.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T00:33:18.221+0000] {processor.py:157} INFO - Started process (PID=36934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:33:18.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:33:18.225+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:33:18.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:33:18.236+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:33:18.252+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:33:18.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:33:18.262+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:33:18.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:33:18.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T00:33:48.657+0000] {processor.py:157} INFO - Started process (PID=36959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:33:48.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:33:48.659+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:33:48.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:33:48.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:33:48.689+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:33:48.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:33:48.699+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:33:48.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:33:48.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T00:34:19.106+0000] {processor.py:157} INFO - Started process (PID=36984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:34:19.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:34:19.110+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:34:19.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:34:19.122+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:34:19.141+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:34:19.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:34:19.152+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:34:19.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:34:19.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T00:34:49.591+0000] {processor.py:157} INFO - Started process (PID=37009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:34:49.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:34:49.596+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:34:49.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:34:49.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:34:49.644+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:34:49.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:34:49.660+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:34:49.660+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:34:49.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-19T00:35:20.047+0000] {processor.py:157} INFO - Started process (PID=37034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:35:20.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:35:20.050+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:35:20.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:35:20.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:35:20.078+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:35:20.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:35:20.087+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:35:20.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:35:20.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T00:35:50.533+0000] {processor.py:157} INFO - Started process (PID=37059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:35:50.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:35:50.535+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:35:50.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:35:50.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:35:50.559+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:35:50.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:35:50.572+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:35:50.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:35:50.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T00:36:20.976+0000] {processor.py:157} INFO - Started process (PID=37084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:36:20.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:36:20.979+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:36:20.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:36:20.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:36:21.006+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:36:21.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:36:21.018+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:36:21.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:36:21.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T00:36:51.438+0000] {processor.py:157} INFO - Started process (PID=37109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:36:51.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:36:51.441+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:36:51.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:36:51.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:36:51.470+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:36:51.470+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:36:51.482+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:36:51.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:36:51.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T00:37:21.916+0000] {processor.py:157} INFO - Started process (PID=37134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:37:21.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:37:21.919+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:37:21.919+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:37:21.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:37:21.945+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:37:21.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:37:21.956+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:37:21.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:37:21.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T00:37:52.346+0000] {processor.py:157} INFO - Started process (PID=37159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:37:52.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:37:52.349+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:37:52.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:37:52.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:37:52.373+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:37:52.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:37:52.386+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:37:52.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:37:52.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T00:38:22.820+0000] {processor.py:157} INFO - Started process (PID=37184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:38:22.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:38:22.824+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:38:22.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:38:22.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:38:22.851+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:38:22.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:38:22.861+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:38:22.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:38:22.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T00:38:53.295+0000] {processor.py:157} INFO - Started process (PID=37209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:38:53.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:38:53.299+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:38:53.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:38:53.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:38:53.326+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:38:53.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:38:53.335+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:38:53.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:38:53.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T00:39:23.744+0000] {processor.py:157} INFO - Started process (PID=37234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:39:23.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:39:23.750+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:39:23.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:39:23.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:39:23.789+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:39:23.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:39:23.802+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:39:23.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:39:23.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T00:39:54.245+0000] {processor.py:157} INFO - Started process (PID=37259) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:39:54.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:39:54.249+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:39:54.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:39:54.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:39:54.276+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:39:54.276+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:39:54.286+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:39:54.286+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:39:54.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T00:40:24.696+0000] {processor.py:157} INFO - Started process (PID=37284) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:40:24.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:40:24.699+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:40:24.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:40:24.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:40:24.723+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:40:24.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:40:24.733+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:40:24.733+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:40:24.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T00:40:55.166+0000] {processor.py:157} INFO - Started process (PID=37309) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:40:55.168+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:40:55.170+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:40:55.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:40:55.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:40:55.195+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:40:55.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:40:55.205+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:40:55.205+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:40:55.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T00:41:25.614+0000] {processor.py:157} INFO - Started process (PID=37334) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:41:25.615+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:41:25.616+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:41:25.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:41:25.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:41:25.645+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:41:25.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:41:25.655+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:41:25.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:41:25.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T00:41:56.110+0000] {processor.py:157} INFO - Started process (PID=37359) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:41:56.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:41:56.113+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:41:56.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:41:56.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:41:56.142+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:41:56.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:41:56.153+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:41:56.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:41:56.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T00:42:26.531+0000] {processor.py:157} INFO - Started process (PID=37384) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:42:26.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:42:26.533+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:42:26.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:42:26.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:42:26.564+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:42:26.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:42:26.573+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:42:26.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:42:26.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T00:42:56.984+0000] {processor.py:157} INFO - Started process (PID=37409) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:42:56.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:42:56.989+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:42:56.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:42:57.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:42:57.023+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:42:57.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:42:57.035+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:42:57.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:42:57.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T00:43:27.447+0000] {processor.py:157} INFO - Started process (PID=37434) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:43:27.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:43:27.451+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:43:27.451+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:43:27.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:43:27.477+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:43:27.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:43:27.487+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:43:27.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:43:27.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T00:43:57.840+0000] {processor.py:157} INFO - Started process (PID=37459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:43:57.842+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:43:57.844+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:43:57.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:43:57.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:43:57.873+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:43:57.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:43:57.882+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:43:57.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:43:57.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T00:44:28.333+0000] {processor.py:157} INFO - Started process (PID=37484) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:44:28.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:44:28.337+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:44:28.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:44:28.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:44:28.368+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:44:28.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:44:28.378+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:44:28.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:44:28.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T00:44:58.836+0000] {processor.py:157} INFO - Started process (PID=37509) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:44:58.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:44:58.840+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:44:58.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:44:58.854+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:44:58.872+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:44:58.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:44:58.883+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:44:58.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:44:58.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T00:45:29.266+0000] {processor.py:157} INFO - Started process (PID=37534) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:45:29.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:45:29.268+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:45:29.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:45:29.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:45:29.295+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:45:29.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:45:29.304+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:45:29.304+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:45:29.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T00:45:59.728+0000] {processor.py:157} INFO - Started process (PID=37559) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:45:59.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:45:59.731+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:45:59.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:45:59.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:45:59.763+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:45:59.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:45:59.772+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:45:59.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:45:59.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T00:46:30.178+0000] {processor.py:157} INFO - Started process (PID=37584) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:46:30.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:46:30.181+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:46:30.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:46:30.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:46:30.212+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:46:30.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:46:30.223+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:46:30.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:46:30.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T00:47:00.682+0000] {processor.py:157} INFO - Started process (PID=37609) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:47:00.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:47:00.685+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:47:00.685+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:47:00.695+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:47:00.711+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:47:00.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:47:00.721+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:47:00.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:47:00.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T00:47:31.178+0000] {processor.py:157} INFO - Started process (PID=37634) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:47:31.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:47:31.183+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:47:31.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:47:31.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:47:31.214+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:47:31.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:47:31.225+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:47:31.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:47:31.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T00:48:01.601+0000] {processor.py:157} INFO - Started process (PID=37659) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:48:01.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:48:01.605+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:48:01.605+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:48:01.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:48:01.631+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:48:01.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:48:01.643+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:48:01.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:48:01.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T00:48:32.045+0000] {processor.py:157} INFO - Started process (PID=37684) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:48:32.046+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:48:32.048+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:48:32.048+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:48:32.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:48:32.078+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:48:32.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:48:32.088+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:48:32.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:48:32.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T00:49:02.540+0000] {processor.py:157} INFO - Started process (PID=37709) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:49:02.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:49:02.542+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:49:02.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:49:02.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:49:02.571+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:49:02.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:49:02.580+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:49:02.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:49:02.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T00:49:33.018+0000] {processor.py:157} INFO - Started process (PID=37734) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:49:33.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:49:33.021+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:49:33.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:49:33.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:49:33.055+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:49:33.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:49:33.067+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:49:33.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:49:33.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T00:50:03.525+0000] {processor.py:157} INFO - Started process (PID=37759) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:50:03.527+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:50:03.529+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:50:03.529+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:50:03.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:50:03.558+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:50:03.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:50:03.570+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:50:03.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:50:03.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T00:50:33.965+0000] {processor.py:157} INFO - Started process (PID=37784) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:50:33.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:50:33.968+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:50:33.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:50:33.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:50:33.994+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:50:33.994+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:50:34.008+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:50:34.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:50:34.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T00:51:04.362+0000] {processor.py:157} INFO - Started process (PID=37809) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:51:04.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:51:04.365+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:51:04.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:51:04.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:51:04.391+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:51:04.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:51:04.403+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:51:04.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:51:04.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T00:51:34.852+0000] {processor.py:157} INFO - Started process (PID=37834) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:51:34.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:51:34.859+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:51:34.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:51:34.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:51:34.887+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:51:34.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:51:34.897+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:51:34.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:51:34.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T00:52:05.283+0000] {processor.py:157} INFO - Started process (PID=37859) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:52:05.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:52:05.286+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:52:05.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:52:05.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:52:05.311+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:52:05.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:52:05.322+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:52:05.322+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:52:05.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T00:52:35.776+0000] {processor.py:157} INFO - Started process (PID=37884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:52:35.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:52:35.779+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:52:35.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:52:35.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:52:35.805+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:52:35.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:52:35.817+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:52:35.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:52:35.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T00:53:06.215+0000] {processor.py:157} INFO - Started process (PID=37909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:53:06.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:53:06.217+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:53:06.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:53:06.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:53:06.243+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:53:06.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:53:06.252+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:53:06.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:53:06.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T00:53:36.637+0000] {processor.py:157} INFO - Started process (PID=37934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:53:36.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:53:36.640+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:53:36.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:53:36.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:53:36.671+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:53:36.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:53:36.684+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:53:36.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:53:36.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T00:54:07.098+0000] {processor.py:157} INFO - Started process (PID=37959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:54:07.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:54:07.100+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:54:07.100+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:54:07.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:54:07.126+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:54:07.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:54:07.138+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:54:07.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:54:07.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T00:54:37.594+0000] {processor.py:157} INFO - Started process (PID=37984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:54:37.595+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:54:37.598+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:54:37.597+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:54:37.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:54:37.626+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:54:37.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:54:37.638+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:54:37.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:54:37.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T00:55:08.088+0000] {processor.py:157} INFO - Started process (PID=38009) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:55:08.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:55:08.092+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:55:08.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:55:08.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:55:08.120+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:55:08.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:55:08.131+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:55:08.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:55:08.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T00:55:38.559+0000] {processor.py:157} INFO - Started process (PID=38034) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:55:38.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:55:38.563+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:55:38.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:55:38.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:55:38.594+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:55:38.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:55:38.606+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:55:38.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:55:38.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T00:56:08.959+0000] {processor.py:157} INFO - Started process (PID=38059) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:56:08.961+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:56:08.962+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:56:08.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:56:08.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:56:08.990+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:56:08.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:56:09.000+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:56:09.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:56:09.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T00:56:39.395+0000] {processor.py:157} INFO - Started process (PID=38084) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:56:39.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:56:39.397+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:56:39.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:56:39.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:56:39.425+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:56:39.425+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:56:39.435+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:56:39.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:56:39.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T00:57:09.859+0000] {processor.py:157} INFO - Started process (PID=38109) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:57:09.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:57:09.861+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:57:09.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:57:09.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:57:09.889+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:57:09.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:57:09.902+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:57:09.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:57:09.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T00:57:40.315+0000] {processor.py:157} INFO - Started process (PID=38134) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:57:40.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:57:40.317+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:57:40.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:57:40.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:57:40.345+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:57:40.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:57:40.354+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:57:40.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:57:40.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T00:58:10.782+0000] {processor.py:157} INFO - Started process (PID=38159) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:58:10.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:58:10.785+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:58:10.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:58:10.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:58:10.812+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:58:10.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:58:10.823+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:58:10.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:58:10.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T00:58:41.235+0000] {processor.py:157} INFO - Started process (PID=38184) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:58:41.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:58:41.237+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:58:41.237+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:58:41.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:58:41.262+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:58:41.262+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:58:41.271+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:58:41.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:58:41.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T00:59:11.708+0000] {processor.py:157} INFO - Started process (PID=38209) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:59:11.711+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:59:11.714+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:59:11.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:59:11.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:59:11.747+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:59:11.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:59:11.761+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:59:11.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:59:11.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T00:59:42.193+0000] {processor.py:157} INFO - Started process (PID=38234) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:59:42.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T00:59:42.196+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:59:42.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:59:42.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T00:59:42.226+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:59:42.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T00:59:42.241+0000] {logging_mixin.py:151} INFO - [2024-07-19T00:59:42.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-18T01:00:00+00:00, run_after=2024-07-19T01:00:00+00:00
[2024-07-19T00:59:42.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T01:00:12.581+0000] {processor.py:157} INFO - Started process (PID=38649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:00:12.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:00:12.586+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:00:12.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:00:12.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:00:12.628+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:00:12.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:00:12.640+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:00:12.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:00:12.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T01:00:43.026+0000] {processor.py:157} INFO - Started process (PID=38674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:00:43.027+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:00:43.029+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:00:43.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:00:43.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:00:43.061+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:00:43.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:00:43.075+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:00:43.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:00:43.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T01:01:13.480+0000] {processor.py:157} INFO - Started process (PID=38699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:01:13.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:01:13.482+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:01:13.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:01:13.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:01:13.510+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:01:13.510+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:01:13.521+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:01:13.520+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:01:13.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T01:01:43.890+0000] {processor.py:157} INFO - Started process (PID=38724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:01:43.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:01:43.893+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:01:43.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:01:43.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:01:43.920+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:01:43.920+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:01:43.932+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:01:43.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:01:43.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T01:02:14.380+0000] {processor.py:157} INFO - Started process (PID=38749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:02:14.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:02:14.387+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:02:14.387+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:02:14.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:02:14.415+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:02:14.415+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:02:14.425+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:02:14.425+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:02:14.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T01:02:44.872+0000] {processor.py:157} INFO - Started process (PID=38774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:02:44.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:02:44.880+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:02:44.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:02:44.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:02:44.914+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:02:44.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:02:44.927+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:02:44.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:02:44.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T01:03:15.347+0000] {processor.py:157} INFO - Started process (PID=38799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:03:15.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:03:15.351+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:03:15.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:03:15.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:03:15.382+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:03:15.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:03:15.392+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:03:15.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:03:15.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T01:03:45.790+0000] {processor.py:157} INFO - Started process (PID=38824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:03:45.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:03:45.793+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:03:45.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:03:45.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:03:45.823+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:03:45.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:03:45.833+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:03:45.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:03:45.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T01:04:16.259+0000] {processor.py:157} INFO - Started process (PID=38849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:04:16.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:04:16.264+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:04:16.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:04:16.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:04:16.296+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:04:16.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:04:16.308+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:04:16.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:04:16.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T01:04:46.691+0000] {processor.py:157} INFO - Started process (PID=38874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:04:46.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:04:46.693+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:04:46.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:04:46.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:04:46.717+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:04:46.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:04:46.728+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:04:46.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:04:46.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T01:05:17.146+0000] {processor.py:157} INFO - Started process (PID=38899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:05:17.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:05:17.151+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:05:17.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:05:17.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:05:17.177+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:05:17.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:05:17.188+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:05:17.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:05:17.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T01:05:47.600+0000] {processor.py:157} INFO - Started process (PID=38924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:05:47.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:05:47.604+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:05:47.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:05:47.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:05:47.633+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:05:47.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:05:47.643+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:05:47.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:05:47.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T01:06:18.095+0000] {processor.py:157} INFO - Started process (PID=38949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:06:18.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:06:18.098+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:06:18.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:06:18.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:06:18.124+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:06:18.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:06:18.134+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:06:18.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:06:18.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T01:06:48.492+0000] {processor.py:157} INFO - Started process (PID=38974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:06:48.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:06:48.494+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:06:48.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:06:48.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:06:48.520+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:06:48.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:06:48.532+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:06:48.532+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:06:48.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T01:07:18.904+0000] {processor.py:157} INFO - Started process (PID=38999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:07:18.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:07:18.907+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:07:18.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:07:18.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:07:18.933+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:07:18.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:07:18.942+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:07:18.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:07:18.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T01:07:49.379+0000] {processor.py:157} INFO - Started process (PID=39024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:07:49.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:07:49.381+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:07:49.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:07:49.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:07:49.409+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:07:49.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:07:49.420+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:07:49.420+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:07:49.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T01:08:19.870+0000] {processor.py:157} INFO - Started process (PID=39049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:08:19.871+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:08:19.872+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:08:19.872+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:08:19.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:08:19.901+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:08:19.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:08:19.912+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:08:19.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:08:19.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T01:08:50.354+0000] {processor.py:157} INFO - Started process (PID=39074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:08:50.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:08:50.356+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:08:50.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:08:50.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:08:50.383+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:08:50.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:08:50.394+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:08:50.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:08:50.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T01:09:20.833+0000] {processor.py:157} INFO - Started process (PID=39099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:09:20.835+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:09:20.837+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:09:20.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:09:20.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:09:20.869+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:09:20.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:09:20.881+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:09:20.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:09:20.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T01:09:51.318+0000] {processor.py:157} INFO - Started process (PID=39124) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:09:51.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:09:51.322+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:09:51.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:09:51.332+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:09:51.347+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:09:51.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:09:51.357+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:09:51.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:09:51.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T01:10:21.761+0000] {processor.py:157} INFO - Started process (PID=39149) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:10:21.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:10:21.765+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:10:21.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:10:21.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:10:21.792+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:10:21.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:10:21.801+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:10:21.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:10:21.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T01:10:52.153+0000] {processor.py:157} INFO - Started process (PID=39174) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:10:52.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:10:52.159+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:10:52.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:10:52.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:10:52.187+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:10:52.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:10:52.199+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:10:52.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:10:52.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T01:11:22.579+0000] {processor.py:157} INFO - Started process (PID=39199) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:11:22.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:11:22.582+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:11:22.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:11:22.593+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:11:22.608+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:11:22.608+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:11:22.618+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:11:22.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:11:22.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T01:11:53.049+0000] {processor.py:157} INFO - Started process (PID=39224) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:11:53.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:11:53.052+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:11:53.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:11:53.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:11:53.078+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:11:53.078+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:11:53.089+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:11:53.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:11:53.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T01:12:23.454+0000] {processor.py:157} INFO - Started process (PID=39249) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:12:23.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:12:23.457+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:12:23.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:12:23.469+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:12:23.486+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:12:23.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:12:23.498+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:12:23.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:12:23.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T01:12:53.890+0000] {processor.py:157} INFO - Started process (PID=39274) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:12:53.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:12:53.894+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:12:53.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:12:53.905+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:12:53.924+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:12:53.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:12:53.934+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:12:53.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:12:53.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T01:13:24.304+0000] {processor.py:157} INFO - Started process (PID=39299) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:13:24.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:13:24.307+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:13:24.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:13:24.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:13:24.335+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:13:24.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:13:24.346+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:13:24.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:13:24.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T01:13:54.744+0000] {processor.py:157} INFO - Started process (PID=39324) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:13:54.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:13:54.748+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:13:54.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:13:54.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:13:54.774+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:13:54.774+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:13:54.785+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:13:54.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:13:54.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T01:14:25.233+0000] {processor.py:157} INFO - Started process (PID=39349) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:14:25.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:14:25.238+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:14:25.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:14:25.254+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:14:25.267+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:14:25.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:14:25.280+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:14:25.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:14:25.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T01:14:55.688+0000] {processor.py:157} INFO - Started process (PID=39374) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:14:55.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:14:55.691+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:14:55.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:14:55.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:14:55.720+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:14:55.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:14:55.730+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:14:55.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:14:55.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T01:15:26.192+0000] {processor.py:157} INFO - Started process (PID=39399) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:15:26.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:15:26.194+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:15:26.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:15:26.204+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:15:26.221+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:15:26.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:15:26.232+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:15:26.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:15:26.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T01:15:56.662+0000] {processor.py:157} INFO - Started process (PID=39424) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:15:56.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:15:56.665+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:15:56.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:15:56.680+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:15:56.693+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:15:56.693+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:15:56.705+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:15:56.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:15:56.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T01:16:27.095+0000] {processor.py:157} INFO - Started process (PID=39449) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:16:27.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:16:27.098+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:16:27.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:16:27.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:16:27.125+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:16:27.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:16:27.138+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:16:27.138+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:16:27.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T01:16:57.515+0000] {processor.py:157} INFO - Started process (PID=39474) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:16:57.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:16:57.519+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:16:57.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:16:57.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:16:57.546+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:16:57.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:16:57.558+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:16:57.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:16:57.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T01:17:27.934+0000] {processor.py:157} INFO - Started process (PID=39499) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:17:27.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:17:27.938+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:17:27.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:17:27.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:17:27.965+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:17:27.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:17:27.977+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:17:27.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:17:27.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T01:17:58.363+0000] {processor.py:157} INFO - Started process (PID=39524) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:17:58.364+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:17:58.366+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:17:58.366+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:17:58.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:17:58.393+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:17:58.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:17:58.403+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:17:58.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:17:58.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T01:18:28.790+0000] {processor.py:157} INFO - Started process (PID=39549) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:18:28.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:18:28.792+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:18:28.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:18:28.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:18:28.821+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:18:28.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:18:28.832+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:18:28.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:18:28.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T01:18:59.227+0000] {processor.py:157} INFO - Started process (PID=39574) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:18:59.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:18:59.230+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:18:59.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:18:59.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:18:59.259+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:18:59.259+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:18:59.270+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:18:59.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:18:59.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T01:19:29.700+0000] {processor.py:157} INFO - Started process (PID=39599) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:19:29.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:19:29.704+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:19:29.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:19:29.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:19:29.734+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:19:29.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:19:29.746+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:19:29.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:19:29.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T01:20:00.201+0000] {processor.py:157} INFO - Started process (PID=39624) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:20:00.202+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:20:00.205+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:20:00.204+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:20:00.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:20:00.234+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:20:00.234+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:20:00.244+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:20:00.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:20:00.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T01:20:30.650+0000] {processor.py:157} INFO - Started process (PID=39649) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:20:30.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:20:30.653+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:20:30.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:20:30.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:20:30.682+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:20:30.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:20:30.692+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:20:30.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:20:30.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T01:21:01.117+0000] {processor.py:157} INFO - Started process (PID=39674) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:21:01.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:21:01.120+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:21:01.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:21:01.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:21:01.151+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:21:01.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:21:01.163+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:21:01.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:21:01.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T01:21:31.585+0000] {processor.py:157} INFO - Started process (PID=39699) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:21:31.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:21:31.590+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:21:31.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:21:31.604+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:21:31.622+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:21:31.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:21:31.631+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:21:31.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:21:31.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T01:22:02.091+0000] {processor.py:157} INFO - Started process (PID=39724) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:22:02.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:22:02.094+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:22:02.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:22:02.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:22:02.120+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:22:02.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:22:02.131+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:22:02.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:22:02.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T01:22:32.559+0000] {processor.py:157} INFO - Started process (PID=39749) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:22:32.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:22:32.562+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:22:32.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:22:32.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:22:32.592+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:22:32.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:22:32.603+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:22:32.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:22:32.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T01:23:03.046+0000] {processor.py:157} INFO - Started process (PID=39774) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:23:03.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:23:03.049+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:23:03.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:23:03.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:23:03.074+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:23:03.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:23:03.084+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:23:03.084+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:23:03.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T01:23:33.511+0000] {processor.py:157} INFO - Started process (PID=39799) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:23:33.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:23:33.515+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:23:33.514+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:23:33.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:23:33.544+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:23:33.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:23:33.555+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:23:33.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:23:33.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T01:24:03.974+0000] {processor.py:157} INFO - Started process (PID=39824) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:24:03.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:24:03.977+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:24:03.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:24:03.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:24:04.004+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:24:04.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:24:04.018+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:24:04.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:24:04.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T01:24:34.441+0000] {processor.py:157} INFO - Started process (PID=39849) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:24:34.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:24:34.444+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:24:34.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:24:34.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:24:34.474+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:24:34.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:24:34.485+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:24:34.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:24:34.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T01:25:04.886+0000] {processor.py:157} INFO - Started process (PID=39874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:25:04.887+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:25:04.889+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:25:04.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:25:04.898+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:25:04.914+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:25:04.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:25:04.924+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:25:04.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:25:04.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T01:25:35.360+0000] {processor.py:157} INFO - Started process (PID=39899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:25:35.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:25:35.363+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:25:35.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:25:35.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:25:35.393+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:25:35.393+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:25:35.403+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:25:35.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:25:35.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T01:26:05.776+0000] {processor.py:157} INFO - Started process (PID=39924) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:26:05.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:26:05.779+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:26:05.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:26:05.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:26:05.805+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:26:05.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:26:05.817+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:26:05.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:26:05.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T01:26:36.163+0000] {processor.py:157} INFO - Started process (PID=39949) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:26:36.163+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:26:36.165+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:26:36.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:26:36.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:26:36.193+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:26:36.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:26:36.202+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:26:36.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:26:36.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T01:27:06.647+0000] {processor.py:157} INFO - Started process (PID=39974) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:27:06.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:27:06.650+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:27:06.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:27:06.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:27:06.681+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:27:06.681+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:27:06.691+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:27:06.691+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:27:06.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T01:27:37.064+0000] {processor.py:157} INFO - Started process (PID=39999) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:27:37.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:27:37.068+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:27:37.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:27:37.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:27:37.094+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:27:37.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:27:37.107+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:27:37.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:27:37.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T01:28:07.507+0000] {processor.py:157} INFO - Started process (PID=40024) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:28:07.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:28:07.513+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:28:07.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:28:07.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:28:07.543+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:28:07.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:28:07.553+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:28:07.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:28:07.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T01:28:37.947+0000] {processor.py:157} INFO - Started process (PID=40049) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:28:37.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:28:37.952+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:28:37.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:28:37.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:28:37.993+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:28:37.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:28:38.006+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:28:38.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:28:38.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T01:29:08.449+0000] {processor.py:157} INFO - Started process (PID=40074) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:29:08.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:29:08.452+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:29:08.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:29:08.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:29:08.488+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:29:08.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:29:08.499+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:29:08.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:29:08.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T01:29:38.906+0000] {processor.py:157} INFO - Started process (PID=40099) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:29:38.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:29:38.910+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:29:38.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:29:38.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:29:38.948+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:29:38.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:29:38.961+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:29:38.961+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:29:38.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T01:43:48.450+0000] {processor.py:157} INFO - Started process (PID=40125) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:43:48.452+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:43:48.454+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:43:48.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:43:48.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:43:48.507+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:43:48.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:43:48.527+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:43:48.527+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:43:48.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-19T01:44:19.144+0000] {processor.py:157} INFO - Started process (PID=40150) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:44:19.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:44:19.151+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:44:19.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:44:19.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:44:19.202+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:44:19.202+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:44:19.220+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:44:19.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:44:19.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-19T01:44:49.703+0000] {processor.py:157} INFO - Started process (PID=40176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:44:49.704+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:44:49.706+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:44:49.706+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:44:49.723+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:44:49.737+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:44:49.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:44:49.749+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:44:49.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:44:49.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T01:45:20.203+0000] {processor.py:157} INFO - Started process (PID=40201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:45:20.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:45:20.205+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:45:20.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:45:20.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:45:20.232+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:45:20.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:45:20.243+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:45:20.243+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:45:20.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T01:45:50.708+0000] {processor.py:157} INFO - Started process (PID=40226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:45:50.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:45:50.711+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:45:50.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:45:50.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:45:50.737+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:45:50.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:45:50.746+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:45:50.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:45:50.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T01:46:21.238+0000] {processor.py:157} INFO - Started process (PID=40251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:46:21.239+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:46:21.241+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:46:21.241+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:46:21.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:46:21.264+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:46:21.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:46:21.274+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:46:21.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:46:21.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T01:46:51.606+0000] {processor.py:157} INFO - Started process (PID=40276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:46:51.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:46:51.610+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:46:51.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:46:51.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:46:51.634+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:46:51.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:46:51.643+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:46:51.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:46:51.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T01:47:22.049+0000] {processor.py:157} INFO - Started process (PID=40301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:47:22.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:47:22.052+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:47:22.052+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:47:22.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:47:22.080+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:47:22.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:47:22.090+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:47:22.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:47:22.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T01:47:52.543+0000] {processor.py:157} INFO - Started process (PID=40326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:47:52.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:47:52.549+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:47:52.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:47:52.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:47:52.584+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:47:52.584+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:47:52.596+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:47:52.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:47:52.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T01:48:23.057+0000] {processor.py:157} INFO - Started process (PID=40351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:48:23.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:48:23.059+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:48:23.059+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:48:23.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:48:23.088+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:48:23.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:48:23.098+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:48:23.098+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:48:23.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T01:48:53.587+0000] {processor.py:157} INFO - Started process (PID=40376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:48:53.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:48:53.589+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:48:53.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:48:53.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:48:53.611+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:48:53.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:48:53.623+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:48:53.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:48:53.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T01:49:23.962+0000] {processor.py:157} INFO - Started process (PID=40401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:49:23.964+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:49:23.967+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:49:23.966+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:49:23.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:49:23.993+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:49:23.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:49:24.004+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:49:24.004+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:49:24.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T01:49:54.378+0000] {processor.py:157} INFO - Started process (PID=40426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:49:54.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:49:54.381+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:49:54.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:49:54.392+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:49:54.407+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:49:54.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:49:54.416+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:49:54.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:49:54.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T01:50:24.803+0000] {processor.py:157} INFO - Started process (PID=40451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:50:24.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:50:24.806+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:50:24.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:50:24.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:50:24.831+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:50:24.830+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:50:24.842+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:50:24.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:50:24.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T01:50:55.304+0000] {processor.py:157} INFO - Started process (PID=40476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:50:55.306+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:50:55.308+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:50:55.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:50:55.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:50:55.333+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:50:55.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:50:55.345+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:50:55.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:50:55.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T01:51:25.759+0000] {processor.py:157} INFO - Started process (PID=40501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:51:25.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:51:25.761+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:51:25.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:51:25.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:51:25.791+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:51:25.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:51:25.799+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:51:25.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:51:25.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T01:51:56.254+0000] {processor.py:157} INFO - Started process (PID=40525) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:51:56.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:51:56.257+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:51:56.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:51:56.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:51:56.289+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:51:56.289+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:51:56.302+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:51:56.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:51:56.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T01:52:26.740+0000] {processor.py:157} INFO - Started process (PID=40551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:52:26.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:52:26.746+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:52:26.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:52:26.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:52:26.769+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:52:26.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:52:26.778+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:52:26.778+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:52:26.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T01:52:57.273+0000] {processor.py:157} INFO - Started process (PID=40576) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:52:57.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:52:57.275+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:52:57.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:52:57.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:52:57.302+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:52:57.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:52:57.314+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:52:57.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:52:57.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T01:53:27.809+0000] {processor.py:157} INFO - Started process (PID=40601) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:53:27.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:53:27.817+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:53:27.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:53:27.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:53:27.838+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:53:27.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:53:27.848+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:53:27.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:53:27.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T01:53:58.333+0000] {processor.py:157} INFO - Started process (PID=40626) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:53:58.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:53:58.336+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:53:58.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:53:58.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:53:58.363+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:53:58.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:53:58.373+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:53:58.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:53:58.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T01:54:28.725+0000] {processor.py:157} INFO - Started process (PID=40651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:54:28.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:54:28.727+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:54:28.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:54:28.738+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:54:28.754+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:54:28.754+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:54:28.764+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:54:28.764+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:54:28.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T01:54:59.199+0000] {processor.py:157} INFO - Started process (PID=40676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:54:59.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:54:59.201+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:54:59.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:54:59.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:54:59.228+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:54:59.228+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:54:59.239+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:54:59.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:54:59.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T01:55:29.731+0000] {processor.py:157} INFO - Started process (PID=40701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:55:29.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:55:29.737+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:55:29.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:55:29.745+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:55:29.758+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:55:29.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:55:29.766+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:55:29.766+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:55:29.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T01:56:00.129+0000] {processor.py:157} INFO - Started process (PID=40726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:56:00.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:56:00.130+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:56:00.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:56:00.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:56:00.158+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:56:00.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:56:00.170+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:56:00.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:56:00.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T01:56:30.622+0000] {processor.py:157} INFO - Started process (PID=40751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:56:30.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:56:30.624+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:56:30.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:56:30.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:56:30.657+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:56:30.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:56:30.667+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:56:30.667+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:56:30.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T01:57:01.149+0000] {processor.py:157} INFO - Started process (PID=40776) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:57:01.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:57:01.157+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:57:01.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:57:01.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:57:01.176+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:57:01.176+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:57:01.185+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:57:01.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:57:01.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T01:57:31.650+0000] {processor.py:157} INFO - Started process (PID=40801) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:57:31.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:57:31.658+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:57:31.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:57:31.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:57:31.678+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:57:31.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:57:31.687+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:57:31.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:57:31.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T01:58:02.195+0000] {processor.py:157} INFO - Started process (PID=40826) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:58:02.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:58:02.198+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:58:02.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:58:02.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:58:02.221+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:58:02.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:58:02.231+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:58:02.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:58:02.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T01:58:32.807+0000] {processor.py:157} INFO - Started process (PID=40851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:58:32.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:58:32.810+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:58:32.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:58:32.822+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:58:32.838+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:58:32.838+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:58:32.848+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:58:32.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:58:32.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T01:59:03.114+0000] {processor.py:157} INFO - Started process (PID=40876) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:59:03.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:59:03.116+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:59:03.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:59:03.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:59:03.145+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:59:03.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:59:03.156+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:59:03.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:59:03.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T01:59:33.591+0000] {processor.py:157} INFO - Started process (PID=40901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:59:33.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T01:59:33.593+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:59:33.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:59:33.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T01:59:33.620+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:59:33.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T01:59:33.630+0000] {logging_mixin.py:151} INFO - [2024-07-19T01:59:33.630+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T01:59:33.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T02:00:04.058+0000] {processor.py:157} INFO - Started process (PID=40926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:00:04.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:00:04.065+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:00:04.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:00:04.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:00:04.084+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:00:04.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:00:04.093+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:00:04.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:00:04.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-19T02:00:34.536+0000] {processor.py:157} INFO - Started process (PID=40951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:00:34.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:00:34.538+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:00:34.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:00:34.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:00:34.566+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:00:34.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:00:34.575+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:00:34.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:00:34.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T02:01:05.019+0000] {processor.py:157} INFO - Started process (PID=40976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:01:05.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:01:05.027+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:01:05.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:01:05.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:01:05.047+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:01:05.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:01:05.057+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:01:05.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:01:05.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T02:01:35.571+0000] {processor.py:157} INFO - Started process (PID=41001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:01:35.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:01:35.576+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:01:35.576+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:01:35.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:01:35.610+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:01:35.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:01:35.622+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:01:35.622+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:01:35.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T02:02:06.137+0000] {processor.py:157} INFO - Started process (PID=41026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:02:06.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:02:06.139+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:02:06.139+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:02:06.149+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:02:06.166+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:02:06.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:02:06.178+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:02:06.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:02:06.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T02:02:36.628+0000] {processor.py:157} INFO - Started process (PID=41051) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:02:36.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:02:36.634+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:02:36.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:02:36.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:02:36.656+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:02:36.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:02:36.665+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:02:36.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:02:36.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T02:03:07.115+0000] {processor.py:157} INFO - Started process (PID=41076) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:03:07.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:03:07.117+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:03:07.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:03:07.133+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:03:07.148+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:03:07.147+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:03:07.161+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:03:07.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:03:07.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T02:03:37.567+0000] {processor.py:157} INFO - Started process (PID=41101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:03:37.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:03:37.569+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:03:37.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:03:37.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:03:37.599+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:03:37.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:03:37.609+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:03:37.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:03:37.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T02:04:08.059+0000] {processor.py:157} INFO - Started process (PID=41126) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:04:08.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:04:08.063+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:04:08.063+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:04:08.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:04:08.092+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:04:08.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:04:08.101+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:04:08.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:04:08.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T02:04:38.526+0000] {processor.py:157} INFO - Started process (PID=41151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:04:38.526+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:04:38.528+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:04:38.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:04:38.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:04:38.559+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:04:38.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:04:38.569+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:04:38.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:04:38.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T02:05:08.974+0000] {processor.py:157} INFO - Started process (PID=41176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:05:08.975+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:05:08.980+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:05:08.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:05:08.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:05:09.006+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:05:09.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:05:09.016+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:05:09.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:05:09.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T02:05:39.392+0000] {processor.py:157} INFO - Started process (PID=41201) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:05:39.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:05:39.395+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:05:39.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:05:39.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:05:39.424+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:05:39.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:05:39.433+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:05:39.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:05:39.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T02:06:09.789+0000] {processor.py:157} INFO - Started process (PID=41226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:06:09.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:06:09.791+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:06:09.791+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:06:09.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:06:09.822+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:06:09.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:06:09.833+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:06:09.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:06:09.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T02:06:40.319+0000] {processor.py:157} INFO - Started process (PID=41251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:06:40.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:06:40.321+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:06:40.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:06:40.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:06:40.347+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:06:40.347+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:06:40.357+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:06:40.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:06:40.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T02:07:10.840+0000] {processor.py:157} INFO - Started process (PID=41276) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:07:10.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:07:10.848+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:07:10.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:07:10.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:07:10.869+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:07:10.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:07:10.879+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:07:10.879+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:07:10.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T02:07:41.358+0000] {processor.py:157} INFO - Started process (PID=41301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:07:41.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:07:41.364+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:07:41.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:07:41.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:07:41.386+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:07:41.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:07:41.396+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:07:41.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:07:41.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T02:08:11.848+0000] {processor.py:157} INFO - Started process (PID=41326) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:08:11.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:08:11.851+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:08:11.850+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:08:11.860+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:08:11.877+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:08:11.877+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:08:11.887+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:08:11.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:08:11.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T02:08:42.340+0000] {processor.py:157} INFO - Started process (PID=41351) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:08:42.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:08:42.343+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:08:42.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:08:42.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:08:42.370+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:08:42.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:08:42.380+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:08:42.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:08:42.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T02:09:12.843+0000] {processor.py:157} INFO - Started process (PID=41376) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:09:12.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:09:12.845+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:09:12.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:09:12.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:09:12.870+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:09:12.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:09:12.881+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:09:12.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:09:12.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T02:09:43.339+0000] {processor.py:157} INFO - Started process (PID=41401) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:09:43.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:09:43.347+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:09:43.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:09:43.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:09:43.367+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:09:43.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:09:43.376+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:09:43.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:09:43.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T02:10:13.896+0000] {processor.py:157} INFO - Started process (PID=41426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:10:13.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:10:13.898+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:10:13.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:10:13.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:10:13.925+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:10:13.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:10:13.937+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:10:13.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:10:13.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T02:10:44.340+0000] {processor.py:157} INFO - Started process (PID=41451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:10:44.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:10:44.342+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:10:44.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:10:44.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:10:44.368+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:10:44.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:10:44.378+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:10:44.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:10:44.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T02:11:14.745+0000] {processor.py:157} INFO - Started process (PID=41476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:11:14.747+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:11:14.749+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:11:14.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:11:14.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:11:14.773+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:11:14.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:11:14.784+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:11:14.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:11:14.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T02:11:45.283+0000] {processor.py:157} INFO - Started process (PID=41501) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:11:45.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:11:45.287+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:11:45.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:11:45.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:11:45.314+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:11:45.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:11:45.323+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:11:45.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:11:45.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T02:12:15.760+0000] {processor.py:157} INFO - Started process (PID=41526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:12:15.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:12:15.765+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:12:15.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:12:15.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:12:15.791+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:12:15.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:12:15.803+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:12:15.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:12:15.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T02:12:46.306+0000] {processor.py:157} INFO - Started process (PID=41551) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:12:46.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:12:46.314+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:12:46.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:12:46.338+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:12:46.373+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:12:46.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:12:46.450+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:12:46.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:12:46.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.209 seconds
[2024-07-19T02:13:17.076+0000] {processor.py:157} INFO - Started process (PID=41578) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:13:17.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:13:17.078+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:13:17.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:13:17.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:13:17.104+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:13:17.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:13:17.114+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:13:17.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:13:17.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T02:13:47.519+0000] {processor.py:157} INFO - Started process (PID=41603) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:13:47.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:13:47.523+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:13:47.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:13:47.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:13:47.551+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:13:47.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:13:47.561+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:13:47.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:13:47.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T02:14:41.699+0000] {processor.py:157} INFO - Started process (PID=41628) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:14:41.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:14:41.702+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:14:41.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:14:41.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:14:41.728+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:14:41.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:14:41.738+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:14:41.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:14:41.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T02:20:35.274+0000] {processor.py:157} INFO - Started process (PID=41652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:20:35.279+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:20:35.282+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:20:35.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:20:35.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:20:35.343+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:20:35.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:20:35.373+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:20:35.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:20:35.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-19T02:21:05.937+0000] {processor.py:157} INFO - Started process (PID=41678) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:21:05.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:21:05.940+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:21:05.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:21:05.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:21:05.968+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:21:05.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:21:05.979+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:21:05.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:21:05.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T02:26:26.854+0000] {processor.py:157} INFO - Started process (PID=41702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:26:26.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:26:26.858+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:26:26.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:26:26.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:26:26.917+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:26:26.917+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:26:26.935+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:26:26.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:26:26.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-19T02:26:57.600+0000] {processor.py:157} INFO - Started process (PID=41728) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:26:57.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:26:57.602+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:26:57.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:26:57.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:26:57.627+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:26:57.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:26:57.637+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:26:57.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:26:57.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T02:27:55.557+0000] {processor.py:157} INFO - Started process (PID=41753) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:27:55.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:27:55.559+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:27:55.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:27:55.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:27:55.591+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:27:55.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:27:55.602+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:27:55.602+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:27:55.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T02:29:29.106+0000] {processor.py:157} INFO - Started process (PID=41778) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:29:29.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:29:29.110+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:29:29.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:29:29.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:29:29.153+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:29:29.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:29:29.166+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:29:29.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:29:29.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-19T02:29:59.552+0000] {processor.py:157} INFO - Started process (PID=41803) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:29:59.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:29:59.555+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:29:59.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:29:59.569+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:29:59.582+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:29:59.582+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:29:59.592+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:29:59.592+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:29:59.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T02:30:57.532+0000] {processor.py:157} INFO - Started process (PID=41830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:30:57.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:30:57.536+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:30:57.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:30:57.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:30:57.567+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:30:57.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:30:57.578+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:30:57.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:30:57.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T02:41:44.191+0000] {processor.py:157} INFO - Started process (PID=41855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:41:44.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:41:44.204+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:41:44.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:41:44.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:41:44.318+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:41:44.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:41:44.340+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:41:44.339+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:41:44.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.188 seconds
[2024-07-19T02:42:14.815+0000] {processor.py:157} INFO - Started process (PID=41879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:42:14.816+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:42:14.819+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:42:14.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:42:14.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:42:14.870+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:42:14.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:42:14.887+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:42:14.886+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:42:14.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-19T02:42:45.329+0000] {processor.py:157} INFO - Started process (PID=41905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:42:45.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:42:45.332+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:42:45.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:42:45.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:42:45.361+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:42:45.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:42:45.373+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:42:45.373+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:42:45.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T02:43:15.762+0000] {processor.py:157} INFO - Started process (PID=41930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:43:15.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:43:15.765+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:43:15.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:43:15.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:43:15.797+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:43:15.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:43:15.808+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:43:15.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:43:15.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T02:43:46.224+0000] {processor.py:157} INFO - Started process (PID=41955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:43:46.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:43:46.227+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:43:46.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:43:46.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:43:46.254+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:43:46.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:43:46.266+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:43:46.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:43:46.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T02:44:16.623+0000] {processor.py:157} INFO - Started process (PID=41980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:44:16.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:44:16.630+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:44:16.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:44:16.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:44:16.674+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:44:16.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:44:16.687+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:44:16.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:44:16.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-19T02:44:47.039+0000] {processor.py:157} INFO - Started process (PID=42005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:44:47.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:44:47.043+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:44:47.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:44:47.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:44:47.067+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:44:47.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:44:47.078+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:44:47.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:44:47.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T02:45:17.407+0000] {processor.py:157} INFO - Started process (PID=42030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:45:17.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:45:17.410+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:45:17.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:45:17.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:45:17.436+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:45:17.436+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:45:17.446+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:45:17.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:45:17.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T02:45:47.817+0000] {processor.py:157} INFO - Started process (PID=42055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:45:47.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:45:47.822+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:45:47.822+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:45:47.833+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:45:47.853+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:45:47.853+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:45:47.863+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:45:47.863+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:45:47.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T02:46:18.260+0000] {processor.py:157} INFO - Started process (PID=42080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:46:18.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:46:18.264+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:46:18.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:46:18.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:46:18.299+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:46:18.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:46:18.314+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:46:18.314+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:46:18.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T02:46:48.715+0000] {processor.py:157} INFO - Started process (PID=42105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:46:48.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:46:48.718+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:46:48.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:46:48.733+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:46:48.749+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:46:48.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:46:48.760+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:46:48.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:46:48.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T02:47:19.154+0000] {processor.py:157} INFO - Started process (PID=42130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:47:19.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:47:19.157+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:47:19.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:47:19.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:47:19.184+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:47:19.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:47:19.195+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:47:19.195+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:47:19.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T02:47:49.551+0000] {processor.py:157} INFO - Started process (PID=42155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:47:49.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:47:49.555+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:47:49.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:47:49.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:47:49.579+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:47:49.579+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:47:49.590+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:47:49.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:47:49.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T02:48:19.941+0000] {processor.py:157} INFO - Started process (PID=42180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:48:19.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:48:19.942+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:48:19.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:48:19.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:48:19.966+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:48:19.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:48:19.976+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:48:19.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:48:19.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-19T02:48:50.350+0000] {processor.py:157} INFO - Started process (PID=42205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:48:50.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:48:50.353+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:48:50.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:48:50.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:48:50.379+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:48:50.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:48:50.388+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:48:50.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:48:50.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T02:49:20.730+0000] {processor.py:157} INFO - Started process (PID=42230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:49:20.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:49:20.732+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:49:20.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:49:20.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:49:20.761+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:49:20.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:49:20.770+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:49:20.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:49:20.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T02:49:51.188+0000] {processor.py:157} INFO - Started process (PID=42255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:49:51.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:49:51.192+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:49:51.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:49:51.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:49:51.218+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:49:51.218+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:49:51.228+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:49:51.228+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:49:51.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T02:50:21.618+0000] {processor.py:157} INFO - Started process (PID=42280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:50:21.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:50:21.621+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:50:21.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:50:21.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:50:21.647+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:50:21.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:50:21.658+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:50:21.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:50:21.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T02:50:52.094+0000] {processor.py:157} INFO - Started process (PID=42305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:50:52.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:50:52.096+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:50:52.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:50:52.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:50:52.121+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:50:52.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:50:52.131+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:50:52.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:50:52.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T02:51:22.555+0000] {processor.py:157} INFO - Started process (PID=42330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:51:22.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:51:22.558+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:51:22.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:51:22.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:51:22.586+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:51:22.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:51:22.597+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:51:22.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:51:22.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T02:51:53.023+0000] {processor.py:157} INFO - Started process (PID=42355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:51:53.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:51:53.029+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:51:53.028+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:51:53.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:51:53.064+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:51:53.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:51:53.076+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:51:53.076+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:51:53.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T02:52:23.495+0000] {processor.py:157} INFO - Started process (PID=42380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:52:23.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:52:23.498+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:52:23.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:52:23.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:52:23.526+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:52:23.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:52:23.535+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:52:23.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:52:23.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T02:52:53.906+0000] {processor.py:157} INFO - Started process (PID=42405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:52:53.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:52:53.909+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:52:53.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:52:53.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:52:53.936+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:52:53.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:52:53.948+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:52:53.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:52:53.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T02:53:24.357+0000] {processor.py:157} INFO - Started process (PID=42430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:53:24.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:53:24.359+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:53:24.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:53:24.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:53:24.388+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:53:24.388+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:53:24.398+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:53:24.398+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:53:24.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T02:53:54.750+0000] {processor.py:157} INFO - Started process (PID=42455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:53:54.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:53:54.752+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:53:54.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:53:54.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:53:54.776+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:53:54.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:53:54.785+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:53:54.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:53:54.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-19T02:54:25.210+0000] {processor.py:157} INFO - Started process (PID=42480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:54:25.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:54:25.213+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:54:25.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:54:25.224+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:54:25.242+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:54:25.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:54:25.254+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:54:25.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:54:25.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T02:54:55.640+0000] {processor.py:157} INFO - Started process (PID=42505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:54:55.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:54:55.644+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:54:55.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:54:55.658+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:54:55.675+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:54:55.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:54:55.685+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:54:55.685+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:54:55.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T02:55:26.041+0000] {processor.py:157} INFO - Started process (PID=42530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:55:26.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:55:26.045+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:55:26.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:55:26.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:55:26.073+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:55:26.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:55:26.082+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:55:26.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:55:26.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T02:55:56.486+0000] {processor.py:157} INFO - Started process (PID=42555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:55:56.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:55:56.490+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:55:56.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:55:56.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:55:56.517+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:55:56.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:55:56.528+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:55:56.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:55:56.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T02:56:26.867+0000] {processor.py:157} INFO - Started process (PID=42580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:56:26.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:56:26.870+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:56:26.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:56:26.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:56:26.900+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:56:26.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:56:26.912+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:56:26.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:56:26.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T02:56:57.350+0000] {processor.py:157} INFO - Started process (PID=42605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:56:57.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:56:57.353+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:56:57.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:56:57.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:56:57.383+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:56:57.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:56:57.394+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:56:57.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:56:57.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T02:57:27.797+0000] {processor.py:157} INFO - Started process (PID=42630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:57:27.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:57:27.801+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:57:27.801+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:57:27.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:57:27.833+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:57:27.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:57:27.844+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:57:27.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:57:27.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T02:57:58.184+0000] {processor.py:157} INFO - Started process (PID=42655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:57:58.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:57:58.187+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:57:58.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:57:58.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:57:58.213+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:57:58.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:57:58.223+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:57:58.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:57:58.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T02:58:28.574+0000] {processor.py:157} INFO - Started process (PID=42680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:58:28.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:58:28.579+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:58:28.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:58:28.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:58:28.617+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:58:28.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:58:28.628+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:58:28.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:58:28.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T02:58:59.008+0000] {processor.py:157} INFO - Started process (PID=42705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:58:59.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:58:59.011+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:58:59.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:58:59.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:58:59.043+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:58:59.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:58:59.057+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:58:59.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:58:59.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T02:59:29.421+0000] {processor.py:157} INFO - Started process (PID=42730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:59:29.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:59:29.424+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:59:29.424+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:59:29.438+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:59:29.451+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:59:29.451+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:59:29.463+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:59:29.463+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:59:29.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T02:59:59.817+0000] {processor.py:157} INFO - Started process (PID=42755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:59:59.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T02:59:59.820+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:59:59.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:59:59.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T02:59:59.849+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:59:59.849+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T02:59:59.862+0000] {logging_mixin.py:151} INFO - [2024-07-19T02:59:59.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T02:59:59.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T03:00:30.212+0000] {processor.py:157} INFO - Started process (PID=42780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:00:30.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:00:30.215+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:00:30.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:00:30.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:00:30.243+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:00:30.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:00:30.255+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:00:30.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:00:30.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T03:01:00.626+0000] {processor.py:157} INFO - Started process (PID=42805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:01:00.627+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:01:00.629+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:01:00.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:01:00.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:01:00.659+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:01:00.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:01:00.669+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:01:00.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:01:00.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T03:01:30.999+0000] {processor.py:157} INFO - Started process (PID=42830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:01:31.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:01:31.001+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:01:31.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:01:31.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:01:31.024+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:01:31.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:01:31.035+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:01:31.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:01:31.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T03:02:01.410+0000] {processor.py:157} INFO - Started process (PID=42855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:02:01.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:02:01.414+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:02:01.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:02:01.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:02:01.442+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:02:01.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:02:01.453+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:02:01.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:02:01.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T03:02:31.856+0000] {processor.py:157} INFO - Started process (PID=42880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:02:31.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:02:31.866+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:02:31.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:02:31.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:02:31.887+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:02:31.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:02:31.897+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:02:31.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:02:31.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T03:03:02.289+0000] {processor.py:157} INFO - Started process (PID=42905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:03:02.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:03:02.294+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:03:02.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:03:02.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:03:02.329+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:03:02.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:03:02.341+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:03:02.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:03:02.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T03:03:32.750+0000] {processor.py:157} INFO - Started process (PID=42930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:03:32.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:03:32.753+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:03:32.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:03:32.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:03:32.781+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:03:32.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:03:32.793+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:03:32.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:03:32.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T03:04:03.163+0000] {processor.py:157} INFO - Started process (PID=42955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:04:03.165+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:04:03.167+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:04:03.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:04:03.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:04:03.192+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:04:03.192+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:04:03.202+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:04:03.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:04:03.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T03:04:33.535+0000] {processor.py:157} INFO - Started process (PID=42980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:04:33.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:04:33.538+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:04:33.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:04:33.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:04:33.561+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:04:33.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:04:33.571+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:04:33.571+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:04:33.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T03:05:03.958+0000] {processor.py:157} INFO - Started process (PID=43005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:05:03.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:05:03.961+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:05:03.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:05:03.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:05:03.992+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:05:03.992+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:05:04.002+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:05:04.002+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:05:04.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T03:05:34.366+0000] {processor.py:157} INFO - Started process (PID=43030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:05:34.368+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:05:34.369+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:05:34.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:05:34.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:05:34.394+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:05:34.394+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:05:34.403+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:05:34.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:05:34.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T03:06:04.802+0000] {processor.py:157} INFO - Started process (PID=43055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:06:04.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:06:04.806+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:06:04.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:06:04.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:06:04.835+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:06:04.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:06:04.847+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:06:04.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:06:04.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T03:06:35.190+0000] {processor.py:157} INFO - Started process (PID=43080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:06:35.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:06:35.193+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:06:35.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:06:35.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:06:35.221+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:06:35.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:06:35.231+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:06:35.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:06:35.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T03:07:05.610+0000] {processor.py:157} INFO - Started process (PID=43105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:07:05.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:07:05.614+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:07:05.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:07:05.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:07:05.644+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:07:05.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:07:05.654+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:07:05.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:07:05.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T03:07:35.990+0000] {processor.py:157} INFO - Started process (PID=43130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:07:35.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:07:35.993+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:07:35.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:07:36.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:07:36.019+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:07:36.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:07:36.029+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:07:36.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:07:36.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T03:08:06.370+0000] {processor.py:157} INFO - Started process (PID=43155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:08:06.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:08:06.373+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:08:06.373+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:08:06.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:08:06.398+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:08:06.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:08:06.408+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:08:06.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:08:06.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T03:08:36.761+0000] {processor.py:157} INFO - Started process (PID=43180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:08:36.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:08:36.763+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:08:36.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:08:36.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:08:36.789+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:08:36.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:08:36.799+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:08:36.799+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:08:36.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T03:09:07.212+0000] {processor.py:157} INFO - Started process (PID=43205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:09:07.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:09:07.214+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:09:07.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:09:07.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:09:07.242+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:09:07.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:09:07.256+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:09:07.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:09:07.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T03:09:37.629+0000] {processor.py:157} INFO - Started process (PID=43230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:09:37.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:09:37.633+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:09:37.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:09:37.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:09:37.658+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:09:37.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:09:37.669+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:09:37.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:09:37.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T03:10:08.110+0000] {processor.py:157} INFO - Started process (PID=43255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:10:08.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:10:08.115+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:10:08.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:10:08.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:10:08.145+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:10:08.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:10:08.155+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:10:08.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:10:08.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T03:10:38.531+0000] {processor.py:157} INFO - Started process (PID=43280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:10:38.532+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:10:38.534+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:10:38.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:10:38.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:10:38.567+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:10:38.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:10:38.580+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:10:38.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:10:38.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T03:11:09.012+0000] {processor.py:157} INFO - Started process (PID=43305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:11:09.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:11:09.017+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:11:09.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:11:09.029+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:11:09.047+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:11:09.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:11:09.057+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:11:09.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:11:09.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T03:11:39.472+0000] {processor.py:157} INFO - Started process (PID=43330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:11:39.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:11:39.474+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:11:39.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:11:39.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:11:39.501+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:11:39.500+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:11:39.510+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:11:39.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:11:39.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T03:12:09.933+0000] {processor.py:157} INFO - Started process (PID=43355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:12:09.934+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:12:09.935+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:12:09.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:12:09.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:12:09.961+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:12:09.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:12:09.972+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:12:09.972+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:12:09.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T03:12:40.396+0000] {processor.py:157} INFO - Started process (PID=43380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:12:40.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:12:40.400+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:12:40.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:12:40.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:12:40.430+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:12:40.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:12:40.440+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:12:40.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:12:40.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T03:13:10.808+0000] {processor.py:157} INFO - Started process (PID=43405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:13:10.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:13:10.811+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:13:10.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:13:10.821+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:13:10.836+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:13:10.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:13:10.849+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:13:10.849+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:13:10.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T03:13:41.240+0000] {processor.py:157} INFO - Started process (PID=43430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:13:41.241+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:13:41.244+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:13:41.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:13:41.256+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:13:41.272+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:13:41.272+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:13:41.282+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:13:41.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:13:41.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T03:14:11.667+0000] {processor.py:157} INFO - Started process (PID=43455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:14:11.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:14:11.670+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:14:11.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:14:11.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:14:11.694+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:14:11.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:14:11.706+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:14:11.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:14:11.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T03:14:42.134+0000] {processor.py:157} INFO - Started process (PID=43480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:14:42.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:14:42.138+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:14:42.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:14:42.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:14:42.167+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:14:42.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:14:42.179+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:14:42.179+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:14:42.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T03:15:12.597+0000] {processor.py:157} INFO - Started process (PID=43505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:15:12.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:15:12.600+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:15:12.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:15:12.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:15:12.629+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:15:12.629+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:15:12.639+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:15:12.639+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:15:12.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T03:15:43.029+0000] {processor.py:157} INFO - Started process (PID=43530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:15:43.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:15:43.032+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:15:43.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:15:43.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:15:43.062+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:15:43.062+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:15:43.072+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:15:43.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:15:43.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T03:16:13.459+0000] {processor.py:157} INFO - Started process (PID=43555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:16:13.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:16:13.462+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:16:13.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:16:13.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:16:13.489+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:16:13.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:16:13.502+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:16:13.502+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:16:13.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T03:16:43.851+0000] {processor.py:157} INFO - Started process (PID=43580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:16:43.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:16:43.856+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:16:43.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:16:43.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:16:43.893+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:16:43.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:16:43.907+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:16:43.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:16:43.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T03:17:14.344+0000] {processor.py:157} INFO - Started process (PID=43605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:17:14.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:17:14.347+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:17:14.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:17:14.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:17:14.372+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:17:14.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:17:14.382+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:17:14.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:17:14.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T03:17:44.772+0000] {processor.py:157} INFO - Started process (PID=43630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:17:44.773+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:17:44.775+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:17:44.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:17:44.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:17:44.801+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:17:44.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:17:44.811+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:17:44.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:17:44.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T03:18:15.233+0000] {processor.py:157} INFO - Started process (PID=43655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:18:15.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:18:15.235+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:18:15.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:18:15.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:18:15.261+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:18:15.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:18:15.271+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:18:15.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:18:15.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T03:18:45.665+0000] {processor.py:157} INFO - Started process (PID=43680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:18:45.666+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:18:45.669+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:18:45.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:18:45.679+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:18:45.696+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:18:45.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:18:45.707+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:18:45.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:18:45.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T03:19:16.114+0000] {processor.py:157} INFO - Started process (PID=43705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:19:16.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:19:16.117+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:19:16.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:19:16.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:19:16.146+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:19:16.146+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:19:16.156+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:19:16.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:19:16.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T03:19:46.579+0000] {processor.py:157} INFO - Started process (PID=43730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:19:46.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:19:46.582+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:19:46.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:19:46.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:19:46.611+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:19:46.611+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:19:46.620+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:19:46.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:19:46.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T03:20:17.014+0000] {processor.py:157} INFO - Started process (PID=43755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:20:17.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:20:17.018+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:20:17.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:20:17.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:20:17.044+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:20:17.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:20:17.054+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:20:17.054+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:20:17.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T03:20:47.441+0000] {processor.py:157} INFO - Started process (PID=43780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:20:47.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:20:47.444+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:20:47.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:20:47.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:20:47.475+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:20:47.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:20:47.485+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:20:47.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:20:47.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T03:21:17.826+0000] {processor.py:157} INFO - Started process (PID=43805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:21:17.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:21:17.828+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:21:17.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:21:17.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:21:17.854+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:21:17.854+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:21:17.867+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:21:17.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:21:17.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T03:21:48.288+0000] {processor.py:157} INFO - Started process (PID=43830) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:21:48.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:21:48.291+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:21:48.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:21:48.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:21:48.319+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:21:48.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:21:48.329+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:21:48.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:21:48.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T03:22:18.765+0000] {processor.py:157} INFO - Started process (PID=43855) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:22:18.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:22:18.767+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:22:18.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:22:18.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:22:18.793+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:22:18.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:22:18.802+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:22:18.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:22:18.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T03:22:49.184+0000] {processor.py:157} INFO - Started process (PID=43880) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:22:49.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:22:49.186+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:22:49.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:22:49.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:22:49.215+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:22:49.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:22:49.227+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:22:49.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:22:49.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T03:23:19.663+0000] {processor.py:157} INFO - Started process (PID=43905) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:23:19.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:23:19.667+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:23:19.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:23:19.682+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:23:19.695+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:23:19.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:23:19.704+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:23:19.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:23:19.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T03:23:50.043+0000] {processor.py:157} INFO - Started process (PID=43930) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:23:50.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:23:50.047+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:23:50.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:23:50.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:23:50.076+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:23:50.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:23:50.087+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:23:50.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:23:50.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T03:24:20.445+0000] {processor.py:157} INFO - Started process (PID=43955) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:24:20.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:24:20.448+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:24:20.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:24:20.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:24:20.473+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:24:20.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:24:20.485+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:24:20.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:24:20.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T03:24:50.843+0000] {processor.py:157} INFO - Started process (PID=43980) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:24:50.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:24:50.846+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:24:50.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:24:50.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:24:50.875+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:24:50.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:24:50.887+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:24:50.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:24:50.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T03:25:21.308+0000] {processor.py:157} INFO - Started process (PID=44005) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:25:21.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:25:21.314+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:25:21.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:25:21.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:25:21.350+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:25:21.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:25:21.367+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:25:21.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:25:21.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T03:25:51.777+0000] {processor.py:157} INFO - Started process (PID=44030) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:25:51.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:25:51.779+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:25:51.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:25:51.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:25:51.809+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:25:51.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:25:51.818+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:25:51.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:25:51.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T03:26:22.249+0000] {processor.py:157} INFO - Started process (PID=44055) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:26:22.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:26:22.253+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:26:22.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:26:22.269+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:26:22.292+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:26:22.292+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:26:22.313+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:26:22.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:26:22.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-19T03:26:52.849+0000] {processor.py:157} INFO - Started process (PID=44080) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:26:52.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:26:52.852+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:26:52.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:26:52.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:26:52.882+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:26:52.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:26:52.892+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:26:52.892+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:26:52.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T03:27:23.290+0000] {processor.py:157} INFO - Started process (PID=44105) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:27:23.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:27:23.293+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:27:23.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:27:23.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:27:23.316+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:27:23.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:27:23.327+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:27:23.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:27:23.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T03:27:53.760+0000] {processor.py:157} INFO - Started process (PID=44130) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:27:53.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:27:53.765+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:27:53.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:27:53.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:27:53.791+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:27:53.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:27:53.803+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:27:53.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:27:53.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T03:28:24.219+0000] {processor.py:157} INFO - Started process (PID=44155) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:28:24.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:28:24.222+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:28:24.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:28:24.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:28:24.251+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:28:24.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:28:24.260+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:28:24.260+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:28:24.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T03:28:54.674+0000] {processor.py:157} INFO - Started process (PID=44180) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:28:54.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:28:54.678+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:28:54.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:28:54.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:28:54.704+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:28:54.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:28:54.717+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:28:54.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:28:54.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T03:29:25.116+0000] {processor.py:157} INFO - Started process (PID=44205) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:29:25.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:29:25.119+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:29:25.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:29:25.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:29:25.145+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:29:25.145+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:29:25.154+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:29:25.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:29:25.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T03:29:55.483+0000] {processor.py:157} INFO - Started process (PID=44230) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:29:55.484+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:29:55.486+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:29:55.486+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:29:55.500+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:29:55.515+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:29:55.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:29:55.526+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:29:55.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:29:55.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T03:30:25.906+0000] {processor.py:157} INFO - Started process (PID=44255) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:30:25.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:30:25.909+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:30:25.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:30:25.921+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:30:25.938+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:30:25.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:30:25.949+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:30:25.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:30:25.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T03:30:56.336+0000] {processor.py:157} INFO - Started process (PID=44280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:30:56.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:30:56.340+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:30:56.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:30:56.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:30:56.376+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:30:56.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:30:56.389+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:30:56.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:30:56.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T03:31:26.781+0000] {processor.py:157} INFO - Started process (PID=44305) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:31:26.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:31:26.784+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:31:26.783+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:31:26.794+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:31:26.809+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:31:26.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:31:26.819+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:31:26.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:31:26.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T03:31:57.224+0000] {processor.py:157} INFO - Started process (PID=44330) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:31:57.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:31:57.227+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:31:57.227+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:31:57.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:31:57.255+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:31:57.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:31:57.264+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:31:57.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:31:57.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T03:32:27.688+0000] {processor.py:157} INFO - Started process (PID=44355) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:32:27.689+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:32:27.690+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:32:27.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:32:27.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:32:27.719+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:32:27.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:32:27.730+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:32:27.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:32:27.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T03:32:58.118+0000] {processor.py:157} INFO - Started process (PID=44380) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:32:58.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:32:58.121+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:32:58.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:32:58.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:32:58.149+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:32:58.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:32:58.159+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:32:58.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:32:58.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T03:33:28.574+0000] {processor.py:157} INFO - Started process (PID=44405) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:33:28.575+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:33:28.577+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:33:28.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:33:28.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:33:28.604+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:33:28.604+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:33:28.617+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:33:28.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:33:28.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T03:33:59.016+0000] {processor.py:157} INFO - Started process (PID=44430) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:33:59.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:33:59.019+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:33:59.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:33:59.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:33:59.047+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:33:59.047+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:33:59.056+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:33:59.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:33:59.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T03:34:29.406+0000] {processor.py:157} INFO - Started process (PID=44455) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:34:29.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:34:29.411+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:34:29.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:34:29.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:34:29.439+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:34:29.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:34:29.448+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:34:29.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:34:29.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T03:34:59.843+0000] {processor.py:157} INFO - Started process (PID=44480) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:34:59.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:34:59.846+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:34:59.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:34:59.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:34:59.871+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:34:59.871+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:34:59.881+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:34:59.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:34:59.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T03:35:30.298+0000] {processor.py:157} INFO - Started process (PID=44505) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:35:30.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:35:30.302+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:35:30.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:35:30.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:35:30.329+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:35:30.329+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:35:30.341+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:35:30.341+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:35:30.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T03:36:00.707+0000] {processor.py:157} INFO - Started process (PID=44530) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:36:00.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:36:00.710+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:36:00.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:36:00.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:36:00.736+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:36:00.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:36:00.746+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:36:00.746+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:36:00.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T03:36:31.190+0000] {processor.py:157} INFO - Started process (PID=44555) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:36:31.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:36:31.194+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:36:31.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:36:31.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:36:31.231+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:36:31.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:36:31.244+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:36:31.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:36:31.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T03:37:01.687+0000] {processor.py:157} INFO - Started process (PID=44580) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:37:01.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:37:01.690+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:37:01.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:37:01.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:37:01.719+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:37:01.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:37:01.729+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:37:01.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:37:01.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T03:37:32.153+0000] {processor.py:157} INFO - Started process (PID=44605) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:37:32.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:37:32.156+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:37:32.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:37:32.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:37:32.187+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:37:32.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:37:32.198+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:37:32.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:37:32.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T03:38:02.582+0000] {processor.py:157} INFO - Started process (PID=44630) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:38:02.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:38:02.586+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:38:02.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:38:02.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:38:02.614+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:38:02.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:38:02.623+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:38:02.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:38:02.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T03:38:32.982+0000] {processor.py:157} INFO - Started process (PID=44655) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:38:32.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:38:32.985+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:38:32.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:38:32.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:38:33.013+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:38:33.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:38:33.024+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:38:33.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:38:33.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T03:39:03.376+0000] {processor.py:157} INFO - Started process (PID=44680) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:39:03.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:39:03.380+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:39:03.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:39:03.391+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:39:03.409+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:39:03.409+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:39:03.421+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:39:03.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:39:03.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T03:39:33.801+0000] {processor.py:157} INFO - Started process (PID=44705) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:39:33.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:39:33.804+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:39:33.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:39:33.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:39:33.835+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:39:33.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:39:33.846+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:39:33.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:39:33.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T03:40:04.216+0000] {processor.py:157} INFO - Started process (PID=44730) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:40:04.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:40:04.219+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:40:04.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:40:04.234+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:40:04.248+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:40:04.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:40:04.257+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:40:04.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:40:04.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T03:40:34.647+0000] {processor.py:157} INFO - Started process (PID=44755) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:40:34.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:40:34.649+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:40:34.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:40:34.663+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:40:34.677+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:40:34.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:40:34.688+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:40:34.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:40:34.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T03:41:05.148+0000] {processor.py:157} INFO - Started process (PID=44780) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:41:05.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:41:05.156+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:41:05.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:41:05.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:41:05.201+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:41:05.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:41:05.214+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:41:05.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:41:05.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-19T03:54:01.647+0000] {processor.py:157} INFO - Started process (PID=44807) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:54:01.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:54:01.654+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:54:01.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:54:01.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:54:01.708+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:54:01.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:54:01.730+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:54:01.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:54:01.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-19T03:54:32.281+0000] {processor.py:157} INFO - Started process (PID=44832) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:54:32.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T03:54:32.287+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:54:32.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:54:32.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T03:54:32.329+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:54:32.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T03:54:32.346+0000] {logging_mixin.py:151} INFO - [2024-07-19T03:54:32.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T03:54:32.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-19T04:11:03.295+0000] {processor.py:157} INFO - Started process (PID=44857) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:11:03.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:11:03.298+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:11:03.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:11:03.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:11:03.323+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:11:03.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:11:03.336+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:11:03.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:11:03.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T04:11:33.762+0000] {processor.py:157} INFO - Started process (PID=44884) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:11:33.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:11:33.764+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:11:33.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:11:33.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:11:33.790+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:11:33.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:11:33.803+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:11:33.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:11:33.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T04:12:04.251+0000] {processor.py:157} INFO - Started process (PID=44909) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:12:04.255+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:12:04.258+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:12:04.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:12:04.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:12:04.292+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:12:04.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:12:04.303+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:12:04.303+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:12:04.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T04:12:34.740+0000] {processor.py:157} INFO - Started process (PID=44934) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:12:34.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:12:34.752+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:12:34.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:12:34.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:12:34.779+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:12:34.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:12:34.789+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:12:34.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:12:34.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T04:13:05.181+0000] {processor.py:157} INFO - Started process (PID=44959) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:13:05.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:13:05.185+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:13:05.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:13:05.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:13:05.213+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:13:05.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:13:05.225+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:13:05.225+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:13:05.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T04:30:03.973+0000] {processor.py:157} INFO - Started process (PID=44986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:30:03.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:30:03.975+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:30:03.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:30:03.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:30:04.020+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:30:04.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:30:04.040+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:30:04.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:30:04.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-19T04:30:34.570+0000] {processor.py:157} INFO - Started process (PID=45011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:30:34.571+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:30:34.574+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:30:34.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:30:34.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:30:34.605+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:30:34.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:30:34.616+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:30:34.616+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:30:34.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T04:46:47.042+0000] {processor.py:157} INFO - Started process (PID=45036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:46:47.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:46:47.046+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:46:47.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:46:47.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:46:47.094+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:46:47.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:46:47.113+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:46:47.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:46:47.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-19T04:47:17.700+0000] {processor.py:157} INFO - Started process (PID=45061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:47:17.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:47:17.702+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:47:17.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:47:17.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:47:17.724+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:47:17.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:47:17.734+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:47:17.734+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:47:17.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-19T04:47:48.222+0000] {processor.py:157} INFO - Started process (PID=45086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:47:48.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:47:48.228+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:47:48.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:47:48.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:47:48.257+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:47:48.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:47:48.268+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:47:48.267+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:47:48.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T04:48:18.777+0000] {processor.py:157} INFO - Started process (PID=45111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:48:18.780+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:48:18.782+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:48:18.782+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:48:18.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:48:18.818+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:48:18.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:48:18.831+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:48:18.831+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:48:18.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T04:48:49.276+0000] {processor.py:157} INFO - Started process (PID=45136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:48:49.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:48:49.279+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:48:49.279+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:48:49.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:48:49.306+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:48:49.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:48:49.318+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:48:49.318+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:48:49.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T04:49:19.869+0000] {processor.py:157} INFO - Started process (PID=45161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:49:19.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:49:19.872+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:49:19.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:49:19.886+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:49:19.899+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:49:19.899+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:49:19.909+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:49:19.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:49:19.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T04:49:50.357+0000] {processor.py:157} INFO - Started process (PID=45186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:49:50.358+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:49:50.359+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:49:50.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:49:50.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:49:50.386+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:49:50.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:49:50.396+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:49:50.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:49:50.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T04:50:20.895+0000] {processor.py:157} INFO - Started process (PID=45211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:50:20.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:50:20.898+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:50:20.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:50:20.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:50:20.929+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:50:20.929+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:50:20.939+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:50:20.939+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:50:20.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T04:50:51.371+0000] {processor.py:157} INFO - Started process (PID=45236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:50:51.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:50:51.375+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:50:51.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:50:51.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:50:51.406+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:50:51.406+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:50:51.417+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:50:51.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:50:51.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T04:51:21.850+0000] {processor.py:157} INFO - Started process (PID=45261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:51:21.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:51:21.853+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:51:21.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:51:21.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:51:21.879+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:51:21.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:51:21.889+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:51:21.888+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:51:21.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T04:51:52.348+0000] {processor.py:157} INFO - Started process (PID=45286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:51:52.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:51:52.352+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:51:52.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:51:52.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:51:52.378+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:51:52.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:51:52.391+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:51:52.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:51:52.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T04:52:22.859+0000] {processor.py:157} INFO - Started process (PID=45311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:52:22.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:52:22.862+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:52:22.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:52:22.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:52:22.889+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:52:22.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:52:22.900+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:52:22.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:52:22.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T04:52:53.320+0000] {processor.py:157} INFO - Started process (PID=45336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:52:53.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:52:53.322+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:52:53.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:52:53.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:52:53.348+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:52:53.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:52:53.358+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:52:53.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:52:53.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T04:53:23.801+0000] {processor.py:157} INFO - Started process (PID=45361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:53:23.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:53:23.804+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:53:23.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:53:23.814+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:53:23.831+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:53:23.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:53:23.841+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:53:23.840+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:53:23.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T04:53:54.308+0000] {processor.py:157} INFO - Started process (PID=45386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:53:54.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:53:54.310+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:53:54.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:53:54.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:53:54.340+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:53:54.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:53:54.357+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:53:54.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:53:54.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T04:54:24.724+0000] {processor.py:157} INFO - Started process (PID=45411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:54:24.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:54:24.726+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:54:24.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:54:24.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:54:24.752+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:54:24.752+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:54:24.765+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:54:24.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:54:24.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T04:54:55.232+0000] {processor.py:157} INFO - Started process (PID=45436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:54:55.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:54:55.236+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:54:55.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:54:55.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:54:55.266+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:54:55.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:54:55.277+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:54:55.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:54:55.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T04:55:25.642+0000] {processor.py:157} INFO - Started process (PID=45461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:55:25.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:55:25.646+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:55:25.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:55:25.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:55:25.671+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:55:25.671+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:55:25.681+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:55:25.681+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:55:25.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T04:55:56.091+0000] {processor.py:157} INFO - Started process (PID=45486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:55:56.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:55:56.095+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:55:56.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:55:56.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:55:56.123+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:55:56.123+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:55:56.133+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:55:56.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:55:56.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T04:56:26.615+0000] {processor.py:157} INFO - Started process (PID=45511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:56:26.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:56:26.619+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:56:26.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:56:26.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:56:26.648+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:56:26.647+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:56:26.659+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:56:26.659+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:56:26.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T04:56:57.028+0000] {processor.py:157} INFO - Started process (PID=45536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:56:57.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:56:57.030+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:56:57.030+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:56:57.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:56:57.055+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:56:57.055+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:56:57.066+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:56:57.065+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:56:57.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T04:57:27.464+0000] {processor.py:157} INFO - Started process (PID=45561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:57:27.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:57:27.467+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:57:27.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:57:27.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:57:27.497+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:57:27.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:57:27.507+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:57:27.507+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:57:27.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T04:57:57.978+0000] {processor.py:157} INFO - Started process (PID=45586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:57:57.979+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:57:57.981+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:57:57.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:57:57.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:57:58.011+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:57:58.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:57:58.021+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:57:58.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:57:58.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T04:58:28.442+0000] {processor.py:157} INFO - Started process (PID=45611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:58:28.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:58:28.445+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:58:28.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:58:28.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:58:28.472+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:58:28.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:58:28.481+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:58:28.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:58:28.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T04:58:58.978+0000] {processor.py:157} INFO - Started process (PID=45636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:58:58.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:58:58.982+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:58:58.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:58:58.998+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:58:59.010+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:58:59.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:58:59.020+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:58:59.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:58:59.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T04:59:29.428+0000] {processor.py:157} INFO - Started process (PID=45661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:59:29.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T04:59:29.433+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:59:29.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:59:29.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T04:59:29.462+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:59:29.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T04:59:29.472+0000] {logging_mixin.py:151} INFO - [2024-07-19T04:59:29.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T04:59:29.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T05:00:00.000+0000] {processor.py:157} INFO - Started process (PID=45686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:00:00.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:00:00.004+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:00:00.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:00:00.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:00:00.033+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:00:00.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:00:00.043+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:00:00.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:00:00.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T05:00:30.506+0000] {processor.py:157} INFO - Started process (PID=45711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:00:30.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:00:30.508+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:00:30.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:00:30.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:00:30.540+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:00:30.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:00:30.552+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:00:30.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:00:30.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T05:01:01.002+0000] {processor.py:157} INFO - Started process (PID=45736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:01:01.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:01:01.004+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:01:01.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:01:01.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:01:01.033+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:01:01.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:01:01.045+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:01:01.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:01:01.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T05:01:31.522+0000] {processor.py:157} INFO - Started process (PID=45761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:01:31.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:01:31.526+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:01:31.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:01:31.536+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:01:31.552+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:01:31.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:01:31.563+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:01:31.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:01:31.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T05:02:02.002+0000] {processor.py:157} INFO - Started process (PID=45786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:02:02.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:02:02.005+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:02:02.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:02:02.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:02:02.036+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:02:02.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:02:02.047+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:02:02.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:02:02.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T05:02:32.296+0000] {processor.py:157} INFO - Started process (PID=45811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:02:32.297+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:02:32.299+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:02:32.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:02:32.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:02:32.332+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:02:32.332+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:02:32.345+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:02:32.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:02:32.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T05:03:02.755+0000] {processor.py:157} INFO - Started process (PID=45836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:03:02.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:03:02.759+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:03:02.759+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:03:02.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:03:02.788+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:03:02.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:03:02.801+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:03:02.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:03:02.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T05:03:33.186+0000] {processor.py:157} INFO - Started process (PID=45861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:03:33.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:03:33.190+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:03:33.190+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:03:33.200+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:03:33.217+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:03:33.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:03:33.227+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:03:33.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:03:33.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T05:04:03.599+0000] {processor.py:157} INFO - Started process (PID=45886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:04:03.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:04:03.600+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:04:03.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:04:03.616+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:04:03.628+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:04:03.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:04:03.636+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:04:03.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:04:03.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T05:04:34.109+0000] {processor.py:157} INFO - Started process (PID=45911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:04:34.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:04:34.111+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:04:34.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:04:34.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:04:34.140+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:04:34.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:04:34.152+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:04:34.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:04:34.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T05:05:04.558+0000] {processor.py:157} INFO - Started process (PID=45936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:05:04.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:05:04.562+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:05:04.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:05:04.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:05:04.587+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:05:04.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:05:04.597+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:05:04.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:05:04.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T05:05:35.064+0000] {processor.py:157} INFO - Started process (PID=45961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:05:35.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:05:35.066+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:05:35.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:05:35.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:05:35.095+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:05:35.095+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:05:35.108+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:05:35.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:05:35.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T05:06:05.568+0000] {processor.py:157} INFO - Started process (PID=45986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:06:05.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:06:05.570+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:06:05.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:06:05.579+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:06:05.597+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:06:05.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:06:05.609+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:06:05.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:06:05.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T05:06:35.999+0000] {processor.py:157} INFO - Started process (PID=46011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:06:36.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:06:36.003+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:06:36.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:06:36.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:06:36.031+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:06:36.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:06:36.042+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:06:36.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:06:36.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T05:07:06.507+0000] {processor.py:157} INFO - Started process (PID=46036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:07:06.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:07:06.510+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:07:06.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:07:06.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:07:06.544+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:07:06.544+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:07:06.554+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:07:06.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:07:06.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T05:07:36.997+0000] {processor.py:157} INFO - Started process (PID=46061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:07:36.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:07:36.999+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:07:36.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:07:37.008+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:07:37.023+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:07:37.023+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:07:37.035+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:07:37.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:07:37.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T05:08:07.431+0000] {processor.py:157} INFO - Started process (PID=46086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:08:07.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:08:07.434+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:08:07.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:08:07.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:08:07.460+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:08:07.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:08:07.471+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:08:07.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:08:07.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T05:08:37.836+0000] {processor.py:157} INFO - Started process (PID=46111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:08:37.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:08:37.840+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:08:37.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:08:37.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:08:37.867+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:08:37.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:08:37.877+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:08:37.877+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:08:37.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T05:09:08.330+0000] {processor.py:157} INFO - Started process (PID=46136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:09:08.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:09:08.333+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:09:08.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:09:08.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:09:08.359+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:09:08.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:09:08.372+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:09:08.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:09:08.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T05:09:38.782+0000] {processor.py:157} INFO - Started process (PID=46161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:09:38.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:09:38.784+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:09:38.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:09:38.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:09:38.807+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:09:38.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:09:38.817+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:09:38.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:09:38.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-19T05:10:09.325+0000] {processor.py:157} INFO - Started process (PID=46186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:10:09.327+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:10:09.329+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:10:09.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:10:09.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:10:09.363+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:10:09.362+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:10:09.372+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:10:09.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:10:09.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T05:10:39.803+0000] {processor.py:157} INFO - Started process (PID=46211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:10:39.804+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:10:39.806+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:10:39.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:10:39.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:10:39.833+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:10:39.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:10:39.842+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:10:39.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:10:39.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T05:11:10.236+0000] {processor.py:157} INFO - Started process (PID=46236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:11:10.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:11:10.239+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:11:10.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:11:10.251+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:11:10.266+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:11:10.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:11:10.277+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:11:10.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:11:10.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T05:11:40.663+0000] {processor.py:157} INFO - Started process (PID=46261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:11:40.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:11:40.666+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:11:40.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:11:40.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:11:40.694+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:11:40.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:11:40.707+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:11:40.707+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:11:40.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T05:12:11.098+0000] {processor.py:157} INFO - Started process (PID=46286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:12:11.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:12:11.101+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:12:11.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:12:11.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:12:11.127+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:12:11.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:12:11.136+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:12:11.136+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:12:11.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T05:12:41.634+0000] {processor.py:157} INFO - Started process (PID=46311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:12:41.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:12:41.639+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:12:41.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:12:41.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:12:41.664+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:12:41.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:12:41.673+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:12:41.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:12:41.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T05:13:12.083+0000] {processor.py:157} INFO - Started process (PID=46336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:13:12.084+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:13:12.086+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:13:12.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:13:12.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:13:12.113+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:13:12.113+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:13:12.124+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:13:12.124+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:13:12.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T05:13:42.563+0000] {processor.py:157} INFO - Started process (PID=46361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:13:42.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:13:42.567+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:13:42.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:13:42.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:13:42.598+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:13:42.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:13:42.608+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:13:42.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:13:42.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T05:14:13.019+0000] {processor.py:157} INFO - Started process (PID=46386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:14:13.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:14:13.022+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:14:13.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:14:13.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:14:13.049+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:14:13.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:14:13.059+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:14:13.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:14:13.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T05:14:43.520+0000] {processor.py:157} INFO - Started process (PID=46411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:14:43.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:14:43.523+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:14:43.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:14:43.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:14:43.550+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:14:43.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:14:43.560+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:14:43.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:14:43.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T05:15:13.989+0000] {processor.py:157} INFO - Started process (PID=46436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:15:13.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:15:13.992+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:15:13.992+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:15:14.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:15:14.021+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:15:14.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:15:14.032+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:15:14.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:15:14.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T05:15:44.491+0000] {processor.py:157} INFO - Started process (PID=46461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:15:44.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:15:44.493+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:15:44.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:15:44.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:15:44.520+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:15:44.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:15:44.530+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:15:44.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:15:44.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T05:16:14.993+0000] {processor.py:157} INFO - Started process (PID=46486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:16:14.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:16:14.996+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:16:14.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:16:15.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:16:15.024+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:16:15.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:16:15.035+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:16:15.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:16:15.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T05:16:45.487+0000] {processor.py:157} INFO - Started process (PID=46511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:16:45.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:16:45.490+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:16:45.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:16:45.502+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:16:45.518+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:16:45.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:16:45.531+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:16:45.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:16:45.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T05:17:15.945+0000] {processor.py:157} INFO - Started process (PID=46536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:17:15.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:17:15.949+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:17:15.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:17:15.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:17:15.975+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:17:15.975+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:17:15.988+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:17:15.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:17:15.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T05:17:46.561+0000] {processor.py:157} INFO - Started process (PID=46561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:17:46.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:17:46.570+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:17:46.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:17:46.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:17:46.591+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:17:46.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:17:46.601+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:17:46.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:17:46.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T05:18:17.161+0000] {processor.py:157} INFO - Started process (PID=46586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:18:17.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:18:17.163+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:18:17.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:18:17.184+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:18:17.201+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:18:17.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:18:17.213+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:18:17.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:18:17.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T05:18:47.674+0000] {processor.py:157} INFO - Started process (PID=46611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:18:47.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:18:47.676+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:18:47.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:18:47.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:18:47.704+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:18:47.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:18:47.714+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:18:47.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:18:47.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T05:19:18.170+0000] {processor.py:157} INFO - Started process (PID=46636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:19:18.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:19:18.179+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:19:18.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:19:18.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:19:18.200+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:19:18.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:19:18.209+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:19:18.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:19:18.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T05:19:48.621+0000] {processor.py:157} INFO - Started process (PID=46661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:19:48.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:19:48.623+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:19:48.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:19:48.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:19:48.652+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:19:48.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:19:48.663+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:19:48.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:19:48.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T05:20:19.063+0000] {processor.py:157} INFO - Started process (PID=46686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:20:19.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:20:19.066+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:20:19.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:20:19.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:20:19.090+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:20:19.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:20:19.104+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:20:19.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:20:19.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T05:20:49.542+0000] {processor.py:157} INFO - Started process (PID=46711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:20:49.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:20:49.550+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:20:49.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:20:49.557+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:20:49.571+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:20:49.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:20:49.580+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:20:49.580+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:20:49.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T05:21:20.082+0000] {processor.py:157} INFO - Started process (PID=46736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:21:20.087+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:21:20.090+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:21:20.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:21:20.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:21:20.110+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:21:20.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:21:20.119+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:21:20.119+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:21:20.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T05:21:50.515+0000] {processor.py:157} INFO - Started process (PID=46761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:21:50.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:21:50.518+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:21:50.517+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:21:50.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:21:50.544+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:21:50.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:21:50.553+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:21:50.553+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:21:50.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T05:22:20.872+0000] {processor.py:157} INFO - Started process (PID=46786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:22:20.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:22:20.875+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:22:20.875+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:22:20.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:22:20.905+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:22:20.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:22:20.914+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:22:20.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:22:20.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T05:22:51.315+0000] {processor.py:157} INFO - Started process (PID=46811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:22:51.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:22:51.317+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:22:51.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:22:51.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:22:51.344+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:22:51.344+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:22:51.355+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:22:51.355+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:22:51.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T05:23:21.767+0000] {processor.py:157} INFO - Started process (PID=46836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:23:21.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:23:21.769+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:23:21.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:23:21.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:23:21.798+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:23:21.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:23:21.809+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:23:21.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:23:21.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T05:23:52.278+0000] {processor.py:157} INFO - Started process (PID=46861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:23:52.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:23:52.286+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:23:52.286+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:23:52.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:23:52.306+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:23:52.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:23:52.315+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:23:52.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:23:52.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T05:24:22.756+0000] {processor.py:157} INFO - Started process (PID=46886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:24:22.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:24:22.764+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:24:22.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:24:22.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:24:22.783+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:24:22.783+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:24:22.793+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:24:22.793+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:24:22.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T05:24:53.193+0000] {processor.py:157} INFO - Started process (PID=46911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:24:53.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:24:53.195+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:24:53.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:24:53.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:24:53.217+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:24:53.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:24:53.229+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:24:53.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:24:53.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T05:25:23.659+0000] {processor.py:157} INFO - Started process (PID=46936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:25:23.661+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:25:23.663+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:25:23.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:25:23.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:25:23.688+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:25:23.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:25:23.701+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:25:23.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:25:23.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T05:25:54.122+0000] {processor.py:157} INFO - Started process (PID=46961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:25:54.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:25:54.124+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:25:54.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:25:54.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:25:54.150+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:25:54.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:25:54.160+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:25:54.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:25:54.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T05:26:24.582+0000] {processor.py:157} INFO - Started process (PID=46986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:26:24.583+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:26:24.585+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:26:24.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:26:24.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:26:24.609+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:26:24.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:26:24.619+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:26:24.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:26:24.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T05:26:55.036+0000] {processor.py:157} INFO - Started process (PID=47011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:26:55.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:26:55.040+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:26:55.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:26:55.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:26:55.068+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:26:55.068+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:26:55.077+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:26:55.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:26:55.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T05:27:25.548+0000] {processor.py:157} INFO - Started process (PID=47036) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:27:25.548+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:27:25.550+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:27:25.550+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:27:25.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:27:25.577+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:27:25.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:27:25.587+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:27:25.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:27:25.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T05:27:56.085+0000] {processor.py:157} INFO - Started process (PID=47061) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:27:56.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:27:56.088+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:27:56.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:27:56.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:27:56.120+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:27:56.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:27:56.130+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:27:56.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:27:56.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T05:28:26.529+0000] {processor.py:157} INFO - Started process (PID=47086) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:28:26.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:28:26.536+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:28:26.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:28:26.544+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:28:26.557+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:28:26.557+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:28:26.567+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:28:26.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:28:26.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T05:28:57.017+0000] {processor.py:157} INFO - Started process (PID=47111) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:28:57.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:28:57.019+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:28:57.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:28:57.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:28:57.046+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:28:57.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:28:57.056+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:28:57.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:28:57.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T05:29:27.571+0000] {processor.py:157} INFO - Started process (PID=47136) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:29:27.573+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:29:27.575+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:29:27.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:29:27.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:29:27.603+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:29:27.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:29:27.613+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:29:27.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:29:27.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T05:29:58.049+0000] {processor.py:157} INFO - Started process (PID=47161) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:29:58.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:29:58.056+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:29:58.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:29:58.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:29:58.077+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:29:58.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:29:58.087+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:29:58.087+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:29:58.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T05:30:28.516+0000] {processor.py:157} INFO - Started process (PID=47186) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:30:28.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:30:28.518+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:30:28.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:30:28.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:30:28.545+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:30:28.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:30:28.554+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:30:28.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:30:28.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T05:30:58.984+0000] {processor.py:157} INFO - Started process (PID=47211) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:30:58.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:30:58.988+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:30:58.987+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:30:58.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:30:59.020+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:30:59.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:30:59.029+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:30:59.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:30:59.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T05:31:29.463+0000] {processor.py:157} INFO - Started process (PID=47236) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:31:29.464+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:31:29.466+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:31:29.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:31:29.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:31:29.495+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:31:29.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:31:29.504+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:31:29.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:31:29.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T05:32:00.037+0000] {processor.py:157} INFO - Started process (PID=47261) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:32:00.039+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:32:00.041+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:32:00.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:32:00.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:32:00.067+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:32:00.067+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:32:00.079+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:32:00.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:32:00.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T05:32:30.605+0000] {processor.py:157} INFO - Started process (PID=47286) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:32:30.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:32:30.608+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:32:30.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:32:30.618+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:32:30.633+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:32:30.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:32:30.642+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:32:30.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:32:30.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T05:33:01.134+0000] {processor.py:157} INFO - Started process (PID=47311) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:33:01.136+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:33:01.137+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:33:01.137+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:33:01.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:33:01.165+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:33:01.165+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:33:01.176+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:33:01.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:33:01.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T05:33:31.581+0000] {processor.py:157} INFO - Started process (PID=47336) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:33:31.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:33:31.589+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:33:31.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:33:31.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:33:31.610+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:33:31.609+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:33:31.620+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:33:31.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:33:31.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T05:34:02.068+0000] {processor.py:157} INFO - Started process (PID=47361) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:34:02.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:34:02.072+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:34:02.071+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:34:02.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:34:02.104+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:34:02.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:34:02.114+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:34:02.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:34:02.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T05:34:32.602+0000] {processor.py:157} INFO - Started process (PID=47386) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:34:32.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:34:32.605+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:34:32.604+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:34:32.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:34:32.639+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:34:32.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:34:32.651+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:34:32.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:34:32.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T05:35:03.058+0000] {processor.py:157} INFO - Started process (PID=47411) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:35:03.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:35:03.061+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:35:03.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:35:03.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:35:03.089+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:35:03.089+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:35:03.099+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:35:03.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:35:03.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T05:35:33.547+0000] {processor.py:157} INFO - Started process (PID=47436) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:35:33.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:35:33.551+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:35:33.551+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:35:33.562+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:35:33.576+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:35:33.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:35:33.585+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:35:33.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:35:33.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T05:36:04.059+0000] {processor.py:157} INFO - Started process (PID=47461) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:36:04.066+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:36:04.067+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:36:04.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:36:04.074+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:36:04.087+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:36:04.087+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:36:04.096+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:36:04.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:36:04.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T05:36:34.540+0000] {processor.py:157} INFO - Started process (PID=47486) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:36:34.541+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:36:34.543+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:36:34.542+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:36:34.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:36:34.568+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:36:34.568+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:36:34.578+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:36:34.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:36:34.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T05:37:05.035+0000] {processor.py:157} INFO - Started process (PID=47511) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:37:05.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:37:05.044+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:37:05.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:37:05.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:37:05.065+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:37:05.064+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:37:05.075+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:37:05.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:37:05.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T05:37:35.535+0000] {processor.py:157} INFO - Started process (PID=47536) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:37:35.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:37:35.538+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:37:35.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:37:35.549+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:37:35.564+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:37:35.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:37:35.574+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:37:35.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:37:35.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T05:38:06.067+0000] {processor.py:157} INFO - Started process (PID=47561) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:38:06.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:38:06.069+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:38:06.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:38:06.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:38:06.097+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:38:06.097+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:38:06.107+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:38:06.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:38:06.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T05:38:36.569+0000] {processor.py:157} INFO - Started process (PID=47586) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:38:36.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:38:36.571+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:38:36.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:38:36.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:38:36.594+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:38:36.594+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:38:36.603+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:38:36.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:38:36.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-19T05:39:07.110+0000] {processor.py:157} INFO - Started process (PID=47611) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:39:07.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:39:07.112+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:39:07.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:39:07.127+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:39:07.140+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:39:07.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:39:07.152+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:39:07.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:39:07.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T05:39:37.604+0000] {processor.py:157} INFO - Started process (PID=47636) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:39:37.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:39:37.607+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:39:37.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:39:37.614+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:39:37.630+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:39:37.630+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:39:37.640+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:39:37.640+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:39:37.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-19T05:40:08.214+0000] {processor.py:157} INFO - Started process (PID=47661) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:40:08.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:40:08.220+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:40:08.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:40:08.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:40:08.245+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:40:08.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:40:08.257+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:40:08.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:40:08.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T05:40:38.648+0000] {processor.py:157} INFO - Started process (PID=47686) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:40:38.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:40:38.657+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:40:38.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:40:38.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:40:38.679+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:40:38.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:40:38.689+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:40:38.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:40:38.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T05:41:09.160+0000] {processor.py:157} INFO - Started process (PID=47711) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:41:09.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:41:09.162+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:41:09.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:41:09.178+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:41:09.191+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:41:09.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:41:09.201+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:41:09.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:41:09.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T05:41:39.638+0000] {processor.py:157} INFO - Started process (PID=47736) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:41:39.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:41:39.640+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:41:39.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:41:39.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:41:39.667+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:41:39.667+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:41:39.679+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:41:39.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:41:39.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T05:42:10.091+0000] {processor.py:157} INFO - Started process (PID=47761) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:42:10.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:42:10.094+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:42:10.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:42:10.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:42:10.121+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:42:10.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:42:10.130+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:42:10.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:42:10.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T05:42:40.554+0000] {processor.py:157} INFO - Started process (PID=47786) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:42:40.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:42:40.557+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:42:40.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:42:40.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:42:40.588+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:42:40.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:42:40.600+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:42:40.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:42:40.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T05:43:11.053+0000] {processor.py:157} INFO - Started process (PID=47811) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:43:11.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:43:11.057+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:43:11.056+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:43:11.068+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:43:11.084+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:43:11.084+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:43:11.094+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:43:11.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:43:11.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T05:43:41.586+0000] {processor.py:157} INFO - Started process (PID=47836) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:43:41.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:43:41.588+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:43:41.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:43:41.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:43:41.613+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:43:41.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:43:41.623+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:43:41.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:43:41.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T05:44:12.112+0000] {processor.py:157} INFO - Started process (PID=47861) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:44:12.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:44:12.114+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:44:12.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:44:12.124+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:44:12.140+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:44:12.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:44:12.150+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:44:12.150+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:44:12.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T05:44:42.613+0000] {processor.py:157} INFO - Started process (PID=47886) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:44:42.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:44:42.616+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:44:42.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:44:42.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:44:42.644+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:44:42.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:44:42.654+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:44:42.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:44:42.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T05:45:13.090+0000] {processor.py:157} INFO - Started process (PID=47911) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:45:13.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:45:13.092+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:45:13.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:45:13.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:45:13.120+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:45:13.120+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:45:13.130+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:45:13.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:45:13.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-19T05:45:43.771+0000] {processor.py:157} INFO - Started process (PID=47936) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:45:43.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:45:43.778+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:45:43.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:45:43.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:45:43.801+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:45:43.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:45:43.810+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:45:43.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:45:43.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T05:46:14.247+0000] {processor.py:157} INFO - Started process (PID=47961) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:46:14.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:46:14.251+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:46:14.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:46:14.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:46:14.278+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:46:14.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:46:14.288+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:46:14.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:46:14.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T05:46:44.694+0000] {processor.py:157} INFO - Started process (PID=47986) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:46:44.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:46:44.698+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:46:44.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:46:44.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:46:44.728+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:46:44.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:46:44.738+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:46:44.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:46:44.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T05:47:15.482+0000] {processor.py:157} INFO - Started process (PID=48011) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:47:15.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T05:47:15.485+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:47:15.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:47:15.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T05:47:15.515+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:47:15.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T05:47:15.527+0000] {logging_mixin.py:151} INFO - [2024-07-19T05:47:15.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T05:47:15.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T06:04:17.339+0000] {processor.py:157} INFO - Started process (PID=48038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:04:17.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:04:17.346+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:04:17.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:04:17.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:04:17.392+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:04:17.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:04:17.416+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:04:17.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:04:17.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-19T06:20:50.889+0000] {processor.py:157} INFO - Started process (PID=48063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:20:50.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:20:50.895+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:20:50.895+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:20:50.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:20:50.945+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:20:50.945+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:20:50.958+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:20:50.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:20:50.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-19T06:21:21.408+0000] {processor.py:157} INFO - Started process (PID=48088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:21:21.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:21:21.411+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:21:21.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:21:21.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:21:21.441+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:21:21.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:21:21.452+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:21:21.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:21:21.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T06:21:51.844+0000] {processor.py:157} INFO - Started process (PID=48113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:21:51.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:21:51.848+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:21:51.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:21:51.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:21:51.874+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:21:51.874+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:21:51.883+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:21:51.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:21:51.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T06:37:40.147+0000] {processor.py:157} INFO - Started process (PID=48138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:37:40.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:37:40.152+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:37:40.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:37:40.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:37:40.201+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:37:40.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:37:40.230+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:37:40.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:37:40.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.105 seconds
[2024-07-19T06:38:10.677+0000] {processor.py:157} INFO - Started process (PID=48163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:38:10.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:38:10.679+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:38:10.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:38:10.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:38:10.709+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:38:10.709+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:38:10.721+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:38:10.721+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:38:10.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T06:38:41.188+0000] {processor.py:157} INFO - Started process (PID=48188) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:38:41.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:38:41.191+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:38:41.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:38:41.202+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:38:41.219+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:38:41.219+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:38:41.229+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:38:41.229+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:38:41.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T06:39:11.675+0000] {processor.py:157} INFO - Started process (PID=48213) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:39:11.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:39:11.678+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:39:11.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:39:11.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:39:11.704+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:39:11.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:39:11.717+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:39:11.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:39:11.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-07-19T06:39:42.442+0000] {processor.py:157} INFO - Started process (PID=48238) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:39:42.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:39:42.446+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:39:42.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:39:42.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:39:42.478+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:39:42.478+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:39:42.494+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:39:42.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:39:42.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T06:40:12.940+0000] {processor.py:157} INFO - Started process (PID=48263) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:40:12.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:40:12.943+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:40:12.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:40:12.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:40:12.970+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:40:12.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:40:12.980+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:40:12.980+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:40:12.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T06:40:43.450+0000] {processor.py:157} INFO - Started process (PID=48288) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:40:43.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:40:43.455+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:40:43.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:40:43.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:40:43.503+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:40:43.503+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:40:43.517+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:40:43.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:40:43.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-19T06:41:13.961+0000] {processor.py:157} INFO - Started process (PID=48313) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:41:13.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:41:13.964+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:41:13.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:41:13.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:41:14.001+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:41:14.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:41:14.015+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:41:14.015+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:41:14.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T06:41:44.430+0000] {processor.py:157} INFO - Started process (PID=48338) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:41:44.431+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:41:44.433+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:41:44.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:41:44.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:41:44.463+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:41:44.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:41:44.473+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:41:44.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:41:44.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T06:42:14.875+0000] {processor.py:157} INFO - Started process (PID=48363) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:42:14.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:42:14.877+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:42:14.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:42:14.887+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:42:14.901+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:42:14.901+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:42:14.912+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:42:14.912+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:42:15.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.185 seconds
[2024-07-19T06:42:45.727+0000] {processor.py:157} INFO - Started process (PID=48388) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:42:45.729+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:42:45.731+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:42:45.730+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:42:45.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:42:45.760+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:42:45.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:42:45.770+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:42:45.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:42:45.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T06:43:16.171+0000] {processor.py:157} INFO - Started process (PID=48413) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:43:16.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:43:16.176+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:43:16.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:43:16.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:43:16.208+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:43:16.208+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:43:16.219+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:43:16.219+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:43:16.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T06:43:46.688+0000] {processor.py:157} INFO - Started process (PID=48438) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:43:46.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:43:46.689+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:43:46.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:43:46.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:43:46.717+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:43:46.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:43:46.728+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:43:46.727+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:43:46.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T06:44:17.156+0000] {processor.py:157} INFO - Started process (PID=48463) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:44:17.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:44:17.158+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:44:17.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:44:17.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:44:17.185+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:44:17.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:44:17.196+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:44:17.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:44:17.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T06:44:47.558+0000] {processor.py:157} INFO - Started process (PID=48488) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:44:47.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:44:47.560+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:44:47.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:44:47.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:44:47.590+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:44:47.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:44:47.600+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:44:47.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:44:47.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T06:45:18.128+0000] {processor.py:157} INFO - Started process (PID=48513) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:45:18.130+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:45:18.132+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:45:18.132+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:45:18.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:45:18.159+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:45:18.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:45:18.169+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:45:18.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:45:18.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T06:45:48.612+0000] {processor.py:157} INFO - Started process (PID=48538) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:45:48.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:45:48.614+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:45:48.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:45:48.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:45:48.650+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:45:48.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:45:48.662+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:45:48.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:45:48.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T06:46:19.159+0000] {processor.py:157} INFO - Started process (PID=48563) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:46:19.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:46:19.162+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:46:19.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:46:19.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:46:19.187+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:46:19.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:46:19.197+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:46:19.197+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:46:19.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T06:46:49.655+0000] {processor.py:157} INFO - Started process (PID=48588) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:46:49.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:46:49.658+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:46:49.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:46:49.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:46:49.682+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:46:49.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:46:49.692+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:46:49.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:46:49.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T06:47:20.087+0000] {processor.py:157} INFO - Started process (PID=48613) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:47:20.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:47:20.091+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:47:20.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:47:20.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:47:20.119+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:47:20.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:47:20.130+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:47:20.130+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:47:20.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T06:47:50.577+0000] {processor.py:157} INFO - Started process (PID=48638) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:47:50.578+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:47:50.580+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:47:50.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:47:50.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:47:50.607+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:47:50.607+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:47:50.618+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:47:50.618+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:47:50.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-07-19T06:48:21.205+0000] {processor.py:157} INFO - Started process (PID=48663) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:48:21.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:48:21.213+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:48:21.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:48:21.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:48:21.236+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:48:21.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:48:21.246+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:48:21.246+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:48:21.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T06:48:51.635+0000] {processor.py:157} INFO - Started process (PID=48688) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:48:51.637+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:48:51.639+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:48:51.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:48:51.649+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:48:51.664+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:48:51.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:48:51.676+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:48:51.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:48:51.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T06:49:22.198+0000] {processor.py:157} INFO - Started process (PID=48713) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:49:22.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:49:22.201+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:49:22.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:49:22.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:49:22.229+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:49:22.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:49:22.241+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:49:22.241+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:49:22.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T06:49:52.624+0000] {processor.py:157} INFO - Started process (PID=48738) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:49:52.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:49:52.627+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:49:52.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:49:52.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:49:52.652+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:49:52.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:49:52.661+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:49:52.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:49:52.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T06:50:23.176+0000] {processor.py:157} INFO - Started process (PID=48763) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:50:23.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:50:23.180+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:50:23.179+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:50:23.194+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:50:23.207+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:50:23.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:50:23.216+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:50:23.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:50:23.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T06:50:53.644+0000] {processor.py:157} INFO - Started process (PID=48788) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:50:53.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:50:53.647+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:50:53.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:50:53.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:50:53.672+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:50:53.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:50:53.752+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:50:53.752+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:50:53.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-19T06:51:24.217+0000] {processor.py:157} INFO - Started process (PID=48813) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:51:24.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:51:24.221+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:51:24.221+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:51:24.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:51:24.249+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:51:24.249+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:51:24.259+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:51:24.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:51:24.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T06:51:54.717+0000] {processor.py:157} INFO - Started process (PID=48838) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:51:54.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:51:54.720+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:51:54.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:51:54.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:51:54.747+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:51:54.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:51:54.756+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:51:54.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:51:54.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T06:52:25.199+0000] {processor.py:157} INFO - Started process (PID=48863) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:52:25.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:52:25.205+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:52:25.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:52:25.219+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:52:25.239+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:52:25.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:52:25.253+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:52:25.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:52:25.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T06:52:55.689+0000] {processor.py:157} INFO - Started process (PID=48888) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:52:55.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:52:55.692+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:52:55.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:52:55.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:52:55.718+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:52:55.718+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:52:55.728+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:52:55.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:52:55.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T06:53:26.193+0000] {processor.py:157} INFO - Started process (PID=48913) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:53:26.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:53:26.196+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:53:26.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:53:26.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:53:26.224+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:53:26.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:53:26.234+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:53:26.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:53:26.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-19T06:53:56.804+0000] {processor.py:157} INFO - Started process (PID=48938) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:53:56.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:53:56.807+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:53:56.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:53:56.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:53:56.834+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:53:56.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:53:56.915+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:53:56.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:53:56.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-19T06:54:27.434+0000] {processor.py:157} INFO - Started process (PID=48963) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:54:27.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:54:27.438+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:54:27.437+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:54:27.452+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:54:27.466+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:54:27.466+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:54:27.475+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:54:27.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:54:27.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T06:54:57.807+0000] {processor.py:157} INFO - Started process (PID=48988) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:54:57.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:54:57.812+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:54:57.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:54:57.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:54:57.834+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:54:57.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:54:57.845+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:54:57.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:54:57.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T06:55:28.340+0000] {processor.py:157} INFO - Started process (PID=49013) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:55:28.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:55:28.343+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:55:28.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:55:28.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:55:28.375+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:55:28.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:55:28.386+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:55:28.386+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:55:28.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T06:55:58.751+0000] {processor.py:157} INFO - Started process (PID=49038) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:55:58.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:55:58.753+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:55:58.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:55:58.765+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:55:58.778+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:55:58.778+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:55:58.789+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:55:58.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:55:58.801+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T06:56:29.177+0000] {processor.py:157} INFO - Started process (PID=49063) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:56:29.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:56:29.181+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:56:29.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:56:29.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:56:29.209+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:56:29.209+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:56:29.222+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:56:29.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:56:29.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-19T06:56:59.839+0000] {processor.py:157} INFO - Started process (PID=49088) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:56:59.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:56:59.841+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:56:59.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:56:59.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:56:59.867+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:56:59.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:56:59.876+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:56:59.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:56:59.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T06:57:30.365+0000] {processor.py:157} INFO - Started process (PID=49113) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:57:30.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:57:30.368+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:57:30.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:57:30.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:57:30.396+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:57:30.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:57:30.407+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:57:30.406+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:57:30.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T06:58:00.865+0000] {processor.py:157} INFO - Started process (PID=49138) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:58:00.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:58:00.870+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:58:00.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:58:00.884+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:58:00.905+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:58:00.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:58:00.916+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:58:00.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:58:00.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T06:59:14.165+0000] {processor.py:157} INFO - Started process (PID=49163) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:59:14.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T06:59:14.168+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:59:14.168+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:59:14.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T06:59:14.193+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:59:14.193+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T06:59:14.203+0000] {logging_mixin.py:151} INFO - [2024-07-19T06:59:14.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T06:59:14.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T07:01:01.102+0000] {processor.py:157} INFO - Started process (PID=49192) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:01:01.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:01:01.106+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:01:01.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:01:01.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:01:01.132+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:01:01.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:01:01.141+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:01:01.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:01:01.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T07:01:31.528+0000] {processor.py:157} INFO - Started process (PID=49217) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:01:31.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:01:31.532+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:01:31.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:01:31.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:01:31.559+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:01:31.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:01:31.573+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:01:31.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:01:31.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-07-19T07:17:00.916+0000] {processor.py:157} INFO - Started process (PID=49242) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:17:00.917+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:17:00.918+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:17:00.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:17:00.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:17:00.952+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:17:00.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:17:01.093+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:17:01.093+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:17:01.107+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.193 seconds
[2024-07-19T07:17:31.710+0000] {processor.py:157} INFO - Started process (PID=49267) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:17:31.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:17:31.714+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:17:31.714+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:17:31.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:17:31.747+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:17:31.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:17:31.758+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:17:31.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:17:31.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T07:34:17.089+0000] {processor.py:157} INFO - Started process (PID=49292) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:34:17.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:34:17.096+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:34:17.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:34:17.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:34:17.154+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:34:17.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:34:17.169+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:34:17.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:34:17.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-19T07:34:47.569+0000] {processor.py:157} INFO - Started process (PID=49319) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:34:47.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:34:47.572+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:34:47.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:34:47.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:34:47.598+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:34:47.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:34:47.607+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:34:47.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:34:47.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T07:35:18.088+0000] {processor.py:157} INFO - Started process (PID=49344) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:35:18.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:35:18.094+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:35:18.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:35:18.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:35:18.128+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:35:18.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:35:18.139+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:35:18.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:35:18.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T07:35:48.613+0000] {processor.py:157} INFO - Started process (PID=49369) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:35:48.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:35:48.622+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:35:48.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:35:48.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:35:48.645+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:35:48.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:35:48.768+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:35:48.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:35:48.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.166 seconds
[2024-07-19T07:36:19.200+0000] {processor.py:157} INFO - Started process (PID=49394) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:36:19.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:36:19.203+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:36:19.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:36:19.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:36:19.233+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:36:19.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:36:19.244+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:36:19.244+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:36:19.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T07:39:31.670+0000] {processor.py:157} INFO - Started process (PID=49421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:39:31.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:39:31.684+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:39:31.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:39:31.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:39:31.768+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:39:31.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:39:31.800+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:39:31.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:39:31.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-07-19T07:40:02.406+0000] {processor.py:157} INFO - Started process (PID=49445) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:40:02.408+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:40:02.411+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:40:02.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:40:02.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:40:02.468+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:40:02.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:40:02.481+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:40:02.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:40:02.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-19T07:40:33.027+0000] {processor.py:157} INFO - Started process (PID=49469) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:40:33.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:40:33.033+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:40:33.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:40:33.067+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:40:33.125+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:40:33.124+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:40:33.146+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:40:33.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:40:33.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-19T07:41:03.700+0000] {processor.py:157} INFO - Started process (PID=49496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:41:03.702+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:41:03.706+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:41:03.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:41:03.725+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:41:03.749+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:41:03.749+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:41:03.762+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:41:03.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:41:03.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.206 seconds
[2024-07-19T07:41:34.357+0000] {processor.py:157} INFO - Started process (PID=49521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:41:34.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:41:34.360+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:41:34.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:41:34.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:41:34.386+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:41:34.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:41:34.477+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:41:34.476+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:41:34.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-19T07:42:05.032+0000] {processor.py:157} INFO - Started process (PID=49546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:42:05.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:42:05.041+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:42:05.040+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:42:05.064+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:42:05.088+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:42:05.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:42:05.104+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:42:05.104+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:42:05.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-19T07:42:35.506+0000] {processor.py:157} INFO - Started process (PID=49571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:42:35.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:42:35.509+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:42:35.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:42:35.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:42:35.540+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:42:35.540+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:42:35.552+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:42:35.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:42:35.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T07:43:05.982+0000] {processor.py:157} INFO - Started process (PID=49596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:43:05.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:43:05.985+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:43:05.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:43:05.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:43:06.011+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:43:06.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:43:06.020+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:43:06.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:43:06.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T07:43:36.384+0000] {processor.py:157} INFO - Started process (PID=49621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:43:36.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:43:36.390+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:43:36.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:43:36.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:43:36.427+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:43:36.427+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:43:36.440+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:43:36.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:43:36.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T07:44:06.920+0000] {processor.py:157} INFO - Started process (PID=49646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:44:06.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:44:06.929+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:44:06.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:44:06.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:44:06.971+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:44:06.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:44:06.984+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:44:06.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:44:07.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.204 seconds
[2024-07-19T07:44:37.522+0000] {processor.py:157} INFO - Started process (PID=49671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:44:37.522+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:44:37.524+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:44:37.524+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:44:37.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:44:37.552+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:44:37.552+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:44:37.631+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:44:37.631+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:44:37.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-19T07:45:08.042+0000] {processor.py:157} INFO - Started process (PID=49696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:45:08.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:45:08.045+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:45:08.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:45:08.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:45:08.073+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:45:08.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:45:08.082+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:45:08.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:45:08.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T07:45:38.472+0000] {processor.py:157} INFO - Started process (PID=49721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:45:38.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:45:38.474+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:45:38.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:45:38.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:45:38.498+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:45:38.498+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:45:38.508+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:45:38.508+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:45:38.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T07:46:08.976+0000] {processor.py:157} INFO - Started process (PID=49746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:46:08.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:46:08.981+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:46:08.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:46:08.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:46:09.017+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:46:09.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:46:09.030+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:46:09.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:46:09.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T07:46:39.467+0000] {processor.py:157} INFO - Started process (PID=49771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:46:39.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:46:39.470+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:46:39.470+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:46:39.485+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:46:39.501+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:46:39.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:46:39.516+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:46:39.516+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:46:39.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T07:47:09.889+0000] {processor.py:157} INFO - Started process (PID=49796) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:47:09.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:47:09.892+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:47:09.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:47:09.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:47:09.922+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:47:09.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:47:10.060+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:47:10.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:47:10.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.180 seconds
[2024-07-19T07:47:40.477+0000] {processor.py:157} INFO - Started process (PID=49821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:47:40.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:47:40.481+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:47:40.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:47:40.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:47:40.507+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:47:40.507+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:47:40.517+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:47:40.517+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:47:40.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T07:48:10.894+0000] {processor.py:157} INFO - Started process (PID=49846) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:48:10.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:48:10.900+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:48:10.899+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:48:10.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:48:10.937+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:48:10.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:48:10.951+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:48:10.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:48:10.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T07:48:41.387+0000] {processor.py:157} INFO - Started process (PID=49871) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:48:41.388+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:48:41.390+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:48:41.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:48:41.406+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:48:41.420+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:48:41.420+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:48:41.433+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:48:41.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:48:41.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T07:49:11.854+0000] {processor.py:157} INFO - Started process (PID=49896) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:49:11.856+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:49:11.857+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:49:11.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:49:11.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:49:11.887+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:49:11.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:49:11.896+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:49:11.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:49:11.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T07:49:42.286+0000] {processor.py:157} INFO - Started process (PID=49921) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:49:42.289+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:49:42.294+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:49:42.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:49:42.313+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:49:42.338+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:49:42.338+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:49:42.354+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:49:42.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:49:42.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.228 seconds
[2024-07-19T07:50:12.968+0000] {processor.py:157} INFO - Started process (PID=49946) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:50:12.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:50:12.970+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:50:12.970+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:50:12.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:50:12.996+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:50:12.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:50:13.075+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:50:13.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:50:13.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.117 seconds
[2024-07-19T07:50:43.509+0000] {processor.py:157} INFO - Started process (PID=49971) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:50:43.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:50:43.514+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:50:43.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:50:43.531+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:50:43.554+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:50:43.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:50:43.567+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:50:43.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:50:43.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-19T07:51:13.987+0000] {processor.py:157} INFO - Started process (PID=49996) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:51:13.988+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:51:13.989+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:51:13.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:51:14.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:51:14.019+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:51:14.019+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:51:14.030+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:51:14.030+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:51:14.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T07:51:44.472+0000] {processor.py:157} INFO - Started process (PID=50021) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:51:44.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:51:44.476+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:51:44.476+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:51:44.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:51:44.509+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:51:44.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:51:44.522+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:51:44.522+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:51:44.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T07:52:15.034+0000] {processor.py:157} INFO - Started process (PID=50046) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:52:15.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:52:15.039+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:52:15.038+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:52:15.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:52:15.077+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:52:15.077+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:52:15.090+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:52:15.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:52:15.100+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T07:52:45.546+0000] {processor.py:157} INFO - Started process (PID=50071) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:52:45.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:52:45.549+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:52:45.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:52:45.559+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:52:45.576+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:52:45.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:52:45.590+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:52:45.590+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:52:45.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.179 seconds
[2024-07-19T07:53:16.281+0000] {processor.py:157} INFO - Started process (PID=50096) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:53:16.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:53:16.284+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:53:16.284+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:53:16.295+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:53:16.313+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:53:16.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:53:16.393+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:53:16.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:53:16.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-19T07:53:46.795+0000] {processor.py:157} INFO - Started process (PID=50121) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:53:46.796+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:53:46.799+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:53:46.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:53:46.815+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:53:46.837+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:53:46.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:53:46.848+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:53:46.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:53:46.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T07:54:17.232+0000] {processor.py:157} INFO - Started process (PID=50146) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:54:17.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:54:17.236+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:54:17.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:54:17.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:54:17.261+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:54:17.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:54:17.271+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:54:17.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:54:17.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T07:54:47.668+0000] {processor.py:157} INFO - Started process (PID=50171) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:54:47.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:54:47.670+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:54:47.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:54:47.683+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:54:47.702+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:54:47.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:54:47.713+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:54:47.713+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:54:47.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T07:55:18.087+0000] {processor.py:157} INFO - Started process (PID=50196) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:55:18.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:55:18.090+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:55:18.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:55:18.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:55:18.119+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:55:18.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:55:18.132+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:55:18.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:55:18.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T07:55:48.629+0000] {processor.py:157} INFO - Started process (PID=50221) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:55:48.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:55:48.632+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:55:48.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:55:48.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:55:48.659+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:55:48.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:55:48.750+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:55:48.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:55:48.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-19T07:56:19.345+0000] {processor.py:157} INFO - Started process (PID=50246) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:56:19.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:56:19.348+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:56:19.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:56:19.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:56:19.377+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:56:19.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:56:19.462+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:56:19.462+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:56:19.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.129 seconds
[2024-07-19T07:56:49.968+0000] {processor.py:157} INFO - Started process (PID=50271) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:56:49.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:56:49.974+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:56:49.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:56:49.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:56:50.010+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:56:50.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:56:50.023+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:56:50.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:56:50.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T07:57:20.461+0000] {processor.py:157} INFO - Started process (PID=50296) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:57:20.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:57:20.464+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:57:20.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:57:20.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:57:20.489+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:57:20.489+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:57:20.501+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:57:20.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:57:20.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T07:57:50.854+0000] {processor.py:157} INFO - Started process (PID=50321) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:57:50.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:57:50.857+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:57:50.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:57:50.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:57:50.882+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:57:50.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:57:50.891+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:57:50.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:57:50.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T07:58:21.274+0000] {processor.py:157} INFO - Started process (PID=50346) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:58:21.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:58:21.277+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:58:21.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:58:21.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:58:21.304+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:58:21.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:58:21.316+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:58:21.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:58:21.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.181 seconds
[2024-07-19T07:58:51.936+0000] {processor.py:157} INFO - Started process (PID=50371) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:58:51.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:58:51.938+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:58:51.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:58:51.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:58:51.965+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:58:51.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:58:52.043+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:58:52.043+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:58:52.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-19T07:59:22.608+0000] {processor.py:157} INFO - Started process (PID=50396) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:59:22.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:59:22.612+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:59:22.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:59:22.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:59:22.643+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:59:22.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:59:22.730+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:59:22.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:59:22.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-19T07:59:53.148+0000] {processor.py:157} INFO - Started process (PID=50421) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:59:53.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T07:59:53.152+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:59:53.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:59:53.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T07:59:53.196+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:59:53.196+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T07:59:53.208+0000] {logging_mixin.py:151} INFO - [2024-07-19T07:59:53.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T07:59:53.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T08:00:23.631+0000] {processor.py:157} INFO - Started process (PID=50446) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:00:23.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T08:00:23.633+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:00:23.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:00:23.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:00:23.659+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:00:23.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T08:00:23.673+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:00:23.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T08:00:23.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T08:00:54.030+0000] {processor.py:157} INFO - Started process (PID=50471) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:00:54.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T08:00:54.033+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:00:54.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:00:54.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:00:54.060+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:00:54.059+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T08:00:54.069+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:00:54.069+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T08:00:54.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T08:01:24.439+0000] {processor.py:157} INFO - Started process (PID=50496) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:01:24.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T08:01:24.441+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:01:24.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:01:24.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:01:24.471+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:01:24.471+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T08:01:24.550+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:01:24.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T08:01:24.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-19T08:01:55.069+0000] {processor.py:157} INFO - Started process (PID=50521) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:01:55.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T08:01:55.072+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:01:55.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:01:55.083+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:01:55.098+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:01:55.098+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T08:01:55.176+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:01:55.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T08:01:55.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-19T08:02:25.708+0000] {processor.py:157} INFO - Started process (PID=50546) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:02:25.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T08:02:25.711+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:02:25.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:02:25.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:02:25.737+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:02:25.737+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T08:02:25.749+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:02:25.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T08:02:25.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T08:02:56.156+0000] {processor.py:157} INFO - Started process (PID=50571) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:02:56.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T08:02:56.159+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:02:56.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:02:56.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:02:56.186+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:02:56.186+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T08:02:56.198+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:02:56.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T08:02:56.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T08:03:26.629+0000] {processor.py:157} INFO - Started process (PID=50596) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:03:26.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T08:03:26.632+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:03:26.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:03:26.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:03:26.660+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:03:26.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T08:03:26.670+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:03:26.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T08:03:26.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T08:03:57.051+0000] {processor.py:157} INFO - Started process (PID=50621) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:03:57.052+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T08:03:57.054+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:03:57.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:03:57.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:03:57.080+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:03:57.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T08:03:57.089+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:03:57.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T08:03:57.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.183 seconds
[2024-07-19T08:04:27.784+0000] {processor.py:157} INFO - Started process (PID=50646) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:04:27.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T08:04:27.790+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:04:27.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:04:27.805+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:04:27.827+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:04:27.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T08:04:27.907+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:04:27.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T08:04:27.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-19T08:04:58.363+0000] {processor.py:157} INFO - Started process (PID=50671) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:04:58.366+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T08:04:58.368+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:04:58.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:04:58.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:04:58.391+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:04:58.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T08:04:58.468+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:04:58.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T08:04:58.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-19T08:05:28.909+0000] {processor.py:157} INFO - Started process (PID=50696) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:05:28.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T08:05:28.913+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:05:28.913+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:05:28.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:05:28.942+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:05:28.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T08:05:28.951+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:05:28.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T08:05:28.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T08:05:59.349+0000] {processor.py:157} INFO - Started process (PID=50721) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:05:59.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T08:05:59.352+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:05:59.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:05:59.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:05:59.380+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:05:59.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T08:05:59.390+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:05:59.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T08:05:59.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T08:06:29.826+0000] {processor.py:157} INFO - Started process (PID=50746) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:06:29.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T08:06:29.828+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:06:29.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:06:29.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:06:29.857+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:06:29.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T08:06:29.867+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:06:29.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T08:06:29.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T08:07:00.421+0000] {processor.py:157} INFO - Started process (PID=50771) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:07:00.422+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T08:07:00.433+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:07:00.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:07:00.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:07:00.506+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:07:00.506+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T08:07:00.530+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:07:00.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T08:07:00.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.291 seconds
[2024-07-19T08:55:41.454+0000] {processor.py:157} INFO - Started process (PID=50798) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:55:41.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T08:55:41.460+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:55:41.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:55:41.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T08:55:41.526+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:55:41.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T08:55:41.781+0000] {logging_mixin.py:151} INFO - [2024-07-19T08:55:41.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T08:55:41.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.362 seconds
[2024-07-19T09:25:21.583+0000] {processor.py:157} INFO - Started process (PID=50821) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T09:25:21.586+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T09:25:21.590+0000] {logging_mixin.py:151} INFO - [2024-07-19T09:25:21.590+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T09:25:21.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T09:25:21.659+0000] {logging_mixin.py:151} INFO - [2024-07-19T09:25:21.659+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T09:25:21.857+0000] {logging_mixin.py:151} INFO - [2024-07-19T09:25:21.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T09:25:21.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.290 seconds
[2024-07-19T09:42:13.819+0000] {processor.py:157} INFO - Started process (PID=50850) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T09:42:13.820+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T09:42:13.824+0000] {logging_mixin.py:151} INFO - [2024-07-19T09:42:13.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T09:42:13.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T09:42:13.876+0000] {logging_mixin.py:151} INFO - [2024-07-19T09:42:13.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T09:42:14.191+0000] {logging_mixin.py:151} INFO - [2024-07-19T09:42:14.191+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T09:42:14.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.463 seconds
[2024-07-19T10:08:05.038+0000] {processor.py:157} INFO - Started process (PID=50874) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T10:08:05.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T10:08:05.047+0000] {logging_mixin.py:151} INFO - [2024-07-19T10:08:05.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T10:08:05.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T10:08:05.095+0000] {logging_mixin.py:151} INFO - [2024-07-19T10:08:05.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T10:08:05.120+0000] {logging_mixin.py:151} INFO - [2024-07-19T10:08:05.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T10:08:05.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-19T10:41:08.471+0000] {processor.py:157} INFO - Started process (PID=50899) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T10:41:08.475+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T10:41:08.479+0000] {logging_mixin.py:151} INFO - [2024-07-19T10:41:08.479+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T10:41:08.504+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T10:41:08.539+0000] {logging_mixin.py:151} INFO - [2024-07-19T10:41:08.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T10:41:08.565+0000] {logging_mixin.py:151} INFO - [2024-07-19T10:41:08.564+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T10:41:08.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-19T11:09:01.231+0000] {processor.py:157} INFO - Started process (PID=50923) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:09:01.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:09:01.235+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:09:01.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:09:01.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:09:01.271+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:09:01.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:09:01.284+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:09:01.284+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:09:01.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-07-19T11:25:46.100+0000] {processor.py:157} INFO - Started process (PID=50952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:25:46.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:25:46.102+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:25:46.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:25:46.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:25:46.134+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:25:46.134+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:25:46.262+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:25:46.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:25:46.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.182 seconds
[2024-07-19T11:35:05.654+0000] {processor.py:157} INFO - Started process (PID=50976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:35:05.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:35:05.663+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:35:05.663+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:35:05.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:35:05.897+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:35:05.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:35:05.906+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:35:05.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:35:05.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.275 seconds
[2024-07-19T11:35:36.501+0000] {processor.py:157} INFO - Started process (PID=51002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:35:36.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:35:36.506+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:35:36.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:35:36.518+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:35:36.534+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:35:36.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:35:36.544+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:35:36.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:35:36.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T11:36:06.971+0000] {processor.py:157} INFO - Started process (PID=51027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:36:06.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:36:06.976+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:36:06.976+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:36:06.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:36:07.011+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:36:07.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:36:07.023+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:36:07.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:36:07.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T11:36:37.441+0000] {processor.py:157} INFO - Started process (PID=51052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:36:37.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:36:37.446+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:36:37.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:36:37.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:36:37.472+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:36:37.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:36:37.482+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:36:37.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:36:37.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T11:37:07.924+0000] {processor.py:157} INFO - Started process (PID=51077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:37:07.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:37:07.927+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:37:07.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:37:07.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:37:07.951+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:37:07.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:37:08.113+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:37:08.112+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:37:08.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.200 seconds
[2024-07-19T11:37:38.591+0000] {processor.py:157} INFO - Started process (PID=51102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:37:38.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:37:38.594+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:37:38.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:37:38.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:37:38.625+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:37:38.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:37:38.704+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:37:38.704+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:37:38.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-19T11:38:09.256+0000] {processor.py:157} INFO - Started process (PID=51127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:38:09.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:38:09.259+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:38:09.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:38:09.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:38:09.361+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:38:09.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:38:09.369+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:38:09.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:38:09.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-19T11:38:39.919+0000] {processor.py:157} INFO - Started process (PID=51152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:38:39.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:38:39.921+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:38:39.921+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:38:39.930+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:38:39.947+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:38:39.947+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:38:39.957+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:38:39.957+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:38:39.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T11:39:10.454+0000] {processor.py:157} INFO - Started process (PID=51176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:39:10.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:39:10.474+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:39:10.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:39:10.492+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:39:10.515+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:39:10.515+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:39:10.528+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:39:10.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:39:10.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-19T11:39:40.897+0000] {processor.py:157} INFO - Started process (PID=51202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:39:40.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:39:40.901+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:39:40.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:39:40.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:39:40.935+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:39:40.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:39:40.946+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:39:40.946+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:39:41.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.190 seconds
[2024-07-19T11:40:11.507+0000] {processor.py:157} INFO - Started process (PID=51227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:40:11.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:40:11.510+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:40:11.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:40:11.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:40:11.538+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:40:11.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:40:11.626+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:40:11.625+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:40:11.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-19T11:40:42.187+0000] {processor.py:157} INFO - Started process (PID=51251) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:40:42.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:40:42.194+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:40:42.193+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:40:42.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:40:42.267+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:40:42.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:40:42.467+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:40:42.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:40:42.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.310 seconds
[2024-07-19T11:41:13.075+0000] {processor.py:157} INFO - Started process (PID=51277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:41:13.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:41:13.084+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:41:13.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:41:13.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:41:13.154+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:41:13.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:41:13.175+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:41:13.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:41:13.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-19T11:41:43.610+0000] {processor.py:157} INFO - Started process (PID=51302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:41:43.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:41:43.612+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:41:43.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:41:43.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:41:43.643+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:41:43.643+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:41:43.653+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:41:43.653+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:41:43.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T11:42:14.015+0000] {processor.py:157} INFO - Started process (PID=51327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:42:14.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:42:14.018+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:42:14.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:42:14.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:42:14.046+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:42:14.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:42:14.056+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:42:14.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:42:14.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T11:42:44.455+0000] {processor.py:157} INFO - Started process (PID=51350) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:42:44.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:42:44.467+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:42:44.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:42:44.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:42:44.530+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:42:44.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:42:44.753+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:42:44.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:42:44.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.317 seconds
[2024-07-19T11:43:15.376+0000] {processor.py:157} INFO - Started process (PID=51377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:43:15.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:43:15.393+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:43:15.391+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:43:15.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:43:15.435+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:43:15.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:43:15.576+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:43:15.576+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:43:15.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.215 seconds
[2024-07-19T11:43:46.224+0000] {processor.py:157} INFO - Started process (PID=51402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:43:46.228+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:43:46.235+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:43:46.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:43:46.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:43:46.516+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:43:46.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:43:46.528+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:43:46.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:43:46.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.321 seconds
[2024-07-19T11:44:17.136+0000] {processor.py:157} INFO - Started process (PID=51427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:44:17.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:44:17.155+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:44:17.153+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:44:17.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:44:17.233+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:44:17.233+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:44:17.248+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:44:17.248+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:44:17.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-19T11:44:47.963+0000] {processor.py:157} INFO - Started process (PID=51452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:44:47.968+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:44:47.972+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:44:47.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:44:48.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:44:48.041+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:44:48.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:44:48.057+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:44:48.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:44:48.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-19T11:45:18.549+0000] {processor.py:157} INFO - Started process (PID=51477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:45:18.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:45:18.562+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:45:18.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:45:18.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:45:18.618+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:45:18.617+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:45:18.636+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:45:18.636+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:45:18.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.305 seconds
[2024-07-19T11:45:49.468+0000] {processor.py:157} INFO - Started process (PID=51502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:45:49.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:45:49.473+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:45:49.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:45:49.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:45:49.516+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:45:49.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:45:49.642+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:45:49.642+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:45:49.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.189 seconds
[2024-07-19T11:46:20.112+0000] {processor.py:157} INFO - Started process (PID=51527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:46:20.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:46:20.119+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:46:20.119+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:46:20.145+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:46:20.185+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:46:20.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:46:20.340+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:46:20.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:46:20.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.243 seconds
[2024-07-19T11:46:50.892+0000] {processor.py:157} INFO - Started process (PID=51552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:46:50.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:46:50.897+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:46:50.897+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:46:50.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:46:50.997+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:46:50.997+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:46:51.005+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:46:51.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:46:51.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-19T11:47:21.423+0000] {processor.py:157} INFO - Started process (PID=51577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:47:21.430+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:47:21.441+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:47:21.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:47:21.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:47:21.477+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:47:21.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:47:21.489+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:47:21.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:47:21.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-19T11:47:51.872+0000] {processor.py:157} INFO - Started process (PID=51602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:47:51.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:47:51.878+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:47:51.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:47:51.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:47:51.908+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:47:51.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:47:51.920+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:47:51.920+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:47:51.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T11:48:22.342+0000] {processor.py:157} INFO - Started process (PID=51627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:48:22.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:48:22.345+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:48:22.345+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:48:22.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:48:22.378+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:48:22.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:48:22.389+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:48:22.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:48:22.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.213 seconds
[2024-07-19T11:48:52.941+0000] {processor.py:157} INFO - Started process (PID=51652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:48:52.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:48:52.946+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:48:52.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:48:52.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:48:52.972+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:48:52.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:48:53.060+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:48:53.060+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:48:53.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-19T11:49:23.486+0000] {processor.py:157} INFO - Started process (PID=51677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:49:23.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:49:23.494+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:49:23.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:49:23.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:49:23.534+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:49:23.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:49:23.676+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:49:23.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:49:23.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.202 seconds
[2024-07-19T11:49:54.217+0000] {processor.py:157} INFO - Started process (PID=51702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:49:54.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:49:54.223+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:49:54.223+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:49:54.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:49:54.411+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:49:54.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:49:54.419+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:49:54.419+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:49:54.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.217 seconds
[2024-07-19T11:50:24.812+0000] {processor.py:157} INFO - Started process (PID=51727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:50:24.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:50:24.816+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:50:24.816+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:50:24.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:50:24.846+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:50:24.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:50:24.856+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:50:24.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:50:24.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T11:50:55.175+0000] {processor.py:157} INFO - Started process (PID=51752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:50:55.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:50:55.180+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:50:55.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:50:55.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:50:55.206+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:50:55.206+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:50:55.221+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:50:55.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:50:55.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T11:51:25.549+0000] {processor.py:157} INFO - Started process (PID=51777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:51:25.554+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:51:25.558+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:51:25.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:51:25.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:51:25.603+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:51:25.603+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:51:25.772+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:51:25.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:51:25.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.237 seconds
[2024-07-19T11:51:56.319+0000] {processor.py:157} INFO - Started process (PID=51802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:51:56.320+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:51:56.322+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:51:56.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:51:56.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:51:56.355+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:51:56.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:51:56.477+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:51:56.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:51:56.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.168 seconds
[2024-07-19T11:52:27.018+0000] {processor.py:157} INFO - Started process (PID=51827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:52:27.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:52:27.022+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:52:27.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:52:27.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:52:27.160+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:52:27.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:52:27.170+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:52:27.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:52:27.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-07-19T11:52:57.584+0000] {processor.py:157} INFO - Started process (PID=51852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:52:57.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:52:57.593+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:52:57.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:52:57.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:52:57.656+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:52:57.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:52:57.673+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:52:57.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:52:57.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-19T11:53:28.137+0000] {processor.py:157} INFO - Started process (PID=51877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:53:28.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:53:28.142+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:53:28.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:53:28.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:53:28.172+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:53:28.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:53:28.182+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:53:28.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:53:28.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T11:53:58.620+0000] {processor.py:157} INFO - Started process (PID=51902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:53:58.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:53:58.625+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:53:58.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:53:58.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:53:58.662+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:53:58.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:53:58.674+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:53:58.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:53:58.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.218 seconds
[2024-07-19T11:54:29.290+0000] {processor.py:157} INFO - Started process (PID=51927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:54:29.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:54:29.293+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:54:29.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:54:29.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:54:29.318+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:54:29.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:54:29.397+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:54:29.397+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:54:29.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-19T11:54:59.968+0000] {processor.py:157} INFO - Started process (PID=51952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:54:59.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:54:59.971+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:54:59.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:54:59.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:55:00.000+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:54:59.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:55:00.106+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:55:00.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:55:00.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-19T11:55:30.663+0000] {processor.py:157} INFO - Started process (PID=51977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:55:30.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:55:30.667+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:55:30.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:55:30.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:55:30.776+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:55:30.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:55:30.785+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:55:30.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:55:30.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-19T11:56:01.207+0000] {processor.py:157} INFO - Started process (PID=52002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:56:01.209+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:56:01.211+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:56:01.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:56:01.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:56:01.235+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:56:01.235+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:56:01.245+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:56:01.245+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:56:01.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T11:56:31.622+0000] {processor.py:157} INFO - Started process (PID=52027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:56:31.624+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:56:31.626+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:56:31.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:56:31.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:56:31.652+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:56:31.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:56:31.661+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:56:31.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:56:31.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T11:57:02.088+0000] {processor.py:157} INFO - Started process (PID=52052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:57:02.089+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:57:02.091+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:57:02.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:57:02.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:57:02.132+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:57:02.132+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:57:02.145+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:57:02.145+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:57:02.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.152 seconds
[2024-07-19T11:57:32.857+0000] {processor.py:157} INFO - Started process (PID=52077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:57:32.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:57:32.864+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:57:32.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:57:32.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:57:32.905+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:57:32.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:57:33.039+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:57:33.039+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:57:33.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.195 seconds
[2024-07-19T11:58:03.455+0000] {processor.py:157} INFO - Started process (PID=52102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:58:03.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:58:03.460+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:58:03.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:58:03.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:58:03.627+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:58:03.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:58:03.637+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:58:03.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:58:03.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.197 seconds
[2024-07-19T11:58:34.230+0000] {processor.py:157} INFO - Started process (PID=52127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:58:34.232+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:58:34.234+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:58:34.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:58:34.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:58:34.372+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:58:34.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:58:34.384+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:58:34.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:58:34.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.167 seconds
[2024-07-19T11:59:04.812+0000] {processor.py:157} INFO - Started process (PID=52152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:59:04.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:59:04.818+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:59:04.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:59:04.839+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:59:04.856+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:59:04.856+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:59:04.867+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:59:04.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:59:04.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T11:59:35.247+0000] {processor.py:157} INFO - Started process (PID=52177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:59:35.247+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T11:59:35.250+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:59:35.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:59:35.261+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T11:59:35.278+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:59:35.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T11:59:35.288+0000] {logging_mixin.py:151} INFO - [2024-07-19T11:59:35.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T11:59:35.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T12:00:05.678+0000] {processor.py:157} INFO - Started process (PID=52202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:00:05.679+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:00:05.681+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:00:05.681+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:00:05.691+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:00:05.707+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:00:05.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:00:05.790+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:00:05.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:00:05.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-19T12:00:36.206+0000] {processor.py:157} INFO - Started process (PID=52227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:00:36.206+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:00:36.208+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:00:36.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:00:36.221+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:00:36.236+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:00:36.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:00:36.317+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:00:36.317+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:00:36.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-19T12:01:06.698+0000] {processor.py:157} INFO - Started process (PID=52252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:01:06.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:01:06.700+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:01:06.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:01:06.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:01:06.794+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:01:06.794+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:01:06.802+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:01:06.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:01:06.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-19T12:01:37.347+0000] {processor.py:157} INFO - Started process (PID=52277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:01:37.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:01:37.350+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:01:37.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:01:37.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:01:37.382+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:01:37.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:01:37.394+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:01:37.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:01:37.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T12:02:07.719+0000] {processor.py:157} INFO - Started process (PID=52302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:02:07.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:02:07.728+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:02:07.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:02:07.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:02:07.782+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:02:07.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:02:07.803+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:02:07.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:02:07.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-19T12:02:38.293+0000] {processor.py:157} INFO - Started process (PID=52327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:02:38.294+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:02:38.295+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:02:38.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:02:38.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:02:38.324+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:02:38.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:02:38.333+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:02:38.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:02:38.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.217 seconds
[2024-07-19T12:03:09.074+0000] {processor.py:157} INFO - Started process (PID=52352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:03:09.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:03:09.078+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:03:09.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:03:09.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:03:09.109+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:03:09.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:03:09.188+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:03:09.188+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:03:09.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-19T12:03:39.763+0000] {processor.py:157} INFO - Started process (PID=52377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:03:39.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:03:39.767+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:03:39.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:03:39.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:03:39.806+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:03:39.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:03:39.934+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:03:39.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:03:39.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.205 seconds
[2024-07-19T12:04:10.460+0000] {processor.py:157} INFO - Started process (PID=52402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:04:10.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:04:10.463+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:04:10.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:04:10.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:04:10.565+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:04:10.565+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:04:10.574+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:04:10.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:04:10.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-19T12:04:40.936+0000] {processor.py:157} INFO - Started process (PID=52427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:04:40.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:04:40.943+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:04:40.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:04:40.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:04:40.976+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:04:40.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:04:40.988+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:04:40.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:04:41.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T12:05:11.458+0000] {processor.py:157} INFO - Started process (PID=52451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:05:11.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:05:11.466+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:05:11.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:05:11.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:05:11.530+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:05:11.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:05:11.550+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:05:11.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:05:11.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-19T12:05:41.967+0000] {processor.py:157} INFO - Started process (PID=52477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:05:41.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:05:41.975+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:05:41.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:05:41.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:05:42.016+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:05:42.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:05:42.187+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:05:42.187+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:05:42.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.234 seconds
[2024-07-19T12:06:12.913+0000] {processor.py:157} INFO - Started process (PID=52502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:06:12.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:06:12.918+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:06:12.918+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:06:12.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:06:12.958+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:06:12.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:06:13.101+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:06:13.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:06:13.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.201 seconds
[2024-07-19T12:06:43.642+0000] {processor.py:157} INFO - Started process (PID=52527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:06:43.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:06:43.646+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:06:43.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:06:43.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:06:43.753+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:06:43.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:06:43.762+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:06:43.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:06:43.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-19T12:07:14.271+0000] {processor.py:157} INFO - Started process (PID=52552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:07:14.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:07:14.275+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:07:14.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:07:14.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:07:14.368+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:07:14.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:07:14.375+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:07:14.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:07:14.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.114 seconds
[2024-07-19T12:07:44.992+0000] {processor.py:157} INFO - Started process (PID=52577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:07:44.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:07:44.995+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:07:44.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:07:45.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:07:45.025+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:07:45.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:07:45.037+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:07:45.037+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:07:45.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T12:08:15.449+0000] {processor.py:157} INFO - Started process (PID=52602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:08:15.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:08:15.452+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:08:15.452+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:08:15.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:08:15.481+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:08:15.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:08:15.491+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:08:15.491+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:08:15.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T12:08:46.020+0000] {processor.py:157} INFO - Started process (PID=52627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:08:46.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:08:46.027+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:08:46.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:08:46.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:08:46.049+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:08:46.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:08:46.130+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:08:46.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:08:46.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-19T12:09:16.686+0000] {processor.py:157} INFO - Started process (PID=52652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:09:16.687+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:09:16.688+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:09:16.688+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:09:16.699+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:09:16.714+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:09:16.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:09:16.791+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:09:16.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:09:16.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.115 seconds
[2024-07-19T12:09:47.239+0000] {processor.py:157} INFO - Started process (PID=52677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:09:47.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:09:47.243+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:09:47.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:09:47.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:09:47.355+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:09:47.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:09:47.363+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:09:47.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:09:47.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.135 seconds
[2024-07-19T12:10:17.805+0000] {processor.py:157} INFO - Started process (PID=52702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:10:17.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:10:17.811+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:10:17.811+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:10:17.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:10:17.843+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:10:17.843+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:10:17.855+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:10:17.855+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:10:17.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T12:10:48.194+0000] {processor.py:157} INFO - Started process (PID=52727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:10:48.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:10:48.198+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:10:48.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:10:48.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:10:48.227+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:10:48.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:10:48.237+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:10:48.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:10:48.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T12:11:18.633+0000] {processor.py:157} INFO - Started process (PID=52752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:11:18.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:11:18.635+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:11:18.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:11:18.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:11:18.662+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:11:18.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:11:18.676+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:11:18.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:11:18.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-19T12:11:49.338+0000] {processor.py:157} INFO - Started process (PID=52777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:11:49.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:11:49.342+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:11:49.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:11:49.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:11:49.373+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:11:49.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:11:49.453+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:11:49.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:11:49.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-19T12:12:19.927+0000] {processor.py:157} INFO - Started process (PID=52802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:12:19.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:12:19.937+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:12:19.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:12:19.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:12:20.002+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:12:20.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:12:20.182+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:12:20.182+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:12:20.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.272 seconds
[2024-07-19T12:12:50.787+0000] {processor.py:157} INFO - Started process (PID=52827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:12:50.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:12:50.790+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:12:50.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:12:50.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:12:50.908+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:12:50.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:12:50.916+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:12:50.916+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:12:50.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-19T12:13:21.486+0000] {processor.py:157} INFO - Started process (PID=52852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:13:21.488+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:13:21.490+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:13:21.490+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:13:21.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:13:21.623+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:13:21.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:13:21.633+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:13:21.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:13:21.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.158 seconds
[2024-07-19T12:13:52.299+0000] {processor.py:157} INFO - Started process (PID=52877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:13:52.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:13:52.302+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:13:52.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:13:52.318+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:13:52.335+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:13:52.335+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:13:52.345+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:13:52.345+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:13:52.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T12:14:22.749+0000] {processor.py:157} INFO - Started process (PID=52902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:14:22.751+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:14:22.753+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:14:22.753+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:14:22.764+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:14:22.780+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:14:22.780+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:14:22.790+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:14:22.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:14:22.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T12:14:53.196+0000] {processor.py:157} INFO - Started process (PID=52927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:14:53.197+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:14:53.200+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:14:53.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:14:53.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:14:53.229+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:14:53.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:14:53.239+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:14:53.239+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:14:53.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T12:15:23.672+0000] {processor.py:157} INFO - Started process (PID=52952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:15:23.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:15:23.681+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:15:23.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:15:23.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:15:23.703+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:15:23.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:15:23.714+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:15:23.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:15:23.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T12:15:54.145+0000] {processor.py:157} INFO - Started process (PID=52977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:15:54.147+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:15:54.148+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:15:54.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:15:54.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:15:54.173+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:15:54.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:15:54.183+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:15:54.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:15:54.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T12:16:24.651+0000] {processor.py:157} INFO - Started process (PID=53002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:16:24.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:16:24.659+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:16:24.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:16:24.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:16:24.717+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:16:24.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:16:24.731+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:16:24.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:16:24.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-19T12:16:55.109+0000] {processor.py:157} INFO - Started process (PID=53027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:16:55.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:16:55.115+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:16:55.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:16:55.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:16:55.155+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:16:55.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:16:55.171+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:16:55.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:16:55.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-19T12:17:25.604+0000] {processor.py:157} INFO - Started process (PID=53052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:17:25.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:17:25.608+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:17:25.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:17:25.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:17:25.634+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:17:25.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:17:25.644+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:17:25.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:17:25.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T12:17:56.073+0000] {processor.py:157} INFO - Started process (PID=53077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:17:56.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:17:56.080+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:17:56.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:17:56.098+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:17:56.118+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:17:56.118+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:17:56.132+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:17:56.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:17:56.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T12:18:26.576+0000] {processor.py:157} INFO - Started process (PID=53102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:18:26.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:18:26.579+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:18:26.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:18:26.595+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:18:26.610+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:18:26.610+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:18:26.619+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:18:26.619+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:18:26.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T12:18:57.048+0000] {processor.py:157} INFO - Started process (PID=53127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:18:57.048+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:18:57.050+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:18:57.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:18:57.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:18:57.076+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:18:57.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:18:57.085+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:18:57.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:18:57.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T12:19:27.545+0000] {processor.py:157} INFO - Started process (PID=53152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:19:27.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:19:27.549+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:19:27.549+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:19:27.558+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:19:27.573+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:19:27.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:19:27.583+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:19:27.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:19:27.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T12:19:58.021+0000] {processor.py:157} INFO - Started process (PID=53177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:19:58.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:19:58.027+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:19:58.027+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:19:58.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:19:58.072+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:19:58.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:19:58.088+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:19:58.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:19:58.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-19T12:20:28.459+0000] {processor.py:157} INFO - Started process (PID=53202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:20:28.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:20:28.464+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:20:28.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:20:28.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:20:28.491+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:20:28.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:20:28.501+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:20:28.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:20:28.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T12:20:58.868+0000] {processor.py:157} INFO - Started process (PID=53227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:20:58.869+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:20:58.870+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:20:58.870+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:20:58.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:20:58.898+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:20:58.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:20:58.909+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:20:58.909+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:20:58.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T12:21:29.301+0000] {processor.py:157} INFO - Started process (PID=53252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:21:29.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:21:29.304+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:21:29.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:21:29.320+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:21:29.333+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:21:29.333+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:21:29.342+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:21:29.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:21:29.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T12:21:59.645+0000] {processor.py:157} INFO - Started process (PID=53277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:21:59.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:21:59.648+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:21:59.648+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:21:59.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:21:59.679+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:21:59.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:21:59.689+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:21:59.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:21:59.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T12:22:30.143+0000] {processor.py:157} INFO - Started process (PID=53302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:22:30.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:22:30.147+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:22:30.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:22:30.160+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:22:30.185+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:22:30.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:22:30.199+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:22:30.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:22:30.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T12:23:00.609+0000] {processor.py:157} INFO - Started process (PID=53327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:23:00.610+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:23:00.611+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:23:00.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:23:00.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:23:00.639+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:23:00.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:23:00.651+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:23:00.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:23:00.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T12:23:31.013+0000] {processor.py:157} INFO - Started process (PID=53352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:23:31.014+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:23:31.016+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:23:31.016+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:23:31.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:23:31.056+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:23:31.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:23:31.068+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:23:31.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:23:31.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T12:24:01.490+0000] {processor.py:157} INFO - Started process (PID=53377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:24:01.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:24:01.494+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:24:01.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:24:01.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:24:01.521+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:24:01.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:24:01.534+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:24:01.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:24:01.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T12:24:31.861+0000] {processor.py:157} INFO - Started process (PID=53402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:24:31.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:24:31.865+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:24:31.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:24:31.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:24:31.893+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:24:31.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:24:31.903+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:24:31.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:24:31.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T12:25:02.333+0000] {processor.py:157} INFO - Started process (PID=53427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:25:02.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:25:02.338+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:25:02.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:25:02.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:25:02.368+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:25:02.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:25:02.378+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:25:02.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:25:02.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T12:25:32.792+0000] {processor.py:157} INFO - Started process (PID=53452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:25:32.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:25:32.796+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:25:32.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:25:32.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:25:32.827+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:25:32.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:25:32.838+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:25:32.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:25:32.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T12:26:03.271+0000] {processor.py:157} INFO - Started process (PID=53477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:26:03.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:26:03.273+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:26:03.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:26:03.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:26:03.303+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:26:03.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:26:03.316+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:26:03.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:26:03.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T12:26:33.765+0000] {processor.py:157} INFO - Started process (PID=53502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:26:33.767+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:26:33.769+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:26:33.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:26:33.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:26:33.793+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:26:33.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:26:33.803+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:26:33.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:26:33.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T12:27:04.262+0000] {processor.py:157} INFO - Started process (PID=53526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:27:04.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:27:04.268+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:27:04.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:27:04.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:27:04.330+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:27:04.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:27:04.343+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:27:04.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:27:04.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-19T12:27:34.715+0000] {processor.py:157} INFO - Started process (PID=53552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:27:34.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:27:34.718+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:27:34.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:27:34.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:27:34.756+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:27:34.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:27:34.770+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:27:34.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:27:34.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T12:28:05.194+0000] {processor.py:157} INFO - Started process (PID=53577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:28:05.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:28:05.198+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:28:05.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:28:05.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:28:05.239+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:28:05.239+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:28:05.252+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:28:05.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:28:05.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T12:28:35.630+0000] {processor.py:157} INFO - Started process (PID=53602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:28:35.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:28:35.633+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:28:35.633+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:28:35.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:28:35.661+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:28:35.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:28:35.674+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:28:35.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:28:35.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T12:29:06.079+0000] {processor.py:157} INFO - Started process (PID=53627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:29:06.080+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:29:06.083+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:29:06.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:29:06.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:29:06.110+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:29:06.110+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:29:06.120+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:29:06.120+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:29:06.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T12:29:36.438+0000] {processor.py:157} INFO - Started process (PID=53652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:29:36.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:29:36.441+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:29:36.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:29:36.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:29:36.467+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:29:36.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:29:36.478+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:29:36.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:29:36.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T12:30:06.883+0000] {processor.py:157} INFO - Started process (PID=53677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:30:06.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:30:06.885+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:30:06.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:30:06.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:30:06.916+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:30:06.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:30:06.927+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:30:06.927+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:30:06.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T12:30:37.314+0000] {processor.py:157} INFO - Started process (PID=53702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:30:37.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:30:37.316+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:30:37.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:30:37.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:30:37.345+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:30:37.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:30:37.355+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:30:37.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:30:37.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T12:31:07.763+0000] {processor.py:157} INFO - Started process (PID=53727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:31:07.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:31:07.765+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:31:07.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:31:07.780+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:31:07.792+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:31:07.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:31:07.802+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:31:07.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:31:07.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T12:31:38.201+0000] {processor.py:157} INFO - Started process (PID=53752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:31:38.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:31:38.211+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:31:38.211+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:31:38.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:31:38.231+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:31:38.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:31:38.240+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:31:38.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:31:38.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T12:32:08.616+0000] {processor.py:157} INFO - Started process (PID=53777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:32:08.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:32:08.621+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:32:08.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:32:08.640+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:32:08.658+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:32:08.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:32:08.673+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:32:08.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:32:08.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T12:32:38.994+0000] {processor.py:157} INFO - Started process (PID=53802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:32:38.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:32:38.996+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:32:38.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:32:39.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:32:39.022+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:32:39.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:32:39.034+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:32:39.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:32:39.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T12:33:09.470+0000] {processor.py:157} INFO - Started process (PID=53827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:33:09.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:33:09.473+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:33:09.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:33:09.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:33:09.499+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:33:09.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:33:09.509+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:33:09.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:33:09.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T12:33:39.944+0000] {processor.py:157} INFO - Started process (PID=53852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:33:39.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:33:39.949+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:33:39.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:33:39.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:33:39.982+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:33:39.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:33:39.993+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:33:39.993+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:33:40.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T12:34:10.453+0000] {processor.py:157} INFO - Started process (PID=53877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:34:10.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:34:10.456+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:34:10.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:34:10.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:34:10.488+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:34:10.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:34:10.499+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:34:10.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:34:10.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T12:34:40.866+0000] {processor.py:157} INFO - Started process (PID=53902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:34:40.868+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:34:40.869+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:34:40.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:34:40.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:34:40.895+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:34:40.895+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:34:40.905+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:34:40.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:34:40.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T12:35:11.310+0000] {processor.py:157} INFO - Started process (PID=53927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:35:11.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:35:11.313+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:35:11.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:35:11.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:35:11.341+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:35:11.341+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:35:11.351+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:35:11.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:35:11.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T12:35:41.764+0000] {processor.py:157} INFO - Started process (PID=53952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:35:41.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:35:41.767+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:35:41.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:35:41.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:35:41.793+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:35:41.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:35:41.802+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:35:41.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:35:41.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T12:36:12.208+0000] {processor.py:157} INFO - Started process (PID=53977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:36:12.208+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:36:12.210+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:36:12.210+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:36:12.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:36:12.241+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:36:12.241+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:36:12.252+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:36:12.252+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:36:12.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T12:36:42.672+0000] {processor.py:157} INFO - Started process (PID=54002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:36:42.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:36:42.676+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:36:42.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:36:42.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:36:42.702+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:36:42.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:36:42.712+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:36:42.712+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:36:42.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T12:37:13.076+0000] {processor.py:157} INFO - Started process (PID=54027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:37:13.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:37:13.079+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:37:13.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:37:13.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:37:13.105+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:37:13.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:37:13.115+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:37:13.115+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:37:13.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T12:37:43.623+0000] {processor.py:157} INFO - Started process (PID=54052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:37:43.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:37:43.627+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:37:43.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:37:43.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:37:43.662+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:37:43.662+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:37:43.675+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:37:43.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:37:43.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T12:38:14.113+0000] {processor.py:157} INFO - Started process (PID=54077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:38:14.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:38:14.118+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:38:14.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:38:14.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:38:14.150+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:38:14.150+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:38:14.160+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:38:14.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:38:14.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T12:38:44.555+0000] {processor.py:157} INFO - Started process (PID=54102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:38:44.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:38:44.557+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:38:44.557+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:38:44.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:38:44.586+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:38:44.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:38:44.596+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:38:44.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:38:44.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T12:39:14.934+0000] {processor.py:157} INFO - Started process (PID=54127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:39:14.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:39:14.937+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:39:14.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:39:14.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:39:14.964+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:39:14.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:39:14.974+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:39:14.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:39:14.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T12:39:45.276+0000] {processor.py:157} INFO - Started process (PID=54152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:39:45.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:39:45.279+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:39:45.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:39:45.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:39:45.304+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:39:45.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:39:45.313+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:39:45.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:39:45.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T12:40:15.759+0000] {processor.py:157} INFO - Started process (PID=54177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:40:15.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:40:15.762+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:40:15.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:40:15.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:40:15.792+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:40:15.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:40:15.802+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:40:15.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:40:15.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T12:40:46.244+0000] {processor.py:157} INFO - Started process (PID=54202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:40:46.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:40:46.246+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:40:46.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:40:46.262+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:40:46.275+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:40:46.275+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:40:46.286+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:40:46.285+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:40:46.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T12:41:16.713+0000] {processor.py:157} INFO - Started process (PID=54227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:41:16.714+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:41:16.716+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:41:16.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:41:16.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:41:16.747+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:41:16.747+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:41:16.760+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:41:16.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:41:16.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T12:41:47.094+0000] {processor.py:157} INFO - Started process (PID=54252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:41:47.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:41:47.096+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:41:47.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:41:47.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:41:47.131+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:41:47.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:41:47.143+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:41:47.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:41:47.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T12:42:17.529+0000] {processor.py:157} INFO - Started process (PID=54277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:42:17.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:42:17.532+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:42:17.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:42:17.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:42:17.563+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:42:17.563+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:42:17.573+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:42:17.573+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:42:17.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T12:42:47.983+0000] {processor.py:157} INFO - Started process (PID=54302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:42:47.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:42:47.986+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:42:47.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:42:47.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:42:48.011+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:42:48.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:42:48.021+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:42:48.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:42:48.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T12:43:18.515+0000] {processor.py:157} INFO - Started process (PID=54327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:43:18.516+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:43:18.518+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:43:18.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:43:18.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:43:18.546+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:43:18.546+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:43:18.558+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:43:18.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:43:18.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T12:43:48.942+0000] {processor.py:157} INFO - Started process (PID=54352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:43:48.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:43:48.944+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:43:48.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:43:48.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:43:48.974+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:43:48.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:43:48.983+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:43:48.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:43:48.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T12:44:19.436+0000] {processor.py:157} INFO - Started process (PID=54377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:44:19.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:44:19.439+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:44:19.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:44:19.451+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:44:19.467+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:44:19.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:44:19.479+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:44:19.479+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:44:19.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T12:44:49.877+0000] {processor.py:157} INFO - Started process (PID=54402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:44:49.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:44:49.880+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:44:49.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:44:49.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:44:49.910+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:44:49.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:44:49.919+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:44:49.919+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:44:49.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T12:45:20.331+0000] {processor.py:157} INFO - Started process (PID=54427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:45:20.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:45:20.333+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:45:20.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:45:20.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:45:20.359+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:45:20.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:45:20.368+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:45:20.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:45:20.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T12:45:50.804+0000] {processor.py:157} INFO - Started process (PID=54452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:45:50.805+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:45:50.807+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:45:50.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:45:50.817+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:45:50.834+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:45:50.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:45:50.844+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:45:50.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:45:50.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T12:46:21.199+0000] {processor.py:157} INFO - Started process (PID=54477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:46:21.200+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:46:21.202+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:46:21.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:46:21.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:46:21.229+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:46:21.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:46:21.242+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:46:21.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:46:21.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T12:46:51.632+0000] {processor.py:157} INFO - Started process (PID=54502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:46:51.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:46:51.637+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:46:51.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:46:51.648+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:46:51.672+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:46:51.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:46:51.684+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:46:51.684+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:46:51.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T12:47:22.056+0000] {processor.py:157} INFO - Started process (PID=54527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:47:22.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:47:22.061+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:47:22.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:47:22.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:47:22.091+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:47:22.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:47:22.102+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:47:22.101+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:47:22.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T12:47:52.628+0000] {processor.py:157} INFO - Started process (PID=54552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:47:52.631+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:47:52.638+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:47:52.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:47:52.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:47:52.687+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:47:52.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:47:52.701+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:47:52.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:47:52.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-19T12:48:23.173+0000] {processor.py:157} INFO - Started process (PID=54577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:48:23.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:48:23.180+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:48:23.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:48:23.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:48:23.238+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:48:23.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:48:23.253+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:48:23.253+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:48:23.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-19T12:48:53.674+0000] {processor.py:157} INFO - Started process (PID=54602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:48:53.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:48:53.677+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:48:53.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:48:53.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:48:53.706+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:48:53.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:48:53.718+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:48:53.718+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:48:53.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T12:49:24.103+0000] {processor.py:157} INFO - Started process (PID=54627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:49:24.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:49:24.108+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:49:24.107+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:49:24.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:49:24.149+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:49:24.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:49:24.162+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:49:24.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:49:24.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T12:49:54.531+0000] {processor.py:157} INFO - Started process (PID=54652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:49:54.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:49:54.534+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:49:54.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:49:54.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:49:54.560+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:49:54.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:49:54.569+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:49:54.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:49:54.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T12:50:24.982+0000] {processor.py:157} INFO - Started process (PID=54677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:50:24.983+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:50:24.985+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:50:24.984+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:50:24.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:50:25.010+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:50:25.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:50:25.019+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:50:25.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:50:25.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T12:50:55.413+0000] {processor.py:157} INFO - Started process (PID=54702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:50:55.415+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:50:55.417+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:50:55.417+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:50:55.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:50:55.445+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:50:55.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:50:55.453+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:50:55.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:50:55.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T12:51:25.858+0000] {processor.py:157} INFO - Started process (PID=54727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:51:25.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:51:25.863+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:51:25.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:51:25.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:51:25.900+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:51:25.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:51:25.914+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:51:25.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:51:25.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T12:51:56.297+0000] {processor.py:157} INFO - Started process (PID=54752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:51:56.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:51:56.301+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:51:56.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:51:56.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:51:56.328+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:51:56.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:51:56.342+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:51:56.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:51:56.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T12:52:26.759+0000] {processor.py:157} INFO - Started process (PID=54777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:52:26.760+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:52:26.761+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:52:26.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:52:26.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:52:26.791+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:52:26.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:52:26.800+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:52:26.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:52:26.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T12:52:57.183+0000] {processor.py:157} INFO - Started process (PID=54802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:52:57.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:52:57.188+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:52:57.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:52:57.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:52:57.226+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:52:57.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:52:57.238+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:52:57.238+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:52:57.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T12:53:27.627+0000] {processor.py:157} INFO - Started process (PID=54827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:53:27.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:53:27.630+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:53:27.629+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:53:27.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:53:27.660+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:53:27.660+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:53:27.675+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:53:27.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:53:27.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T12:53:58.066+0000] {processor.py:157} INFO - Started process (PID=54852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:53:58.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:53:58.070+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:53:58.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:53:58.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:53:58.096+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:53:58.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:53:58.106+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:53:58.106+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:53:58.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T12:54:28.493+0000] {processor.py:157} INFO - Started process (PID=54877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:54:28.496+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:54:28.499+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:54:28.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:54:28.511+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:54:28.533+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:54:28.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:54:28.544+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:54:28.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:54:28.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T12:54:58.942+0000] {processor.py:157} INFO - Started process (PID=54902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:54:58.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:54:58.944+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:54:58.944+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:54:58.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:54:58.971+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:54:58.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:54:58.983+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:54:58.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:54:58.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T12:55:29.400+0000] {processor.py:157} INFO - Started process (PID=54927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:55:29.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:55:29.402+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:55:29.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:55:29.412+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:55:29.431+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:55:29.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:55:29.442+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:55:29.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:55:29.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T12:55:59.825+0000] {processor.py:157} INFO - Started process (PID=54952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:55:59.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:55:59.829+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:55:59.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:55:59.844+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:55:59.857+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:55:59.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:55:59.868+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:55:59.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:55:59.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T12:56:30.284+0000] {processor.py:157} INFO - Started process (PID=54977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:56:30.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:56:30.287+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:56:30.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:56:30.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:56:30.315+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:56:30.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:56:30.324+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:56:30.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:56:30.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T12:57:00.720+0000] {processor.py:157} INFO - Started process (PID=55002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:57:00.720+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:57:00.722+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:57:00.722+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:57:00.731+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:57:00.748+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:57:00.748+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:57:00.758+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:57:00.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:57:00.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T12:57:31.194+0000] {processor.py:157} INFO - Started process (PID=55027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:57:31.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:57:31.200+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:57:31.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:57:31.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:57:31.236+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:57:31.236+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:57:31.247+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:57:31.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:57:31.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T12:58:01.629+0000] {processor.py:157} INFO - Started process (PID=55052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:58:01.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:58:01.632+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:58:01.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:58:01.643+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:58:01.663+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:58:01.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:58:01.676+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:58:01.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:58:01.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T12:58:32.029+0000] {processor.py:157} INFO - Started process (PID=55077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:58:32.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:58:32.035+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:58:32.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:58:32.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:58:32.077+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:58:32.076+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:58:32.088+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:58:32.088+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:58:32.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T12:59:02.511+0000] {processor.py:157} INFO - Started process (PID=55102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:59:02.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:59:02.516+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:59:02.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:59:02.525+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:59:02.541+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:59:02.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:59:02.554+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:59:02.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:59:02.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T12:59:32.986+0000] {processor.py:157} INFO - Started process (PID=55127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:59:32.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T12:59:32.989+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:59:32.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:59:33.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T12:59:33.016+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:59:33.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T12:59:33.026+0000] {logging_mixin.py:151} INFO - [2024-07-19T12:59:33.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T12:59:33.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T13:00:03.478+0000] {processor.py:157} INFO - Started process (PID=55152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:00:03.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:00:03.497+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:00:03.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:00:03.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:00:03.539+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:00:03.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:00:03.552+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:00:03.552+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:00:03.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-19T13:00:34.055+0000] {processor.py:157} INFO - Started process (PID=55175) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:00:34.056+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:00:34.062+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:00:34.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:00:34.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:00:34.150+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:00:34.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:00:34.172+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:00:34.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:00:34.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.141 seconds
[2024-07-19T13:01:04.621+0000] {processor.py:157} INFO - Started process (PID=55202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:01:04.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:01:04.627+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:01:04.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:01:04.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:01:04.676+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:01:04.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:01:04.688+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:01:04.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:01:04.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-19T13:01:35.098+0000] {processor.py:157} INFO - Started process (PID=55227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:01:35.100+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:01:35.106+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:01:35.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:01:35.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:01:35.187+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:01:35.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:01:35.224+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:01:35.224+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:01:35.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-07-19T13:02:05.671+0000] {processor.py:157} INFO - Started process (PID=55252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:02:05.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:02:05.676+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:02:05.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:02:05.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:02:05.722+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:02:05.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:02:05.739+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:02:05.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:02:05.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-19T13:02:36.222+0000] {processor.py:157} INFO - Started process (PID=55277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:02:36.223+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:02:36.226+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:02:36.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:02:36.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:02:36.265+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:02:36.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:02:36.279+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:02:36.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:02:36.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T13:03:06.719+0000] {processor.py:157} INFO - Started process (PID=55302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:03:06.723+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:03:06.725+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:03:06.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:03:06.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:03:06.761+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:03:06.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:03:06.777+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:03:06.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:03:06.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T13:03:37.150+0000] {processor.py:157} INFO - Started process (PID=55327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:03:37.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:03:37.165+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:03:37.165+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:03:37.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:03:37.255+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:03:37.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:03:37.275+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:03:37.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:03:37.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.157 seconds
[2024-07-19T13:04:07.623+0000] {processor.py:157} INFO - Started process (PID=55352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:04:07.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:04:07.625+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:04:07.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:04:07.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:04:07.655+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:04:07.654+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:04:07.666+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:04:07.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:04:07.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T13:04:37.997+0000] {processor.py:157} INFO - Started process (PID=55377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:04:38.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:04:38.007+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:04:38.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:04:38.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:04:38.037+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:04:38.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:04:38.048+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:04:38.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:04:38.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T13:05:08.501+0000] {processor.py:157} INFO - Started process (PID=55402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:05:08.502+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:05:08.506+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:05:08.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:05:08.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:05:08.545+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:05:08.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:05:08.557+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:05:08.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:05:08.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T13:05:38.964+0000] {processor.py:157} INFO - Started process (PID=55427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:05:38.965+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:05:38.969+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:05:38.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:05:38.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:05:39.008+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:05:39.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:05:39.023+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:05:39.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:05:39.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-19T13:06:09.503+0000] {processor.py:157} INFO - Started process (PID=55452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:06:09.505+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:06:09.507+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:06:09.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:06:09.524+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:06:09.554+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:06:09.554+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:06:09.575+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:06:09.575+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:06:09.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-19T13:06:40.019+0000] {processor.py:157} INFO - Started process (PID=55477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:06:40.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:06:40.024+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:06:40.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:06:40.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:06:40.054+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:06:40.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:06:40.064+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:06:40.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:06:40.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T13:07:10.514+0000] {processor.py:157} INFO - Started process (PID=55502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:07:10.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:07:10.519+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:07:10.519+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:07:10.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:07:10.575+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:07:10.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:07:10.588+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:07:10.588+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:07:10.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-19T13:07:41.008+0000] {processor.py:157} INFO - Started process (PID=55527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:07:41.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:07:41.011+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:07:41.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:07:41.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:07:41.041+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:07:41.040+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:07:41.051+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:07:41.051+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:07:41.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T13:08:11.484+0000] {processor.py:157} INFO - Started process (PID=55552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:08:11.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:08:11.487+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:08:11.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:08:11.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:08:11.513+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:08:11.513+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:08:11.524+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:08:11.524+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:08:11.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T13:08:41.905+0000] {processor.py:157} INFO - Started process (PID=55577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:08:41.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:08:41.908+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:08:41.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:08:41.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:08:41.939+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:08:41.939+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:08:41.949+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:08:41.949+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:08:41.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T13:09:12.323+0000] {processor.py:157} INFO - Started process (PID=55602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:09:12.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:09:12.328+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:09:12.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:09:12.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:09:12.364+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:09:12.364+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:09:12.374+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:09:12.374+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:09:12.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T13:09:42.823+0000] {processor.py:157} INFO - Started process (PID=55627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:09:42.825+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:09:42.828+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:09:42.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:09:42.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:09:42.869+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:09:42.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:09:42.887+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:09:42.887+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:09:42.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-19T13:10:13.266+0000] {processor.py:157} INFO - Started process (PID=55652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:10:13.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:10:13.268+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:10:13.268+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:10:13.283+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:10:13.296+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:10:13.296+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:10:13.305+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:10:13.305+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:10:13.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T13:10:43.728+0000] {processor.py:157} INFO - Started process (PID=55677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:10:43.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:10:43.732+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:10:43.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:10:43.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:10:43.779+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:10:43.779+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:10:43.791+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:10:43.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:10:43.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-19T13:11:14.242+0000] {processor.py:157} INFO - Started process (PID=55702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:11:14.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:11:14.247+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:11:14.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:11:14.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:11:14.287+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:11:14.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:11:14.301+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:11:14.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:11:14.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-19T13:11:44.714+0000] {processor.py:157} INFO - Started process (PID=55727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:11:44.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:11:44.716+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:11:44.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:11:44.732+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:11:44.745+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:11:44.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:11:44.758+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:11:44.758+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:11:44.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T13:12:15.142+0000] {processor.py:157} INFO - Started process (PID=55752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:12:15.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:12:15.149+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:12:15.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:12:15.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:12:15.187+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:12:15.187+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:12:15.200+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:12:15.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:12:15.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T13:12:45.596+0000] {processor.py:157} INFO - Started process (PID=55777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:12:45.599+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:12:45.602+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:12:45.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:12:45.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:12:45.626+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:12:45.626+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:12:45.635+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:12:45.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:12:45.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T13:13:15.999+0000] {processor.py:157} INFO - Started process (PID=55802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:13:16.002+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:13:16.005+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:13:16.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:13:16.019+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:13:16.037+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:13:16.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:13:16.046+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:13:16.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:13:16.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T13:13:46.392+0000] {processor.py:157} INFO - Started process (PID=55827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:13:46.393+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:13:46.395+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:13:46.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:13:46.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:13:46.428+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:13:46.428+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:13:46.445+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:13:46.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:13:46.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T13:14:16.841+0000] {processor.py:157} INFO - Started process (PID=55852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:14:16.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:14:16.849+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:14:16.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:14:16.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:14:16.893+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:14:16.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:14:16.909+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:14:16.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:14:16.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-19T13:14:47.350+0000] {processor.py:157} INFO - Started process (PID=55877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:14:47.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:14:47.356+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:14:47.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:14:47.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:14:47.412+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:14:47.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:14:47.426+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:14:47.426+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:14:47.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-19T13:15:17.906+0000] {processor.py:157} INFO - Started process (PID=55902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:15:17.908+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:15:17.910+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:15:17.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:15:17.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:15:17.950+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:15:17.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:15:17.963+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:15:17.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:15:17.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T13:15:48.388+0000] {processor.py:157} INFO - Started process (PID=55927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:15:48.390+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:15:48.393+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:15:48.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:15:48.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:15:48.432+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:15:48.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:15:48.446+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:15:48.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:15:48.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T13:16:18.878+0000] {processor.py:157} INFO - Started process (PID=55952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:16:18.882+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:16:18.885+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:16:18.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:16:18.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:16:18.921+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:16:18.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:16:18.932+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:16:18.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:16:18.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T13:16:49.244+0000] {processor.py:157} INFO - Started process (PID=55977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:16:49.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:16:49.247+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:16:49.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:16:49.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:16:49.281+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:16:49.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:16:49.299+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:16:49.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:16:49.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T13:17:19.669+0000] {processor.py:157} INFO - Started process (PID=56002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:17:19.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:17:19.673+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:17:19.673+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:17:19.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:17:19.703+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:17:19.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:17:19.716+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:17:19.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:17:19.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T13:17:50.099+0000] {processor.py:157} INFO - Started process (PID=56027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:17:50.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:17:50.104+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:17:50.103+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:17:50.118+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:17:50.139+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:17:50.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:17:50.151+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:17:50.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:17:50.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T13:18:20.579+0000] {processor.py:157} INFO - Started process (PID=56052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:18:20.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:18:20.582+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:18:20.581+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:18:20.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:18:20.614+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:18:20.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:18:20.626+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:18:20.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:18:20.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T13:18:50.992+0000] {processor.py:157} INFO - Started process (PID=56077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:18:50.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:18:50.995+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:18:50.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:18:51.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:18:51.028+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:18:51.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:18:51.040+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:18:51.040+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:18:51.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T13:19:21.464+0000] {processor.py:157} INFO - Started process (PID=56102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:19:21.465+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:19:21.467+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:19:21.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:19:21.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:19:21.501+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:19:21.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:19:21.515+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:19:21.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:19:21.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T13:19:51.926+0000] {processor.py:157} INFO - Started process (PID=56127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:19:51.928+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:19:51.930+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:19:51.930+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:19:51.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:19:51.970+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:19:51.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:19:51.984+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:19:51.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:19:51.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T13:20:22.655+0000] {processor.py:157} INFO - Started process (PID=56152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:20:22.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:20:22.662+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:20:22.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:20:22.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:20:22.750+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:20:22.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:20:22.775+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:20:22.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:20:22.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.139 seconds
[2024-07-19T13:20:53.224+0000] {processor.py:157} INFO - Started process (PID=56177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:20:53.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:20:53.226+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:20:53.226+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:20:53.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:20:53.253+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:20:53.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:20:53.264+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:20:53.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:20:53.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T13:21:23.732+0000] {processor.py:157} INFO - Started process (PID=56202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:21:23.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:21:23.737+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:21:23.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:21:23.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:21:23.777+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:21:23.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:21:23.790+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:21:23.790+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:21:23.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T13:21:54.194+0000] {processor.py:157} INFO - Started process (PID=56227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:21:54.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:21:54.197+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:21:54.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:21:54.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:21:54.229+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:21:54.229+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:21:54.240+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:21:54.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:21:54.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T13:22:24.654+0000] {processor.py:157} INFO - Started process (PID=56252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:22:24.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:22:24.659+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:22:24.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:22:24.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:22:24.683+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:22:24.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:22:24.692+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:22:24.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:22:24.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T13:22:55.084+0000] {processor.py:157} INFO - Started process (PID=56277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:22:55.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:22:55.087+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:22:55.086+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:22:55.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:22:55.121+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:22:55.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:22:55.132+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:22:55.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:22:55.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T13:23:25.512+0000] {processor.py:157} INFO - Started process (PID=56302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:23:25.514+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:23:25.516+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:23:25.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:23:25.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:23:25.549+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:23:25.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:23:25.558+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:23:25.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:23:25.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T13:23:55.898+0000] {processor.py:157} INFO - Started process (PID=56327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:23:55.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:23:55.902+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:23:55.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:23:55.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:23:55.941+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:23:55.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:23:55.958+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:23:55.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:23:55.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-19T13:24:26.408+0000] {processor.py:157} INFO - Started process (PID=56352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:24:26.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:24:26.411+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:24:26.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:24:26.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:24:26.442+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:24:26.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:24:26.454+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:24:26.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:24:26.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T13:24:56.862+0000] {processor.py:157} INFO - Started process (PID=56377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:24:56.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:24:56.865+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:24:56.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:24:56.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:24:56.897+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:24:56.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:24:56.908+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:24:56.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:24:56.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T13:25:27.337+0000] {processor.py:157} INFO - Started process (PID=56402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:25:27.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:25:27.339+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:25:27.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:25:27.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:25:27.368+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:25:27.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:25:27.379+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:25:27.379+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:25:27.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T13:25:57.898+0000] {processor.py:157} INFO - Started process (PID=56427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:25:57.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:25:57.906+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:25:57.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:25:57.922+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:25:57.944+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:25:57.944+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:25:57.958+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:25:57.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:25:57.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-19T13:26:28.391+0000] {processor.py:157} INFO - Started process (PID=56452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:26:28.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:26:28.397+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:26:28.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:26:28.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:26:28.444+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:26:28.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:26:28.459+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:26:28.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:26:28.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-19T13:26:58.878+0000] {processor.py:157} INFO - Started process (PID=56477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:26:58.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:26:58.881+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:26:58.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:26:58.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:26:58.911+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:26:58.911+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:26:58.922+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:26:58.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:26:58.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T13:27:29.361+0000] {processor.py:157} INFO - Started process (PID=56502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:27:29.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:27:29.368+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:27:29.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:27:29.382+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:27:29.401+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:27:29.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:27:29.410+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:27:29.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:27:29.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T13:27:59.788+0000] {processor.py:157} INFO - Started process (PID=56527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:27:59.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:27:59.794+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:27:59.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:27:59.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:27:59.831+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:27:59.831+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:27:59.847+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:27:59.847+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:27:59.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-19T13:28:30.235+0000] {processor.py:157} INFO - Started process (PID=56552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:28:30.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:28:30.238+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:28:30.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:28:30.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:28:30.263+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:28:30.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:28:30.273+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:28:30.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:28:30.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T13:29:00.674+0000] {processor.py:157} INFO - Started process (PID=56577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:29:00.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:29:00.677+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:29:00.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:29:00.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:29:00.704+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:29:00.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:29:00.715+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:29:00.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:29:00.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T13:29:31.182+0000] {processor.py:157} INFO - Started process (PID=56602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:29:31.184+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:29:31.186+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:29:31.186+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:29:31.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:29:31.214+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:29:31.214+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:29:31.226+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:29:31.226+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:29:31.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T13:30:01.643+0000] {processor.py:157} INFO - Started process (PID=56627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:30:01.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:30:01.650+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:30:01.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:30:01.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:30:01.689+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:30:01.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:30:01.701+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:30:01.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:30:01.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T13:30:32.451+0000] {processor.py:157} INFO - Started process (PID=56652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:30:32.473+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:30:32.477+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:30:32.477+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:30:32.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:30:32.618+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:30:32.618+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:30:32.697+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:30:32.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:30:32.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.282 seconds
[2024-07-19T13:31:03.358+0000] {processor.py:157} INFO - Started process (PID=56677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:31:03.360+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:31:03.362+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:31:03.362+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:31:03.377+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:31:03.399+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:31:03.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:31:03.415+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:31:03.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:31:03.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T13:31:33.866+0000] {processor.py:157} INFO - Started process (PID=56702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:31:33.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:31:33.869+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:31:33.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:31:33.883+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:31:33.897+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:31:33.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:31:33.910+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:31:33.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:31:33.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T13:32:04.308+0000] {processor.py:157} INFO - Started process (PID=56727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:32:04.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:32:04.312+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:32:04.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:32:04.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:32:04.340+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:32:04.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:32:04.349+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:32:04.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:32:04.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T13:32:34.716+0000] {processor.py:157} INFO - Started process (PID=56752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:32:34.718+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:32:34.721+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:32:34.721+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:32:34.736+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:32:34.756+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:32:34.756+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:32:34.770+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:32:34.770+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:32:34.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T13:33:05.215+0000] {processor.py:157} INFO - Started process (PID=56777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:33:05.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:33:05.217+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:33:05.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:33:05.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:33:05.247+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:33:05.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:33:05.257+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:33:05.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:33:05.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T13:33:35.648+0000] {processor.py:157} INFO - Started process (PID=56802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:33:35.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:33:35.651+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:33:35.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:33:35.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:33:35.683+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:33:35.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:33:35.696+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:33:35.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:33:35.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T13:34:06.160+0000] {processor.py:157} INFO - Started process (PID=56827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:34:06.162+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:34:06.164+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:34:06.164+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:34:06.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:34:06.195+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:34:06.195+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:34:06.210+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:34:06.209+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:34:06.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T13:34:36.902+0000] {processor.py:157} INFO - Started process (PID=56852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:34:36.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:34:36.911+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:34:36.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:34:36.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:34:37.005+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:34:37.005+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:34:37.028+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:34:37.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:34:37.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.151 seconds
[2024-07-19T13:35:07.498+0000] {processor.py:157} INFO - Started process (PID=56877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:35:07.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:35:07.508+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:35:07.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:35:07.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:35:07.570+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:35:07.570+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:35:07.591+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:35:07.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:35:07.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-19T13:35:38.024+0000] {processor.py:157} INFO - Started process (PID=56902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:35:38.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:35:38.026+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:35:38.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:35:38.038+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:35:38.050+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:35:38.050+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:35:38.058+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:35:38.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:35:38.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-19T13:36:08.454+0000] {processor.py:157} INFO - Started process (PID=56927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:36:08.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:36:08.462+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:36:08.461+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:36:08.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:36:08.499+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:36:08.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:36:08.512+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:36:08.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:36:08.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T13:36:38.823+0000] {processor.py:157} INFO - Started process (PID=56952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:36:38.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:36:38.829+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:36:38.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:36:38.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:36:38.859+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:36:38.859+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:36:38.868+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:36:38.868+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:36:38.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T13:37:09.204+0000] {processor.py:157} INFO - Started process (PID=56977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:37:09.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:37:09.207+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:37:09.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:37:09.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:37:09.238+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:37:09.238+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:37:09.249+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:37:09.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:37:09.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T13:37:39.638+0000] {processor.py:157} INFO - Started process (PID=57002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:37:39.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:37:39.641+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:37:39.641+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:37:39.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:37:39.667+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:37:39.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:37:39.679+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:37:39.679+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:37:39.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T13:38:10.002+0000] {processor.py:157} INFO - Started process (PID=57027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:38:10.004+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:38:10.007+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:38:10.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:38:10.022+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:38:10.037+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:38:10.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:38:10.048+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:38:10.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:38:10.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T13:38:40.444+0000] {processor.py:157} INFO - Started process (PID=57052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:38:40.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:38:40.449+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:38:40.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:38:40.465+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:38:40.486+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:38:40.486+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:38:40.500+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:38:40.500+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:38:40.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T13:39:10.919+0000] {processor.py:157} INFO - Started process (PID=57077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:39:10.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:39:10.923+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:39:10.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:39:10.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:39:10.965+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:39:10.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:39:10.979+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:39:10.979+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:39:10.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-19T13:39:41.439+0000] {processor.py:157} INFO - Started process (PID=57102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:39:41.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:39:41.445+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:39:41.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:39:41.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:39:41.477+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:39:41.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:39:41.490+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:39:41.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:39:41.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T13:40:11.863+0000] {processor.py:157} INFO - Started process (PID=57127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:40:11.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:40:11.866+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:40:11.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:40:11.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:40:11.898+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:40:11.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:40:11.914+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:40:11.914+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:40:11.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T13:40:42.306+0000] {processor.py:157} INFO - Started process (PID=57152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:40:42.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:40:42.311+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:40:42.311+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:40:42.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:40:42.339+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:40:42.339+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:40:42.350+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:40:42.349+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:40:42.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T13:41:12.773+0000] {processor.py:157} INFO - Started process (PID=57177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:41:12.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:41:12.776+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:41:12.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:41:12.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:41:12.805+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:41:12.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:41:12.816+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:41:12.816+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:41:12.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T13:41:43.202+0000] {processor.py:157} INFO - Started process (PID=57202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:41:43.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:41:43.206+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:41:43.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:41:43.231+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:41:43.251+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:41:43.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:41:43.264+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:41:43.264+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:41:43.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-19T13:42:13.654+0000] {processor.py:157} INFO - Started process (PID=57227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:42:13.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:42:13.659+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:42:13.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:42:13.674+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:42:13.703+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:42:13.703+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:42:13.722+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:42:13.722+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:42:13.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-19T13:42:44.084+0000] {processor.py:157} INFO - Started process (PID=57252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:42:44.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:42:44.088+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:42:44.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:42:44.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:42:44.117+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:42:44.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:42:44.129+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:42:44.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:42:44.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T13:43:14.523+0000] {processor.py:157} INFO - Started process (PID=57277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:43:14.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:43:14.526+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:43:14.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:43:14.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:43:14.559+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:43:14.559+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:43:14.574+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:43:14.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:43:14.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T13:43:45.024+0000] {processor.py:157} INFO - Started process (PID=57301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:43:45.026+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:43:45.029+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:43:45.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:43:45.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:43:45.060+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:43:45.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:43:45.070+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:43:45.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:43:45.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T13:44:15.445+0000] {processor.py:157} INFO - Started process (PID=57327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:44:15.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:44:15.447+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:44:15.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:44:15.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:44:15.474+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:44:15.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:44:15.484+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:44:15.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:44:15.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T13:44:45.898+0000] {processor.py:157} INFO - Started process (PID=57352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:44:45.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:44:45.902+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:44:45.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:44:45.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:44:45.941+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:44:45.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:44:45.955+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:44:45.955+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:44:45.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T13:45:16.350+0000] {processor.py:157} INFO - Started process (PID=57377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:45:16.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:45:16.358+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:45:16.358+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:45:16.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:45:16.381+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:45:16.381+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:45:16.390+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:45:16.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:45:16.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T13:45:46.758+0000] {processor.py:157} INFO - Started process (PID=57402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:45:46.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:45:46.761+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:45:46.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:45:46.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:45:46.788+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:45:46.788+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:45:46.798+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:45:46.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:45:46.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T13:46:17.188+0000] {processor.py:157} INFO - Started process (PID=57427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:46:17.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:46:17.191+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:46:17.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:46:17.209+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:46:17.224+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:46:17.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:46:17.236+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:46:17.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:46:17.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T13:46:47.573+0000] {processor.py:157} INFO - Started process (PID=57452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:46:47.574+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:46:47.575+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:46:47.575+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:46:47.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:46:47.606+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:46:47.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:46:47.617+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:46:47.617+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:46:47.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T13:47:17.990+0000] {processor.py:157} INFO - Started process (PID=57477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:47:17.991+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:47:17.993+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:47:17.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:47:18.004+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:47:18.022+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:47:18.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:47:18.033+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:47:18.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:47:18.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T13:47:48.480+0000] {processor.py:157} INFO - Started process (PID=57502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:47:48.481+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:47:48.485+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:47:48.485+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:47:48.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:47:48.535+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:47:48.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:47:48.550+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:47:48.550+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:47:48.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-19T13:48:18.934+0000] {processor.py:157} INFO - Started process (PID=57527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:48:18.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:48:18.941+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:48:18.940+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:48:18.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:48:19.009+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:48:19.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:48:19.041+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:48:19.041+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:48:19.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.127 seconds
[2024-07-19T13:48:49.433+0000] {processor.py:157} INFO - Started process (PID=57552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:48:49.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:48:49.435+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:48:49.435+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:48:49.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:48:49.467+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:48:49.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:48:49.478+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:48:49.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:48:49.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T13:49:19.916+0000] {processor.py:157} INFO - Started process (PID=57577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:49:19.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:49:19.922+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:49:19.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:49:19.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:49:19.960+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:49:19.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:49:19.973+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:49:19.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:49:19.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T13:49:50.538+0000] {processor.py:157} INFO - Started process (PID=57602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:49:50.539+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:49:50.541+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:49:50.541+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:49:50.553+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:49:50.571+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:49:50.571+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:49:50.581+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:49:50.581+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:49:50.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T13:50:20.988+0000] {processor.py:157} INFO - Started process (PID=57627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:50:20.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:50:20.990+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:50:20.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:50:21.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:50:21.018+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:50:21.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:50:21.028+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:50:21.028+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:50:21.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T13:50:51.409+0000] {processor.py:157} INFO - Started process (PID=57652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:50:51.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:50:51.412+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:50:51.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:50:51.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:50:51.438+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:50:51.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:50:51.450+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:50:51.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:50:51.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T13:51:21.812+0000] {processor.py:157} INFO - Started process (PID=57677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:51:21.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:51:21.814+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:51:21.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:51:21.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:51:21.841+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:51:21.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:51:21.852+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:51:21.852+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:51:21.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T13:51:52.325+0000] {processor.py:157} INFO - Started process (PID=57702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:51:52.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:51:52.331+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:51:52.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:51:52.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:51:52.390+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:51:52.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:51:52.410+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:51:52.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:51:52.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.101 seconds
[2024-07-19T13:52:22.867+0000] {processor.py:157} INFO - Started process (PID=57727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:52:22.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:52:22.874+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:52:22.874+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:52:22.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:52:22.932+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:52:22.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:52:22.962+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:52:22.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:52:22.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-19T13:52:53.437+0000] {processor.py:157} INFO - Started process (PID=57752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:52:53.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:52:53.444+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:52:53.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:52:53.463+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:52:53.493+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:52:53.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:52:53.509+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:52:53.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:52:53.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-19T13:53:23.969+0000] {processor.py:157} INFO - Started process (PID=57777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:53:23.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:53:23.971+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:53:23.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:53:23.986+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:53:24.000+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:53:24.000+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:53:24.011+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:53:24.011+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:53:24.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T13:53:54.400+0000] {processor.py:157} INFO - Started process (PID=57802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:53:54.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:53:54.406+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:53:54.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:53:54.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:53:54.444+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:53:54.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:53:54.458+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:53:54.458+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:53:54.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T13:54:24.855+0000] {processor.py:157} INFO - Started process (PID=57827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:54:24.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:54:24.860+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:54:24.860+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:54:24.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:54:24.888+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:54:24.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:54:24.898+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:54:24.898+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:54:24.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T13:54:55.289+0000] {processor.py:157} INFO - Started process (PID=57852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:54:55.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:54:55.292+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:54:55.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:54:55.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:54:55.319+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:54:55.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:54:55.331+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:54:55.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:54:55.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T13:55:25.775+0000] {processor.py:157} INFO - Started process (PID=57877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:55:25.777+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:55:25.779+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:55:25.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:55:25.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:55:25.811+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:55:25.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:55:25.820+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:55:25.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:55:25.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T13:55:56.230+0000] {processor.py:157} INFO - Started process (PID=57902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:55:56.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:55:56.233+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:55:56.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:55:56.244+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:55:56.260+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:55:56.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:55:56.270+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:55:56.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:55:56.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T13:56:26.725+0000] {processor.py:157} INFO - Started process (PID=57927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:56:26.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:56:26.733+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:56:26.732+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:56:26.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:56:26.798+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:56:26.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:56:26.818+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:56:26.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:56:26.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.111 seconds
[2024-07-19T13:56:57.236+0000] {processor.py:157} INFO - Started process (PID=57952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:56:57.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:56:57.239+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:56:57.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:56:57.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:56:57.273+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:56:57.273+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:56:57.287+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:56:57.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:56:57.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T13:57:27.730+0000] {processor.py:157} INFO - Started process (PID=57976) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:57:27.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:57:27.748+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:57:27.747+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:57:27.771+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:57:27.801+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:57:27.800+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:57:27.821+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:57:27.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:57:27.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-19T13:57:58.223+0000] {processor.py:157} INFO - Started process (PID=58002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:57:58.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:57:58.225+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:57:58.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:57:58.237+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:57:58.252+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:57:58.252+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:57:58.262+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:57:58.262+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:57:58.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T13:58:28.676+0000] {processor.py:157} INFO - Started process (PID=58027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:58:28.678+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:58:28.683+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:58:28.682+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:58:28.716+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:58:28.753+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:58:28.753+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:58:28.775+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:58:28.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:58:28.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-19T13:58:59.245+0000] {processor.py:157} INFO - Started process (PID=58052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:58:59.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:58:59.246+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:58:59.246+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:58:59.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:58:59.277+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:58:59.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:58:59.287+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:58:59.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:58:59.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T13:59:29.651+0000] {processor.py:157} INFO - Started process (PID=58077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:59:29.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T13:59:29.657+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:59:29.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:59:29.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T13:59:29.697+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:59:29.697+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T13:59:29.711+0000] {logging_mixin.py:151} INFO - [2024-07-19T13:59:29.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T13:59:29.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T14:00:00.120+0000] {processor.py:157} INFO - Started process (PID=58102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:00:00.121+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:00:00.123+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:00:00.123+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:00:00.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:00:00.155+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:00:00.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:00:00.169+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:00:00.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:00:00.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T14:00:30.621+0000] {processor.py:157} INFO - Started process (PID=58127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:00:30.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:00:30.625+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:00:30.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:00:30.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:00:30.661+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:00:30.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:00:30.676+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:00:30.676+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:00:30.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T14:01:01.122+0000] {processor.py:157} INFO - Started process (PID=58152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:01:01.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:01:01.126+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:01:01.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:01:01.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:01:01.158+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:01:01.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:01:01.171+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:01:01.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:01:01.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T14:01:31.544+0000] {processor.py:157} INFO - Started process (PID=58177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:01:31.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:01:31.553+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:01:31.553+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:01:31.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:01:31.605+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:01:31.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:01:31.623+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:01:31.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:01:31.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-19T14:02:02.107+0000] {processor.py:157} INFO - Started process (PID=58202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:02:02.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:02:02.113+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:02:02.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:02:02.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:02:02.156+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:02:02.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:02:02.171+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:02:02.171+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:02:02.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-19T14:02:32.604+0000] {processor.py:157} INFO - Started process (PID=58227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:02:32.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:02:32.610+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:02:32.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:02:32.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:02:32.673+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:02:32.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:02:32.692+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:02:32.692+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:02:32.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-19T14:03:03.021+0000] {processor.py:157} INFO - Started process (PID=58252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:03:03.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:03:03.024+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:03:03.024+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:03:03.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:03:03.054+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:03:03.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:03:03.066+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:03:03.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:03:03.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T14:03:33.429+0000] {processor.py:157} INFO - Started process (PID=58277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:03:33.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:03:33.455+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:03:33.454+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:03:33.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:03:33.508+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:03:33.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:03:33.525+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:03:33.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:03:33.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-19T14:04:03.924+0000] {processor.py:157} INFO - Started process (PID=58302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:04:03.924+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:04:03.926+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:04:03.926+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:04:03.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:04:03.957+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:04:03.956+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:04:03.969+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:04:03.969+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:04:03.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T14:04:34.299+0000] {processor.py:157} INFO - Started process (PID=58327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:04:34.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:04:34.300+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:04:34.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:04:34.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:04:34.321+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:04:34.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:04:34.331+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:04:34.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:04:34.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-19T14:05:04.668+0000] {processor.py:157} INFO - Started process (PID=58352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:05:04.669+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:05:04.670+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:05:04.670+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:05:04.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:05:04.694+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:05:04.694+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:05:04.705+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:05:04.705+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:05:04.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T14:05:35.042+0000] {processor.py:157} INFO - Started process (PID=58377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:05:35.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:05:35.043+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:05:35.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:05:35.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:05:35.065+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:05:35.065+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:05:35.074+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:05:35.074+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:05:35.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-19T14:06:05.435+0000] {processor.py:157} INFO - Started process (PID=58402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:06:05.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:06:05.438+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:06:05.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:06:05.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:06:05.469+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:06:05.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:06:05.482+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:06:05.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:06:05.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T14:06:35.901+0000] {processor.py:157} INFO - Started process (PID=58427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:06:35.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:06:35.903+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:06:35.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:06:35.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:06:35.936+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:06:35.935+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:06:35.950+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:06:35.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:06:35.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T14:07:06.399+0000] {processor.py:157} INFO - Started process (PID=58452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:07:06.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:07:06.404+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:07:06.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:07:06.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:07:06.441+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:07:06.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:07:06.451+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:07:06.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:07:06.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T14:07:36.825+0000] {processor.py:157} INFO - Started process (PID=58477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:07:36.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:07:36.827+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:07:36.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:07:36.834+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:07:36.852+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:07:36.852+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:07:36.866+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:07:36.866+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:07:36.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T14:08:07.300+0000] {processor.py:157} INFO - Started process (PID=58502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:08:07.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:08:07.307+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:08:07.307+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:08:07.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:08:07.368+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:08:07.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:08:07.381+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:08:07.381+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:08:07.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-19T14:08:37.828+0000] {processor.py:157} INFO - Started process (PID=58527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:08:37.831+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:08:37.835+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:08:37.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:08:37.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:08:37.880+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:08:37.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:08:37.894+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:08:37.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:08:37.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-19T14:09:08.329+0000] {processor.py:157} INFO - Started process (PID=58552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:09:08.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:09:08.335+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:09:08.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:09:08.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:09:08.377+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:09:08.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:09:08.390+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:09:08.390+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:09:08.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-19T14:09:38.795+0000] {processor.py:157} INFO - Started process (PID=58577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:09:38.797+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:09:38.799+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:09:38.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:09:38.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:09:38.827+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:09:38.827+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:09:38.837+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:09:38.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:09:38.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T14:10:09.216+0000] {processor.py:157} INFO - Started process (PID=58602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:10:09.217+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:10:09.219+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:10:09.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:10:09.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:10:09.247+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:10:09.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:10:09.257+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:10:09.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:10:09.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T14:10:39.763+0000] {processor.py:157} INFO - Started process (PID=58627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:10:39.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:10:39.768+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:10:39.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:10:39.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:10:39.819+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:10:39.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:10:39.836+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:10:39.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:10:39.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-19T14:11:10.251+0000] {processor.py:157} INFO - Started process (PID=58651) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:11:10.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:11:10.257+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:11:10.256+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:11:10.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:11:10.331+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:11:10.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:11:10.349+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:11:10.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:11:10.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-19T14:11:40.956+0000] {processor.py:157} INFO - Started process (PID=58676) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:11:40.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:11:40.961+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:11:40.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:11:40.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:11:41.013+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:11:41.013+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:11:41.026+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:11:41.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:11:41.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-19T14:12:11.434+0000] {processor.py:157} INFO - Started process (PID=58702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:12:11.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:12:11.439+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:12:11.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:12:11.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:12:11.477+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:12:11.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:12:11.490+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:12:11.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:12:11.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T14:12:41.910+0000] {processor.py:157} INFO - Started process (PID=58727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:12:41.911+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:12:41.915+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:12:41.914+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:12:41.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:12:41.957+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:12:41.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:12:41.970+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:12:41.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:12:41.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-19T14:13:12.432+0000] {processor.py:157} INFO - Started process (PID=58751) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:13:12.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:13:12.436+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:13:12.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:13:12.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:13:12.494+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:13:12.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:13:12.525+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:13:12.525+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:13:12.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-19T14:13:42.899+0000] {processor.py:157} INFO - Started process (PID=58777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:13:42.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:13:42.902+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:13:42.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:13:42.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:13:42.938+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:13:42.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:13:42.952+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:13:42.951+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:13:42.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T14:14:13.351+0000] {processor.py:157} INFO - Started process (PID=58802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:14:13.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:14:13.354+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:14:13.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:14:13.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:14:13.389+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:14:13.389+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:14:13.409+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:14:13.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:14:13.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-19T14:14:43.849+0000] {processor.py:157} INFO - Started process (PID=58827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:14:43.850+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:14:43.852+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:14:43.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:14:43.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:14:43.882+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:14:43.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:14:43.891+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:14:43.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:14:43.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T14:15:14.304+0000] {processor.py:157} INFO - Started process (PID=58852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:15:14.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:15:14.309+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:15:14.308+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:15:14.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:15:14.354+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:15:14.354+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:15:14.369+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:15:14.369+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:15:14.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-19T14:15:44.793+0000] {processor.py:157} INFO - Started process (PID=58877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:15:44.795+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:15:44.796+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:15:44.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:15:44.812+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:15:44.826+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:15:44.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:15:44.837+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:15:44.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:15:44.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T14:16:15.228+0000] {processor.py:157} INFO - Started process (PID=58902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:16:15.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:16:15.234+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:16:15.234+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:16:15.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:16:15.283+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:16:15.283+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:16:15.302+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:16:15.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:16:15.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-19T14:16:45.729+0000] {processor.py:157} INFO - Started process (PID=58927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:16:45.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:16:45.732+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:16:45.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:16:45.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:16:45.757+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:16:45.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:16:45.767+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:16:45.767+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:16:45.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T14:17:16.130+0000] {processor.py:157} INFO - Started process (PID=58952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:17:16.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:17:16.136+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:17:16.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:17:16.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:17:16.180+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:17:16.180+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:17:16.201+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:17:16.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:17:16.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-19T14:17:46.600+0000] {processor.py:157} INFO - Started process (PID=58977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:17:46.601+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:17:46.603+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:17:46.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:17:46.612+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:17:46.628+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:17:46.627+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:17:46.637+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:17:46.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:17:46.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T14:18:17.059+0000] {processor.py:157} INFO - Started process (PID=59002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:18:17.061+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:18:17.066+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:18:17.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:18:17.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:18:17.115+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:18:17.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:18:17.133+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:18:17.133+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:18:17.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-19T14:18:47.561+0000] {processor.py:157} INFO - Started process (PID=59027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:18:47.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:18:47.586+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:18:47.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:18:47.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:18:47.635+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:18:47.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:18:47.650+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:18:47.650+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:18:47.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-19T14:19:18.124+0000] {processor.py:157} INFO - Started process (PID=59052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:19:18.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:19:18.128+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:19:18.128+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:19:18.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:19:18.160+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:19:18.160+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:19:18.172+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:19:18.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:19:18.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T14:19:48.498+0000] {processor.py:157} INFO - Started process (PID=59077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:19:48.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:19:48.501+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:19:48.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:19:48.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:19:48.526+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:19:48.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:19:48.536+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:19:48.536+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:19:48.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T14:20:18.941+0000] {processor.py:157} INFO - Started process (PID=59102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:20:18.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:20:18.945+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:20:18.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:20:18.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:20:18.970+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:20:18.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:20:18.982+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:20:18.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:20:18.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T14:20:49.386+0000] {processor.py:157} INFO - Started process (PID=59127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:20:49.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:20:49.388+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:20:49.388+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:20:49.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:20:49.408+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:20:49.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:20:49.418+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:20:49.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:20:49.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-19T14:21:19.851+0000] {processor.py:157} INFO - Started process (PID=59152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:21:19.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:21:19.855+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:21:19.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:21:19.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:21:19.883+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:21:19.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:21:19.893+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:21:19.893+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:21:19.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T14:21:50.332+0000] {processor.py:157} INFO - Started process (PID=59177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:21:50.336+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:21:50.339+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:21:50.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:21:50.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:21:50.388+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:21:50.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:21:50.407+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:21:50.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:21:50.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-19T14:22:20.884+0000] {processor.py:157} INFO - Started process (PID=59202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:22:20.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:22:20.890+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:22:20.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:22:20.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:22:20.930+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:22:20.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:22:20.943+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:22:20.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:22:20.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-19T14:22:51.376+0000] {processor.py:157} INFO - Started process (PID=59227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:22:51.378+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:22:51.380+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:22:51.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:22:51.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:22:51.408+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:22:51.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:22:51.418+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:22:51.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:22:51.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T14:23:21.882+0000] {processor.py:157} INFO - Started process (PID=59252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:23:21.883+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:23:21.885+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:23:21.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:23:21.897+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:23:21.914+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:23:21.914+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:23:21.925+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:23:21.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:23:21.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T14:23:52.355+0000] {processor.py:157} INFO - Started process (PID=59277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:23:52.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:23:52.359+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:23:52.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:23:52.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:23:52.399+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:23:52.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:23:52.415+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:23:52.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:23:52.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-19T14:24:22.821+0000] {processor.py:157} INFO - Started process (PID=59302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:24:22.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:24:22.824+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:24:22.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:24:22.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:24:22.864+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:24:22.864+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:24:22.878+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:24:22.878+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:24:22.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T14:24:53.270+0000] {processor.py:157} INFO - Started process (PID=59327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:24:53.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:24:53.273+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:24:53.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:24:53.286+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:24:53.309+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:24:53.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:24:53.323+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:24:53.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:24:53.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T14:25:23.747+0000] {processor.py:157} INFO - Started process (PID=59352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:25:23.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:25:23.752+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:25:23.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:25:23.768+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:25:23.789+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:25:23.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:25:23.801+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:25:23.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:25:23.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T14:25:54.212+0000] {processor.py:157} INFO - Started process (PID=59377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:25:54.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:25:54.215+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:25:54.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:25:54.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:25:54.242+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:25:54.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:25:54.254+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:25:54.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:25:54.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T14:26:24.636+0000] {processor.py:157} INFO - Started process (PID=59402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:26:24.638+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:26:24.642+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:26:24.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:26:24.657+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:26:24.677+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:26:24.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:26:24.690+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:26:24.690+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:26:24.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T14:26:55.150+0000] {processor.py:157} INFO - Started process (PID=59426) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:26:55.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:26:55.158+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:26:55.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:26:55.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:26:55.213+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:26:55.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:26:55.230+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:26:55.230+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:26:55.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-19T14:27:25.607+0000] {processor.py:157} INFO - Started process (PID=59452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:27:25.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:27:25.611+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:27:25.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:27:25.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:27:25.633+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:27:25.633+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:27:25.643+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:27:25.643+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:27:25.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T14:27:56.032+0000] {processor.py:157} INFO - Started process (PID=59476) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:27:56.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:27:56.038+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:27:56.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:27:56.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:27:56.083+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:27:56.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:27:56.099+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:27:56.099+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:27:56.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-19T14:28:26.497+0000] {processor.py:157} INFO - Started process (PID=59502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:28:26.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:28:26.501+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:28:26.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:28:26.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:28:26.529+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:28:26.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:28:26.540+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:28:26.540+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:28:26.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T14:28:56.944+0000] {processor.py:157} INFO - Started process (PID=59527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:28:56.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:28:56.970+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:28:56.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:28:57.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:28:57.042+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:28:57.041+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:28:57.064+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:28:57.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:28:57.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.143 seconds
[2024-07-19T14:29:27.564+0000] {processor.py:157} INFO - Started process (PID=59552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:29:27.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:29:27.568+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:29:27.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:29:27.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:29:27.599+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:29:27.599+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:29:27.613+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:29:27.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:29:27.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T14:29:58.067+0000] {processor.py:157} INFO - Started process (PID=59575) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:29:58.069+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:29:58.076+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:29:58.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:29:58.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:29:58.133+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:29:58.133+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:29:58.168+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:29:58.168+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:29:58.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-19T14:30:28.646+0000] {processor.py:157} INFO - Started process (PID=59602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:30:28.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:30:28.651+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:30:28.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:30:28.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:30:28.690+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:30:28.690+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:30:28.706+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:30:28.706+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:30:28.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-19T14:30:59.124+0000] {processor.py:157} INFO - Started process (PID=59627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:30:59.126+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:30:59.127+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:30:59.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:30:59.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:30:59.155+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:30:59.155+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:30:59.167+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:30:59.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:30:59.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T14:31:29.678+0000] {processor.py:157} INFO - Started process (PID=59652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:31:29.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:31:29.683+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:31:29.683+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:31:29.697+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:31:29.726+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:31:29.725+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:31:29.743+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:31:29.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:31:29.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.080 seconds
[2024-07-19T14:32:00.132+0000] {processor.py:157} INFO - Started process (PID=59677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:32:00.133+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:32:00.135+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:32:00.135+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:32:00.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:32:00.164+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:32:00.164+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:32:00.174+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:32:00.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:32:00.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T14:32:30.602+0000] {processor.py:157} INFO - Started process (PID=59702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:32:30.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:32:30.609+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:32:30.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:32:30.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:32:30.669+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:32:30.668+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:32:30.689+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:32:30.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:32:30.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-19T14:33:00.994+0000] {processor.py:157} INFO - Started process (PID=59727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:33:00.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:33:00.996+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:33:00.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:33:01.006+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:33:01.022+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:33:01.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:33:01.035+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:33:01.035+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:33:01.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T14:33:31.437+0000] {processor.py:157} INFO - Started process (PID=59752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:33:31.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:33:31.442+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:33:31.442+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:33:31.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:33:31.480+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:33:31.480+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:33:31.493+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:33:31.493+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:33:31.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T14:34:01.855+0000] {processor.py:157} INFO - Started process (PID=59777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:34:01.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:34:01.858+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:34:01.858+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:34:01.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:34:01.889+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:34:01.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:34:01.900+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:34:01.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:34:01.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T14:34:32.304+0000] {processor.py:157} INFO - Started process (PID=59802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:34:32.305+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:34:32.306+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:34:32.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:34:32.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:34:32.336+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:34:32.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:34:32.348+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:34:32.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:34:32.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T14:35:02.741+0000] {processor.py:157} INFO - Started process (PID=59827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:35:02.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:35:02.743+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:35:02.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:35:02.755+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:35:02.773+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:35:02.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:35:02.784+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:35:02.784+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:35:02.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T14:35:33.189+0000] {processor.py:157} INFO - Started process (PID=59852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:35:33.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:35:33.192+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:35:33.191+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:35:33.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:35:33.221+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:35:33.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:35:33.231+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:35:33.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:35:33.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T14:36:03.679+0000] {processor.py:157} INFO - Started process (PID=59877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:36:03.682+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:36:03.684+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:36:03.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:36:03.702+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:36:03.722+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:36:03.722+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:36:03.735+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:36:03.735+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:36:03.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T14:36:34.115+0000] {processor.py:157} INFO - Started process (PID=59902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:36:34.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:36:34.119+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:36:34.118+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:36:34.134+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:36:34.149+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:36:34.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:36:34.160+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:36:34.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:36:34.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T14:37:04.522+0000] {processor.py:157} INFO - Started process (PID=59927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:37:04.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:37:04.526+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:37:04.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:37:04.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:37:04.555+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:37:04.555+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:37:04.567+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:37:04.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:37:04.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T14:37:35.001+0000] {processor.py:157} INFO - Started process (PID=59952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:37:35.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:37:35.008+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:37:35.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:37:35.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:37:35.049+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:37:35.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:37:35.064+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:37:35.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:37:35.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-19T14:38:05.456+0000] {processor.py:157} INFO - Started process (PID=59977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:38:05.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:38:05.459+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:38:05.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:38:05.470+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:38:05.488+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:38:05.488+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:38:05.499+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:38:05.498+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:38:05.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T14:38:35.951+0000] {processor.py:157} INFO - Started process (PID=60002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:38:35.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:38:35.959+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:38:35.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:38:35.984+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:38:36.027+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:38:36.027+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:38:36.052+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:38:36.052+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:38:36.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-19T14:39:06.556+0000] {processor.py:157} INFO - Started process (PID=60027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:39:06.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:39:06.559+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:39:06.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:39:06.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:39:06.590+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:39:06.590+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:39:06.600+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:39:06.600+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:39:06.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T14:39:37.055+0000] {processor.py:157} INFO - Started process (PID=60052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:39:37.057+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:39:37.075+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:39:37.074+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:39:37.092+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:39:37.116+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:39:37.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:39:37.131+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:39:37.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:39:37.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.092 seconds
[2024-07-19T14:40:07.527+0000] {processor.py:157} INFO - Started process (PID=60077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:40:07.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:40:07.531+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:40:07.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:40:07.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:40:07.566+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:40:07.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:40:07.584+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:40:07.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:40:07.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-19T14:40:38.028+0000] {processor.py:157} INFO - Started process (PID=60102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:40:38.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:40:38.031+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:40:38.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:40:38.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:40:38.056+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:40:38.056+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:40:38.067+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:40:38.067+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:40:38.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T14:41:08.434+0000] {processor.py:157} INFO - Started process (PID=60127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:41:08.436+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:41:08.439+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:41:08.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:41:08.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:41:08.481+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:41:08.481+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:41:08.496+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:41:08.496+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:41:08.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-19T14:41:38.878+0000] {processor.py:157} INFO - Started process (PID=60152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:41:38.879+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:41:38.881+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:41:38.881+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:41:38.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:41:38.909+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:41:38.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:41:38.922+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:41:38.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:41:38.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T14:42:09.282+0000] {processor.py:157} INFO - Started process (PID=60177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:42:09.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:42:09.286+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:42:09.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:42:09.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:42:09.314+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:42:09.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:42:09.324+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:42:09.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:42:09.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T14:42:39.764+0000] {processor.py:157} INFO - Started process (PID=60202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:42:39.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:42:39.767+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:42:39.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:42:39.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:42:39.798+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:42:39.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:42:39.810+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:42:39.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:42:39.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T14:43:10.203+0000] {processor.py:157} INFO - Started process (PID=60227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:43:10.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:43:10.208+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:43:10.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:43:10.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:43:10.244+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:43:10.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:43:10.257+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:43:10.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:43:10.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T14:43:40.700+0000] {processor.py:157} INFO - Started process (PID=60252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:43:40.701+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:43:40.703+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:43:40.703+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:43:40.721+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:43:40.735+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:43:40.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:43:40.744+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:43:40.744+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:43:40.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T14:44:11.121+0000] {processor.py:157} INFO - Started process (PID=60277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:44:11.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:44:11.125+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:44:11.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:44:11.139+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:44:11.152+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:44:11.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:44:11.161+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:44:11.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:44:11.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T14:44:41.559+0000] {processor.py:157} INFO - Started process (PID=60302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:44:41.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:44:41.563+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:44:41.562+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:44:41.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:44:41.591+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:44:41.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:44:41.601+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:44:41.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:44:41.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T14:45:12.048+0000] {processor.py:157} INFO - Started process (PID=60327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:45:12.051+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:45:12.055+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:45:12.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:45:12.071+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:45:12.093+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:45:12.093+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:45:12.107+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:45:12.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:45:12.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T14:45:42.461+0000] {processor.py:157} INFO - Started process (PID=60352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:45:42.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:45:42.464+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:45:42.464+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:45:42.481+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:45:42.497+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:45:42.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:45:42.511+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:45:42.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:45:42.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T14:46:12.853+0000] {processor.py:157} INFO - Started process (PID=60377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:46:12.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:46:12.859+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:46:12.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:46:12.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:46:12.899+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:46:12.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:46:12.915+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:46:12.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:46:12.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-19T14:46:43.267+0000] {processor.py:157} INFO - Started process (PID=60402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:46:43.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:46:43.275+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:46:43.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:46:43.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:46:43.301+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:46:43.301+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:46:43.310+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:46:43.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:46:43.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T14:47:13.741+0000] {processor.py:157} INFO - Started process (PID=60427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:47:13.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:47:13.744+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:47:13.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:47:13.757+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:47:13.771+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:47:13.771+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:47:13.781+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:47:13.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:47:13.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T14:47:44.125+0000] {processor.py:157} INFO - Started process (PID=60452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:47:44.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:47:44.133+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:47:44.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:47:44.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:47:44.157+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:47:44.157+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:47:44.166+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:47:44.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:47:44.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T14:48:14.558+0000] {processor.py:157} INFO - Started process (PID=60477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:48:14.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:48:14.562+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:48:14.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:48:14.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:48:14.591+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:48:14.591+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:48:14.603+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:48:14.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:48:14.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T14:48:44.956+0000] {processor.py:157} INFO - Started process (PID=60502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:48:44.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:48:44.961+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:48:44.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:48:44.972+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:48:44.989+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:48:44.989+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:48:45.001+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:48:45.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:48:45.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T14:49:15.394+0000] {processor.py:157} INFO - Started process (PID=60527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:49:15.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:49:15.398+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:49:15.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:49:15.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:49:15.440+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:49:15.439+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:49:15.451+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:49:15.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:49:15.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T14:49:45.869+0000] {processor.py:157} INFO - Started process (PID=60552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:49:45.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:49:45.871+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:49:45.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:49:45.882+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:49:45.898+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:49:45.898+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:49:45.908+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:49:45.908+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:49:45.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T14:50:16.267+0000] {processor.py:157} INFO - Started process (PID=60577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:50:16.267+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:50:16.269+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:50:16.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:50:16.282+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:50:16.298+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:50:16.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:50:16.308+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:50:16.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:50:16.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T14:50:46.712+0000] {processor.py:157} INFO - Started process (PID=60602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:50:46.713+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:50:46.715+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:50:46.715+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:50:46.726+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:50:46.743+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:50:46.743+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:50:46.754+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:50:46.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:50:46.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T14:51:17.145+0000] {processor.py:157} INFO - Started process (PID=60627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:51:17.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:51:17.147+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:51:17.147+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:51:17.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:51:17.175+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:51:17.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:51:17.185+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:51:17.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:51:17.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T14:51:47.542+0000] {processor.py:157} INFO - Started process (PID=60652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:51:47.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:51:47.545+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:51:47.545+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:51:47.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:51:47.572+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:51:47.572+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:51:47.583+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:51:47.583+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:51:47.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T14:52:18.068+0000] {processor.py:157} INFO - Started process (PID=60677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:52:18.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:52:18.074+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:52:18.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:52:18.090+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:52:18.115+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:52:18.115+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:52:18.130+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:52:18.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:52:18.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-19T14:52:48.519+0000] {processor.py:157} INFO - Started process (PID=60702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:52:48.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:52:48.523+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:52:48.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:52:48.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:52:48.553+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:52:48.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:52:48.563+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:52:48.563+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:52:48.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T14:53:18.953+0000] {processor.py:157} INFO - Started process (PID=60727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:53:18.954+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:53:18.956+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:53:18.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:53:18.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:53:18.985+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:53:18.985+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:53:18.996+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:53:18.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:53:19.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T14:53:49.413+0000] {processor.py:157} INFO - Started process (PID=60752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:53:49.414+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:53:49.416+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:53:49.416+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:53:49.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:53:49.444+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:53:49.444+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:53:49.459+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:53:49.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:53:49.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T14:54:19.829+0000] {processor.py:157} INFO - Started process (PID=60777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:54:19.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:54:19.831+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:54:19.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:54:19.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:54:19.860+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:54:19.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:54:19.871+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:54:19.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:54:19.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T14:54:50.210+0000] {processor.py:157} INFO - Started process (PID=60802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:54:50.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:54:50.212+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:54:50.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:54:50.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:54:50.240+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:54:50.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:54:50.249+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:54:50.249+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:54:50.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T14:55:20.642+0000] {processor.py:157} INFO - Started process (PID=60827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:55:20.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:55:20.646+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:55:20.646+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:55:20.660+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:55:20.680+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:55:20.680+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:55:20.694+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:55:20.694+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:55:20.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T14:55:51.109+0000] {processor.py:157} INFO - Started process (PID=60852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:55:51.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:55:51.112+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:55:51.112+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:55:51.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:55:51.142+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:55:51.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:55:51.154+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:55:51.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:55:51.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T14:56:21.484+0000] {processor.py:157} INFO - Started process (PID=60877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:56:21.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:56:21.487+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:56:21.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:56:21.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:56:21.517+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:56:21.517+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:56:21.531+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:56:21.531+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:56:21.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T14:56:51.944+0000] {processor.py:157} INFO - Started process (PID=60902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:56:51.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:56:51.949+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:56:51.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:56:51.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:56:52.021+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:56:52.020+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:56:52.053+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:56:52.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:56:52.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.133 seconds
[2024-07-19T14:57:22.448+0000] {processor.py:157} INFO - Started process (PID=60927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:57:22.451+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:57:22.453+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:57:22.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:57:22.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:57:22.484+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:57:22.483+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:57:22.494+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:57:22.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:57:22.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T14:57:52.917+0000] {processor.py:157} INFO - Started process (PID=60952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:57:52.918+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:57:52.920+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:57:52.920+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:57:52.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:57:52.957+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:57:52.957+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:57:52.973+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:57:52.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:57:52.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T14:58:23.399+0000] {processor.py:157} INFO - Started process (PID=60977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:58:23.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:58:23.401+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:58:23.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:58:23.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:58:23.431+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:58:23.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:58:23.442+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:58:23.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:58:23.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T14:58:53.827+0000] {processor.py:157} INFO - Started process (PID=61002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:58:53.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:58:53.830+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:58:53.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:58:53.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:58:53.857+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:58:53.857+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:58:53.869+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:58:53.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:58:53.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T14:59:24.182+0000] {processor.py:157} INFO - Started process (PID=61027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:59:24.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:59:24.185+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:59:24.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:59:24.193+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:59:24.207+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:59:24.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:59:24.218+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:59:24.218+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:59:24.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-19T14:59:54.618+0000] {processor.py:157} INFO - Started process (PID=61052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:59:54.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T14:59:54.623+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:59:54.622+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:59:54.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T14:59:54.650+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:59:54.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T14:59:54.662+0000] {logging_mixin.py:151} INFO - [2024-07-19T14:59:54.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T14:59:54.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T15:00:25.093+0000] {processor.py:157} INFO - Started process (PID=61077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:00:25.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:00:25.097+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:00:25.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:00:25.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:00:25.135+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:00:25.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:00:25.149+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:00:25.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:00:25.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T15:00:55.556+0000] {processor.py:157} INFO - Started process (PID=61102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:00:55.557+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:00:55.559+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:00:55.559+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:00:55.575+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:00:55.589+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:00:55.589+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:00:55.601+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:00:55.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:00:55.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T15:01:25.939+0000] {processor.py:157} INFO - Started process (PID=61127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:01:25.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:01:25.942+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:01:25.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:01:25.958+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:01:25.973+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:01:25.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:01:25.983+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:01:25.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:01:25.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T15:01:56.403+0000] {processor.py:157} INFO - Started process (PID=61152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:01:56.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:01:56.407+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:01:56.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:01:56.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:01:56.438+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:01:56.438+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:01:56.450+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:01:56.450+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:01:56.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T15:02:26.826+0000] {processor.py:157} INFO - Started process (PID=61177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:02:26.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:02:26.828+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:02:26.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:02:26.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:02:26.852+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:02:26.851+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:02:26.861+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:02:26.861+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:02:26.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.045 seconds
[2024-07-19T15:02:57.217+0000] {processor.py:157} INFO - Started process (PID=61202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:02:57.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:02:57.224+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:02:57.224+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:02:57.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:02:57.261+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:02:57.261+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:02:57.275+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:02:57.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:02:57.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T15:03:27.682+0000] {processor.py:157} INFO - Started process (PID=61227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:03:27.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:03:27.686+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:03:27.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:03:27.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:03:27.714+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:03:27.714+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:03:27.726+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:03:27.726+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:03:27.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T15:03:58.211+0000] {processor.py:157} INFO - Started process (PID=61252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:03:58.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:03:58.218+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:03:58.217+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:03:58.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:03:58.295+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:03:58.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:03:58.315+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:03:58.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:03:58.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.125 seconds
[2024-07-19T15:04:28.668+0000] {processor.py:157} INFO - Started process (PID=61277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:04:28.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:04:28.672+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:04:28.672+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:04:28.685+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:04:28.704+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:04:28.704+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:04:28.716+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:04:28.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:04:28.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T15:04:59.157+0000] {processor.py:157} INFO - Started process (PID=61302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:04:59.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:04:59.162+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:04:59.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:04:59.177+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:04:59.199+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:04:59.199+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:04:59.212+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:04:59.212+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:04:59.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T15:05:29.612+0000] {processor.py:157} INFO - Started process (PID=61327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:05:29.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:05:29.616+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:05:29.616+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:05:29.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:05:29.645+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:05:29.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:05:29.658+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:05:29.658+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:05:29.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T15:06:00.027+0000] {processor.py:157} INFO - Started process (PID=61352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:06:00.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:06:00.031+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:06:00.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:06:00.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:06:00.060+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:06:00.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:06:00.070+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:06:00.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:06:00.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T15:06:30.443+0000] {processor.py:157} INFO - Started process (PID=61377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:06:30.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:06:30.447+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:06:30.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:06:30.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:06:30.475+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:06:30.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:06:30.486+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:06:30.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:06:30.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T15:07:00.896+0000] {processor.py:157} INFO - Started process (PID=61402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:07:00.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:07:00.903+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:07:00.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:07:00.923+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:07:00.950+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:07:00.950+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:07:00.968+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:07:00.968+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:07:00.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-19T15:07:31.509+0000] {processor.py:157} INFO - Started process (PID=61427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:07:31.512+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:07:31.527+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:07:31.526+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:07:31.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:07:31.577+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:07:31.576+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:07:31.591+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:07:31.591+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:07:31.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.104 seconds
[2024-07-19T15:08:01.998+0000] {processor.py:157} INFO - Started process (PID=61452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:08:02.000+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:08:02.001+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:08:02.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:08:02.017+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:08:02.031+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:08:02.031+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:08:02.045+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:08:02.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:08:02.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T15:08:32.483+0000] {processor.py:157} INFO - Started process (PID=61477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:08:32.483+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:08:32.485+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:08:32.484+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:08:32.493+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:08:32.508+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:08:32.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:08:32.519+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:08:32.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:08:32.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T15:09:02.895+0000] {processor.py:157} INFO - Started process (PID=61502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:09:02.896+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:09:02.898+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:09:02.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:09:02.908+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:09:02.925+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:09:02.925+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:09:02.935+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:09:02.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:09:02.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T15:09:33.378+0000] {processor.py:157} INFO - Started process (PID=61527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:09:33.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:09:33.383+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:09:33.383+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:09:33.398+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:09:33.420+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:09:33.419+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:09:33.435+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:09:33.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:09:33.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T15:10:03.876+0000] {processor.py:157} INFO - Started process (PID=61552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:10:03.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:10:03.879+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:10:03.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:10:03.895+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:10:03.910+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:10:03.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:10:03.922+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:10:03.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:10:03.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T15:10:34.298+0000] {processor.py:157} INFO - Started process (PID=61577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:10:34.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:10:34.300+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:10:34.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:10:34.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:10:34.324+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:10:34.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:10:34.334+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:10:34.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:10:34.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T15:11:04.766+0000] {processor.py:157} INFO - Started process (PID=61602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:11:04.768+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:11:04.769+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:11:04.769+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:11:04.784+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:11:04.798+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:11:04.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:11:04.808+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:11:04.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:11:04.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T15:11:35.170+0000] {processor.py:157} INFO - Started process (PID=61627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:11:35.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:11:35.173+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:11:35.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:11:35.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:11:35.201+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:11:35.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:11:35.211+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:11:35.211+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:11:35.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T15:12:05.633+0000] {processor.py:157} INFO - Started process (PID=61652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:12:05.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:12:05.636+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:12:05.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:12:05.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:12:05.672+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:12:05.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:12:05.686+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:12:05.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:12:05.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T15:12:36.097+0000] {processor.py:157} INFO - Started process (PID=61677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:12:36.098+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:12:36.099+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:12:36.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:12:36.114+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:12:36.126+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:12:36.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:12:36.135+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:12:36.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:12:36.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T15:13:06.493+0000] {processor.py:157} INFO - Started process (PID=61702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:13:06.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:13:06.497+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:13:06.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:13:06.506+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:13:06.523+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:13:06.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:13:06.535+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:13:06.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:13:06.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T15:13:36.961+0000] {processor.py:157} INFO - Started process (PID=61727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:13:36.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:13:36.965+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:13:36.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:13:36.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:13:37.001+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:13:37.001+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:13:37.015+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:13:37.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:13:37.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T15:14:07.391+0000] {processor.py:157} INFO - Started process (PID=61752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:14:07.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:14:07.394+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:14:07.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:14:07.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:14:07.425+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:14:07.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:14:07.435+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:14:07.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:14:07.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T15:14:37.846+0000] {processor.py:157} INFO - Started process (PID=61777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:14:37.849+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:14:37.851+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:14:37.851+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:14:37.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:14:37.880+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:14:37.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:14:37.891+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:14:37.891+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:14:37.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T15:15:08.324+0000] {processor.py:157} INFO - Started process (PID=61802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:15:08.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:15:08.328+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:15:08.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:15:08.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:15:08.367+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:15:08.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:15:08.380+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:15:08.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:15:08.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T15:15:38.830+0000] {processor.py:157} INFO - Started process (PID=61827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:15:38.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:15:38.832+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:15:38.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:15:38.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:15:38.860+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:15:38.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:15:38.870+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:15:38.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:15:38.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T15:16:09.347+0000] {processor.py:157} INFO - Started process (PID=61852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:16:09.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:16:09.349+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:16:09.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:16:09.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:16:09.380+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:16:09.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:16:09.395+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:16:09.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:16:09.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T15:16:39.791+0000] {processor.py:157} INFO - Started process (PID=61877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:16:39.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:16:39.796+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:16:39.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:16:39.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:16:39.825+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:16:39.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:16:39.836+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:16:39.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:16:39.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T15:17:10.211+0000] {processor.py:157} INFO - Started process (PID=61902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:17:10.212+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:17:10.215+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:17:10.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:17:10.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:17:10.255+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:17:10.255+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:17:10.271+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:17:10.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:17:10.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T15:17:40.723+0000] {processor.py:157} INFO - Started process (PID=61927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:17:40.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:17:40.727+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:17:40.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:17:40.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:17:40.751+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:17:40.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:17:40.762+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:17:40.762+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:17:40.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T15:18:11.152+0000] {processor.py:157} INFO - Started process (PID=61952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:18:11.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:18:11.155+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:18:11.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:18:11.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:18:11.183+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:18:11.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:18:11.192+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:18:11.192+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:18:11.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T15:18:41.619+0000] {processor.py:157} INFO - Started process (PID=61977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:18:41.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:18:41.624+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:18:41.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:18:41.636+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:18:41.654+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:18:41.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:18:41.665+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:18:41.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:18:41.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T15:19:12.109+0000] {processor.py:157} INFO - Started process (PID=62002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:19:12.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:19:12.114+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:19:12.113+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:19:12.130+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:19:12.153+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:19:12.153+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:19:12.166+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:19:12.166+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:19:12.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T15:19:42.590+0000] {processor.py:157} INFO - Started process (PID=62027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:19:42.591+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:19:42.593+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:19:42.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:19:42.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:19:42.621+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:19:42.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:19:42.632+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:19:42.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:19:42.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T15:20:13.098+0000] {processor.py:157} INFO - Started process (PID=62052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:20:13.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:20:13.106+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:20:13.105+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:20:13.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:20:13.131+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:20:13.131+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:20:13.141+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:20:13.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:20:13.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T15:20:43.501+0000] {processor.py:157} INFO - Started process (PID=62077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:20:43.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:20:43.505+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:20:43.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:20:43.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:20:43.535+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:20:43.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:20:43.548+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:20:43.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:20:43.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T15:21:13.995+0000] {processor.py:157} INFO - Started process (PID=62102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:21:13.996+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:21:13.997+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:21:13.997+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:21:14.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:21:14.024+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:21:14.024+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:21:14.034+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:21:14.034+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:21:14.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T15:21:44.444+0000] {processor.py:157} INFO - Started process (PID=62127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:21:44.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:21:44.448+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:21:44.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:21:44.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:21:44.476+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:21:44.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:21:44.490+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:21:44.490+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:21:44.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T15:22:14.929+0000] {processor.py:157} INFO - Started process (PID=62152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:22:14.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:22:14.933+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:22:14.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:22:14.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:22:14.969+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:22:14.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:22:14.982+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:22:14.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:22:14.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T15:22:45.408+0000] {processor.py:157} INFO - Started process (PID=62177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:22:45.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:22:45.411+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:22:45.411+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:22:45.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:22:45.435+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:22:45.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:22:45.446+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:22:45.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:22:45.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T15:23:15.810+0000] {processor.py:157} INFO - Started process (PID=62202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:23:15.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:23:15.813+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:23:15.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:23:15.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:23:15.844+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:23:15.844+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:23:15.858+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:23:15.858+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:23:15.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T15:23:46.256+0000] {processor.py:157} INFO - Started process (PID=62226) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:23:46.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:23:46.261+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:23:46.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:23:46.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:23:46.295+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:23:46.295+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:23:46.308+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:23:46.308+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:23:46.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T15:24:16.706+0000] {processor.py:157} INFO - Started process (PID=62252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:24:16.707+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:24:16.709+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:24:16.708+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:24:16.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:24:16.734+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:24:16.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:24:16.745+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:24:16.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:24:16.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T15:24:47.106+0000] {processor.py:157} INFO - Started process (PID=62277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:24:47.107+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:24:47.109+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:24:47.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:24:47.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:24:47.136+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:24:47.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:24:47.148+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:24:47.148+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:24:47.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T15:25:17.564+0000] {processor.py:157} INFO - Started process (PID=62302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:25:17.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:25:17.570+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:25:17.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:25:17.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:25:17.596+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:25:17.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:25:17.606+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:25:17.606+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:25:17.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T15:25:47.979+0000] {processor.py:157} INFO - Started process (PID=62327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:25:47.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:25:47.981+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:25:47.981+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:25:47.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:25:48.011+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:25:48.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:25:48.023+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:25:48.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:25:48.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T15:26:18.456+0000] {processor.py:157} INFO - Started process (PID=62352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:26:18.459+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:26:18.460+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:26:18.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:26:18.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:26:18.487+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:26:18.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:26:18.497+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:26:18.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:26:18.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T15:26:48.933+0000] {processor.py:157} INFO - Started process (PID=62377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:26:48.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:26:48.938+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:26:48.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:26:48.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:26:48.973+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:26:48.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:26:48.986+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:26:48.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:26:48.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T15:27:19.361+0000] {processor.py:157} INFO - Started process (PID=62402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:27:19.363+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:27:19.364+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:27:19.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:27:19.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:27:19.391+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:27:19.391+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:27:19.400+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:27:19.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:27:19.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T15:27:49.804+0000] {processor.py:157} INFO - Started process (PID=62427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:27:49.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:27:49.808+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:27:49.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:27:49.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:27:49.835+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:27:49.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:27:49.845+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:27:49.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:27:49.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T15:28:20.261+0000] {processor.py:157} INFO - Started process (PID=62452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:28:20.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:28:20.264+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:28:20.264+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:28:20.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:28:20.290+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:28:20.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:28:20.300+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:28:20.300+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:28:20.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T15:28:50.699+0000] {processor.py:157} INFO - Started process (PID=62477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:28:50.700+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:28:50.702+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:28:50.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:28:50.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:28:50.726+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:28:50.726+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:28:50.739+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:28:50.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:28:50.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T15:29:21.153+0000] {processor.py:157} INFO - Started process (PID=62502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:29:21.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:29:21.156+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:29:21.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:29:21.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:29:21.184+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:29:21.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:29:21.193+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:29:21.193+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:29:21.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T15:29:51.582+0000] {processor.py:157} INFO - Started process (PID=62527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:29:51.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:29:51.585+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:29:51.585+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:29:51.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:29:51.612+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:29:51.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:29:51.624+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:29:51.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:29:51.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T15:30:22.134+0000] {processor.py:157} INFO - Started process (PID=62552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:30:22.137+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:30:22.143+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:30:22.142+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:30:22.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:30:22.215+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:30:22.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:30:22.235+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:30:22.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:30:22.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.122 seconds
[2024-07-19T15:30:52.638+0000] {processor.py:157} INFO - Started process (PID=62577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:30:52.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:30:52.640+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:30:52.640+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:30:52.651+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:30:52.666+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:30:52.666+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:30:52.677+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:30:52.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:30:52.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T15:31:23.077+0000] {processor.py:157} INFO - Started process (PID=62602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:31:23.081+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:31:23.084+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:31:23.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:31:23.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:31:23.107+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:31:23.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:31:23.118+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:31:23.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:31:23.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T15:31:53.532+0000] {processor.py:157} INFO - Started process (PID=62627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:31:53.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:31:53.538+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:31:53.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:31:53.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:31:53.577+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:31:53.577+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:31:53.593+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:31:53.593+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:31:53.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-19T15:32:24.026+0000] {processor.py:157} INFO - Started process (PID=62652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:32:24.029+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:32:24.031+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:32:24.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:32:24.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:32:24.058+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:32:24.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:32:24.068+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:32:24.068+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:32:24.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T15:32:54.490+0000] {processor.py:157} INFO - Started process (PID=62677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:32:54.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:32:54.493+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:32:54.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:32:54.505+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:32:54.524+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:32:54.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:32:54.539+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:32:54.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:32:54.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T15:33:24.927+0000] {processor.py:157} INFO - Started process (PID=62702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:33:24.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:33:24.932+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:33:24.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:33:24.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:33:24.965+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:33:24.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:33:24.978+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:33:24.978+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:33:24.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T15:33:55.373+0000] {processor.py:157} INFO - Started process (PID=62727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:33:55.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:33:55.381+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:33:55.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:33:55.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:33:55.426+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:33:55.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:33:55.442+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:33:55.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:33:55.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-19T15:34:25.846+0000] {processor.py:157} INFO - Started process (PID=62752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:34:25.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:34:25.849+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:34:25.849+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:34:25.864+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:34:25.878+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:34:25.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:34:25.890+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:34:25.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:34:25.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T15:34:56.237+0000] {processor.py:157} INFO - Started process (PID=62777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:34:56.237+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:34:56.239+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:34:56.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:34:56.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:34:56.265+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:34:56.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:34:56.277+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:34:56.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:34:56.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T15:35:26.757+0000] {processor.py:157} INFO - Started process (PID=62802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:35:26.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:35:26.765+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:35:26.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:35:26.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:35:26.806+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:35:26.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:35:26.820+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:35:26.820+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:35:26.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-19T15:35:57.218+0000] {processor.py:157} INFO - Started process (PID=62827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:35:57.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:35:57.221+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:35:57.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:35:57.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:35:57.250+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:35:57.250+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:35:57.263+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:35:57.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:35:57.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T15:36:27.645+0000] {processor.py:157} INFO - Started process (PID=62852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:36:27.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:36:27.647+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:36:27.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:36:27.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:36:27.682+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:36:27.682+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:36:27.699+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:36:27.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:36:27.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T15:36:58.041+0000] {processor.py:157} INFO - Started process (PID=62877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:36:58.041+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:36:58.043+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:36:58.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:36:58.052+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:36:58.069+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:36:58.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:36:58.082+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:36:58.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:36:58.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T15:37:28.467+0000] {processor.py:157} INFO - Started process (PID=62902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:37:28.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:37:28.471+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:37:28.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:37:28.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:37:28.512+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:37:28.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:37:28.526+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:37:28.526+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:37:28.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-19T15:37:58.915+0000] {processor.py:157} INFO - Started process (PID=62927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:37:58.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:37:58.917+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:37:58.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:37:58.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:37:58.952+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:37:58.952+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:37:58.965+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:37:58.965+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:37:58.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T15:38:29.361+0000] {processor.py:157} INFO - Started process (PID=62952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:38:29.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:38:29.364+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:38:29.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:38:29.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:38:29.392+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:38:29.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:38:29.403+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:38:29.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:38:29.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T15:38:59.793+0000] {processor.py:157} INFO - Started process (PID=62977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:38:59.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:38:59.796+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:38:59.796+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:38:59.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:38:59.834+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:38:59.834+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:38:59.850+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:38:59.850+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:38:59.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-19T15:39:30.192+0000] {processor.py:157} INFO - Started process (PID=63002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:39:30.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:39:30.196+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:39:30.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:39:30.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:39:30.224+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:39:30.224+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:39:30.238+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:39:30.237+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:39:30.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T15:40:00.573+0000] {processor.py:157} INFO - Started process (PID=63027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:40:00.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:40:00.581+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:40:00.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:40:00.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:40:00.621+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:40:00.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:40:00.636+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:40:00.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:40:00.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-19T15:40:31.099+0000] {processor.py:157} INFO - Started process (PID=63052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:40:31.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:40:31.101+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:40:31.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:40:31.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:40:31.128+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:40:31.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:40:31.141+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:40:31.141+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:40:31.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T15:41:01.502+0000] {processor.py:157} INFO - Started process (PID=63077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:41:01.503+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:41:01.505+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:41:01.504+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:41:01.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:41:01.533+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:41:01.533+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:41:01.547+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:41:01.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:41:01.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T15:41:31.947+0000] {processor.py:157} INFO - Started process (PID=63102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:41:31.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:41:31.950+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:41:31.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:41:31.967+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:41:31.986+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:41:31.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:41:31.997+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:41:31.997+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:41:32.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T15:42:02.408+0000] {processor.py:157} INFO - Started process (PID=63127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:42:02.410+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:42:02.413+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:42:02.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:42:02.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:42:02.453+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:42:02.453+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:42:02.468+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:42:02.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:42:02.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-19T15:42:32.888+0000] {processor.py:157} INFO - Started process (PID=63152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:42:32.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:42:32.892+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:42:32.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:42:32.906+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:42:32.922+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:42:32.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:42:32.935+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:42:32.935+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:42:32.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T15:43:03.220+0000] {processor.py:157} INFO - Started process (PID=63177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:43:03.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:43:03.222+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:43:03.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:43:03.230+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:43:03.246+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:43:03.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:43:03.256+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:43:03.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:43:03.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T15:43:33.605+0000] {processor.py:157} INFO - Started process (PID=63202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:43:33.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:43:33.609+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:43:33.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:43:33.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:43:33.639+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:43:33.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:43:33.652+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:43:33.652+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:43:33.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T15:44:04.036+0000] {processor.py:157} INFO - Started process (PID=63227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:44:04.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:44:04.039+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:44:04.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:44:04.051+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:44:04.069+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:44:04.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:44:04.083+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:44:04.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:44:04.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T15:44:34.508+0000] {processor.py:157} INFO - Started process (PID=63252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:44:34.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:44:34.511+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:44:34.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:44:34.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:44:34.545+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:44:34.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:44:34.554+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:44:34.554+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:44:34.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T15:45:04.938+0000] {processor.py:157} INFO - Started process (PID=63277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:45:04.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:45:04.942+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:45:04.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:45:04.952+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:45:04.968+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:45:04.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:45:04.981+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:45:04.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:45:04.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T15:45:35.360+0000] {processor.py:157} INFO - Started process (PID=63302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:45:35.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:45:35.363+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:45:35.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:45:35.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:45:35.395+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:45:35.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:45:35.407+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:45:35.407+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:45:35.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T15:46:05.798+0000] {processor.py:157} INFO - Started process (PID=63327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:46:05.800+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:46:05.803+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:46:05.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:46:05.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:46:05.837+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:46:05.837+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:46:05.846+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:46:05.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:46:05.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T15:46:36.270+0000] {processor.py:157} INFO - Started process (PID=63352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:46:36.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:46:36.274+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:46:36.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:46:36.285+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:46:36.306+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:46:36.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:46:36.319+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:46:36.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:46:36.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T15:47:06.734+0000] {processor.py:157} INFO - Started process (PID=63377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:47:06.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:47:06.737+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:47:06.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:47:06.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:47:06.765+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:47:06.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:47:06.777+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:47:06.777+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:47:06.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T15:47:37.180+0000] {processor.py:157} INFO - Started process (PID=63402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:47:37.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:47:37.184+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:47:37.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:47:37.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:47:37.212+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:47:37.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:47:37.220+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:47:37.220+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:47:37.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T15:48:07.632+0000] {processor.py:157} INFO - Started process (PID=63427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:48:07.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:48:07.635+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:48:07.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:48:07.647+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:48:07.663+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:48:07.663+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:48:07.675+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:48:07.675+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:48:07.682+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T15:48:38.077+0000] {processor.py:157} INFO - Started process (PID=63452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:48:38.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:48:38.081+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:48:38.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:48:38.089+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:48:38.104+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:48:38.104+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:48:38.114+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:48:38.114+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:48:38.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T15:49:08.494+0000] {processor.py:157} INFO - Started process (PID=63477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:49:08.495+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:49:08.497+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:49:08.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:49:08.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:49:08.523+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:49:08.523+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:49:08.533+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:49:08.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:49:08.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T15:49:39.023+0000] {processor.py:157} INFO - Started process (PID=63502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:49:39.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:49:39.025+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:49:39.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:49:39.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:49:39.054+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:49:39.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:49:39.064+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:49:39.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:49:39.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T15:50:09.479+0000] {processor.py:157} INFO - Started process (PID=63527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:50:09.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:50:09.482+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:50:09.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:50:09.496+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:50:09.511+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:50:09.511+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:50:09.524+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:50:09.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:50:09.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T15:50:39.980+0000] {processor.py:157} INFO - Started process (PID=63552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:50:39.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:50:39.982+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:50:39.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:50:39.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:50:40.011+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:50:40.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:50:40.023+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:50:40.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:50:40.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T15:51:10.415+0000] {processor.py:157} INFO - Started process (PID=63577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:51:10.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:51:10.420+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:51:10.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:51:10.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:51:10.449+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:51:10.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:51:10.460+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:51:10.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:51:10.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T15:51:40.828+0000] {processor.py:157} INFO - Started process (PID=63602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:51:40.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:51:40.833+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:51:40.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:51:40.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:51:40.870+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:51:40.870+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:51:40.884+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:51:40.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:51:40.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T15:52:11.339+0000] {processor.py:157} INFO - Started process (PID=63627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:52:11.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:52:11.342+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:52:11.342+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:52:11.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:52:11.370+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:52:11.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:52:11.382+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:52:11.382+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:52:11.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T15:52:41.798+0000] {processor.py:157} INFO - Started process (PID=63652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:52:41.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:52:41.800+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:52:41.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:52:41.811+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:52:41.826+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:52:41.826+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:52:41.836+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:52:41.836+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:52:41.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T15:53:12.175+0000] {processor.py:157} INFO - Started process (PID=63677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:53:12.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:53:12.178+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:53:12.178+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:53:12.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:53:12.205+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:53:12.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:53:12.216+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:53:12.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:53:12.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T15:53:42.554+0000] {processor.py:157} INFO - Started process (PID=63702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:53:42.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:53:42.558+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:53:42.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:53:42.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:53:42.586+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:53:42.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:53:42.599+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:53:42.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:53:42.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T15:54:12.979+0000] {processor.py:157} INFO - Started process (PID=63727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:54:12.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:54:12.982+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:54:12.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:54:12.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:54:13.006+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:54:13.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:54:13.021+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:54:13.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:54:13.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T15:54:43.396+0000] {processor.py:157} INFO - Started process (PID=63752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:54:43.397+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:54:43.400+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:54:43.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:54:43.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:54:43.426+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:54:43.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:54:43.437+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:54:43.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:54:43.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T15:55:13.817+0000] {processor.py:157} INFO - Started process (PID=63777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:55:13.818+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:55:13.820+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:55:13.820+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:55:13.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:55:13.846+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:55:13.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:55:13.856+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:55:13.856+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:55:13.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T15:55:44.306+0000] {processor.py:157} INFO - Started process (PID=63802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:55:44.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:55:44.312+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:55:44.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:55:44.325+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:55:44.343+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:55:44.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:55:44.354+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:55:44.354+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:55:44.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T15:56:14.717+0000] {processor.py:157} INFO - Started process (PID=63827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:56:14.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:56:14.721+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:56:14.720+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:56:14.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:56:14.750+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:56:14.750+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:56:14.761+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:56:14.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:56:14.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T15:56:45.191+0000] {processor.py:157} INFO - Started process (PID=63852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:56:45.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:56:45.194+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:56:45.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:56:45.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:56:45.221+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:56:45.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:56:45.234+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:56:45.234+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:56:45.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T15:57:15.695+0000] {processor.py:157} INFO - Started process (PID=63877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:57:15.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:57:15.700+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:57:15.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:57:15.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:57:15.741+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:57:15.741+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:57:15.753+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:57:15.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:57:15.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T15:57:46.122+0000] {processor.py:157} INFO - Started process (PID=63902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:57:46.123+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:57:46.127+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:57:46.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:57:46.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:57:46.154+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:57:46.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:57:46.164+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:57:46.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:57:46.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T15:58:16.562+0000] {processor.py:157} INFO - Started process (PID=63927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:58:16.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:58:16.567+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:58:16.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:58:16.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:58:16.597+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:58:16.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:58:16.608+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:58:16.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:58:16.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T15:58:46.976+0000] {processor.py:157} INFO - Started process (PID=63952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:58:46.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:58:46.979+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:58:46.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:58:46.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:58:47.010+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:58:47.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:58:47.021+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:58:47.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:58:47.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T15:59:17.436+0000] {processor.py:157} INFO - Started process (PID=63977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:59:17.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:59:17.438+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:59:17.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:59:17.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:59:17.464+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:59:17.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:59:17.475+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:59:17.474+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:59:17.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T15:59:47.866+0000] {processor.py:157} INFO - Started process (PID=64001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:59:47.866+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T15:59:47.868+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:59:47.868+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:59:47.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T15:59:47.893+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:59:47.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T15:59:47.903+0000] {logging_mixin.py:151} INFO - [2024-07-19T15:59:47.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T15:59:47.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T16:00:18.226+0000] {processor.py:157} INFO - Started process (PID=64027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:00:18.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:00:18.230+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:00:18.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:00:18.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:00:18.264+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:00:18.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:00:18.273+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:00:18.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:00:18.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T16:00:48.645+0000] {processor.py:157} INFO - Started process (PID=64052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:00:48.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:00:48.649+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:00:48.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:00:48.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:00:48.677+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:00:48.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:00:48.687+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:00:48.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:00:48.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T16:01:19.018+0000] {processor.py:157} INFO - Started process (PID=64077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:01:19.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:01:19.022+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:01:19.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:01:19.031+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:01:19.049+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:01:19.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:01:19.059+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:01:19.059+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:01:19.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T16:01:49.443+0000] {processor.py:157} INFO - Started process (PID=64102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:01:49.444+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:01:49.446+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:01:49.446+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:01:49.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:01:49.473+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:01:49.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:01:49.484+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:01:49.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:01:49.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T16:02:19.888+0000] {processor.py:157} INFO - Started process (PID=64127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:02:19.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:02:19.892+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:02:19.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:02:19.910+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:02:19.930+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:02:19.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:02:19.943+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:02:19.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:02:19.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T16:02:50.403+0000] {processor.py:157} INFO - Started process (PID=64152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:02:50.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:02:50.405+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:02:50.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:02:50.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:02:50.430+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:02:50.430+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:02:50.440+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:02:50.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:02:50.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T16:03:20.866+0000] {processor.py:157} INFO - Started process (PID=64177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:03:20.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:03:20.869+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:03:20.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:03:20.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:03:20.897+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:03:20.897+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:03:20.907+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:03:20.907+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:03:20.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T16:03:51.332+0000] {processor.py:157} INFO - Started process (PID=64202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:03:51.334+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:03:51.339+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:03:51.339+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:03:51.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:03:51.372+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:03:51.372+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:03:51.384+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:03:51.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:03:51.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T16:04:21.823+0000] {processor.py:157} INFO - Started process (PID=64227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:04:21.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:04:21.830+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:04:21.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:04:21.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:04:21.890+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:04:21.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:04:21.903+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:04:21.903+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:04:21.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-19T16:04:52.351+0000] {processor.py:157} INFO - Started process (PID=64252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:04:52.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:04:52.353+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:04:52.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:04:52.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:04:52.384+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:04:52.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:04:52.395+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:04:52.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:04:52.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T16:05:22.748+0000] {processor.py:157} INFO - Started process (PID=64277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:05:22.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:05:22.752+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:05:22.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:05:22.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:05:22.782+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:05:22.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:05:22.792+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:05:22.792+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:05:22.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T16:05:53.256+0000] {processor.py:157} INFO - Started process (PID=64301) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:05:53.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:05:53.262+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:05:53.262+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:05:53.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:05:53.330+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:05:53.330+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:05:53.346+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:05:53.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:05:53.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-19T16:06:23.687+0000] {processor.py:157} INFO - Started process (PID=64327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:06:23.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:06:23.690+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:06:23.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:06:23.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:06:23.714+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:06:23.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:06:23.728+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:06:23.728+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:06:23.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T16:06:54.111+0000] {processor.py:157} INFO - Started process (PID=64352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:06:54.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:06:54.114+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:06:54.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:06:54.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:06:54.142+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:06:54.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:06:54.154+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:06:54.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:06:54.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T16:07:24.593+0000] {processor.py:157} INFO - Started process (PID=64377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:07:24.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:07:24.596+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:07:24.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:07:24.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:07:24.625+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:07:24.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:07:24.635+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:07:24.635+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:07:24.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T16:07:55.051+0000] {processor.py:157} INFO - Started process (PID=64402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:07:55.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:07:55.055+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:07:55.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:07:55.069+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:07:55.083+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:07:55.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:07:55.094+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:07:55.094+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:07:55.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T16:08:25.459+0000] {processor.py:157} INFO - Started process (PID=64427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:08:25.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:08:25.463+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:08:25.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:08:25.475+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:08:25.496+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:08:25.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:08:25.511+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:08:25.511+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:08:25.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T16:08:55.967+0000] {processor.py:157} INFO - Started process (PID=64452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:08:55.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:08:55.972+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:08:55.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:08:55.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:08:55.998+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:08:55.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:08:56.008+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:08:56.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:08:56.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T16:09:26.454+0000] {processor.py:157} INFO - Started process (PID=64477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:09:26.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:09:26.460+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:09:26.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:09:26.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:09:26.516+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:09:26.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:09:26.533+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:09:26.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:09:26.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-19T16:09:56.957+0000] {processor.py:157} INFO - Started process (PID=64502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:09:56.958+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:09:56.966+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:09:56.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:09:56.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:09:57.018+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:09:57.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:09:57.038+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:09:57.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:09:57.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-19T16:10:27.504+0000] {processor.py:157} INFO - Started process (PID=64526) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:10:27.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:10:27.512+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:10:27.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:10:27.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:10:27.566+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:10:27.566+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:10:27.584+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:10:27.584+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:10:27.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-19T16:10:58.075+0000] {processor.py:157} INFO - Started process (PID=64552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:10:58.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:10:58.083+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:10:58.082+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:10:58.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:10:58.139+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:10:58.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:10:58.161+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:10:58.161+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:10:58.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.110 seconds
[2024-07-19T16:11:28.584+0000] {processor.py:157} INFO - Started process (PID=64577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:11:28.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:11:28.592+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:11:28.591+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:11:28.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:11:28.631+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:11:28.631+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:11:28.645+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:11:28.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:11:28.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-19T16:11:59.062+0000] {processor.py:157} INFO - Started process (PID=64602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:11:59.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:11:59.066+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:11:59.066+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:11:59.077+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:11:59.103+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:11:59.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:11:59.122+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:11:59.122+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:11:59.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-19T16:12:29.636+0000] {processor.py:157} INFO - Started process (PID=64627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:12:29.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:12:29.642+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:12:29.642+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:12:29.656+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:12:29.679+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:12:29.679+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:12:29.693+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:12:29.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:12:29.702+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T16:13:00.041+0000] {processor.py:157} INFO - Started process (PID=64652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:13:00.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:13:00.045+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:13:00.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:13:00.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:13:00.075+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:13:00.075+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:13:00.086+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:13:00.086+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:13:00.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T16:13:30.455+0000] {processor.py:157} INFO - Started process (PID=64677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:13:30.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:13:30.460+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:13:30.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:13:30.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:13:30.491+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:13:30.491+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:13:30.502+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:13:30.501+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:13:30.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T16:14:00.918+0000] {processor.py:157} INFO - Started process (PID=64702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:14:00.920+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:14:00.922+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:14:00.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:14:00.937+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:14:00.960+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:14:00.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:14:00.975+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:14:00.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:14:00.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T16:14:31.386+0000] {processor.py:157} INFO - Started process (PID=64727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:14:31.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:14:31.389+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:14:31.389+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:14:31.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:14:31.418+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:14:31.418+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:14:31.431+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:14:31.431+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:14:31.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T16:15:01.883+0000] {processor.py:157} INFO - Started process (PID=64752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:15:01.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:15:01.886+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:15:01.886+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:15:01.901+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:15:01.916+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:15:01.916+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:15:01.926+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:15:01.926+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:15:01.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T16:15:32.313+0000] {processor.py:157} INFO - Started process (PID=64777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:15:32.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:15:32.316+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:15:32.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:15:32.330+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:15:32.348+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:15:32.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:15:32.358+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:15:32.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:15:32.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T16:16:02.780+0000] {processor.py:157} INFO - Started process (PID=64802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:16:02.783+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:16:02.784+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:16:02.784+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:16:02.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:16:02.806+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:16:02.806+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:16:02.815+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:16:02.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:16:02.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T16:16:33.252+0000] {processor.py:157} INFO - Started process (PID=64827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:16:33.253+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:16:33.255+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:16:33.255+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:16:33.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:16:33.282+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:16:33.282+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:16:33.294+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:16:33.294+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:16:33.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T16:17:03.709+0000] {processor.py:157} INFO - Started process (PID=64852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:17:03.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:17:03.712+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:17:03.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:17:03.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:17:03.739+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:17:03.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:17:03.749+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:17:03.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:17:03.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T16:17:34.198+0000] {processor.py:157} INFO - Started process (PID=64877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:17:34.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:17:34.201+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:17:34.201+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:17:34.210+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:17:34.226+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:17:34.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:17:34.235+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:17:34.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:17:34.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T16:18:04.604+0000] {processor.py:157} INFO - Started process (PID=64902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:18:04.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:18:04.610+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:18:04.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:18:04.620+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:18:04.637+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:18:04.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:18:04.647+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:18:04.647+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:18:04.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T16:18:35.066+0000] {processor.py:157} INFO - Started process (PID=64926) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:18:35.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:18:35.075+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:18:35.075+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:18:35.097+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:18:35.130+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:18:35.130+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:18:35.153+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:18:35.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:18:35.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-19T16:19:05.624+0000] {processor.py:157} INFO - Started process (PID=64952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:19:05.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:19:05.628+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:19:05.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:19:05.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:19:05.658+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:19:05.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:19:05.670+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:19:05.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:19:05.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T16:19:36.110+0000] {processor.py:157} INFO - Started process (PID=64977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:19:36.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:19:36.116+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:19:36.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:19:36.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:19:36.150+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:19:36.149+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:19:36.163+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:19:36.163+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:19:36.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T16:20:06.532+0000] {processor.py:157} INFO - Started process (PID=65002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:20:06.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:20:06.536+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:20:06.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:20:06.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:20:06.564+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:20:06.564+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:20:06.574+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:20:06.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:20:06.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T16:20:36.928+0000] {processor.py:157} INFO - Started process (PID=65027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:20:36.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:20:36.931+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:20:36.931+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:20:36.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:20:36.964+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:20:36.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:20:36.973+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:20:36.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:20:36.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T16:21:07.345+0000] {processor.py:157} INFO - Started process (PID=65052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:21:07.346+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:21:07.348+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:21:07.348+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:21:07.360+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:21:07.376+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:21:07.376+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:21:07.387+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:21:07.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:21:07.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T16:21:37.786+0000] {processor.py:157} INFO - Started process (PID=65077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:21:37.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:21:37.790+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:21:37.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:21:37.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:21:37.824+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:21:37.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:21:37.837+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:21:37.837+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:21:37.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T16:22:08.303+0000] {processor.py:157} INFO - Started process (PID=65102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:22:08.307+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:22:08.332+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:22:08.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:22:08.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:22:08.390+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:22:08.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:22:08.409+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:22:08.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:22:08.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.137 seconds
[2024-07-19T16:22:38.882+0000] {processor.py:157} INFO - Started process (PID=65127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:22:38.885+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:22:38.891+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:22:38.891+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:22:38.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:22:38.934+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:22:38.934+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:22:38.963+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:22:38.962+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:22:38.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-19T16:23:09.400+0000] {processor.py:157} INFO - Started process (PID=65152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:23:09.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:23:09.408+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:23:09.408+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:23:09.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:23:09.446+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:23:09.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:23:09.460+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:23:09.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:23:09.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-19T16:23:39.858+0000] {processor.py:157} INFO - Started process (PID=65177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:23:39.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:23:39.862+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:23:39.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:23:39.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:23:39.894+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:23:39.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:23:39.904+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:23:39.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:23:39.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T16:24:10.312+0000] {processor.py:157} INFO - Started process (PID=65202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:24:10.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:24:10.315+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:24:10.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:24:10.323+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:24:10.340+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:24:10.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:24:10.350+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:24:10.350+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:24:10.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T16:24:40.707+0000] {processor.py:157} INFO - Started process (PID=65227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:24:40.708+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:24:40.710+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:24:40.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:24:40.727+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:24:40.745+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:24:40.745+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:24:40.757+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:24:40.757+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:24:40.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T16:25:11.200+0000] {processor.py:157} INFO - Started process (PID=65252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:25:11.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:25:11.205+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:25:11.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:25:11.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:25:11.266+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:25:11.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:25:11.287+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:25:11.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:25:11.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-19T16:25:41.675+0000] {processor.py:157} INFO - Started process (PID=65277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:25:41.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:25:41.680+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:25:41.680+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:25:41.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:25:41.717+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:25:41.717+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:25:41.730+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:25:41.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:25:41.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T16:26:12.149+0000] {processor.py:157} INFO - Started process (PID=65302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:26:12.150+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:26:12.152+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:26:12.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:26:12.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:26:12.183+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:26:12.183+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:26:12.198+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:26:12.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:26:12.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T16:26:42.622+0000] {processor.py:157} INFO - Started process (PID=65327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:26:42.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:26:42.632+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:26:42.632+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:26:42.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:26:42.661+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:26:42.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:26:42.671+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:26:42.671+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:26:42.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T16:27:13.032+0000] {processor.py:157} INFO - Started process (PID=65352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:27:13.038+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:27:13.041+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:27:13.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:27:13.053+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:27:13.069+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:27:13.069+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:27:13.081+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:27:13.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:27:13.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T16:27:43.438+0000] {processor.py:157} INFO - Started process (PID=65377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:27:43.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:27:43.444+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:27:43.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:27:43.488+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:27:43.529+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:27:43.529+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:27:43.550+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:27:43.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:27:43.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-19T16:28:13.975+0000] {processor.py:157} INFO - Started process (PID=65402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:28:13.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:28:13.977+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:28:13.977+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:28:13.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:28:14.009+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:28:14.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:28:14.023+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:28:14.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:28:14.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T16:28:44.412+0000] {processor.py:157} INFO - Started process (PID=65427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:28:44.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:28:44.416+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:28:44.415+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:28:44.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:28:44.448+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:28:44.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:28:44.459+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:28:44.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:28:44.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T16:29:14.791+0000] {processor.py:157} INFO - Started process (PID=65452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:29:14.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:29:14.795+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:29:14.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:29:14.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:29:14.824+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:29:14.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:29:14.834+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:29:14.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:29:14.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T16:29:45.242+0000] {processor.py:157} INFO - Started process (PID=65477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:29:45.246+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:29:45.248+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:29:45.248+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:29:45.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:29:45.287+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:29:45.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:29:45.301+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:29:45.301+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:29:45.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-19T16:30:15.688+0000] {processor.py:157} INFO - Started process (PID=65502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:30:15.691+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:30:15.694+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:30:15.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:30:15.712+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:30:15.738+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:30:15.738+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:30:15.751+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:30:15.751+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:30:15.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-19T16:30:46.203+0000] {processor.py:157} INFO - Started process (PID=65527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:30:46.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:30:46.206+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:30:46.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:30:46.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:30:46.231+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:30:46.231+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:30:46.242+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:30:46.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:30:46.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T16:31:16.606+0000] {processor.py:157} INFO - Started process (PID=65552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:31:16.609+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:31:16.610+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:31:16.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:31:16.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:31:16.640+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:31:16.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:31:16.651+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:31:16.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:31:16.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T16:31:46.969+0000] {processor.py:157} INFO - Started process (PID=65577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:31:46.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:31:46.975+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:31:46.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:31:46.993+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:31:47.018+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:31:47.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:31:47.033+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:31:47.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:31:47.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-19T16:32:17.431+0000] {processor.py:157} INFO - Started process (PID=65602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:32:17.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:32:17.434+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:32:17.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:32:17.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:32:17.462+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:32:17.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:32:17.504+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:32:17.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:32:17.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-19T16:32:47.993+0000] {processor.py:157} INFO - Started process (PID=65627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:32:47.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:32:48.000+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:32:47.999+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:32:48.020+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:32:48.057+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:32:48.057+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:32:48.080+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:32:48.079+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:32:48.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.116 seconds
[2024-07-19T16:33:18.526+0000] {processor.py:157} INFO - Started process (PID=65652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:33:18.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:33:18.530+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:33:18.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:33:18.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:33:18.561+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:33:18.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:33:18.573+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:33:18.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:33:18.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T16:33:48.958+0000] {processor.py:157} INFO - Started process (PID=65677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:33:48.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:33:48.964+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:33:48.963+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:33:48.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:33:49.003+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:33:49.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:33:49.016+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:33:49.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:33:49.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T16:34:19.553+0000] {processor.py:157} INFO - Started process (PID=65702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:34:19.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:34:19.596+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:34:19.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:34:19.615+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:34:19.656+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:34:19.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:34:19.673+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:34:19.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:34:19.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.176 seconds
[2024-07-19T16:34:50.238+0000] {processor.py:157} INFO - Started process (PID=65727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:34:50.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:34:50.251+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:34:50.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:34:50.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:34:50.300+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:34:50.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:34:50.315+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:34:50.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:34:50.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-19T16:35:20.877+0000] {processor.py:157} INFO - Started process (PID=65752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:35:20.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:35:20.886+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:35:20.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:35:20.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:35:20.966+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:35:20.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:35:20.984+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:35:20.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:35:20.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.131 seconds
[2024-07-19T16:35:51.488+0000] {processor.py:157} INFO - Started process (PID=65777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:35:51.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:35:51.494+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:35:51.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:35:51.514+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:35:51.548+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:35:51.548+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:35:51.565+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:35:51.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:35:51.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-19T16:36:21.977+0000] {processor.py:157} INFO - Started process (PID=65802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:36:21.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:36:21.979+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:36:21.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:36:21.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:36:22.009+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:36:22.009+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:36:22.023+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:36:22.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:36:22.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T16:36:52.388+0000] {processor.py:157} INFO - Started process (PID=65827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:36:52.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:36:52.395+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:36:52.394+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:36:52.409+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:36:52.435+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:36:52.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:36:52.449+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:36:52.449+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:36:52.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-19T16:37:22.887+0000] {processor.py:157} INFO - Started process (PID=65852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:37:22.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:37:22.891+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:37:22.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:37:22.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:37:22.921+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:37:22.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:37:22.935+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:37:22.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:37:22.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T16:37:53.294+0000] {processor.py:157} INFO - Started process (PID=65877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:37:53.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:37:53.298+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:37:53.298+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:37:53.311+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:37:53.334+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:37:53.334+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:37:53.348+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:37:53.348+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:37:53.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-19T16:38:23.746+0000] {processor.py:157} INFO - Started process (PID=65902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:38:23.750+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:38:23.753+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:38:23.752+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:38:23.772+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:38:23.793+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:38:23.793+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:38:23.805+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:38:23.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:38:23.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T16:38:54.120+0000] {processor.py:157} INFO - Started process (PID=65927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:38:54.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:38:54.122+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:38:54.122+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:38:54.138+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:38:54.156+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:38:54.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:38:54.167+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:38:54.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:38:54.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T16:39:24.620+0000] {processor.py:157} INFO - Started process (PID=65951) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:39:24.622+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:39:24.626+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:39:24.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:39:24.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:39:24.661+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:39:24.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:39:24.674+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:39:24.674+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:39:24.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T16:39:55.140+0000] {processor.py:157} INFO - Started process (PID=65977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:39:55.142+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:39:55.143+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:39:55.143+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:39:55.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:39:55.177+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:39:55.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:39:55.189+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:39:55.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:39:55.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T16:40:25.678+0000] {processor.py:157} INFO - Started process (PID=66002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:40:25.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:40:25.686+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:40:25.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:40:25.706+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:40:25.739+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:40:25.739+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:40:25.753+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:40:25.753+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:40:25.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-19T16:40:56.174+0000] {processor.py:157} INFO - Started process (PID=66027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:40:56.175+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:40:56.178+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:40:56.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:40:56.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:40:56.207+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:40:56.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:40:56.217+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:40:56.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:40:56.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T16:41:26.618+0000] {processor.py:157} INFO - Started process (PID=66052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:41:26.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:41:26.625+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:41:26.624+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:41:26.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:41:26.683+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:41:26.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:41:26.695+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:41:26.695+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:41:26.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-19T16:41:57.129+0000] {processor.py:157} INFO - Started process (PID=66077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:41:57.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:41:57.133+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:41:57.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:41:57.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:41:57.159+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:41:57.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:41:57.170+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:41:57.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:41:57.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T16:42:27.619+0000] {processor.py:157} INFO - Started process (PID=66102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:42:27.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:42:27.624+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:42:27.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:42:27.641+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:42:27.664+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:42:27.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:42:27.678+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:42:27.678+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:42:27.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-19T16:42:58.107+0000] {processor.py:157} INFO - Started process (PID=66127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:42:58.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:42:58.114+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:42:58.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:42:58.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:42:58.159+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:42:58.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:42:58.175+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:42:58.175+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:42:58.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-19T16:43:28.574+0000] {processor.py:157} INFO - Started process (PID=66152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:43:28.576+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:43:28.577+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:43:28.577+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:43:28.589+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:43:28.605+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:43:28.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:43:28.615+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:43:28.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:43:28.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T16:43:59.072+0000] {processor.py:157} INFO - Started process (PID=66177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:43:59.075+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:43:59.078+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:43:59.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:43:59.094+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:43:59.128+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:43:59.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:43:59.147+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:43:59.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:43:59.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.098 seconds
[2024-07-19T16:44:29.522+0000] {processor.py:157} INFO - Started process (PID=66202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:44:29.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:44:29.530+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:44:29.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:44:29.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:44:29.561+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:44:29.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:44:29.572+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:44:29.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:44:29.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T16:45:00.008+0000] {processor.py:157} INFO - Started process (PID=66227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:45:00.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:45:00.013+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:45:00.013+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:45:00.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:45:00.044+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:45:00.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:45:00.056+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:45:00.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:45:00.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T16:45:30.460+0000] {processor.py:157} INFO - Started process (PID=66252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:45:30.461+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:45:30.463+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:45:30.463+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:45:30.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:45:30.493+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:45:30.493+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:45:30.503+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:45:30.503+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:45:30.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T16:46:00.942+0000] {processor.py:157} INFO - Started process (PID=66277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:46:00.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:46:00.945+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:46:00.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:46:00.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:46:00.973+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:46:00.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:46:00.983+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:46:00.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:46:00.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T16:46:31.376+0000] {processor.py:157} INFO - Started process (PID=66302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:46:31.377+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:46:31.379+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:46:31.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:46:31.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:46:31.407+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:46:31.407+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:46:31.418+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:46:31.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:46:31.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T16:47:01.790+0000] {processor.py:157} INFO - Started process (PID=66327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:47:01.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:47:01.795+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:47:01.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:47:01.813+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:47:01.832+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:47:01.832+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:47:01.845+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:47:01.845+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:47:01.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T16:47:32.189+0000] {processor.py:157} INFO - Started process (PID=66352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:47:32.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:47:32.198+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:47:32.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:47:32.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:47:32.221+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:47:32.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:47:32.231+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:47:32.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:47:32.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T16:48:02.610+0000] {processor.py:157} INFO - Started process (PID=66377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:48:02.612+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:48:02.613+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:48:02.613+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:48:02.633+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:48:02.653+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:48:02.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:48:02.665+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:48:02.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:48:02.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T16:48:33.108+0000] {processor.py:157} INFO - Started process (PID=66402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:48:33.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:48:33.111+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:48:33.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:48:33.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:48:33.144+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:48:33.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:48:33.156+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:48:33.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:48:33.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T16:49:03.496+0000] {processor.py:157} INFO - Started process (PID=66427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:49:03.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:49:03.499+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:49:03.499+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:49:03.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:49:03.526+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:49:03.526+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:49:03.537+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:49:03.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:49:03.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T16:49:33.941+0000] {processor.py:157} INFO - Started process (PID=66452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:49:33.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:49:33.945+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:49:33.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:49:33.959+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:49:33.974+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:49:33.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:49:33.987+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:49:33.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:49:33.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T16:50:04.416+0000] {processor.py:157} INFO - Started process (PID=66477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:50:04.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:50:04.419+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:50:04.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:50:04.431+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:50:04.449+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:50:04.448+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:50:04.460+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:50:04.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:50:04.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T16:50:34.902+0000] {processor.py:157} INFO - Started process (PID=66502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:50:34.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:50:34.905+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:50:34.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:50:34.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:50:34.933+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:50:34.933+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:50:34.944+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:50:34.944+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:50:34.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T16:51:05.344+0000] {processor.py:157} INFO - Started process (PID=66527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:51:05.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:51:05.349+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:51:05.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:51:05.365+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:51:05.390+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:51:05.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:51:05.403+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:51:05.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:51:05.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-19T16:51:35.787+0000] {processor.py:157} INFO - Started process (PID=66552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:51:35.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:51:35.790+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:51:35.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:51:35.804+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:51:35.820+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:51:35.820+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:51:35.833+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:51:35.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:51:35.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T16:52:06.180+0000] {processor.py:157} INFO - Started process (PID=66577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:52:06.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:52:06.185+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:52:06.185+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:52:06.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:52:06.212+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:52:06.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:52:06.222+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:52:06.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:52:06.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T16:52:36.529+0000] {processor.py:157} INFO - Started process (PID=66602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:52:36.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:52:36.533+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:52:36.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:52:36.541+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:52:36.556+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:52:36.556+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:52:36.565+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:52:36.565+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:52:36.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T16:53:06.980+0000] {processor.py:157} INFO - Started process (PID=66627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:53:06.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:53:06.985+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:53:06.985+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:53:06.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:53:07.022+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:53:07.022+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:53:07.032+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:53:07.032+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:53:07.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T16:53:37.432+0000] {processor.py:157} INFO - Started process (PID=66652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:53:37.434+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:53:37.436+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:53:37.436+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:53:37.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:53:37.465+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:53:37.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:53:37.478+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:53:37.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:53:37.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T16:54:07.882+0000] {processor.py:157} INFO - Started process (PID=66677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:54:07.884+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:54:07.885+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:54:07.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:54:07.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:54:07.915+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:54:07.915+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:54:07.929+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:54:07.928+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:54:07.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T16:54:38.358+0000] {processor.py:157} INFO - Started process (PID=66702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:54:38.359+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:54:38.361+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:54:38.361+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:54:38.373+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:54:38.392+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:54:38.392+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:54:38.402+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:54:38.402+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:54:38.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T16:55:08.724+0000] {processor.py:157} INFO - Started process (PID=66727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:55:08.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:55:08.726+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:55:08.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:55:08.742+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:55:08.758+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:55:08.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:55:08.769+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:55:08.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:55:08.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T16:55:39.118+0000] {processor.py:157} INFO - Started process (PID=66752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:55:39.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:55:39.124+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:55:39.124+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:55:39.141+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:55:39.162+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:55:39.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:55:39.172+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:55:39.172+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:55:39.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T16:56:09.550+0000] {processor.py:157} INFO - Started process (PID=66777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:56:09.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:56:09.555+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:56:09.555+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:56:09.568+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:56:09.586+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:56:09.586+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:56:09.599+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:56:09.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:56:09.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T16:56:39.938+0000] {processor.py:157} INFO - Started process (PID=66802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:56:39.939+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:56:39.941+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:56:39.941+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:56:39.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:56:39.970+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:56:39.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:56:39.985+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:56:39.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:56:39.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T16:57:10.405+0000] {processor.py:157} INFO - Started process (PID=66827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:57:10.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:57:10.410+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:57:10.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:57:10.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:57:10.445+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:57:10.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:57:10.459+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:57:10.459+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:57:10.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T16:57:40.833+0000] {processor.py:157} INFO - Started process (PID=66852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:57:40.834+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:57:40.836+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:57:40.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:57:40.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:57:40.861+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:57:40.861+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:57:40.871+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:57:40.871+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:57:40.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T16:58:11.279+0000] {processor.py:157} INFO - Started process (PID=66877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:58:11.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:58:11.283+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:58:11.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:58:11.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:58:11.318+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:58:11.318+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:58:11.332+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:58:11.332+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:58:11.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T16:58:41.775+0000] {processor.py:157} INFO - Started process (PID=66902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:58:41.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:58:41.777+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:58:41.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:58:41.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:58:41.811+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:58:41.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:58:41.821+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:58:41.821+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:58:41.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T16:59:12.211+0000] {processor.py:157} INFO - Started process (PID=66927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:59:12.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:59:12.215+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:59:12.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:59:12.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:59:12.246+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:59:12.246+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:59:12.259+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:59:12.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:59:12.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T16:59:42.676+0000] {processor.py:157} INFO - Started process (PID=66952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:59:42.677+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T16:59:42.679+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:59:42.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:59:42.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T16:59:42.706+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:59:42.705+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T16:59:42.717+0000] {logging_mixin.py:151} INFO - [2024-07-19T16:59:42.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T16:59:42.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T17:00:13.091+0000] {processor.py:157} INFO - Started process (PID=66977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:00:13.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:00:13.095+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:00:13.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:00:13.116+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:00:13.139+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:00:13.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:00:13.152+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:00:13.152+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:00:13.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-19T17:00:43.579+0000] {processor.py:157} INFO - Started process (PID=67002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:00:43.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:00:43.580+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:00:43.580+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:00:43.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:00:43.606+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:00:43.606+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:00:43.620+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:00:43.620+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:00:43.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T17:01:14.005+0000] {processor.py:157} INFO - Started process (PID=67027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:01:14.008+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:01:14.010+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:01:14.010+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:01:14.026+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:01:14.049+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:01:14.049+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:01:14.063+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:01:14.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:01:14.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T17:01:44.497+0000] {processor.py:157} INFO - Started process (PID=67052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:01:44.499+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:01:44.501+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:01:44.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:01:44.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:01:44.530+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:01:44.530+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:01:44.543+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:01:44.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:01:44.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T17:02:14.864+0000] {processor.py:157} INFO - Started process (PID=67077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:02:14.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:02:14.866+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:02:14.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:02:14.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:02:14.896+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:02:14.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:02:14.910+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:02:14.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:02:14.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T17:02:45.374+0000] {processor.py:157} INFO - Started process (PID=67101) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:02:45.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:02:45.378+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:02:45.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:02:45.395+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:02:45.421+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:02:45.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:02:45.432+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:02:45.432+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:02:45.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-19T17:03:15.801+0000] {processor.py:157} INFO - Started process (PID=67127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:03:15.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:03:15.803+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:03:15.803+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:03:15.816+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:03:15.829+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:03:15.829+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:03:15.839+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:03:15.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:03:15.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T17:03:46.203+0000] {processor.py:157} INFO - Started process (PID=67152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:03:46.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:03:46.205+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:03:46.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:03:46.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:03:46.232+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:03:46.232+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:03:46.242+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:03:46.242+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:03:46.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T17:04:16.740+0000] {processor.py:157} INFO - Started process (PID=67177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:04:16.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:04:16.745+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:04:16.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:04:16.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:04:16.790+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:04:16.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:04:16.803+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:04:16.803+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:04:16.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-19T17:04:47.113+0000] {processor.py:157} INFO - Started process (PID=67202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:04:47.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:04:47.117+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:04:47.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:04:47.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:04:47.144+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:04:47.144+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:04:47.155+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:04:47.155+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:04:47.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T17:05:17.562+0000] {processor.py:157} INFO - Started process (PID=67227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:05:17.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:05:17.568+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:05:17.568+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:05:17.588+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:05:17.613+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:05:17.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:05:17.628+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:05:17.628+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:05:17.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-19T17:05:47.980+0000] {processor.py:157} INFO - Started process (PID=67252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:05:47.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:05:47.982+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:05:47.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:05:47.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:05:48.011+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:05:48.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:05:48.025+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:05:48.025+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:05:48.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T17:06:18.375+0000] {processor.py:157} INFO - Started process (PID=67277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:06:18.381+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:06:18.384+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:06:18.384+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:06:18.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:06:18.411+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:06:18.411+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:06:18.422+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:06:18.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:06:18.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T17:06:48.791+0000] {processor.py:157} INFO - Started process (PID=67302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:06:48.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:06:48.793+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:06:48.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:06:48.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:06:48.823+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:06:48.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:06:48.833+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:06:48.833+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:06:48.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T17:07:19.217+0000] {processor.py:157} INFO - Started process (PID=67327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:07:19.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:07:19.220+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:07:19.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:07:19.232+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:07:19.265+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:07:19.265+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:07:19.281+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:07:19.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:07:19.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-19T17:07:49.744+0000] {processor.py:157} INFO - Started process (PID=67352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:07:49.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:07:49.749+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:07:49.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:07:49.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:07:49.792+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:07:49.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:07:49.809+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:07:49.809+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:07:49.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.083 seconds
[2024-07-19T17:08:20.202+0000] {processor.py:157} INFO - Started process (PID=67377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:08:20.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:08:20.206+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:08:20.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:08:20.223+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:08:20.240+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:08:20.240+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:08:20.255+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:08:20.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:08:20.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T17:08:50.585+0000] {processor.py:157} INFO - Started process (PID=67402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:08:50.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:08:50.589+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:08:50.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:08:50.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:08:50.621+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:08:50.621+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:08:50.635+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:08:50.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:08:50.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T17:09:21.080+0000] {processor.py:157} INFO - Started process (PID=67427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:09:21.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:09:21.085+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:09:21.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:09:21.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:09:21.121+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:09:21.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:09:21.134+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:09:21.134+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:09:21.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T17:09:51.543+0000] {processor.py:157} INFO - Started process (PID=67452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:09:51.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:09:51.548+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:09:51.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:09:51.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:09:51.583+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:09:51.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:09:51.603+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:09:51.603+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:09:51.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-19T17:10:22.002+0000] {processor.py:157} INFO - Started process (PID=67477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:10:22.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:10:22.004+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:10:22.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:10:22.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:10:22.035+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:10:22.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:10:22.050+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:10:22.050+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:10:22.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T17:10:52.485+0000] {processor.py:157} INFO - Started process (PID=67502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:10:52.486+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:10:52.487+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:10:52.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:10:52.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:10:52.520+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:10:52.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:10:52.530+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:10:52.530+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:10:52.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T17:11:22.918+0000] {processor.py:157} INFO - Started process (PID=67527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:11:22.919+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:11:22.922+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:11:22.922+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:11:22.933+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:11:22.955+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:11:22.954+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:11:22.967+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:11:22.967+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:11:22.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T17:11:53.397+0000] {processor.py:157} INFO - Started process (PID=67552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:11:53.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:11:53.407+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:11:53.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:11:53.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:11:53.455+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:11:53.455+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:11:53.477+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:11:53.477+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:11:53.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-19T17:12:23.843+0000] {processor.py:157} INFO - Started process (PID=67577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:12:23.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:12:23.848+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:12:23.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:12:23.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:12:23.886+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:12:23.886+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:12:23.899+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:12:23.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:12:23.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T17:12:54.234+0000] {processor.py:157} INFO - Started process (PID=67602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:12:54.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:12:54.238+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:12:54.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:12:54.250+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:12:54.267+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:12:54.267+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:12:54.277+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:12:54.277+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:12:54.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T17:13:24.694+0000] {processor.py:157} INFO - Started process (PID=67627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:13:24.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:13:24.700+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:13:24.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:13:24.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:13:24.728+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:13:24.728+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:13:24.740+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:13:24.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:13:24.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T17:13:55.109+0000] {processor.py:157} INFO - Started process (PID=67652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:13:55.111+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:13:55.114+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:13:55.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:13:55.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:13:55.151+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:13:55.151+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:13:55.164+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:13:55.164+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:13:55.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T17:14:25.504+0000] {processor.py:157} INFO - Started process (PID=67677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:14:25.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:14:25.507+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:14:25.507+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:14:25.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:14:25.543+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:14:25.542+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:14:25.556+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:14:25.556+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:14:25.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T17:14:55.939+0000] {processor.py:157} INFO - Started process (PID=67702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:14:55.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:14:55.942+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:14:55.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:14:55.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:14:55.972+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:14:55.972+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:14:55.984+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:14:55.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:14:55.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T17:15:26.339+0000] {processor.py:157} INFO - Started process (PID=67727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:15:26.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:15:26.343+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:15:26.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:15:26.359+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:15:26.375+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:15:26.375+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:15:26.393+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:15:26.393+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:15:26.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T17:15:56.824+0000] {processor.py:157} INFO - Started process (PID=67752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:15:56.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:15:56.834+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:15:56.833+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:15:56.843+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:15:56.858+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:15:56.858+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:15:56.869+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:15:56.869+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:15:56.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T17:16:27.220+0000] {processor.py:157} INFO - Started process (PID=67777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:16:27.221+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:16:27.225+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:16:27.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:16:27.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:16:27.260+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:16:27.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:16:27.274+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:16:27.273+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:16:27.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T17:16:57.750+0000] {processor.py:157} INFO - Started process (PID=67802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:16:57.753+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:16:57.756+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:16:57.756+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:16:57.778+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:16:57.801+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:16:57.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:16:57.815+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:16:57.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:16:57.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-19T17:17:28.180+0000] {processor.py:157} INFO - Started process (PID=67827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:17:28.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:17:28.183+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:17:28.183+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:17:28.198+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:17:28.212+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:17:28.212+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:17:28.221+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:17:28.221+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:17:28.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T17:17:58.649+0000] {processor.py:157} INFO - Started process (PID=67852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:17:58.651+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:17:58.652+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:17:58.652+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:17:58.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:17:58.678+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:17:58.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:17:58.689+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:17:58.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:17:58.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T17:18:29.133+0000] {processor.py:157} INFO - Started process (PID=67877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:18:29.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:18:29.139+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:18:29.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:18:29.159+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:18:29.198+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:18:29.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:18:29.232+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:18:29.232+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:18:29.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.126 seconds
[2024-07-19T17:18:59.697+0000] {processor.py:157} INFO - Started process (PID=67902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:18:59.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:18:59.700+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:18:59.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:18:59.711+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:18:59.735+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:18:59.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:18:59.746+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:18:59.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:18:59.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T17:19:30.169+0000] {processor.py:157} INFO - Started process (PID=67927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:19:30.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:19:30.173+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:19:30.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:19:30.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:19:30.203+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:19:30.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:19:30.216+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:19:30.216+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:19:30.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T17:20:00.715+0000] {processor.py:157} INFO - Started process (PID=67952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:20:00.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:20:00.717+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:20:00.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:20:00.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:20:00.746+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:20:00.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:20:00.756+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:20:00.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:20:00.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T17:20:31.138+0000] {processor.py:157} INFO - Started process (PID=67977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:20:31.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:20:31.141+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:20:31.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:20:31.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:20:31.170+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:20:31.170+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:20:31.180+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:20:31.180+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:20:31.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T17:21:01.541+0000] {processor.py:157} INFO - Started process (PID=68002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:21:01.542+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:21:01.544+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:21:01.544+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:21:01.560+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:21:01.573+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:21:01.573+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:21:01.585+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:21:01.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:21:01.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T17:21:32.009+0000] {processor.py:157} INFO - Started process (PID=68027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:21:32.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:21:32.014+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:21:32.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:21:32.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:21:32.039+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:21:32.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:21:32.049+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:21:32.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:21:32.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T17:22:02.430+0000] {processor.py:157} INFO - Started process (PID=68052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:22:02.437+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:22:02.438+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:22:02.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:22:02.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:22:02.462+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:22:02.462+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:22:02.472+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:22:02.472+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:22:02.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T17:22:32.874+0000] {processor.py:157} INFO - Started process (PID=68077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:22:32.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:22:32.878+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:22:32.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:22:32.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:22:32.908+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:22:32.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:22:32.918+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:22:32.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:22:32.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T17:23:03.350+0000] {processor.py:157} INFO - Started process (PID=68102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:23:03.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:23:03.381+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:23:03.381+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:23:03.394+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:23:03.412+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:23:03.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:23:03.422+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:23:03.422+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:23:03.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-19T17:23:33.859+0000] {processor.py:157} INFO - Started process (PID=68127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:23:33.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:23:33.866+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:23:33.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:23:33.890+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:23:33.921+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:23:33.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:23:33.937+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:23:33.937+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:23:33.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-19T17:24:04.349+0000] {processor.py:157} INFO - Started process (PID=68152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:24:04.350+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:24:04.352+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:24:04.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:24:04.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:24:04.384+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:24:04.384+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:24:04.395+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:24:04.395+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:24:04.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T17:24:34.738+0000] {processor.py:157} INFO - Started process (PID=68177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:24:34.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:24:34.744+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:24:34.744+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:24:34.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:24:34.789+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:24:34.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:24:34.806+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:24:34.806+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:24:34.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-19T17:25:05.270+0000] {processor.py:157} INFO - Started process (PID=68202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:25:05.273+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:25:05.275+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:25:05.275+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:25:05.288+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:25:05.304+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:25:05.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:25:05.315+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:25:05.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:25:05.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T17:25:35.670+0000] {processor.py:157} INFO - Started process (PID=68227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:25:35.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:25:35.675+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:25:35.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:25:35.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:25:35.723+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:25:35.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:25:35.741+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:25:35.741+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:25:35.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-19T17:26:06.239+0000] {processor.py:157} INFO - Started process (PID=68252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:26:06.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:26:06.251+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:26:06.250+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:26:06.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:26:06.297+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:26:06.297+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:26:06.310+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:26:06.310+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:26:06.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.090 seconds
[2024-07-19T17:26:36.653+0000] {processor.py:157} INFO - Started process (PID=68277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:26:36.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:26:36.657+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:26:36.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:26:36.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:26:36.685+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:26:36.685+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:26:36.696+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:26:36.696+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:26:36.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T17:27:07.181+0000] {processor.py:157} INFO - Started process (PID=68302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:27:07.183+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:27:07.188+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:27:07.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:27:07.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:27:07.251+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:27:07.251+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:27:07.276+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:27:07.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:27:07.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-19T17:27:37.712+0000] {processor.py:157} INFO - Started process (PID=68327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:27:37.715+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:27:37.717+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:27:37.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:27:37.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:27:37.751+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:27:37.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:27:37.770+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:27:37.769+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:27:37.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-19T17:28:08.305+0000] {processor.py:157} INFO - Started process (PID=68352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:28:08.310+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:28:08.315+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:28:08.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:28:08.336+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:28:08.377+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:28:08.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:28:08.413+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:28:08.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:28:08.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.130 seconds
[2024-07-19T17:28:38.856+0000] {processor.py:157} INFO - Started process (PID=68377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:28:38.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:28:38.865+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:28:38.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:28:38.891+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:28:38.968+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:28:38.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:28:38.990+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:28:38.990+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:28:39.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-19T17:29:09.365+0000] {processor.py:157} INFO - Started process (PID=68402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:29:09.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:29:09.370+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:29:09.370+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:29:09.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:29:09.402+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:29:09.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:29:09.412+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:29:09.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:29:09.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T17:29:39.790+0000] {processor.py:157} INFO - Started process (PID=68427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:29:39.794+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:29:39.798+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:29:39.797+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:29:39.836+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:29:39.878+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:29:39.878+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:29:39.896+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:29:39.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:29:39.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-19T17:30:10.298+0000] {processor.py:157} INFO - Started process (PID=68451) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:30:10.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:30:10.304+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:30:10.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:30:10.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:30:10.350+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:30:10.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:30:10.366+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:30:10.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:30:10.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-19T17:30:40.765+0000] {processor.py:157} INFO - Started process (PID=68477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:30:40.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:30:40.767+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:30:40.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:30:40.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:30:40.800+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:30:40.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:30:40.813+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:30:40.812+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:30:40.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T17:31:11.279+0000] {processor.py:157} INFO - Started process (PID=68502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:31:11.284+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:31:11.288+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:31:11.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:31:11.312+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:31:11.345+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:31:11.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:31:11.372+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:31:11.371+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:31:11.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.112 seconds
[2024-07-19T17:31:41.759+0000] {processor.py:157} INFO - Started process (PID=68527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:31:41.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:31:41.763+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:31:41.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:31:41.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:31:41.799+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:31:41.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:31:41.812+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:31:41.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:31:41.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T17:32:12.277+0000] {processor.py:157} INFO - Started process (PID=68552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:32:12.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:32:12.298+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:32:12.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:32:12.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:32:12.345+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:32:12.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:32:12.359+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:32:12.359+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:32:12.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-19T17:32:42.675+0000] {processor.py:157} INFO - Started process (PID=68577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:32:42.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:32:42.677+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:32:42.677+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:32:42.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:32:42.711+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:32:42.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:32:42.724+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:32:42.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:32:42.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T17:33:13.222+0000] {processor.py:157} INFO - Started process (PID=68602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:33:13.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:33:13.228+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:33:13.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:33:13.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:33:13.277+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:33:13.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:33:13.297+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:33:13.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:33:13.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.093 seconds
[2024-07-19T17:33:43.701+0000] {processor.py:157} INFO - Started process (PID=68627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:33:43.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:33:43.706+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:33:43.705+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:33:43.720+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:33:43.745+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:33:43.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:33:43.762+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:33:43.761+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:33:43.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-19T17:34:14.163+0000] {processor.py:157} INFO - Started process (PID=68652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:34:14.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:34:14.169+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:34:14.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:34:14.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:34:14.215+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:34:14.215+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:34:14.231+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:34:14.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:34:14.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-19T17:34:44.727+0000] {processor.py:157} INFO - Started process (PID=68677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:34:44.728+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:34:44.729+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:34:44.729+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:34:44.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:34:44.766+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:34:44.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:34:44.780+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:34:44.780+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:34:44.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T17:35:15.261+0000] {processor.py:157} INFO - Started process (PID=68701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:35:15.262+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:35:15.274+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:35:15.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:35:15.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:35:15.349+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:35:15.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:35:15.365+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:35:15.365+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:35:15.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.123 seconds
[2024-07-19T17:35:45.761+0000] {processor.py:157} INFO - Started process (PID=68727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:35:45.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:35:45.766+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:35:45.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:35:45.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:35:45.811+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:35:45.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:35:45.827+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:35:45.827+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:35:45.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.085 seconds
[2024-07-19T17:36:16.235+0000] {processor.py:157} INFO - Started process (PID=68752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:36:16.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:36:16.238+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:36:16.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:36:16.252+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:36:16.267+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:36:16.266+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:36:16.279+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:36:16.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:36:16.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T17:36:46.650+0000] {processor.py:157} INFO - Started process (PID=68777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:36:46.650+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:36:46.653+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:36:46.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:36:46.667+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:36:46.695+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:36:46.695+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:36:46.711+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:36:46.711+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:36:46.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-19T17:37:17.077+0000] {processor.py:157} INFO - Started process (PID=68802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:37:17.079+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:37:17.081+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:37:17.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:37:17.104+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:37:17.140+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:37:17.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:37:17.159+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:37:17.159+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:37:17.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-19T17:37:47.666+0000] {processor.py:157} INFO - Started process (PID=68827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:37:47.671+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:37:47.674+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:37:47.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:37:47.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:37:47.736+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:37:47.736+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:37:47.756+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:37:47.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:37:47.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.108 seconds
[2024-07-19T17:38:18.195+0000] {processor.py:157} INFO - Started process (PID=68851) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:38:18.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:38:18.202+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:38:18.202+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:38:18.225+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:38:18.257+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:38:18.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:38:18.275+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:38:18.275+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:38:18.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-19T17:38:48.694+0000] {processor.py:157} INFO - Started process (PID=68877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:38:48.695+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:38:48.697+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:38:48.697+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:38:48.715+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:38:48.734+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:38:48.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:38:48.750+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:38:48.750+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:38:48.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T17:39:19.192+0000] {processor.py:157} INFO - Started process (PID=68901) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:39:19.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:39:19.204+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:39:19.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:39:19.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:39:19.263+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:39:19.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:39:19.279+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:39:19.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:39:19.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-19T17:39:49.662+0000] {processor.py:157} INFO - Started process (PID=68927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:39:49.665+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:39:49.667+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:39:49.667+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:39:49.678+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:39:49.700+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:39:49.700+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:39:49.714+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:39:49.714+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:39:49.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T17:40:20.157+0000] {processor.py:157} INFO - Started process (PID=68952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:40:20.161+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:40:20.163+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:40:20.163+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:40:20.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:40:20.207+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:40:20.207+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:40:20.222+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:40:20.222+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:40:20.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-19T17:40:50.676+0000] {processor.py:157} INFO - Started process (PID=68977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:40:50.676+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:40:50.679+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:40:50.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:40:50.693+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:40:50.716+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:40:50.716+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:40:50.737+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:40:50.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:40:50.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-19T17:41:21.169+0000] {processor.py:157} INFO - Started process (PID=69002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:41:21.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:41:21.178+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:41:21.177+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:41:21.201+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:41:21.312+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:41:21.312+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:41:21.333+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:41:21.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:41:21.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.192 seconds
[2024-07-19T17:41:51.784+0000] {processor.py:157} INFO - Started process (PID=69027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:41:51.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:41:51.787+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:41:51.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:41:51.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:41:51.823+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:41:51.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:41:51.838+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:41:51.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:41:51.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T17:42:22.298+0000] {processor.py:157} INFO - Started process (PID=69052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:42:22.302+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:42:22.305+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:42:22.304+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:42:22.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:42:22.365+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:42:22.365+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:42:22.385+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:42:22.385+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:42:22.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.107 seconds
[2024-07-19T17:42:52.866+0000] {processor.py:157} INFO - Started process (PID=69077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:42:52.867+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:42:52.869+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:42:52.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:42:52.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:42:52.902+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:42:52.902+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:42:52.914+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:42:52.913+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:42:52.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T17:43:23.377+0000] {processor.py:157} INFO - Started process (PID=69102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:43:23.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:43:23.387+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:43:23.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:43:23.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:43:23.468+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:43:23.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:43:23.497+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:43:23.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:43:23.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.142 seconds
[2024-07-19T17:43:53.855+0000] {processor.py:157} INFO - Started process (PID=69127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:43:53.860+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:43:53.862+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:43:53.862+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:43:53.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:43:53.906+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:43:53.906+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:43:53.923+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:43:53.923+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:43:53.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-19T17:44:24.360+0000] {processor.py:157} INFO - Started process (PID=69152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:44:24.361+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:44:24.364+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:44:24.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:44:24.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:44:24.400+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:44:24.400+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:44:24.417+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:44:24.417+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:44:24.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T17:44:54.839+0000] {processor.py:157} INFO - Started process (PID=69177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:44:54.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:44:54.857+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:44:54.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:44:54.885+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:44:54.919+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:44:54.919+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:44:54.941+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:44:54.941+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:44:54.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.121 seconds
[2024-07-19T17:45:25.280+0000] {processor.py:157} INFO - Started process (PID=69202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:45:25.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:45:25.287+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:45:25.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:45:25.297+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:45:25.315+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:45:25.315+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:45:25.327+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:45:25.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:45:25.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T17:45:55.732+0000] {processor.py:157} INFO - Started process (PID=69227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:45:55.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:45:55.743+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:45:55.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:45:55.762+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:45:55.787+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:45:55.787+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:45:55.800+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:45:55.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:45:55.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-19T17:46:26.228+0000] {processor.py:157} INFO - Started process (PID=69252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:46:26.230+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:46:26.233+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:46:26.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:46:26.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:46:26.277+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:46:26.277+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:46:26.292+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:46:26.292+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:46:26.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-19T17:46:56.740+0000] {processor.py:157} INFO - Started process (PID=69277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:46:56.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:46:56.749+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:46:56.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:46:56.769+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:46:56.801+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:46:56.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:46:56.819+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:46:56.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:46:56.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-19T17:47:27.251+0000] {processor.py:157} INFO - Started process (PID=69302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:47:27.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:47:27.255+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:47:27.254+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:47:27.270+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:47:27.292+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:47:27.291+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:47:27.307+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:47:27.307+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:47:27.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T17:47:57.679+0000] {processor.py:157} INFO - Started process (PID=69327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:47:57.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:47:57.686+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:47:57.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:47:57.701+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:47:57.727+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:47:57.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:47:57.742+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:47:57.742+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:47:57.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-19T17:48:28.152+0000] {processor.py:157} INFO - Started process (PID=69352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:48:28.154+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:48:28.156+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:48:28.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:48:28.171+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:48:28.189+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:48:28.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:48:28.201+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:48:28.200+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:48:28.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T17:48:58.661+0000] {processor.py:157} INFO - Started process (PID=69377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:48:58.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:48:58.668+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:48:58.668+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:48:58.688+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:48:58.720+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:48:58.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:48:58.737+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:48:58.737+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:48:58.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.099 seconds
[2024-07-19T17:49:29.121+0000] {processor.py:157} INFO - Started process (PID=69402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:49:29.122+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:49:29.125+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:49:29.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:49:29.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:49:29.162+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:49:29.162+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:49:29.175+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:49:29.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:49:29.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T17:49:59.568+0000] {processor.py:157} INFO - Started process (PID=69427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:49:59.572+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:49:59.575+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:49:59.574+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:49:59.597+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:49:59.623+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:49:59.623+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:49:59.638+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:49:59.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:49:59.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-19T17:50:30.112+0000] {processor.py:157} INFO - Started process (PID=69452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:50:30.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:50:30.115+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:50:30.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:50:30.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:50:30.152+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:50:30.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:50:30.169+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:50:30.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:50:30.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.074 seconds
[2024-07-19T17:51:00.603+0000] {processor.py:157} INFO - Started process (PID=69477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:51:00.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:51:00.609+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:51:00.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:51:00.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:51:00.665+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:51:00.665+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:51:00.693+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:51:00.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:51:00.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-19T17:51:31.093+0000] {processor.py:157} INFO - Started process (PID=69502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:51:31.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:51:31.101+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:51:31.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:51:31.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:51:31.154+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:51:31.154+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:51:31.171+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:51:31.170+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:51:31.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.096 seconds
[2024-07-19T17:52:01.545+0000] {processor.py:157} INFO - Started process (PID=69527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:52:01.546+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:52:01.548+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:52:01.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:52:01.556+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:52:01.574+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:52:01.574+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:52:01.585+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:52:01.585+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:52:01.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T17:52:32.011+0000] {processor.py:157} INFO - Started process (PID=69552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:52:32.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:52:32.019+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:52:32.019+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:52:32.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:52:32.062+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:52:32.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:52:32.076+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:52:32.075+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:52:32.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-19T17:53:02.471+0000] {processor.py:157} INFO - Started process (PID=69577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:53:02.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:53:02.475+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:53:02.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:53:02.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:53:02.520+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:53:02.520+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:53:02.539+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:53:02.538+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:53:02.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-19T17:53:32.994+0000] {processor.py:157} INFO - Started process (PID=69602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:53:32.995+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:53:32.997+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:53:32.996+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:53:33.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:53:33.033+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:53:33.033+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:53:33.049+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:53:33.049+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:53:33.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T17:54:03.448+0000] {processor.py:157} INFO - Started process (PID=69627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:54:03.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:54:03.450+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:54:03.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:54:03.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:54:03.482+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:54:03.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:54:03.494+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:54:03.494+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:54:03.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T17:54:33.875+0000] {processor.py:157} INFO - Started process (PID=69652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:54:33.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:54:33.879+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:54:33.879+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:54:33.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:54:33.908+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:54:33.908+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:54:33.922+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:54:33.922+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:54:33.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T17:55:04.287+0000] {processor.py:157} INFO - Started process (PID=69677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:55:04.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:55:04.293+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:55:04.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:55:04.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:55:04.346+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:55:04.346+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:55:04.361+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:55:04.361+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:55:04.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.091 seconds
[2024-07-19T17:55:34.752+0000] {processor.py:157} INFO - Started process (PID=69702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:55:34.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:55:34.755+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:55:34.755+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:55:34.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:55:34.790+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:55:34.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:55:34.802+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:55:34.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:55:34.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T17:56:05.285+0000] {processor.py:157} INFO - Started process (PID=69727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:56:05.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:56:05.292+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:56:05.291+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:56:05.310+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:56:05.337+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:56:05.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:56:05.353+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:56:05.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:56:05.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-19T17:56:35.831+0000] {processor.py:157} INFO - Started process (PID=69752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:56:35.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:56:35.845+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:56:35.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:56:35.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:56:35.896+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:56:35.896+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:56:35.910+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:56:35.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:56:35.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-19T17:57:06.332+0000] {processor.py:157} INFO - Started process (PID=69777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:57:06.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:57:06.333+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:57:06.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:57:06.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:57:06.361+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:57:06.361+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:57:06.372+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:57:06.372+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:57:06.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T17:57:36.771+0000] {processor.py:157} INFO - Started process (PID=69802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:57:36.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:57:36.776+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:57:36.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:57:36.789+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:57:36.812+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:57:36.812+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:57:36.826+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:57:36.826+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:57:36.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T17:58:07.202+0000] {processor.py:157} INFO - Started process (PID=69827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:58:07.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:58:07.205+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:58:07.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:58:07.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:58:07.245+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:58:07.245+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:58:07.259+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:58:07.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:58:07.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T17:58:37.629+0000] {processor.py:157} INFO - Started process (PID=69852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:58:37.630+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:58:37.631+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:58:37.631+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:58:37.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:58:37.661+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:58:37.661+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:58:37.673+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:58:37.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:58:37.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T17:59:08.101+0000] {processor.py:157} INFO - Started process (PID=69877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:59:08.103+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:59:08.109+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:59:08.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:59:08.128+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:59:08.158+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:59:08.158+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:59:08.175+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:59:08.174+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:59:08.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.097 seconds
[2024-07-19T17:59:38.605+0000] {processor.py:157} INFO - Started process (PID=69902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:59:38.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T17:59:38.611+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:59:38.611+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:59:38.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T17:59:38.656+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:59:38.655+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T17:59:38.673+0000] {logging_mixin.py:151} INFO - [2024-07-19T17:59:38.673+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T17:59:38.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-19T18:00:09.076+0000] {processor.py:157} INFO - Started process (PID=69927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:00:09.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:00:09.079+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:00:09.079+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:00:09.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:00:09.107+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:00:09.107+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:00:09.118+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:00:09.118+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:00:09.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T18:00:39.562+0000] {processor.py:157} INFO - Started process (PID=69952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:00:39.563+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:00:39.565+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:00:39.565+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:00:39.576+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:00:39.593+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:00:39.593+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:00:39.607+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:00:39.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:00:39.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T18:01:09.927+0000] {processor.py:157} INFO - Started process (PID=69977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:01:09.929+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:01:09.932+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:01:09.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:01:09.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:01:09.965+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:01:09.965+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:01:09.977+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:01:09.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:01:09.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T18:01:40.402+0000] {processor.py:157} INFO - Started process (PID=70001) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:01:40.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:01:40.412+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:01:40.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:01:40.430+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:01:40.463+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:01:40.463+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:01:40.492+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:01:40.492+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:01:40.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.120 seconds
[2024-07-19T18:02:10.919+0000] {processor.py:157} INFO - Started process (PID=70027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:02:10.922+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:02:10.924+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:02:10.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:02:10.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:02:10.967+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:02:10.967+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:02:10.981+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:02:10.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:02:10.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-19T18:02:41.314+0000] {processor.py:157} INFO - Started process (PID=70052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:02:41.317+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:02:41.319+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:02:41.319+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:02:41.329+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:02:41.350+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:02:41.350+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:02:41.363+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:02:41.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:02:41.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T18:03:11.796+0000] {processor.py:157} INFO - Started process (PID=70077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:03:11.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:03:11.802+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:03:11.802+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:03:11.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:03:11.846+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:03:11.846+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:03:11.860+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:03:11.860+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:03:11.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-19T18:03:42.281+0000] {processor.py:157} INFO - Started process (PID=70102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:03:42.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:03:42.283+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:03:42.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:03:42.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:03:42.313+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:03:42.313+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:03:42.324+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:03:42.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:03:42.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T18:04:12.696+0000] {processor.py:157} INFO - Started process (PID=70127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:04:12.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:04:12.699+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:04:12.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:04:12.710+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:04:12.727+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:04:12.727+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:04:12.741+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:04:12.740+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:04:12.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T18:04:43.154+0000] {processor.py:157} INFO - Started process (PID=70152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:04:43.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:04:43.157+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:04:43.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:04:43.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:04:43.190+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:04:43.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:04:43.203+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:04:43.203+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:04:43.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T18:05:13.605+0000] {processor.py:157} INFO - Started process (PID=70177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:05:13.606+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:05:13.607+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:05:13.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:05:13.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:05:13.642+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:05:13.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:05:13.657+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:05:13.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:05:13.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T18:05:44.042+0000] {processor.py:157} INFO - Started process (PID=70202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:05:44.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:05:44.045+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:05:44.045+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:05:44.057+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:05:44.073+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:05:44.073+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:05:44.085+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:05:44.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:05:44.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T18:06:14.439+0000] {processor.py:157} INFO - Started process (PID=70227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:06:14.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:06:14.445+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:06:14.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:06:14.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:06:14.494+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:06:14.494+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:06:14.519+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:06:14.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:06:14.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.094 seconds
[2024-07-19T18:06:44.937+0000] {processor.py:157} INFO - Started process (PID=70252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:06:44.940+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:06:44.943+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:06:44.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:06:44.961+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:06:44.991+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:06:44.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:06:45.007+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:06:45.007+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:06:45.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-19T18:07:15.472+0000] {processor.py:157} INFO - Started process (PID=70277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:07:15.474+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:07:15.490+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:07:15.487+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:07:15.532+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:07:15.583+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:07:15.583+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:07:15.602+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:07:15.601+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:07:15.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.156 seconds
[2024-07-19T18:07:45.978+0000] {processor.py:157} INFO - Started process (PID=70302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:07:45.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:07:45.989+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:07:45.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:07:46.015+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:07:46.039+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:07:46.039+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:07:46.059+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:07:46.058+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:07:46.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-19T18:08:16.508+0000] {processor.py:157} INFO - Started process (PID=70327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:08:16.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:08:16.510+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:08:16.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:08:16.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:08:16.545+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:08:16.545+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:08:16.557+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:08:16.557+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:08:16.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T18:08:47.014+0000] {processor.py:157} INFO - Started process (PID=70352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:08:47.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:08:47.022+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:08:47.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:08:47.061+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:08:47.128+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:08:47.128+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:08:47.145+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:08:47.144+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:08:47.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.149 seconds
[2024-07-19T18:09:17.558+0000] {processor.py:157} INFO - Started process (PID=70377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:09:17.564+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:09:17.567+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:09:17.567+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:09:17.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:09:17.628+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:09:17.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:09:17.661+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:09:17.661+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:09:17.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.124 seconds
[2024-07-19T18:09:48.086+0000] {processor.py:157} INFO - Started process (PID=70402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:09:48.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:09:48.092+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:09:48.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:09:48.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:09:48.142+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:09:48.141+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:09:48.161+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:09:48.160+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:09:48.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-19T18:10:18.610+0000] {processor.py:157} INFO - Started process (PID=70427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:10:18.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:10:18.617+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:10:18.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:10:18.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:10:18.658+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:10:18.658+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:10:18.672+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:10:18.672+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:10:18.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-19T18:10:49.077+0000] {processor.py:157} INFO - Started process (PID=70452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:10:49.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:10:49.080+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:10:49.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:10:49.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:10:49.109+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:10:49.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:10:49.121+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:10:49.121+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:10:49.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T18:11:19.471+0000] {processor.py:157} INFO - Started process (PID=70477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:11:19.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:11:19.475+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:11:19.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:11:19.490+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:11:19.504+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:11:19.504+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:11:19.515+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:11:19.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:11:19.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T18:11:49.935+0000] {processor.py:157} INFO - Started process (PID=70502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:11:49.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:11:49.938+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:11:49.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:11:49.948+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:11:49.964+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:11:49.964+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:11:49.974+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:11:49.974+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:11:49.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T18:12:20.325+0000] {processor.py:157} INFO - Started process (PID=70527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:12:20.326+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:12:20.328+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:12:20.328+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:12:20.344+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:12:20.358+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:12:20.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:12:20.367+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:12:20.367+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:12:20.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T18:12:50.791+0000] {processor.py:157} INFO - Started process (PID=70552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:12:50.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:12:50.794+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:12:50.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:12:50.808+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:12:50.822+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:12:50.822+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:12:50.834+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:12:50.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:12:50.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T18:13:21.241+0000] {processor.py:157} INFO - Started process (PID=70577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:13:21.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:13:21.243+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:13:21.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:13:21.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:13:21.271+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:13:21.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:13:21.282+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:13:21.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:13:21.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T18:13:51.668+0000] {processor.py:157} INFO - Started process (PID=70602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:13:51.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:13:51.675+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:13:51.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:13:51.689+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:13:51.710+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:13:51.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:13:51.724+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:13:51.724+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:13:51.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T18:14:22.143+0000] {processor.py:157} INFO - Started process (PID=70627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:14:22.146+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:14:22.148+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:14:22.148+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:14:22.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:14:22.177+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:14:22.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:14:22.190+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:14:22.189+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:14:22.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T18:14:52.567+0000] {processor.py:157} INFO - Started process (PID=70652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:14:52.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:14:52.571+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:14:52.571+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:14:52.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:14:52.601+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:14:52.600+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:14:52.613+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:14:52.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:14:52.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T18:15:22.989+0000] {processor.py:157} INFO - Started process (PID=70677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:15:22.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:15:22.991+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:15:22.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:15:23.013+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:15:23.044+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:15:23.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:15:23.058+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:15:23.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:15:23.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-19T18:15:53.467+0000] {processor.py:157} INFO - Started process (PID=70701) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:15:53.469+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:15:53.473+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:15:53.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:15:53.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:15:53.521+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:15:53.521+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:15:53.537+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:15:53.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:15:53.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-19T18:16:23.960+0000] {processor.py:157} INFO - Started process (PID=70726) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:16:23.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:16:23.968+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:16:23.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:16:23.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:16:24.026+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:16:24.025+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:16:24.042+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:16:24.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:16:24.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.100 seconds
[2024-07-19T18:16:54.559+0000] {processor.py:157} INFO - Started process (PID=70752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:16:54.566+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:16:54.587+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:16:54.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:16:54.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:16:54.642+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:16:54.642+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:16:54.665+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:16:54.665+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:16:54.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.132 seconds
[2024-07-19T18:17:25.103+0000] {processor.py:157} INFO - Started process (PID=70777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:17:25.104+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:17:25.106+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:17:25.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:17:25.117+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:17:25.136+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:17:25.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:17:25.146+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:17:25.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:17:25.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T18:17:55.487+0000] {processor.py:157} INFO - Started process (PID=70802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:17:55.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:17:55.494+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:17:55.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:17:55.515+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:17:55.543+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:17:55.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:17:55.559+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:17:55.559+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:17:55.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.088 seconds
[2024-07-19T18:18:26.002+0000] {processor.py:157} INFO - Started process (PID=70827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:18:26.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:18:26.004+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:18:26.004+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:18:26.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:18:26.030+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:18:26.030+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:18:26.042+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:18:26.042+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:18:26.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T18:18:56.466+0000] {processor.py:157} INFO - Started process (PID=70852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:18:56.468+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:18:56.475+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:18:56.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:18:56.497+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:18:56.531+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:18:56.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:18:56.551+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:18:56.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:18:56.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.109 seconds
[2024-07-19T18:19:27.008+0000] {processor.py:157} INFO - Started process (PID=70877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:19:27.009+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:19:27.012+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:19:27.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:19:27.032+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:19:27.063+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:19:27.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:19:27.080+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:19:27.080+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:19:27.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-19T18:19:57.548+0000] {processor.py:157} INFO - Started process (PID=70902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:19:57.550+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:19:57.564+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:19:57.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:19:57.601+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:19:57.639+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:19:57.638+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:19:57.671+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:19:57.670+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:19:57.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.140 seconds
[2024-07-19T18:20:28.088+0000] {processor.py:157} INFO - Started process (PID=70927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:20:28.093+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:20:28.096+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:20:28.096+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:20:28.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:20:28.119+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:20:28.119+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:20:28.129+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:20:28.129+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:20:28.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T18:20:58.527+0000] {processor.py:157} INFO - Started process (PID=70952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:20:58.528+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:20:58.530+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:20:58.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:20:58.547+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:20:58.562+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:20:58.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:20:58.574+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:20:58.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:20:58.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T18:21:28.944+0000] {processor.py:157} INFO - Started process (PID=70977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:21:28.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:21:28.949+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:21:28.949+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:21:28.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:21:28.987+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:21:28.987+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:21:28.998+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:21:28.998+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:21:29.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T18:21:59.436+0000] {processor.py:157} INFO - Started process (PID=71002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:21:59.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:21:59.441+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:21:59.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:21:59.456+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:21:59.482+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:21:59.482+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:21:59.499+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:21:59.499+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:21:59.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-19T18:22:29.895+0000] {processor.py:157} INFO - Started process (PID=71027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:22:29.900+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:22:29.902+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:22:29.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:22:29.914+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:22:29.930+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:22:29.930+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:22:29.943+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:22:29.943+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:22:29.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T18:23:00.368+0000] {processor.py:157} INFO - Started process (PID=71052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:23:00.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:23:00.372+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:23:00.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:23:00.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:23:00.408+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:23:00.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:23:00.418+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:23:00.418+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:23:00.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T18:23:30.764+0000] {processor.py:157} INFO - Started process (PID=71077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:23:30.764+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:23:30.766+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:23:30.765+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:23:30.779+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:23:30.793+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:23:30.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:23:30.802+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:23:30.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:23:30.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T18:24:01.204+0000] {processor.py:157} INFO - Started process (PID=71102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:24:01.205+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:24:01.207+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:24:01.206+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:24:01.220+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:24:01.237+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:24:01.237+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:24:01.247+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:24:01.247+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:24:01.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T18:24:31.650+0000] {processor.py:157} INFO - Started process (PID=71127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:24:31.654+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:24:31.657+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:24:31.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:24:31.676+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:24:31.720+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:24:31.720+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:24:31.738+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:24:31.738+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:24:31.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.103 seconds
[2024-07-19T18:25:02.086+0000] {processor.py:157} INFO - Started process (PID=71151) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:25:02.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:25:02.092+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:25:02.092+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:25:02.110+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:25:02.140+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:25:02.140+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:25:02.156+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:25:02.156+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:25:02.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-19T18:25:32.587+0000] {processor.py:157} INFO - Started process (PID=71177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:25:32.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:25:32.596+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:25:32.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:25:32.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:25:32.620+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:25:32.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:25:32.629+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:25:32.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:25:32.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T18:26:03.072+0000] {processor.py:157} INFO - Started process (PID=71202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:26:03.078+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:26:03.081+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:26:03.081+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:26:03.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:26:03.127+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:26:03.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:26:03.143+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:26:03.143+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:26:03.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-19T18:26:33.483+0000] {processor.py:157} INFO - Started process (PID=71227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:26:33.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:26:33.488+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:26:33.488+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:26:33.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:26:33.523+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:26:33.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:26:33.539+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:26:33.539+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:26:33.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T18:27:03.880+0000] {processor.py:157} INFO - Started process (PID=71252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:27:03.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:27:03.882+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:27:03.882+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:27:03.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:27:03.921+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:27:03.921+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:27:03.933+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:27:03.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:27:03.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T18:27:34.264+0000] {processor.py:157} INFO - Started process (PID=71277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:27:34.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:27:34.267+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:27:34.267+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:27:34.281+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:27:34.298+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:27:34.298+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:27:34.313+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:27:34.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:27:34.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T18:28:04.643+0000] {processor.py:157} INFO - Started process (PID=71302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:28:04.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:28:04.650+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:28:04.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:28:04.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:28:04.687+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:28:04.686+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:28:04.698+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:28:04.698+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:28:04.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T18:28:35.148+0000] {processor.py:157} INFO - Started process (PID=71327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:28:35.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:28:35.151+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:28:35.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:28:35.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:28:35.184+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:28:35.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:28:35.199+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:28:35.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:28:35.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T18:29:05.601+0000] {processor.py:157} INFO - Started process (PID=71352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:29:05.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:29:05.606+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:29:05.606+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:29:05.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:29:05.637+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:29:05.637+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:29:05.646+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:29:05.646+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:29:05.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T18:29:36.018+0000] {processor.py:157} INFO - Started process (PID=71377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:29:36.019+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:29:36.022+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:29:36.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:29:36.034+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:29:36.053+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:29:36.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:29:36.064+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:29:36.064+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:29:36.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T18:30:06.470+0000] {processor.py:157} INFO - Started process (PID=71402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:30:06.471+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:30:06.472+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:30:06.472+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:30:06.486+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:30:06.502+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:30:06.502+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:30:06.512+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:30:06.512+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:30:06.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T18:30:36.973+0000] {processor.py:157} INFO - Started process (PID=71427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:30:36.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:30:36.980+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:30:36.979+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:30:36.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:30:37.016+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:30:37.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:30:37.029+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:30:37.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:30:37.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T18:31:07.425+0000] {processor.py:157} INFO - Started process (PID=71452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:31:07.426+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:31:07.428+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:31:07.428+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:31:07.440+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:31:07.459+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:31:07.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:31:07.470+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:31:07.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:31:07.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T18:31:37.792+0000] {processor.py:157} INFO - Started process (PID=71477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:31:37.793+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:31:37.795+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:31:37.795+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:31:37.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:31:37.823+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:31:37.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:31:37.834+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:31:37.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:31:37.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T18:32:08.255+0000] {processor.py:157} INFO - Started process (PID=71502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:32:08.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:32:08.259+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:32:08.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:32:08.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:32:08.288+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:32:08.288+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:32:08.299+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:32:08.298+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:32:08.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T18:32:38.706+0000] {processor.py:157} INFO - Started process (PID=71527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:32:38.709+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:32:38.713+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:32:38.713+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:32:38.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:32:38.758+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:32:38.758+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:32:38.774+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:32:38.774+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:32:38.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.082 seconds
[2024-07-19T18:33:09.193+0000] {processor.py:157} INFO - Started process (PID=71552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:33:09.195+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:33:09.197+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:33:09.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:33:09.213+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:33:09.227+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:33:09.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:33:09.237+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:33:09.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:33:09.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T18:33:39.678+0000] {processor.py:157} INFO - Started process (PID=71577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:33:39.685+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:33:39.687+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:33:39.686+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:33:39.698+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:33:39.713+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:33:39.713+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:33:39.723+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:33:39.723+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:33:39.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T18:34:10.035+0000] {processor.py:157} INFO - Started process (PID=71602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:34:10.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:34:10.037+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:34:10.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:34:10.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:34:10.061+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:34:10.061+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:34:10.072+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:34:10.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:34:10.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T18:34:40.447+0000] {processor.py:157} INFO - Started process (PID=71627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:34:40.448+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:34:40.450+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:34:40.450+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:34:40.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:34:40.477+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:34:40.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:34:40.489+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:34:40.489+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:34:40.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T18:35:10.930+0000] {processor.py:157} INFO - Started process (PID=71652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:35:10.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:35:10.933+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:35:10.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:35:10.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:35:10.970+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:35:10.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:35:10.981+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:35:10.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:35:10.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T18:35:41.429+0000] {processor.py:157} INFO - Started process (PID=71677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:35:41.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:35:41.434+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:35:41.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:35:41.444+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:35:41.464+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:35:41.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:35:41.475+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:35:41.475+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:35:41.485+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T18:36:11.904+0000] {processor.py:157} INFO - Started process (PID=71702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:36:11.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:36:11.908+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:36:11.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:36:11.919+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:36:11.939+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:36:11.938+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:36:11.950+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:36:11.950+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:36:11.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T18:36:42.362+0000] {processor.py:157} INFO - Started process (PID=71727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:36:42.365+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:36:42.370+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:36:42.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:36:42.386+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:36:42.408+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:36:42.408+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:36:42.421+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:36:42.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:36:42.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T18:37:12.879+0000] {processor.py:157} INFO - Started process (PID=71752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:37:12.881+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:37:12.886+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:37:12.885+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:37:12.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:37:12.942+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:37:12.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:37:12.976+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:37:12.975+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:37:12.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.128 seconds
[2024-07-19T18:37:43.382+0000] {processor.py:157} INFO - Started process (PID=71777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:37:43.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:37:43.386+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:37:43.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:37:43.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:37:43.424+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:37:43.423+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:37:43.439+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:37:43.439+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:37:43.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-19T18:38:13.897+0000] {processor.py:157} INFO - Started process (PID=71802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:38:13.898+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:38:13.901+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:38:13.901+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:38:13.917+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:38:13.942+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:38:13.942+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:38:13.958+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:38:13.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:38:13.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-19T18:38:44.368+0000] {processor.py:157} INFO - Started process (PID=71827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:38:44.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:38:44.371+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:38:44.371+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:38:44.383+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:38:44.400+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:38:44.399+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:38:44.410+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:38:44.410+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:38:44.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T18:39:14.853+0000] {processor.py:157} INFO - Started process (PID=71852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:39:14.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:39:14.856+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:39:14.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:39:14.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:39:14.884+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:39:14.883+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:39:14.897+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:39:14.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:39:14.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T18:39:45.337+0000] {processor.py:157} INFO - Started process (PID=71877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:39:45.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:39:45.340+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:39:45.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:39:45.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:39:45.368+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:39:45.368+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:39:45.381+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:39:45.380+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:39:45.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T18:40:15.839+0000] {processor.py:157} INFO - Started process (PID=71902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:40:15.843+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:40:15.846+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:40:15.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:40:15.863+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:40:15.885+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:40:15.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:40:15.897+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:40:15.897+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:40:15.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.073 seconds
[2024-07-19T18:40:46.281+0000] {processor.py:157} INFO - Started process (PID=71927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:40:46.282+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:40:46.283+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:40:46.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:40:46.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:40:46.309+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:40:46.309+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:40:46.323+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:40:46.323+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:40:46.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T18:41:16.742+0000] {processor.py:157} INFO - Started process (PID=71952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:41:16.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:41:16.749+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:41:16.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:41:16.767+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:41:16.799+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:41:16.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:41:16.817+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:41:16.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:41:16.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.095 seconds
[2024-07-19T18:41:47.224+0000] {processor.py:157} INFO - Started process (PID=71977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:41:47.226+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:41:47.230+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:41:47.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:41:47.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:41:47.281+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:41:47.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:41:47.296+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:41:47.296+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:41:47.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-19T18:42:17.729+0000] {processor.py:157} INFO - Started process (PID=72002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:42:17.731+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:42:17.733+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:42:17.733+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:42:17.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:42:17.764+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:42:17.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:42:17.776+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:42:17.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:42:17.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T18:42:48.150+0000] {processor.py:157} INFO - Started process (PID=72026) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:42:48.152+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:42:48.157+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:42:48.156+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:42:48.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:42:48.200+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:42:48.200+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:42:48.214+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:42:48.214+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:42:48.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-19T18:43:18.583+0000] {processor.py:157} INFO - Started process (PID=72052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:43:18.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:43:18.587+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:43:18.587+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:43:18.602+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:43:18.615+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:43:18.615+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:43:18.627+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:43:18.627+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:43:18.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T18:43:49.029+0000] {processor.py:157} INFO - Started process (PID=72077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:43:49.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:43:49.032+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:43:49.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:43:49.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:43:49.060+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:43:49.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:43:49.072+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:43:49.072+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:43:49.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T18:44:19.437+0000] {processor.py:157} INFO - Started process (PID=72102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:44:19.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:44:19.440+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:44:19.440+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:44:19.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:44:19.467+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:44:19.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:44:19.478+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:44:19.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:44:19.488+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T18:44:50.069+0000] {processor.py:157} INFO - Started process (PID=72127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:44:50.070+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:44:50.076+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:44:50.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:44:50.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:44:50.161+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:44:50.161+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:44:50.181+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:44:50.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:44:50.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.134 seconds
[2024-07-19T18:45:20.669+0000] {processor.py:157} INFO - Started process (PID=72152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:45:20.673+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:45:20.679+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:45:20.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:45:20.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:45:20.766+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:45:20.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:45:20.795+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:45:20.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:45:20.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.146 seconds
[2024-07-19T18:45:51.343+0000] {processor.py:157} INFO - Started process (PID=72177) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:45:51.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:45:51.350+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:45:51.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:45:51.366+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:45:51.396+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:45:51.396+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:45:51.408+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:45:51.408+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:45:51.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.081 seconds
[2024-07-19T18:46:21.791+0000] {processor.py:157} INFO - Started process (PID=72202) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:46:21.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:46:21.800+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:46:21.800+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:46:21.809+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:46:21.823+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:46:21.823+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:46:21.832+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:46:21.832+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:46:21.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T18:46:52.397+0000] {processor.py:157} INFO - Started process (PID=72227) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:46:52.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:46:52.409+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:46:52.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:46:52.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:46:52.518+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:46:52.518+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:46:52.535+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:46:52.535+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:46:52.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.163 seconds
[2024-07-19T18:47:22.965+0000] {processor.py:157} INFO - Started process (PID=72252) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:47:22.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:47:22.969+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:47:22.969+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:47:22.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:47:22.996+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:47:22.996+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:47:23.006+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:47:23.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:47:23.014+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T18:47:53.455+0000] {processor.py:157} INFO - Started process (PID=72277) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:47:53.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:47:53.461+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:47:53.460+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:47:53.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:47:53.495+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:47:53.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:47:53.509+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:47:53.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:47:53.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T18:48:23.935+0000] {processor.py:157} INFO - Started process (PID=72302) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:48:23.935+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:48:23.937+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:48:23.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:48:23.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:48:23.963+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:48:23.963+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:48:23.973+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:48:23.973+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:48:23.984+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T18:48:54.312+0000] {processor.py:157} INFO - Started process (PID=72327) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:48:54.313+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:48:54.314+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:48:54.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:48:54.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:48:54.345+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:48:54.345+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:48:54.357+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:48:54.357+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:48:54.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T18:49:24.803+0000] {processor.py:157} INFO - Started process (PID=72352) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:49:24.806+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:49:24.808+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:49:24.808+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:49:24.828+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:49:24.884+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:49:24.884+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:49:24.902+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:49:24.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:49:24.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.118 seconds
[2024-07-19T18:49:55.376+0000] {processor.py:157} INFO - Started process (PID=72377) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:49:55.379+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:49:55.387+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:49:55.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:49:55.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:49:55.441+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:49:55.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:49:55.469+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:49:55.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:49:55.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.119 seconds
[2024-07-19T18:50:25.900+0000] {processor.py:157} INFO - Started process (PID=72402) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:50:25.901+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:50:25.903+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:50:25.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:50:25.916+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:50:25.936+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:50:25.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:50:25.948+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:50:25.948+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:50:25.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T18:50:56.337+0000] {processor.py:157} INFO - Started process (PID=72427) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:50:56.338+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:50:56.340+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:50:56.340+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:50:56.353+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:50:56.373+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:50:56.373+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:50:56.384+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:50:56.384+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:50:56.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T18:51:26.784+0000] {processor.py:157} INFO - Started process (PID=72452) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:51:26.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:51:26.786+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:51:26.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:51:26.798+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:51:26.818+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:51:26.818+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:51:26.830+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:51:26.829+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:51:26.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T18:51:57.264+0000] {processor.py:157} INFO - Started process (PID=72477) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:51:57.266+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:51:57.271+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:51:57.271+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:51:57.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:51:57.337+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:51:57.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:51:57.354+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:51:57.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:51:57.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-19T18:52:27.809+0000] {processor.py:157} INFO - Started process (PID=72502) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:52:27.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:52:27.812+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:52:27.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:52:27.823+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:52:27.842+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:52:27.842+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:52:27.853+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:52:27.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:52:27.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T18:52:58.239+0000] {processor.py:157} INFO - Started process (PID=72527) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:52:58.240+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:52:58.243+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:52:58.243+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:52:58.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:52:58.280+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:52:58.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:52:58.291+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:52:58.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:52:58.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T18:53:28.661+0000] {processor.py:157} INFO - Started process (PID=72552) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:53:28.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:53:28.666+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:53:28.665+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:53:28.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:53:28.702+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:53:28.702+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:53:28.716+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:53:28.716+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:53:28.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T18:53:59.102+0000] {processor.py:157} INFO - Started process (PID=72577) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:53:59.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:53:59.109+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:53:59.109+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:53:59.120+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:53:59.143+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:53:59.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:53:59.154+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:53:59.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:53:59.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T18:54:29.556+0000] {processor.py:157} INFO - Started process (PID=72602) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:54:29.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:54:29.560+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:54:29.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:54:29.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:54:29.588+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:54:29.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:54:29.599+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:54:29.599+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:54:29.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T18:54:59.942+0000] {processor.py:157} INFO - Started process (PID=72627) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:54:59.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:54:59.946+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:54:59.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:54:59.960+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:54:59.977+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:54:59.977+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:54:59.988+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:54:59.988+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:54:59.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T18:55:30.381+0000] {processor.py:157} INFO - Started process (PID=72652) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:55:30.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:55:30.386+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:55:30.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:55:30.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:55:30.423+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:55:30.422+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:55:30.434+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:55:30.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:55:30.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T18:56:00.836+0000] {processor.py:157} INFO - Started process (PID=72677) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:56:00.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:56:00.843+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:56:00.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:56:00.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:56:00.912+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:56:00.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:56:00.930+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:56:00.930+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:56:00.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-19T18:56:31.374+0000] {processor.py:157} INFO - Started process (PID=72702) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:56:31.376+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:56:31.379+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:56:31.378+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:56:31.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:56:31.433+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:56:31.433+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:56:31.454+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:56:31.454+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:56:31.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-19T18:57:01.806+0000] {processor.py:157} INFO - Started process (PID=72727) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:57:01.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:57:01.810+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:57:01.810+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:57:01.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:57:01.836+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:57:01.836+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:57:01.846+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:57:01.846+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:57:01.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T18:57:32.274+0000] {processor.py:157} INFO - Started process (PID=72752) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:57:32.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:57:32.281+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:57:32.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:57:32.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:57:32.332+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:57:32.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:57:32.347+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:57:32.347+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:57:32.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-19T18:58:02.778+0000] {processor.py:157} INFO - Started process (PID=72777) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:58:02.782+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:58:02.785+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:58:02.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:58:02.807+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:58:02.825+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:58:02.825+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:58:02.838+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:58:02.838+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:58:02.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.075 seconds
[2024-07-19T18:58:33.228+0000] {processor.py:157} INFO - Started process (PID=72802) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:58:33.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:58:33.232+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:58:33.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:58:33.241+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:58:33.257+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:58:33.257+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:58:33.268+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:58:33.268+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:58:33.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T18:59:03.675+0000] {processor.py:157} INFO - Started process (PID=72827) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:59:03.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:59:03.692+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:59:03.691+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:59:03.719+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:59:03.757+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:59:03.757+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:59:03.775+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:59:03.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:59:03.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.150 seconds
[2024-07-19T18:59:34.222+0000] {processor.py:157} INFO - Started process (PID=72852) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:59:34.224+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T18:59:34.226+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:59:34.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:59:34.238+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T18:59:34.254+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:59:34.254+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T18:59:34.266+0000] {logging_mixin.py:151} INFO - [2024-07-19T18:59:34.266+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T18:59:34.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T19:00:04.631+0000] {processor.py:157} INFO - Started process (PID=72877) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:00:04.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:00:04.638+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:00:04.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:00:04.665+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:00:04.724+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:00:04.724+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:00:04.773+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:00:04.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:00:04.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.206 seconds
[2024-07-19T19:00:35.373+0000] {processor.py:157} INFO - Started process (PID=72902) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:00:35.375+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:00:35.380+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:00:35.380+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:00:35.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:00:35.446+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:00:35.446+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:00:35.468+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:00:35.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:00:35.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.113 seconds
[2024-07-19T19:01:05.911+0000] {processor.py:157} INFO - Started process (PID=72927) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:01:05.913+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:01:05.917+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:01:05.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:01:05.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:01:05.961+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:01:05.961+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:01:05.977+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:01:05.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:01:05.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.087 seconds
[2024-07-19T19:01:36.398+0000] {processor.py:157} INFO - Started process (PID=72952) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:01:36.400+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:01:36.403+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:01:36.403+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:01:36.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:01:36.445+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:01:36.445+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:01:36.460+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:01:36.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:01:36.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.077 seconds
[2024-07-19T19:02:06.874+0000] {processor.py:157} INFO - Started process (PID=72977) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:02:06.875+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:02:06.878+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:02:06.877+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:02:06.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:02:06.910+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:02:06.910+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:02:06.921+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:02:06.921+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:02:06.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T19:02:37.308+0000] {processor.py:157} INFO - Started process (PID=73002) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:02:37.311+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:02:37.314+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:02:37.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:02:37.331+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:02:37.359+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:02:37.359+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:02:37.375+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:02:37.375+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:02:37.388+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.084 seconds
[2024-07-19T19:03:07.736+0000] {processor.py:157} INFO - Started process (PID=73027) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:03:07.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:03:07.739+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:03:07.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:03:07.756+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:03:07.773+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:03:07.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:03:07.788+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:03:07.787+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:03:07.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T19:03:38.232+0000] {processor.py:157} INFO - Started process (PID=73052) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:03:38.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:03:38.238+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:03:38.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:03:38.257+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:03:38.286+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:03:38.286+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:03:38.302+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:03:38.302+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:03:38.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.089 seconds
[2024-07-19T19:04:08.696+0000] {processor.py:157} INFO - Started process (PID=73077) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:04:08.698+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:04:08.700+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:04:08.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:04:08.713+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:04:08.734+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:04:08.734+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:04:08.749+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:04:08.749+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:04:08.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.070 seconds
[2024-07-19T19:04:39.112+0000] {processor.py:157} INFO - Started process (PID=73102) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:04:39.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:04:39.118+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:04:39.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:04:39.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:04:39.156+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:04:39.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:04:39.173+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:04:39.173+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:04:39.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.076 seconds
[2024-07-19T19:05:09.576+0000] {processor.py:157} INFO - Started process (PID=73127) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:05:09.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:05:09.579+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:05:09.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:05:09.596+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:05:09.619+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:05:09.619+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:05:09.632+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:05:09.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:05:09.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.072 seconds
[2024-07-19T19:05:40.046+0000] {processor.py:157} INFO - Started process (PID=73152) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:05:40.047+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:05:40.049+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:05:40.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:05:40.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:05:40.081+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:05:40.081+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:05:40.092+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:05:40.092+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:05:40.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T19:22:56.124+0000] {processor.py:157} INFO - Started process (PID=73176) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:22:56.129+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:22:56.139+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:22:56.138+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:22:56.157+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:22:56.184+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:22:56.184+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:22:56.198+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:22:56.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:22:56.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.106 seconds
[2024-07-19T19:23:26.652+0000] {processor.py:157} INFO - Started process (PID=73204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:23:26.653+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:23:26.655+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:23:26.655+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:23:26.672+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:23:26.687+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:23:26.687+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:23:26.699+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:23:26.699+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:23:26.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T19:23:57.073+0000] {processor.py:157} INFO - Started process (PID=73229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:23:57.074+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:23:57.076+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:23:57.076+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:23:57.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:23:57.103+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:23:57.103+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:23:57.113+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:23:57.113+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:23:57.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T19:24:27.560+0000] {processor.py:157} INFO - Started process (PID=73254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:24:27.561+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:24:27.563+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:24:27.563+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:24:27.577+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:24:27.592+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:24:27.592+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:24:27.605+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:24:27.605+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:24:27.613+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T19:24:58.042+0000] {processor.py:157} INFO - Started process (PID=73279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:24:58.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:24:58.047+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:24:58.047+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:24:58.062+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:24:58.082+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:24:58.082+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:24:58.095+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:24:58.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:24:58.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.067 seconds
[2024-07-19T19:25:28.593+0000] {processor.py:157} INFO - Started process (PID=73304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:25:28.593+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:25:28.596+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:25:28.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:25:28.606+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:25:28.622+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:25:28.622+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:25:28.632+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:25:28.632+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:25:28.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T19:25:59.088+0000] {processor.py:157} INFO - Started process (PID=73329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:25:59.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:25:59.098+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:25:59.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:25:59.107+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:25:59.122+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:25:59.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:25:59.132+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:25:59.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:25:59.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T19:26:29.516+0000] {processor.py:157} INFO - Started process (PID=73354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:26:29.517+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:26:29.518+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:26:29.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:26:29.529+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:26:29.543+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:26:29.543+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:26:29.555+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:26:29.555+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:26:29.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T19:26:59.962+0000] {processor.py:157} INFO - Started process (PID=73379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:26:59.962+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:26:59.964+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:26:59.964+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:26:59.975+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:26:59.991+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:26:59.991+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:27:00.001+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:27:00.001+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:27:00.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T19:27:30.510+0000] {processor.py:157} INFO - Started process (PID=73404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:27:30.511+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:27:30.514+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:27:30.513+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:27:30.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:27:30.539+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:27:30.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:27:30.549+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:27:30.549+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:27:30.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T19:28:00.940+0000] {processor.py:157} INFO - Started process (PID=73429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:28:00.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:28:00.943+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:28:00.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:28:00.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:28:00.970+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:28:00.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:28:00.981+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:28:00.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:28:00.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T19:28:31.352+0000] {processor.py:157} INFO - Started process (PID=73454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:28:31.354+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:28:31.355+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:28:31.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:28:31.374+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:28:31.386+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:28:31.386+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:28:31.396+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:28:31.396+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:28:31.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T19:29:01.836+0000] {processor.py:157} INFO - Started process (PID=73479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:29:01.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:29:01.841+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:29:01.841+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:29:01.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:29:01.873+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:29:01.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:29:01.883+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:29:01.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:29:01.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T19:29:32.220+0000] {processor.py:157} INFO - Started process (PID=73504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:29:32.220+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:29:32.222+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:29:32.222+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:29:32.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:29:32.247+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:29:32.247+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:29:32.259+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:29:32.259+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:29:32.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T19:30:02.714+0000] {processor.py:157} INFO - Started process (PID=73529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:30:02.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:30:02.718+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:30:02.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:30:02.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:30:02.746+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:30:02.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:30:02.756+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:30:02.756+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:30:02.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T19:30:33.168+0000] {processor.py:157} INFO - Started process (PID=73554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:30:33.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:30:33.171+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:30:33.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:30:33.183+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:30:33.198+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:30:33.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:30:33.208+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:30:33.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:30:33.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T19:31:03.675+0000] {processor.py:157} INFO - Started process (PID=73579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:31:03.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:31:03.684+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:31:03.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:31:03.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:31:03.707+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:31:03.707+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:31:03.717+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:31:03.717+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:31:03.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T19:31:34.163+0000] {processor.py:157} INFO - Started process (PID=73604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:31:34.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:31:34.166+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:31:34.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:31:34.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:31:34.190+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:31:34.190+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:31:34.199+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:31:34.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:31:34.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T19:32:04.695+0000] {processor.py:157} INFO - Started process (PID=73629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:32:04.696+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:32:04.698+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:32:04.698+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:32:04.714+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:32:04.729+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:32:04.729+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:32:04.739+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:32:04.739+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:32:04.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T19:32:35.185+0000] {processor.py:157} INFO - Started process (PID=73654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:32:35.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:32:35.188+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:32:35.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:32:35.197+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:32:35.213+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:32:35.213+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:32:35.223+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:32:35.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:32:35.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T19:33:05.619+0000] {processor.py:157} INFO - Started process (PID=73679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:33:05.619+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:33:05.621+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:33:05.621+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:33:05.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:33:05.650+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:33:05.650+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:33:05.664+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:33:05.664+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:33:05.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T19:33:36.064+0000] {processor.py:157} INFO - Started process (PID=73704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:33:36.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:33:36.067+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:33:36.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:33:36.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:33:36.096+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:33:36.096+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:33:36.107+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:33:36.107+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:33:36.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T19:34:06.500+0000] {processor.py:157} INFO - Started process (PID=73729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:34:06.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:34:06.502+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:34:06.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:34:06.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:34:06.531+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:34:06.531+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:34:06.542+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:34:06.542+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:34:06.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T19:34:37.049+0000] {processor.py:157} INFO - Started process (PID=73754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:34:37.055+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:34:37.057+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:34:37.057+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:34:37.066+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:34:37.080+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:34:37.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:34:37.089+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:34:37.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:34:37.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T19:35:07.461+0000] {processor.py:157} INFO - Started process (PID=73779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:35:07.462+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:35:07.465+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:35:07.465+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:35:07.484+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:35:07.501+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:35:07.501+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:35:07.515+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:35:07.515+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:35:07.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.071 seconds
[2024-07-19T19:35:37.969+0000] {processor.py:157} INFO - Started process (PID=73804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:35:37.971+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:35:37.974+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:35:37.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:35:37.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:35:38.011+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:35:38.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:35:38.024+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:35:38.024+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:35:38.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.068 seconds
[2024-07-19T19:36:08.394+0000] {processor.py:157} INFO - Started process (PID=73829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:36:08.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:36:08.397+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:36:08.397+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:36:08.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:36:08.426+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:36:08.426+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:36:08.437+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:36:08.437+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:36:08.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T19:36:38.861+0000] {processor.py:157} INFO - Started process (PID=73854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:36:38.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:36:38.865+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:36:38.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:36:38.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:36:38.894+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:36:38.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:36:38.905+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:36:38.905+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:36:38.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T19:37:09.354+0000] {processor.py:157} INFO - Started process (PID=73879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:37:09.355+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:37:09.357+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:37:09.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:37:09.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:37:09.382+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:37:09.382+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:37:09.391+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:37:09.391+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:37:09.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T19:37:39.875+0000] {processor.py:157} INFO - Started process (PID=73904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:37:39.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:37:39.878+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:37:39.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:37:39.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:37:39.905+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:37:39.905+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:37:39.915+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:37:39.915+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:37:39.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T19:38:10.332+0000] {processor.py:157} INFO - Started process (PID=73929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:38:10.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:38:10.333+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:38:10.333+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:38:10.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:38:10.355+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:38:10.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:38:10.363+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:38:10.363+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:38:10.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-19T19:38:40.760+0000] {processor.py:157} INFO - Started process (PID=73954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:38:40.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:38:40.762+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:38:40.762+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:38:40.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:38:40.790+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:38:40.790+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:38:40.802+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:38:40.802+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:38:40.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T19:39:11.288+0000] {processor.py:157} INFO - Started process (PID=73979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:39:11.290+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:39:11.293+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:39:11.292+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:39:11.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:39:11.321+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:39:11.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:39:11.331+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:39:11.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:39:11.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T19:39:41.839+0000] {processor.py:157} INFO - Started process (PID=74004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:39:41.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:39:41.842+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:39:41.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:39:41.852+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:39:41.869+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:39:41.869+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:39:41.881+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:39:41.881+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:39:41.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T19:40:12.368+0000] {processor.py:157} INFO - Started process (PID=74029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:40:12.369+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:40:12.372+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:40:12.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:40:12.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:40:12.403+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:40:12.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:40:12.416+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:40:12.416+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:40:12.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T19:40:42.864+0000] {processor.py:157} INFO - Started process (PID=74054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:40:42.865+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:40:42.866+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:40:42.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:40:42.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:40:42.894+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:40:42.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:40:42.906+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:40:42.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:40:42.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T19:41:13.286+0000] {processor.py:157} INFO - Started process (PID=74079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:41:13.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:41:13.289+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:41:13.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:41:13.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:41:13.316+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:41:13.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:41:13.326+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:41:13.326+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:41:13.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T19:41:43.817+0000] {processor.py:157} INFO - Started process (PID=74104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:41:43.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:41:43.819+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:41:43.819+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:41:43.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:41:43.847+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:41:43.847+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:41:43.857+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:41:43.857+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:41:43.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T19:42:14.327+0000] {processor.py:157} INFO - Started process (PID=74129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:42:14.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:42:14.329+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:42:14.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:42:14.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:42:14.356+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:42:14.356+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:42:14.366+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:42:14.366+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:42:14.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T19:42:44.772+0000] {processor.py:157} INFO - Started process (PID=74154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:42:44.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:42:44.776+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:42:44.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:42:44.791+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:42:44.804+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:42:44.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:42:44.814+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:42:44.814+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:42:44.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T19:43:15.274+0000] {processor.py:157} INFO - Started process (PID=74179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:43:15.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:43:15.278+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:43:15.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:43:15.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:43:15.304+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:43:15.304+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:43:15.315+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:43:15.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:43:15.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T19:43:45.748+0000] {processor.py:157} INFO - Started process (PID=74204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:43:45.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:43:45.751+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:43:45.751+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:43:45.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:43:45.778+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:43:45.777+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:43:45.789+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:43:45.789+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:43:45.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T19:44:16.159+0000] {processor.py:157} INFO - Started process (PID=74229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:44:16.159+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:44:16.161+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:44:16.161+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:44:16.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:44:16.189+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:44:16.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:44:16.202+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:44:16.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:44:16.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T19:44:46.651+0000] {processor.py:157} INFO - Started process (PID=74254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:44:46.652+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:44:46.653+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:44:46.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:44:46.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:44:46.676+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:44:46.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:44:46.687+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:44:46.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:44:46.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T19:45:17.169+0000] {processor.py:157} INFO - Started process (PID=74279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:45:17.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:45:17.172+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:45:17.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:45:17.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:45:17.204+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:45:17.204+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:45:17.213+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:45:17.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:45:17.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T19:45:47.640+0000] {processor.py:157} INFO - Started process (PID=74304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:45:47.641+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:45:47.643+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:45:47.643+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:45:47.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:45:47.672+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:45:47.672+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:45:47.682+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:45:47.682+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:45:47.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T19:46:18.062+0000] {processor.py:157} INFO - Started process (PID=74329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:46:18.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:46:18.065+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:46:18.065+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:46:18.080+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:46:18.094+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:46:18.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:46:18.103+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:46:18.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:46:18.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T19:46:48.535+0000] {processor.py:157} INFO - Started process (PID=74354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:46:48.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:46:48.538+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:46:48.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:46:48.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:46:48.567+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:46:48.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:46:48.577+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:46:48.577+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:46:48.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T19:47:18.920+0000] {processor.py:157} INFO - Started process (PID=74379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:47:18.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:47:18.924+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:47:18.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:47:18.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:47:18.951+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:47:18.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:47:18.963+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:47:18.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:47:18.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T19:47:49.395+0000] {processor.py:157} INFO - Started process (PID=74404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:47:49.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:47:49.398+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:47:49.398+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:47:49.411+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:47:49.424+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:47:49.424+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:47:49.435+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:47:49.435+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:47:49.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T19:48:19.810+0000] {processor.py:157} INFO - Started process (PID=74429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:48:19.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:48:19.812+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:48:19.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:48:19.827+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:48:19.840+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:48:19.840+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:48:19.851+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:48:19.851+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:48:19.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T19:48:50.287+0000] {processor.py:157} INFO - Started process (PID=74453) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:48:50.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:48:50.289+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:48:50.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:48:50.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:48:50.317+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:48:50.317+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:48:50.327+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:48:50.327+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:48:50.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T19:49:20.748+0000] {processor.py:157} INFO - Started process (PID=74479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:49:20.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:49:20.750+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:49:20.750+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:49:20.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:49:20.782+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:49:20.782+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:49:20.794+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:49:20.794+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:49:20.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T19:49:51.201+0000] {processor.py:157} INFO - Started process (PID=74504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:49:51.201+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:49:51.203+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:49:51.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:49:51.214+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:49:51.230+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:49:51.230+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:49:51.240+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:49:51.240+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:49:51.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T19:50:21.654+0000] {processor.py:157} INFO - Started process (PID=74529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:50:21.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:50:21.656+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:50:21.656+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:50:21.668+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:50:21.683+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:50:21.683+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:50:21.693+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:50:21.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:50:21.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T19:50:52.138+0000] {processor.py:157} INFO - Started process (PID=74554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:50:52.139+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:50:52.141+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:50:52.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:50:52.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:50:52.166+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:50:52.166+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:50:52.176+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:50:52.176+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:50:52.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T19:51:22.607+0000] {processor.py:157} INFO - Started process (PID=74579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:51:22.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:51:22.610+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:51:22.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:51:22.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:51:22.640+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:51:22.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:51:22.649+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:51:22.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:51:22.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T19:51:53.088+0000] {processor.py:157} INFO - Started process (PID=74604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:51:53.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:51:53.090+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:51:53.090+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:51:53.105+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:51:53.121+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:51:53.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:51:53.132+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:51:53.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:51:53.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T19:52:23.644+0000] {processor.py:157} INFO - Started process (PID=74629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:52:23.645+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:52:23.647+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:52:23.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:52:23.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:52:23.677+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:52:23.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:52:23.687+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:52:23.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:52:23.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T19:52:54.144+0000] {processor.py:157} INFO - Started process (PID=74654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:52:54.145+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:52:54.146+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:52:54.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:52:54.162+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:52:54.175+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:52:54.175+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:52:54.185+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:52:54.185+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:52:54.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T19:53:24.622+0000] {processor.py:157} INFO - Started process (PID=74679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:53:24.623+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:53:24.625+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:53:24.625+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:53:24.637+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:53:24.652+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:53:24.652+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:53:24.662+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:53:24.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:53:24.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T19:53:55.178+0000] {processor.py:157} INFO - Started process (PID=74704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:53:55.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:53:55.181+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:53:55.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:53:55.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:53:55.210+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:53:55.210+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:53:55.223+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:53:55.223+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:53:55.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T19:54:25.619+0000] {processor.py:157} INFO - Started process (PID=74729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:54:25.620+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:54:25.623+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:54:25.623+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:54:25.634+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:54:25.651+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:54:25.651+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:54:25.662+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:54:25.662+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:54:25.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T19:54:56.058+0000] {processor.py:157} INFO - Started process (PID=74754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:54:56.059+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:54:56.061+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:54:56.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:54:56.072+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:54:56.090+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:54:56.090+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:54:56.102+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:54:56.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:54:56.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T19:55:26.567+0000] {processor.py:157} INFO - Started process (PID=74779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:55:26.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:55:26.570+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:55:26.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:55:26.584+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:55:26.602+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:55:26.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:55:26.614+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:55:26.614+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:55:26.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T19:55:56.986+0000] {processor.py:157} INFO - Started process (PID=74804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:55:56.987+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:55:56.988+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:55:56.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:55:57.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:55:57.017+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:55:57.017+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:55:57.027+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:55:57.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:55:57.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T19:56:27.531+0000] {processor.py:157} INFO - Started process (PID=74829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:56:27.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:56:27.534+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:56:27.534+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:56:27.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:56:27.560+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:56:27.560+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:56:27.569+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:56:27.569+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:56:27.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T19:56:58.019+0000] {processor.py:157} INFO - Started process (PID=74854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:56:58.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:56:58.022+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:56:58.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:56:58.040+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:56:58.054+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:56:58.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:56:58.063+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:56:58.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:56:58.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T19:57:28.503+0000] {processor.py:157} INFO - Started process (PID=74879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:57:28.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:57:28.506+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:57:28.506+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:57:28.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:57:28.534+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:57:28.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:57:28.545+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:57:28.545+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:57:28.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T19:57:58.966+0000] {processor.py:157} INFO - Started process (PID=74904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:57:58.967+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:57:58.968+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:57:58.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:57:58.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:57:58.993+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:57:58.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:57:59.003+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:57:59.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:57:59.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T19:58:29.408+0000] {processor.py:157} INFO - Started process (PID=74929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:58:29.409+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:58:29.410+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:58:29.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:58:29.420+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:58:29.435+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:58:29.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:58:29.445+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:58:29.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:58:29.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T19:58:59.941+0000] {processor.py:157} INFO - Started process (PID=74954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:58:59.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:58:59.945+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:58:59.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:58:59.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:58:59.969+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:58:59.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:58:59.983+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:58:59.983+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:58:59.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T19:59:30.411+0000] {processor.py:157} INFO - Started process (PID=74979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:59:30.412+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T19:59:30.413+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:59:30.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:59:30.428+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T19:59:30.443+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:59:30.443+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T19:59:30.452+0000] {logging_mixin.py:151} INFO - [2024-07-19T19:59:30.452+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T19:59:30.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T20:00:00.844+0000] {processor.py:157} INFO - Started process (PID=75004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:00:00.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:00:00.847+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:00:00.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:00:00.857+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:00:00.873+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:00:00.873+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:00:00.883+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:00:00.883+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:00:00.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T20:00:31.361+0000] {processor.py:157} INFO - Started process (PID=75029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:00:31.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:00:31.364+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:00:31.364+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:00:31.376+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:00:31.395+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:00:31.395+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:00:31.403+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:00:31.403+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:00:31.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T20:01:01.872+0000] {processor.py:157} INFO - Started process (PID=75054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:01:01.876+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:01:01.878+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:01:01.878+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:01:01.888+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:01:01.900+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:01:01.900+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:01:01.910+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:01:01.910+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:01:01.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T20:01:32.403+0000] {processor.py:157} INFO - Started process (PID=75079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:01:32.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:01:32.406+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:01:32.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:01:32.421+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:01:32.435+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:01:32.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:01:32.445+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:01:32.445+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:01:32.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T20:02:02.975+0000] {processor.py:157} INFO - Started process (PID=75104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:02:02.978+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:02:02.981+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:02:02.980+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:02:02.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:02:03.007+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:02:03.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:02:03.017+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:02:03.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:02:03.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T20:02:33.508+0000] {processor.py:157} INFO - Started process (PID=75128) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:02:33.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:02:33.512+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:02:33.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:02:33.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:02:33.538+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:02:33.538+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:02:33.548+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:02:33.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:02:33.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T20:03:03.949+0000] {processor.py:157} INFO - Started process (PID=75154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:03:03.950+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:03:03.951+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:03:03.951+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:03:03.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:03:03.986+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:03:03.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:03:03.995+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:03:03.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:03:04.004+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T20:03:34.402+0000] {processor.py:157} INFO - Started process (PID=75179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:03:34.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:03:34.404+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:03:34.404+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:03:34.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:03:34.431+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:03:34.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:03:34.441+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:03:34.441+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:03:34.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T20:04:04.816+0000] {processor.py:157} INFO - Started process (PID=75204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:04:04.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:04:04.819+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:04:04.818+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:04:04.831+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:04:04.846+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:04:04.845+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:04:04.859+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:04:04.859+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:04:04.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T20:04:35.295+0000] {processor.py:157} INFO - Started process (PID=75229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:04:35.296+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:04:35.299+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:04:35.299+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:04:35.308+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:04:35.325+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:04:35.325+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:04:35.336+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:04:35.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:04:35.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T20:05:05.784+0000] {processor.py:157} INFO - Started process (PID=75254) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:05:05.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:05:05.787+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:05:05.787+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:05:05.795+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:05:05.811+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:05:05.811+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:05:05.823+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:05:05.823+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:05:05.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T20:05:36.211+0000] {processor.py:157} INFO - Started process (PID=75279) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:05:36.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:05:36.216+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:05:36.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:05:36.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:05:36.244+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:05:36.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:05:36.256+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:05:36.256+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:05:36.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T20:06:06.673+0000] {processor.py:157} INFO - Started process (PID=75304) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:06:06.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:06:06.676+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:06:06.676+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:06:06.690+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:06:06.708+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:06:06.708+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:06:06.719+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:06:06.719+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:06:06.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T20:06:37.111+0000] {processor.py:157} INFO - Started process (PID=75329) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:06:37.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:06:37.114+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:06:37.114+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:06:37.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:06:37.139+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:06:37.139+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:06:37.149+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:06:37.149+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:06:37.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T20:07:07.598+0000] {processor.py:157} INFO - Started process (PID=75354) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:07:07.598+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:07:07.600+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:07:07.600+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:07:07.613+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:07:07.628+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:07:07.628+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:07:07.638+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:07:07.638+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:07:07.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T20:07:38.057+0000] {processor.py:157} INFO - Started process (PID=75379) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:07:38.064+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:07:38.067+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:07:38.067+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:07:38.075+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:07:38.088+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:07:38.088+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:07:38.096+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:07:38.096+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:07:38.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T20:08:08.625+0000] {processor.py:157} INFO - Started process (PID=75404) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:08:08.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:08:08.628+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:08:08.628+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:08:08.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:08:08.653+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:08:08.653+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:08:08.663+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:08:08.663+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:08:08.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T20:08:39.093+0000] {processor.py:157} INFO - Started process (PID=75429) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:08:39.096+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:08:39.099+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:08:39.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:08:39.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:08:39.127+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:08:39.127+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:08:39.139+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:08:39.139+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:08:39.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T20:09:09.582+0000] {processor.py:157} INFO - Started process (PID=75454) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:09:09.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:09:09.585+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:09:09.584+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:09:09.599+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:09:09.612+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:09:09.612+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:09:09.621+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:09:09.621+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:09:09.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T20:09:40.041+0000] {processor.py:157} INFO - Started process (PID=75479) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:09:40.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:09:40.044+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:09:40.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:09:40.054+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:09:40.070+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:09:40.070+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:09:40.081+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:09:40.081+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:09:40.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T20:10:10.441+0000] {processor.py:157} INFO - Started process (PID=75504) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:10:10.443+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:10:10.445+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:10:10.445+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:10:10.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:10:10.472+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:10:10.472+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:10:10.483+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:10:10.483+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:10:10.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T20:10:40.970+0000] {processor.py:157} INFO - Started process (PID=75529) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:10:40.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:10:40.974+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:10:40.974+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:10:40.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:10:41.003+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:10:41.003+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:10:41.014+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:10:41.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:10:41.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T20:11:11.395+0000] {processor.py:157} INFO - Started process (PID=75554) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:11:11.395+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:11:11.399+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:11:11.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:11:11.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:11:11.432+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:11:11.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:11:11.442+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:11:11.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:11:11.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T20:11:41.879+0000] {processor.py:157} INFO - Started process (PID=75579) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:11:41.880+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:11:41.883+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:11:41.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:11:41.894+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:11:41.912+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:11:41.912+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:11:41.924+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:11:41.924+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:11:41.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T20:12:12.291+0000] {processor.py:157} INFO - Started process (PID=75604) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:12:12.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:12:12.294+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:12:12.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:12:12.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:12:12.324+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:12:12.323+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:12:12.334+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:12:12.334+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:12:12.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T20:12:42.775+0000] {processor.py:157} INFO - Started process (PID=75629) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:12:42.776+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:12:42.779+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:12:42.778+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:12:42.788+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:12:42.805+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:12:42.805+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:12:42.819+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:12:42.819+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:12:42.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T20:13:13.233+0000] {processor.py:157} INFO - Started process (PID=75654) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:13:13.234+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:13:13.236+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:13:13.236+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:13:13.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:13:13.265+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:13:13.264+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:13:13.279+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:13:13.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:13:13.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T20:13:43.736+0000] {processor.py:157} INFO - Started process (PID=75679) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:13:43.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:13:43.738+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:13:43.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:13:43.749+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:13:43.765+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:13:43.764+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:13:43.776+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:13:43.776+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:13:43.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T20:14:14.258+0000] {processor.py:157} INFO - Started process (PID=75704) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:14:14.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:14:14.261+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:14:14.260+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:14:14.277+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:14:14.290+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:14:14.290+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:14:14.299+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:14:14.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:14:14.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T20:14:44.751+0000] {processor.py:157} INFO - Started process (PID=75729) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:14:44.752+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:14:44.754+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:14:44.754+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:14:44.766+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:14:44.781+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:14:44.781+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:14:44.791+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:14:44.791+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:14:44.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T20:15:15.178+0000] {processor.py:157} INFO - Started process (PID=75754) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:15:15.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:15:15.181+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:15:15.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:15:15.189+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:15:15.203+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:15:15.203+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:15:15.213+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:15:15.213+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:15:15.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-19T20:15:45.647+0000] {processor.py:157} INFO - Started process (PID=75779) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:15:45.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:15:45.650+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:15:45.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:15:45.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:15:45.676+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:15:45.675+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:15:45.686+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:15:45.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:15:45.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T20:16:16.140+0000] {processor.py:157} INFO - Started process (PID=75804) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:16:16.141+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:16:16.144+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:16:16.144+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:16:16.153+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:16:16.168+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:16:16.168+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:16:16.178+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:16:16.178+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:16:16.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T20:16:46.559+0000] {processor.py:157} INFO - Started process (PID=75829) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:16:46.560+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:16:46.562+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:16:46.561+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:16:46.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:16:46.588+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:16:46.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:16:46.598+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:16:46.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:16:46.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T20:17:17.066+0000] {processor.py:157} INFO - Started process (PID=75854) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:17:17.067+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:17:17.070+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:17:17.069+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:17:17.085+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:17:17.099+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:17:17.099+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:17:17.108+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:17:17.108+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:17:17.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T20:17:47.478+0000] {processor.py:157} INFO - Started process (PID=75879) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:17:47.479+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:17:47.480+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:17:47.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:17:47.495+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:17:47.509+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:17:47.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:17:47.519+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:17:47.519+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:17:47.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T20:18:17.937+0000] {processor.py:157} INFO - Started process (PID=75904) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:18:17.938+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:18:17.939+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:18:17.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:18:17.950+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:18:17.967+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:18:17.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:18:17.976+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:18:17.976+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:18:17.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T20:18:48.361+0000] {processor.py:157} INFO - Started process (PID=75929) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:18:48.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:18:48.364+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:18:48.363+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:18:48.375+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:18:48.390+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:18:48.390+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:18:48.400+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:18:48.400+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:18:48.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T20:19:18.861+0000] {processor.py:157} INFO - Started process (PID=75954) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:19:18.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:19:18.863+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:19:18.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:19:18.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:19:18.890+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:19:18.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:19:18.901+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:19:18.901+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:19:18.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T20:19:49.275+0000] {processor.py:157} INFO - Started process (PID=75979) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:19:49.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:19:49.278+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:19:49.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:19:49.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:19:49.303+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:19:49.303+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:19:49.313+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:19:49.313+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:19:49.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T20:20:19.743+0000] {processor.py:157} INFO - Started process (PID=76004) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:20:19.746+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:20:19.749+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:20:19.748+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:20:19.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:20:19.777+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:20:19.776+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:20:19.786+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:20:19.786+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:20:19.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T20:20:50.261+0000] {processor.py:157} INFO - Started process (PID=76029) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:20:50.261+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:20:50.263+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:20:50.263+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:20:50.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:20:50.326+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:20:50.326+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:20:50.336+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:20:50.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:20:50.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.086 seconds
[2024-07-19T20:21:20.770+0000] {processor.py:157} INFO - Started process (PID=76054) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:21:20.772+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:21:20.773+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:21:20.773+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:21:20.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:21:20.801+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:21:20.801+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:21:20.811+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:21:20.811+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:21:20.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T20:21:51.285+0000] {processor.py:157} INFO - Started process (PID=76079) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:21:51.286+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:21:51.288+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:21:51.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:21:51.302+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:21:51.319+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:21:51.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:21:51.330+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:21:51.330+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:21:51.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T20:22:21.778+0000] {processor.py:157} INFO - Started process (PID=76104) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:22:21.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:22:21.780+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:22:21.780+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:22:21.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:22:21.809+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:22:21.809+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:22:21.818+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:22:21.818+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:22:21.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T20:22:52.323+0000] {processor.py:157} INFO - Started process (PID=76129) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:22:52.325+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:22:52.326+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:22:52.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:22:52.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:22:52.358+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:22:52.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:22:52.368+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:22:52.368+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:22:52.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T20:23:22.755+0000] {processor.py:157} INFO - Started process (PID=76154) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:23:22.756+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:23:22.758+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:23:22.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:23:22.774+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:23:22.789+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:23:22.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:23:22.798+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:23:22.798+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:23:22.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T20:23:53.235+0000] {processor.py:157} INFO - Started process (PID=76179) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:23:53.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:23:53.238+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:23:53.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:23:53.258+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:23:53.278+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:23:53.278+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:23:53.288+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:23:53.288+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:23:53.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T20:24:23.769+0000] {processor.py:157} INFO - Started process (PID=76204) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:24:23.770+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:24:23.772+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:24:23.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:24:23.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:24:23.797+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:24:23.797+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:24:23.808+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:24:23.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:24:23.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T20:24:54.282+0000] {processor.py:157} INFO - Started process (PID=76229) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:24:54.283+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:24:54.285+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:24:54.285+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:24:54.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:24:54.321+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:24:54.321+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:24:54.333+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:24:54.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:24:54.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T20:40:36.623+0000] {processor.py:157} INFO - Started process (PID=76256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:40:36.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:40:36.627+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:40:36.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:40:36.638+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:40:36.656+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:40:36.656+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:40:36.666+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:40:36.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:40:36.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T20:41:07.044+0000] {processor.py:157} INFO - Started process (PID=76280) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:41:07.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:41:07.049+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:41:07.049+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:41:07.063+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:41:07.084+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:41:07.083+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:41:07.095+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:41:07.095+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:41:07.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T20:41:37.566+0000] {processor.py:157} INFO - Started process (PID=76306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:41:37.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:41:37.569+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:41:37.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:41:37.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:41:37.601+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:41:37.601+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:41:37.613+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:41:37.613+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:41:37.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T20:42:08.006+0000] {processor.py:157} INFO - Started process (PID=76331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:42:08.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:42:08.009+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:42:08.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:42:08.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:42:08.036+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:42:08.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:42:08.046+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:42:08.046+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:42:08.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T20:42:38.444+0000] {processor.py:157} INFO - Started process (PID=76356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:42:38.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:42:38.447+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:42:38.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:42:38.460+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:42:38.477+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:42:38.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:42:38.486+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:42:38.486+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:42:38.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T20:43:08.959+0000] {processor.py:157} INFO - Started process (PID=76381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:43:08.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:43:08.961+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:43:08.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:43:08.973+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:43:08.988+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:43:08.988+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:43:08.999+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:43:08.999+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:43:09.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T20:43:39.446+0000] {processor.py:157} INFO - Started process (PID=76406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:43:39.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:43:39.449+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:43:39.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:43:39.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:43:39.476+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:43:39.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:43:39.485+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:43:39.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:43:39.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T20:44:09.970+0000] {processor.py:157} INFO - Started process (PID=76431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:44:09.972+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:44:09.974+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:44:09.973+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:44:09.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:44:10.006+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:44:10.006+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:44:10.016+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:44:10.016+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:44:10.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T20:44:40.490+0000] {processor.py:157} INFO - Started process (PID=76456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:44:40.492+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:44:40.494+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:44:40.494+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:44:40.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:44:40.525+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:44:40.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:44:40.534+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:44:40.534+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:44:40.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T20:45:10.906+0000] {processor.py:157} INFO - Started process (PID=76481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:45:10.907+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:45:10.908+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:45:10.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:45:10.924+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:45:10.937+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:45:10.937+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:45:10.947+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:45:10.947+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:45:10.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T20:45:41.408+0000] {processor.py:157} INFO - Started process (PID=76506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:45:41.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:45:41.413+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:45:41.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:45:41.426+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:45:41.440+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:45:41.440+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:45:41.451+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:45:41.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:45:41.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T20:46:11.838+0000] {processor.py:157} INFO - Started process (PID=76531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:46:11.841+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:46:11.843+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:46:11.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:46:11.856+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:46:11.872+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:46:11.872+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:46:11.882+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:46:11.882+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:46:11.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T20:46:42.286+0000] {processor.py:157} INFO - Started process (PID=76556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:46:42.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:46:42.288+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:46:42.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:46:42.300+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:46:42.316+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:46:42.316+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:46:42.329+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:46:42.329+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:46:42.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T20:47:12.729+0000] {processor.py:157} INFO - Started process (PID=76581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:47:12.730+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:47:12.731+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:47:12.731+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:47:12.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:47:12.759+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:47:12.759+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:47:12.768+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:47:12.768+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:47:12.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T20:47:43.216+0000] {processor.py:157} INFO - Started process (PID=76606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:47:43.216+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:47:43.218+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:47:43.218+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:47:43.233+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:47:43.248+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:47:43.248+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:47:43.257+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:47:43.257+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:47:43.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T20:48:13.699+0000] {processor.py:157} INFO - Started process (PID=76631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:48:13.699+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:48:13.701+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:48:13.701+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:48:13.717+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:48:13.733+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:48:13.733+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:48:13.743+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:48:13.743+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:48:13.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T20:48:44.213+0000] {processor.py:157} INFO - Started process (PID=76656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:48:44.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:48:44.216+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:48:44.216+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:48:44.227+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:48:44.243+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:48:44.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:48:44.255+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:48:44.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:48:44.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T20:49:14.616+0000] {processor.py:157} INFO - Started process (PID=76681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:49:14.618+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:49:14.620+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:49:14.619+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:49:14.628+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:49:14.645+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:49:14.645+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:49:14.656+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:49:14.655+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:49:14.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T20:49:45.112+0000] {processor.py:157} INFO - Started process (PID=76706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:49:45.113+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:49:45.115+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:49:45.115+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:49:45.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:49:45.142+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:49:45.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:49:45.154+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:49:45.154+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:49:45.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T20:50:15.555+0000] {processor.py:157} INFO - Started process (PID=76731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:50:15.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:50:15.560+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:50:15.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:50:15.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:50:15.588+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:50:15.588+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:50:15.598+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:50:15.598+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:50:15.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T20:50:46.009+0000] {processor.py:157} INFO - Started process (PID=76756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:50:46.010+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:50:46.012+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:50:46.012+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:50:46.023+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:50:46.038+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:50:46.038+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:50:46.048+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:50:46.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:50:46.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T20:51:16.495+0000] {processor.py:157} INFO - Started process (PID=76781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:51:16.498+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:51:16.500+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:51:16.500+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:51:16.519+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:51:16.535+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:51:16.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:51:16.547+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:51:16.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:51:16.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T20:51:46.950+0000] {processor.py:157} INFO - Started process (PID=76806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:51:46.957+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:51:46.958+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:51:46.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:51:46.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:51:46.983+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:51:46.982+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:51:46.992+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:51:46.992+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:51:46.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T20:52:17.415+0000] {processor.py:157} INFO - Started process (PID=76831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:52:17.416+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:52:17.418+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:52:17.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:52:17.429+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:52:17.442+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:52:17.442+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:52:17.452+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:52:17.451+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:52:17.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T20:52:47.852+0000] {processor.py:157} INFO - Started process (PID=76856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:52:47.854+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:52:47.857+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:52:47.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:52:47.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:52:47.888+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:52:47.888+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:52:47.899+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:52:47.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:52:47.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T20:53:18.346+0000] {processor.py:157} INFO - Started process (PID=76881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:53:18.347+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:53:18.349+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:53:18.349+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:53:18.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:53:18.378+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:53:18.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:53:18.388+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:53:18.388+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:53:18.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T20:53:48.735+0000] {processor.py:157} INFO - Started process (PID=76906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:53:48.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:53:48.739+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:53:48.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:53:48.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:53:48.765+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:53:48.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:53:48.776+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:53:48.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:53:48.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T20:54:19.188+0000] {processor.py:157} INFO - Started process (PID=76931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:54:19.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:54:19.192+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:54:19.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:54:19.203+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:54:19.217+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:54:19.217+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:54:19.227+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:54:19.227+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:54:19.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T20:54:49.607+0000] {processor.py:157} INFO - Started process (PID=76956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:54:49.607+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:54:49.609+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:54:49.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:54:49.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:54:49.634+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:54:49.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:54:49.644+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:54:49.644+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:54:49.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T20:55:20.070+0000] {processor.py:157} INFO - Started process (PID=76981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:55:20.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:55:20.073+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:55:20.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:55:20.088+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:55:20.102+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:55:20.102+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:55:20.111+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:55:20.111+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:55:20.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T20:55:50.573+0000] {processor.py:157} INFO - Started process (PID=77006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:55:50.577+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:55:50.579+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:55:50.579+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:55:50.591+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:55:50.606+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:55:50.605+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:55:50.615+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:55:50.615+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:55:50.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T20:56:21.121+0000] {processor.py:157} INFO - Started process (PID=77031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:56:21.124+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:56:21.126+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:56:21.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:56:21.137+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:56:21.156+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:56:21.156+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:56:21.167+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:56:21.167+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:56:21.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T20:56:51.604+0000] {processor.py:157} INFO - Started process (PID=77056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:56:51.605+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:56:51.607+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:56:51.607+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:56:51.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:56:51.635+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:56:51.635+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:56:51.645+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:56:51.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:56:51.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T20:57:22.006+0000] {processor.py:157} INFO - Started process (PID=77081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:57:22.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:57:22.009+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:57:22.009+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:57:22.024+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:57:22.036+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:57:22.036+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:57:22.046+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:57:22.045+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:57:22.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T20:57:52.529+0000] {processor.py:157} INFO - Started process (PID=77106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:57:52.529+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:57:52.530+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:57:52.530+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:57:52.542+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:57:52.558+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:57:52.558+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:57:52.567+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:57:52.567+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:57:52.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T20:58:22.922+0000] {processor.py:157} INFO - Started process (PID=77131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:58:22.923+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:58:22.924+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:58:22.924+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:58:22.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:58:22.948+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:58:22.948+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:58:22.958+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:58:22.958+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:58:22.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T20:58:53.342+0000] {processor.py:157} INFO - Started process (PID=77156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:58:53.344+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:58:53.346+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:58:53.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:58:53.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:58:53.378+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:58:53.378+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:58:53.387+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:58:53.387+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:58:53.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T20:59:23.811+0000] {processor.py:157} INFO - Started process (PID=77181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:59:23.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:59:23.812+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:59:23.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:59:23.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:59:23.833+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:59:23.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:59:23.842+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:59:23.842+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:59:23.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-19T20:59:54.273+0000] {processor.py:157} INFO - Started process (PID=77206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:59:54.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T20:59:54.276+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:59:54.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:59:54.284+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T20:59:54.299+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:59:54.299+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T20:59:54.309+0000] {logging_mixin.py:151} INFO - [2024-07-19T20:59:54.309+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T20:59:54.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T21:00:24.765+0000] {processor.py:157} INFO - Started process (PID=77231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:00:24.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:00:24.768+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:00:24.768+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:00:24.783+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:00:24.796+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:00:24.796+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:00:24.805+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:00:24.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:00:24.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T21:00:55.242+0000] {processor.py:157} INFO - Started process (PID=77256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:00:55.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:00:55.245+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:00:55.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:00:55.259+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:00:55.274+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:00:55.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:00:55.287+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:00:55.287+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:00:55.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T21:01:25.733+0000] {processor.py:157} INFO - Started process (PID=77281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:01:25.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:01:25.735+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:01:25.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:01:25.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:01:25.762+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:01:25.762+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:01:25.772+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:01:25.772+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:01:25.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T21:01:56.143+0000] {processor.py:157} INFO - Started process (PID=77306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:01:56.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:01:56.145+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:01:56.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:01:56.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:01:56.172+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:01:56.172+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:01:56.181+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:01:56.181+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:01:56.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T21:02:26.628+0000] {processor.py:157} INFO - Started process (PID=77331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:02:26.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:02:26.635+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:02:26.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:02:26.642+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:02:26.657+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:02:26.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:02:26.670+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:02:26.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:02:26.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T21:02:57.163+0000] {processor.py:157} INFO - Started process (PID=77356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:02:57.164+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:02:57.166+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:02:57.166+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:02:57.176+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:02:57.191+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:02:57.191+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:02:57.201+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:02:57.201+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:02:57.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T21:03:27.696+0000] {processor.py:157} INFO - Started process (PID=77381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:03:27.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:03:27.699+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:03:27.699+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:03:27.708+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:03:27.723+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:03:27.723+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:03:27.733+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:03:27.732+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:03:27.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T21:03:58.142+0000] {processor.py:157} INFO - Started process (PID=77406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:03:58.143+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:03:58.145+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:03:58.145+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:03:58.156+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:03:58.173+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:03:58.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:03:58.184+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:03:58.184+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:03:58.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T21:04:28.566+0000] {processor.py:157} INFO - Started process (PID=77431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:04:28.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:04:28.570+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:04:28.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:04:28.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:04:28.598+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:04:28.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:04:28.608+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:04:28.608+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:04:28.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:04:59.037+0000] {processor.py:157} INFO - Started process (PID=77456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:04:59.037+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:04:59.040+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:04:59.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:04:59.048+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:04:59.063+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:04:59.063+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:04:59.073+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:04:59.073+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:04:59.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T21:05:29.517+0000] {processor.py:157} INFO - Started process (PID=77481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:05:29.518+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:05:29.520+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:05:29.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:05:29.535+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:05:29.549+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:05:29.549+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:05:29.558+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:05:29.558+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:05:29.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T21:05:59.979+0000] {processor.py:157} INFO - Started process (PID=77506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:05:59.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:05:59.982+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:05:59.982+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:05:59.992+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:06:00.007+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:06:00.007+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:06:00.017+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:06:00.017+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:06:00.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T21:06:30.446+0000] {processor.py:157} INFO - Started process (PID=77531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:06:30.446+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:06:30.449+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:06:30.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:06:30.459+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:06:30.475+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:06:30.475+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:06:30.485+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:06:30.485+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:06:30.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T21:07:00.985+0000] {processor.py:157} INFO - Started process (PID=77556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:07:00.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:07:00.988+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:07:00.988+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:07:00.999+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:07:01.015+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:07:01.015+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:07:01.027+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:07:01.027+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:07:01.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T21:07:31.393+0000] {processor.py:157} INFO - Started process (PID=77581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:07:31.394+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:07:31.395+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:07:31.395+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:07:31.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:07:31.421+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:07:31.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:07:31.433+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:07:31.433+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:07:31.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T21:08:01.855+0000] {processor.py:157} INFO - Started process (PID=77606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:08:01.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:08:01.859+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:08:01.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:08:01.872+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:08:01.887+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:08:01.887+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:08:01.899+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:08:01.899+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:08:01.908+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T21:08:32.320+0000] {processor.py:157} INFO - Started process (PID=77631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:08:32.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:08:32.323+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:08:32.323+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:08:32.333+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:08:32.348+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:08:32.348+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:08:32.358+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:08:32.358+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:08:32.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T21:09:02.862+0000] {processor.py:157} INFO - Started process (PID=77656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:09:02.863+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:09:02.865+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:09:02.865+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:09:02.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:09:02.893+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:09:02.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:09:02.904+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:09:02.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:09:02.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T21:09:33.421+0000] {processor.py:157} INFO - Started process (PID=77681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:09:33.421+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:09:33.423+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:09:33.423+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:09:33.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:09:33.449+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:09:33.449+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:09:33.460+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:09:33.460+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:09:33.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T21:10:03.836+0000] {processor.py:157} INFO - Started process (PID=77706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:10:03.837+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:10:03.838+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:10:03.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:10:03.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:10:03.865+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:10:03.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:10:03.874+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:10:03.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:10:03.883+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T21:10:34.347+0000] {processor.py:157} INFO - Started process (PID=77731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:10:34.348+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:10:34.350+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:10:34.350+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:10:34.363+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:10:34.380+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:10:34.379+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:10:34.392+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:10:34.392+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:10:34.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T21:11:04.808+0000] {processor.py:157} INFO - Started process (PID=77756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:11:04.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:11:04.813+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:11:04.813+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:11:04.825+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:11:04.841+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:11:04.841+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:11:04.853+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:11:04.853+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:11:04.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T21:11:35.329+0000] {processor.py:157} INFO - Started process (PID=77781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:11:35.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:11:35.332+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:11:35.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:11:35.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:11:35.361+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:11:35.360+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:11:35.370+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:11:35.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:11:35.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:12:05.812+0000] {processor.py:157} INFO - Started process (PID=77806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:12:05.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:12:05.815+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:12:05.814+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:12:05.824+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:12:05.839+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:12:05.839+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:12:05.848+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:12:05.848+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:12:05.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T21:12:36.228+0000] {processor.py:157} INFO - Started process (PID=77831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:12:36.229+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:12:36.231+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:12:36.231+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:12:36.242+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:12:36.260+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:12:36.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:12:36.270+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:12:36.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:12:36.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T21:13:06.715+0000] {processor.py:157} INFO - Started process (PID=77856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:13:06.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:13:06.718+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:13:06.718+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:13:06.728+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:13:06.746+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:13:06.746+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:13:06.755+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:13:06.755+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:13:06.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T21:13:37.155+0000] {processor.py:157} INFO - Started process (PID=77881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:13:37.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:13:37.158+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:13:37.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:13:37.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:13:37.189+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:13:37.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:13:37.199+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:13:37.199+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:13:37.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T21:14:07.641+0000] {processor.py:157} INFO - Started process (PID=77906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:14:07.643+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:14:07.645+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:14:07.644+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:14:07.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:14:07.676+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:14:07.676+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:14:07.687+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:14:07.687+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:14:07.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T21:14:38.067+0000] {processor.py:157} INFO - Started process (PID=77931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:14:38.068+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:14:38.070+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:14:38.070+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:14:38.084+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:14:38.105+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:14:38.105+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:14:38.116+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:14:38.116+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:14:38.126+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T21:15:08.509+0000] {processor.py:157} INFO - Started process (PID=77956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:15:08.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:15:08.512+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:15:08.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:15:08.523+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:15:08.539+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:15:08.539+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:15:08.548+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:15:08.548+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:15:08.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T21:15:38.965+0000] {processor.py:157} INFO - Started process (PID=77981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:15:38.966+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:15:38.968+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:15:38.968+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:15:38.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:15:38.998+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:15:38.998+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:15:39.008+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:15:39.008+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:15:39.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T21:16:09.440+0000] {processor.py:157} INFO - Started process (PID=78006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:16:09.441+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:16:09.443+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:16:09.443+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:16:09.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:16:09.473+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:16:09.473+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:16:09.482+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:16:09.482+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:16:09.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T21:16:39.854+0000] {processor.py:157} INFO - Started process (PID=78031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:16:39.855+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:16:39.856+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:16:39.856+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:16:39.867+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:16:39.882+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:16:39.882+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:16:39.896+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:16:39.896+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:16:39.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:17:10.328+0000] {processor.py:157} INFO - Started process (PID=78056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:17:10.328+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:17:10.329+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:17:10.329+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:17:10.345+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:17:10.358+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:17:10.358+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:17:10.370+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:17:10.370+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:17:10.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:17:40.858+0000] {processor.py:157} INFO - Started process (PID=78081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:17:40.859+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:17:40.861+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:17:40.861+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:17:40.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:17:40.889+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:17:40.889+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:17:40.900+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:17:40.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:17:40.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:18:11.382+0000] {processor.py:157} INFO - Started process (PID=78106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:18:11.383+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:18:11.385+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:18:11.385+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:18:11.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:18:11.412+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:18:11.412+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:18:11.421+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:18:11.421+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:18:11.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T21:18:41.860+0000] {processor.py:157} INFO - Started process (PID=78131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:18:41.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:18:41.864+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:18:41.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:18:41.877+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:18:41.894+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:18:41.894+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:18:41.906+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:18:41.906+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:18:41.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T21:19:12.313+0000] {processor.py:157} INFO - Started process (PID=78156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:19:12.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:19:12.317+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:19:12.317+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:19:12.327+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:19:12.343+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:19:12.343+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:19:12.353+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:19:12.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:19:12.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:19:42.719+0000] {processor.py:157} INFO - Started process (PID=78181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:19:42.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:19:42.724+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:19:42.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:19:42.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:19:42.760+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:19:42.760+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:19:42.771+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:19:42.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:19:42.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T21:20:13.242+0000] {processor.py:157} INFO - Started process (PID=78206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:20:13.243+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:20:13.244+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:20:13.244+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:20:13.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:20:13.269+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:20:13.269+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:20:13.279+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:20:13.279+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:20:13.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T21:20:43.715+0000] {processor.py:157} INFO - Started process (PID=78231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:20:43.717+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:20:43.719+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:20:43.719+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:20:43.737+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:20:43.751+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:20:43.751+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:20:43.760+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:20:43.760+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:20:43.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T21:21:14.216+0000] {processor.py:157} INFO - Started process (PID=78256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:21:14.218+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:21:14.219+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:21:14.219+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:21:14.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:21:14.244+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:21:14.244+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:21:14.254+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:21:14.254+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:21:14.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T21:21:44.658+0000] {processor.py:157} INFO - Started process (PID=78281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:21:44.659+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:21:44.661+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:21:44.661+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:21:44.673+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:21:44.688+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:21:44.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:21:44.697+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:21:44.697+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:21:44.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T21:22:15.091+0000] {processor.py:157} INFO - Started process (PID=78306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:22:15.092+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:22:15.094+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:22:15.094+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:22:15.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:22:15.122+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:22:15.122+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:22:15.132+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:22:15.132+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:22:15.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T21:22:45.593+0000] {processor.py:157} INFO - Started process (PID=78331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:22:45.594+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:22:45.596+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:22:45.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:22:45.611+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:22:45.625+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:22:45.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:22:45.637+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:22:45.637+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:22:45.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T21:23:16.019+0000] {processor.py:157} INFO - Started process (PID=78356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:23:16.021+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:23:16.022+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:23:16.022+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:23:16.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:23:16.044+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:23:16.044+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:23:16.053+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:23:16.053+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:23:16.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-19T21:23:46.529+0000] {processor.py:157} INFO - Started process (PID=78381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:23:46.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:23:46.532+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:23:46.531+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:23:46.543+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:23:46.561+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:23:46.561+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:23:46.570+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:23:46.570+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:23:46.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T21:24:17.025+0000] {processor.py:157} INFO - Started process (PID=78406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:24:17.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:24:17.033+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:24:17.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:24:17.041+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:24:17.054+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:24:17.054+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:24:17.063+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:24:17.063+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:24:17.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T21:24:47.429+0000] {processor.py:157} INFO - Started process (PID=78431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:24:47.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:24:47.431+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:24:47.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:24:47.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:24:47.459+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:24:47.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:24:47.469+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:24:47.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:24:47.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T21:25:17.948+0000] {processor.py:157} INFO - Started process (PID=78456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:25:17.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:25:17.950+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:25:17.950+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:25:17.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:25:17.976+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:25:17.976+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:25:17.986+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:25:17.986+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:25:17.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T21:25:48.444+0000] {processor.py:157} INFO - Started process (PID=78481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:25:48.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:25:48.448+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:25:48.448+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:25:48.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:25:48.475+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:25:48.474+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:25:48.484+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:25:48.484+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:25:48.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T21:26:18.975+0000] {processor.py:157} INFO - Started process (PID=78506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:26:18.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:26:18.978+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:26:18.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:26:18.988+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:26:19.004+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:26:19.004+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:26:19.014+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:26:19.014+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:26:19.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T21:26:49.402+0000] {processor.py:157} INFO - Started process (PID=78531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:26:49.403+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:26:49.405+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:26:49.405+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:26:49.417+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:26:49.431+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:26:49.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:26:49.444+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:26:49.443+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:26:49.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T21:27:19.800+0000] {processor.py:157} INFO - Started process (PID=78556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:27:19.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:27:19.804+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:27:19.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:27:19.819+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:27:19.833+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:27:19.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:27:19.844+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:27:19.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:27:19.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:27:50.211+0000] {processor.py:157} INFO - Started process (PID=78581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:27:50.213+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:27:50.214+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:27:50.214+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:27:50.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:27:50.242+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:27:50.242+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:27:50.251+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:27:50.251+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:27:50.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T21:28:20.743+0000] {processor.py:157} INFO - Started process (PID=78606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:28:20.744+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:28:20.746+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:28:20.746+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:28:20.760+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:28:20.773+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:28:20.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:28:20.785+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:28:20.785+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:28:20.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:28:51.192+0000] {processor.py:157} INFO - Started process (PID=78631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:28:51.193+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:28:51.194+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:28:51.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:28:51.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:28:51.221+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:28:51.221+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:28:51.233+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:28:51.233+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:28:51.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:29:21.689+0000] {processor.py:157} INFO - Started process (PID=78656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:29:21.690+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:29:21.692+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:29:21.692+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:29:21.705+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:29:21.719+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:29:21.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:29:21.730+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:29:21.730+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:29:21.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T21:29:52.170+0000] {processor.py:157} INFO - Started process (PID=78681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:29:52.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:29:52.173+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:29:52.173+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:29:52.188+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:29:52.201+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:29:52.201+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:29:52.210+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:29:52.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:29:52.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:30:22.643+0000] {processor.py:157} INFO - Started process (PID=78706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:30:22.644+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:30:22.645+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:30:22.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:30:22.655+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:30:22.673+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:30:22.673+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:30:22.683+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:30:22.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:30:22.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T21:30:53.093+0000] {processor.py:157} INFO - Started process (PID=78731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:30:53.094+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:30:53.095+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:30:53.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:30:53.106+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:30:53.121+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:30:53.121+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:30:53.132+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:30:53.131+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:30:53.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T21:31:23.507+0000] {processor.py:157} INFO - Started process (PID=78756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:31:23.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:31:23.509+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:31:23.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:31:23.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:31:23.536+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:31:23.536+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:31:23.547+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:31:23.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:31:23.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T21:31:53.973+0000] {processor.py:157} INFO - Started process (PID=78781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:31:53.974+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:31:53.975+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:31:53.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:31:53.991+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:31:54.011+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:31:54.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:31:54.020+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:31:54.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:31:54.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T21:32:24.372+0000] {processor.py:157} INFO - Started process (PID=78806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:32:24.373+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:32:24.375+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:32:24.375+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:32:24.387+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:32:24.403+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:32:24.402+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:32:24.414+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:32:24.413+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:32:24.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T21:32:54.860+0000] {processor.py:157} INFO - Started process (PID=78831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:32:54.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:32:54.863+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:32:54.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:32:54.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:32:54.893+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:32:54.893+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:32:54.904+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:32:54.904+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:32:54.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T21:33:25.279+0000] {processor.py:157} INFO - Started process (PID=78856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:33:25.281+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:33:25.283+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:33:25.283+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:33:25.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:33:25.311+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:33:25.311+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:33:25.324+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:33:25.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:33:25.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T21:33:55.730+0000] {processor.py:157} INFO - Started process (PID=78881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:33:55.733+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:33:55.735+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:33:55.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:33:55.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:33:55.768+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:33:55.768+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:33:55.781+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:33:55.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:33:55.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T21:34:26.188+0000] {processor.py:157} INFO - Started process (PID=78906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:34:26.190+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:34:26.192+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:34:26.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:34:26.205+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:34:26.220+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:34:26.220+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:34:26.231+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:34:26.231+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:34:26.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T21:34:56.591+0000] {processor.py:157} INFO - Started process (PID=78931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:34:56.592+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:34:56.594+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:34:56.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:34:56.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:34:56.625+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:34:56.625+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:34:56.634+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:34:56.634+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:34:56.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T21:35:27.108+0000] {processor.py:157} INFO - Started process (PID=78956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:35:27.110+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:35:27.111+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:35:27.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:35:27.129+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:35:27.143+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:35:27.143+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:35:27.153+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:35:27.153+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:35:27.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T21:35:57.568+0000] {processor.py:157} INFO - Started process (PID=78981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:35:57.570+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:35:57.572+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:35:57.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:35:57.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:35:57.598+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:35:57.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:35:57.609+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:35:57.609+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:35:57.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:36:28.109+0000] {processor.py:157} INFO - Started process (PID=79006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:36:28.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:36:28.111+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:36:28.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:36:28.126+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:36:28.142+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:36:28.142+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:36:28.151+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:36:28.151+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:36:28.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T21:36:58.613+0000] {processor.py:157} INFO - Started process (PID=79031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:36:58.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:36:58.618+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:36:58.618+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:36:58.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:36:58.647+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:36:58.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:36:58.669+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:36:58.669+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:36:58.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.078 seconds
[2024-07-19T21:37:29.150+0000] {processor.py:157} INFO - Started process (PID=79056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:37:29.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:37:29.154+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:37:29.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:37:29.166+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:37:29.185+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:37:29.185+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:37:29.196+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:37:29.196+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:37:29.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.059 seconds
[2024-07-19T21:37:59.609+0000] {processor.py:157} INFO - Started process (PID=79081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:37:59.611+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:37:59.612+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:37:59.612+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:37:59.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:37:59.640+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:37:59.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:37:59.649+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:37:59.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:37:59.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T21:38:30.117+0000] {processor.py:157} INFO - Started process (PID=79106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:38:30.119+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:38:30.121+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:38:30.121+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:38:30.135+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:38:30.152+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:38:30.152+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:38:30.162+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:38:30.162+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:38:30.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T21:39:00.554+0000] {processor.py:157} INFO - Started process (PID=79131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:39:00.556+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:39:00.558+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:39:00.558+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:39:00.567+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:39:00.585+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:39:00.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:39:00.595+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:39:00.595+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:39:00.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T21:39:30.972+0000] {processor.py:157} INFO - Started process (PID=79156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:39:30.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:39:30.975+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:39:30.975+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:39:30.989+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:39:31.008+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:39:31.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:39:31.019+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:39:31.019+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:39:31.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T21:40:01.431+0000] {processor.py:157} INFO - Started process (PID=79181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:40:01.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:40:01.434+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:40:01.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:40:01.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:40:01.461+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:40:01.461+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:40:01.471+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:40:01.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:40:01.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:40:31.969+0000] {processor.py:157} INFO - Started process (PID=79206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:40:31.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:40:31.972+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:40:31.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:40:31.983+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:40:32.000+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:40:31.999+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:40:32.009+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:40:32.009+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:40:32.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T21:41:02.465+0000] {processor.py:157} INFO - Started process (PID=79231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:41:02.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:41:02.468+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:41:02.467+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:41:02.479+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:41:02.495+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:41:02.495+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:41:02.504+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:41:02.504+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:41:02.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:41:32.913+0000] {processor.py:157} INFO - Started process (PID=79256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:41:32.914+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:41:32.915+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:41:32.915+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:41:32.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:41:32.943+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:41:32.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:41:32.956+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:41:32.956+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:41:32.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:42:03.431+0000] {processor.py:157} INFO - Started process (PID=79281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:42:03.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:42:03.433+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:42:03.433+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:42:03.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:42:03.459+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:42:03.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:42:03.469+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:42:03.468+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:42:03.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T21:42:33.940+0000] {processor.py:157} INFO - Started process (PID=79306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:42:33.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:42:33.942+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:42:33.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:42:33.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:42:33.970+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:42:33.970+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:42:33.982+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:42:33.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:42:33.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T21:43:04.445+0000] {processor.py:157} INFO - Started process (PID=79331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:43:04.445+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:43:04.447+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:43:04.447+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:43:04.458+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:43:04.476+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:43:04.476+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:43:04.487+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:43:04.487+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:43:04.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:43:34.936+0000] {processor.py:157} INFO - Started process (PID=79356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:43:34.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:43:34.939+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:43:34.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:43:34.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:43:34.966+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:43:34.966+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:43:34.977+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:43:34.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:43:34.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T21:44:05.371+0000] {processor.py:157} INFO - Started process (PID=79381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:44:05.372+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:44:05.374+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:44:05.374+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:44:05.389+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:44:05.403+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:44:05.403+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:44:05.415+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:44:05.415+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:44:05.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T21:44:35.862+0000] {processor.py:157} INFO - Started process (PID=79406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:44:35.864+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:44:35.866+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:44:35.866+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:44:35.875+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:44:35.891+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:44:35.891+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:44:35.902+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:44:35.902+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:44:35.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T21:45:06.291+0000] {processor.py:157} INFO - Started process (PID=79431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:45:06.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:45:06.293+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:45:06.293+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:45:06.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:45:06.320+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:45:06.320+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:45:06.333+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:45:06.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:45:06.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T21:45:36.831+0000] {processor.py:157} INFO - Started process (PID=79456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:45:36.832+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:45:36.834+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:45:36.834+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:45:36.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:45:36.860+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:45:36.860+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:45:36.870+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:45:36.870+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:45:36.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T21:46:07.228+0000] {processor.py:157} INFO - Started process (PID=79481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:46:07.235+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:46:07.238+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:46:07.238+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:46:07.246+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:46:07.260+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:46:07.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:46:07.270+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:46:07.270+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:46:07.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:46:37.655+0000] {processor.py:157} INFO - Started process (PID=79506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:46:37.657+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:46:37.659+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:46:37.658+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:46:37.671+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:46:37.689+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:46:37.689+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:46:37.702+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:46:37.701+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:46:37.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T21:47:08.116+0000] {processor.py:157} INFO - Started process (PID=79531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:47:08.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:47:08.120+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:47:08.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:47:08.132+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:47:08.148+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:47:08.148+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:47:08.158+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:47:08.158+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:47:08.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T21:47:38.584+0000] {processor.py:157} INFO - Started process (PID=79556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:47:38.585+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:47:38.587+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:47:38.586+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:47:38.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:47:38.613+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:47:38.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:47:38.625+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:47:38.624+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:47:38.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T21:48:09.097+0000] {processor.py:157} INFO - Started process (PID=79581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:48:09.099+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:48:09.101+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:48:09.101+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:48:09.109+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:48:09.125+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:48:09.125+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:48:09.135+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:48:09.135+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:48:09.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T21:48:39.567+0000] {processor.py:157} INFO - Started process (PID=79606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:48:39.568+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:48:39.570+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:48:39.570+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:48:39.583+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:48:39.596+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:48:39.596+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:48:39.610+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:48:39.610+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:48:39.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T21:49:09.962+0000] {processor.py:157} INFO - Started process (PID=79631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:49:09.963+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:49:09.965+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:49:09.965+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:49:09.979+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:49:09.993+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:49:09.993+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:49:10.003+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:49:10.003+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:49:10.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:49:40.446+0000] {processor.py:157} INFO - Started process (PID=79656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:49:40.447+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:49:40.449+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:49:40.449+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:49:40.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:49:40.477+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:49:40.477+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:49:40.488+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:49:40.488+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:49:40.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T21:50:10.891+0000] {processor.py:157} INFO - Started process (PID=79681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:50:10.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:50:10.894+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:50:10.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:50:10.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:50:10.923+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:50:10.923+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:50:10.934+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:50:10.934+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:50:10.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T21:50:41.307+0000] {processor.py:157} INFO - Started process (PID=79706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:50:41.308+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:50:41.310+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:50:41.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:50:41.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:50:41.336+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:50:41.336+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:50:41.346+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:50:41.346+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:50:41.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T21:51:11.773+0000] {processor.py:157} INFO - Started process (PID=79731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:51:11.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:51:11.776+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:51:11.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:51:11.787+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:51:11.804+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:51:11.804+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:51:11.815+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:51:11.815+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:51:11.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T21:51:42.271+0000] {processor.py:157} INFO - Started process (PID=79756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:51:42.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:51:42.276+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:51:42.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:51:42.290+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:51:42.305+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:51:42.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:51:42.316+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:51:42.316+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:51:42.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T21:52:12.680+0000] {processor.py:157} INFO - Started process (PID=79781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:52:12.681+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:52:12.684+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:52:12.684+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:52:12.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:52:12.710+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:52:12.710+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:52:12.720+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:52:12.720+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:52:12.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T21:52:43.198+0000] {processor.py:157} INFO - Started process (PID=79806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:52:43.199+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:52:43.200+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:52:43.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:52:43.211+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:52:43.226+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:52:43.226+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:52:43.236+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:52:43.235+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:52:43.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T21:53:13.671+0000] {processor.py:157} INFO - Started process (PID=79831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:53:13.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:53:13.674+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:53:13.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:53:13.684+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:53:13.706+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:53:13.706+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:53:13.716+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:53:13.715+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:53:13.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T21:53:44.096+0000] {processor.py:157} INFO - Started process (PID=79856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:53:44.097+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:53:44.099+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:53:44.099+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:53:44.111+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:53:44.126+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:53:44.126+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:53:44.137+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:53:44.137+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:53:44.145+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T21:54:14.519+0000] {processor.py:157} INFO - Started process (PID=79881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:54:14.520+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:54:14.521+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:54:14.521+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:54:14.534+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:54:14.550+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:54:14.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:54:14.560+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:54:14.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:54:14.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:54:45.043+0000] {processor.py:157} INFO - Started process (PID=79906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:54:45.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:54:45.046+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:54:45.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:54:45.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:54:45.074+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:54:45.074+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:54:45.083+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:54:45.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:54:45.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T21:55:15.475+0000] {processor.py:157} INFO - Started process (PID=79931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:55:15.478+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:55:15.480+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:55:15.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:55:15.498+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:55:15.512+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:55:15.512+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:55:15.523+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:55:15.523+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:55:15.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T21:55:45.915+0000] {processor.py:157} INFO - Started process (PID=79956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:55:45.915+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:55:45.917+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:55:45.917+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:55:45.926+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:55:45.943+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:55:45.943+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:55:45.953+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:55:45.953+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:55:45.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T21:56:16.460+0000] {processor.py:157} INFO - Started process (PID=79981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:56:16.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:56:16.463+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:56:16.462+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:56:16.480+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:56:16.497+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:56:16.497+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:56:16.509+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:56:16.509+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:56:16.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.061 seconds
[2024-07-19T21:56:46.837+0000] {processor.py:157} INFO - Started process (PID=80006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:56:46.838+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:56:46.840+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:56:46.840+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:56:46.849+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:56:46.865+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:56:46.865+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:56:46.875+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:56:46.875+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:56:46.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T21:57:17.285+0000] {processor.py:157} INFO - Started process (PID=80031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:57:17.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:57:17.287+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:57:17.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:57:17.298+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:57:17.314+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:57:17.314+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:57:17.324+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:57:17.324+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:57:17.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T21:57:47.791+0000] {processor.py:157} INFO - Started process (PID=80056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:57:47.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:57:47.793+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:57:47.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:57:47.803+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:57:47.819+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:57:47.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:57:47.828+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:57:47.828+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:57:47.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T21:58:18.290+0000] {processor.py:157} INFO - Started process (PID=80081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:58:18.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:58:18.294+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:58:18.294+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:58:18.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:58:18.322+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:58:18.322+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:58:18.333+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:58:18.333+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:58:18.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:58:48.758+0000] {processor.py:157} INFO - Started process (PID=80106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:58:48.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:58:48.761+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:58:48.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:58:48.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:58:48.791+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:58:48.791+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:58:48.801+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:58:48.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:58:48.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T21:59:19.159+0000] {processor.py:157} INFO - Started process (PID=80131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:59:19.160+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:59:19.162+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:59:19.162+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:59:19.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:59:19.188+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:59:19.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:59:19.202+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:59:19.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:59:19.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T21:59:49.641+0000] {processor.py:157} INFO - Started process (PID=80156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:59:49.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T21:59:49.649+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:59:49.649+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:59:49.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T21:59:49.674+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:59:49.674+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T21:59:49.683+0000] {logging_mixin.py:151} INFO - [2024-07-19T21:59:49.683+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T21:59:49.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T22:00:20.052+0000] {processor.py:157} INFO - Started process (PID=80181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:00:20.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:00:20.054+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:00:20.054+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:00:20.065+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:00:20.080+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:00:20.080+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:00:20.090+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:00:20.090+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:00:20.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T22:00:50.586+0000] {processor.py:157} INFO - Started process (PID=80206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:00:50.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:00:50.590+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:00:50.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:00:50.605+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:00:50.620+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:00:50.620+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:00:50.630+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:00:50.629+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:00:50.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T22:01:21.004+0000] {processor.py:157} INFO - Started process (PID=80231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:01:21.005+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:01:21.007+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:01:21.006+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:01:21.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:01:21.028+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:01:21.028+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:01:21.038+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:01:21.038+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:01:21.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.043 seconds
[2024-07-19T22:01:51.485+0000] {processor.py:157} INFO - Started process (PID=80256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:01:51.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:01:51.489+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:01:51.489+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:01:51.501+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:01:51.516+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:01:51.516+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:01:51.528+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:01:51.528+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:01:51.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T22:02:21.943+0000] {processor.py:157} INFO - Started process (PID=80281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:02:21.944+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:02:21.946+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:02:21.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:02:21.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:02:21.971+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:02:21.971+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:02:21.982+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:02:21.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:02:21.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T22:02:52.406+0000] {processor.py:157} INFO - Started process (PID=80306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:02:52.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:02:52.409+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:02:52.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:02:52.423+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:02:52.437+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:02:52.437+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:02:52.446+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:02:52.446+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:02:52.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T22:03:22.849+0000] {processor.py:157} INFO - Started process (PID=80331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:03:22.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:03:22.853+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:03:22.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:03:22.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:03:22.881+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:03:22.881+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:03:22.890+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:03:22.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:03:22.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T22:03:53.310+0000] {processor.py:157} INFO - Started process (PID=80356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:03:53.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:03:53.313+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:03:53.313+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:03:53.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:03:53.342+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:03:53.342+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:03:53.352+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:03:53.352+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:03:53.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T22:04:23.734+0000] {processor.py:157} INFO - Started process (PID=80381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:04:23.735+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:04:23.737+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:04:23.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:04:23.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:04:23.761+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:04:23.761+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:04:23.771+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:04:23.771+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:04:23.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T22:04:54.113+0000] {processor.py:157} INFO - Started process (PID=80406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:04:54.115+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:04:54.116+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:04:54.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:04:54.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:04:54.137+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:04:54.137+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:04:54.146+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:04:54.146+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:04:54.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.044 seconds
[2024-07-19T22:05:24.606+0000] {processor.py:157} INFO - Started process (PID=80431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:05:24.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:05:24.610+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:05:24.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:05:24.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:05:24.641+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:05:24.640+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:05:24.651+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:05:24.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:05:24.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T22:05:55.144+0000] {processor.py:157} INFO - Started process (PID=80456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:05:55.144+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:05:55.147+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:05:55.146+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:05:55.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:05:55.174+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:05:55.173+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:05:55.183+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:05:55.183+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:05:55.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T22:06:25.613+0000] {processor.py:157} INFO - Started process (PID=80481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:06:25.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:06:25.616+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:06:25.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:06:25.626+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:06:25.641+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:06:25.641+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:06:25.651+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:06:25.651+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:06:25.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T22:06:56.106+0000] {processor.py:157} INFO - Started process (PID=80506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:06:56.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:06:56.111+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:06:56.110+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:06:56.121+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:06:56.136+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:06:56.135+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:06:56.147+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:06:56.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:06:56.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T22:07:26.565+0000] {processor.py:157} INFO - Started process (PID=80531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:07:26.567+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:07:26.569+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:07:26.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:07:26.582+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:07:26.598+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:07:26.598+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:07:26.607+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:07:26.607+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:07:26.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T22:07:57.027+0000] {processor.py:157} INFO - Started process (PID=80556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:07:57.028+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:07:57.029+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:07:57.029+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:07:57.045+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:07:57.058+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:07:57.058+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:07:57.070+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:07:57.070+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:07:57.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T22:08:27.425+0000] {processor.py:157} INFO - Started process (PID=80581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:08:27.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:08:27.429+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:08:27.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:08:27.446+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:08:27.459+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:08:27.459+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:08:27.469+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:08:27.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:08:27.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T22:08:57.935+0000] {processor.py:157} INFO - Started process (PID=80606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:08:57.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:08:57.938+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:08:57.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:08:57.955+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:08:57.974+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:08:57.974+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:08:57.984+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:08:57.984+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:08:57.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T22:09:28.402+0000] {processor.py:157} INFO - Started process (PID=80631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:09:28.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:09:28.407+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:09:28.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:09:28.416+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:09:28.431+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:09:28.431+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:09:28.440+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:09:28.440+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:09:28.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T22:09:58.902+0000] {processor.py:157} INFO - Started process (PID=80656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:09:58.903+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:09:58.905+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:09:58.905+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:09:58.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:09:58.932+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:09:58.932+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:09:58.942+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:09:58.942+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:09:58.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T22:10:29.440+0000] {processor.py:157} INFO - Started process (PID=80681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:10:29.442+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:10:29.445+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:10:29.444+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:10:29.453+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:10:29.469+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:10:29.469+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:10:29.481+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:10:29.481+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:10:29.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T22:11:00.005+0000] {processor.py:157} INFO - Started process (PID=80706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:11:00.007+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:11:00.008+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:11:00.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:11:00.021+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:11:00.037+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:11:00.037+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:11:00.048+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:11:00.047+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:11:00.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T22:11:30.391+0000] {processor.py:157} INFO - Started process (PID=80731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:11:30.392+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:11:30.393+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:11:30.393+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:11:30.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:11:30.421+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:11:30.421+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:11:30.434+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:11:30.434+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:11:30.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T22:12:00.802+0000] {processor.py:157} INFO - Started process (PID=80756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:12:00.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:12:00.805+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:12:00.805+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:12:00.818+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:12:00.833+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:12:00.833+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:12:00.845+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:12:00.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:12:00.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T22:12:31.317+0000] {processor.py:157} INFO - Started process (PID=80781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:12:31.319+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:12:31.321+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:12:31.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:12:31.334+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:12:31.353+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:12:31.353+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:12:31.362+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:12:31.362+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:12:31.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T22:13:01.733+0000] {processor.py:157} INFO - Started process (PID=80806) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:13:01.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:13:01.736+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:13:01.736+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:13:01.747+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:13:01.765+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:13:01.765+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:13:01.775+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:13:01.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:13:01.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T22:13:32.224+0000] {processor.py:157} INFO - Started process (PID=80831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:13:32.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:13:32.229+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:13:32.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:13:32.239+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:13:32.253+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:13:32.253+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:13:32.263+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:13:32.263+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:13:32.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T22:14:02.653+0000] {processor.py:157} INFO - Started process (PID=80856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:14:02.656+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:14:02.660+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:14:02.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:14:02.670+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:14:02.684+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:14:02.684+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:14:02.693+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:14:02.693+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:14:02.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T22:14:33.058+0000] {processor.py:157} INFO - Started process (PID=80881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:14:33.058+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:14:33.061+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:14:33.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:14:33.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:14:33.094+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:14:33.094+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:14:33.103+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:14:33.103+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:14:33.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T22:15:03.496+0000] {processor.py:157} INFO - Started process (PID=80906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:15:03.497+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:15:03.498+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:15:03.498+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:15:03.510+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:15:03.525+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:15:03.525+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:15:03.537+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:15:03.537+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:15:03.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T22:15:33.954+0000] {processor.py:157} INFO - Started process (PID=80931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:15:33.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:15:33.959+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:15:33.959+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:15:33.977+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:15:33.995+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:15:33.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:15:34.006+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:15:34.006+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:15:34.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.065 seconds
[2024-07-19T22:16:04.456+0000] {processor.py:157} INFO - Started process (PID=80956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:16:04.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:16:04.458+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:16:04.458+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:16:04.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:16:04.487+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:16:04.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:16:04.496+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:16:04.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:16:04.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T22:16:34.968+0000] {processor.py:157} INFO - Started process (PID=80981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:16:34.970+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:16:34.972+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:16:34.972+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:16:34.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:16:34.995+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:16:34.995+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:16:35.005+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:16:35.005+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:16:35.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T22:17:05.428+0000] {processor.py:157} INFO - Started process (PID=81006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:17:05.429+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:17:05.432+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:17:05.431+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:17:05.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:17:05.458+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:17:05.458+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:17:05.472+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:17:05.471+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:17:05.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T22:17:35.891+0000] {processor.py:157} INFO - Started process (PID=81031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:17:35.892+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:17:35.894+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:17:35.894+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:17:35.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:17:35.924+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:17:35.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:17:35.937+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:17:35.936+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:17:35.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T22:18:06.351+0000] {processor.py:157} INFO - Started process (PID=81056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:18:06.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:18:06.353+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:18:06.353+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:18:06.368+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:18:06.385+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:18:06.385+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:18:06.394+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:18:06.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:18:06.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T22:18:36.857+0000] {processor.py:157} INFO - Started process (PID=81081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:18:36.858+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:18:36.859+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:18:36.859+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:18:36.870+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:18:36.885+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:18:36.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:18:36.895+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:18:36.895+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:18:36.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T22:19:07.322+0000] {processor.py:157} INFO - Started process (PID=81106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:19:07.324+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:19:07.326+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:19:07.326+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:19:07.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:19:07.355+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:19:07.355+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:19:07.364+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:19:07.364+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:19:07.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T22:19:37.756+0000] {processor.py:157} INFO - Started process (PID=81131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:19:37.757+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:19:37.759+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:19:37.758+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:19:37.770+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:19:37.785+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:19:37.785+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:19:37.795+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:19:37.795+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:19:37.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T22:20:08.241+0000] {processor.py:157} INFO - Started process (PID=81156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:20:08.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:20:08.251+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:20:08.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:20:08.260+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:20:08.274+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:20:08.274+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:20:08.282+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:20:08.282+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:20:08.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T22:20:38.737+0000] {processor.py:157} INFO - Started process (PID=81181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:20:38.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:20:38.739+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:20:38.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:20:38.748+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:20:38.763+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:20:38.763+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:20:38.773+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:20:38.773+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:20:38.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T22:21:09.153+0000] {processor.py:157} INFO - Started process (PID=81206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:21:09.156+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:21:09.158+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:21:09.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:21:09.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:21:09.188+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:21:09.188+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:21:09.198+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:21:09.198+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:21:09.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T22:21:39.608+0000] {processor.py:157} INFO - Started process (PID=81231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:21:39.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:21:39.611+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:21:39.610+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:21:39.621+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:21:39.636+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:21:39.636+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:21:39.645+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:21:39.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:21:39.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T22:22:09.984+0000] {processor.py:157} INFO - Started process (PID=81256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:22:09.985+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:22:09.986+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:22:09.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:22:09.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:22:10.008+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:22:10.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:22:10.022+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:22:10.022+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:22:10.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T22:22:40.456+0000] {processor.py:157} INFO - Started process (PID=81281) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:22:40.456+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:22:40.458+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:22:40.457+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:22:40.472+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:22:40.487+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:22:40.487+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:22:40.497+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:22:40.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:22:40.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T22:23:11.019+0000] {processor.py:157} INFO - Started process (PID=81306) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:23:11.020+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:23:11.021+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:23:11.021+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:23:11.030+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:23:11.045+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:23:11.045+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:23:11.056+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:23:11.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:23:11.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T22:23:41.518+0000] {processor.py:157} INFO - Started process (PID=81331) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:23:41.521+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:23:41.523+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:23:41.523+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:23:41.540+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:23:41.553+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:23:41.553+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:23:41.563+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:23:41.562+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:23:41.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T22:24:12.023+0000] {processor.py:157} INFO - Started process (PID=81356) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:24:12.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:24:12.026+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:24:12.026+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:24:12.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:24:12.052+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:24:12.052+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:24:12.062+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:24:12.062+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:24:12.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T22:24:42.480+0000] {processor.py:157} INFO - Started process (PID=81381) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:24:42.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:24:42.483+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:24:42.482+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:24:42.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:24:42.508+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:24:42.508+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:24:42.518+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:24:42.518+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:24:42.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T22:25:12.920+0000] {processor.py:157} INFO - Started process (PID=81406) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:25:12.921+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:25:12.923+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:25:12.923+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:25:12.936+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:25:12.951+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:25:12.951+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:25:12.960+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:25:12.960+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:25:12.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T22:25:43.453+0000] {processor.py:157} INFO - Started process (PID=81431) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:25:43.454+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:25:43.456+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:25:43.455+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:25:43.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:25:43.485+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:25:43.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:25:43.495+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:25:43.495+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:25:43.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T22:26:13.930+0000] {processor.py:157} INFO - Started process (PID=81456) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:26:13.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:26:13.933+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:26:13.933+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:26:13.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:26:13.968+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:26:13.968+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:26:13.977+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:26:13.977+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:26:13.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T22:26:44.350+0000] {processor.py:157} INFO - Started process (PID=81481) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:26:44.351+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:26:44.352+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:26:44.352+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:26:44.364+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:26:44.380+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:26:44.380+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:26:44.394+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:26:44.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:26:44.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T22:27:14.789+0000] {processor.py:157} INFO - Started process (PID=81506) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:27:14.790+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:27:14.792+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:27:14.792+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:27:14.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:27:14.821+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:27:14.821+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:27:14.830+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:27:14.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:27:14.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T22:27:45.279+0000] {processor.py:157} INFO - Started process (PID=81531) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:27:45.280+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:27:45.281+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:27:45.281+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:27:45.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:27:45.307+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:27:45.307+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:27:45.320+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:27:45.320+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:27:45.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T22:28:15.713+0000] {processor.py:157} INFO - Started process (PID=81556) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:28:15.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:28:15.718+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:28:15.717+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:28:15.729+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:28:15.744+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:28:15.744+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:28:15.754+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:28:15.754+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:28:15.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T22:28:46.156+0000] {processor.py:157} INFO - Started process (PID=81581) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:28:46.157+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:28:46.158+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:28:46.158+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:28:46.174+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:28:46.189+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:28:46.189+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:28:46.202+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:28:46.202+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:28:46.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T22:29:16.564+0000] {processor.py:157} INFO - Started process (PID=81606) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:29:16.565+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:29:16.566+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:29:16.566+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:29:16.574+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:29:16.587+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:29:16.587+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:29:16.596+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:29:16.596+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:29:16.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.042 seconds
[2024-07-19T22:29:47.041+0000] {processor.py:157} INFO - Started process (PID=81631) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:29:47.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:29:47.044+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:29:47.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:29:47.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:29:47.072+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:29:47.072+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:29:47.082+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:29:47.082+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:29:47.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T22:30:17.532+0000] {processor.py:157} INFO - Started process (PID=81656) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:30:17.533+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:30:17.535+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:30:17.535+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:30:17.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:30:17.562+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:30:17.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:30:17.574+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:30:17.574+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:30:17.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T22:30:48.061+0000] {processor.py:157} INFO - Started process (PID=81681) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:30:48.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:30:48.065+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:30:48.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:30:48.078+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:30:48.091+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:30:48.091+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:30:48.102+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:30:48.102+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:30:48.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T22:31:18.535+0000] {processor.py:157} INFO - Started process (PID=81706) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:31:18.536+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:31:18.538+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:31:18.538+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:31:18.550+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:31:18.567+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:31:18.567+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:31:18.578+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:31:18.578+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:31:18.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T22:31:48.980+0000] {processor.py:157} INFO - Started process (PID=81731) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:31:48.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:31:48.983+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:31:48.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:31:48.995+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:31:49.011+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:31:49.011+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:31:49.021+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:31:49.021+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:31:49.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T22:32:19.469+0000] {processor.py:157} INFO - Started process (PID=81756) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:32:19.470+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:32:19.471+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:32:19.471+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:32:19.482+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:32:19.499+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:32:19.499+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:32:19.510+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:32:19.510+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:32:19.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T22:32:49.974+0000] {processor.py:157} INFO - Started process (PID=81781) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:32:49.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:32:49.978+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:32:49.978+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:32:49.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:32:50.008+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:32:50.008+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:32:50.018+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:32:50.018+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:32:50.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T22:33:20.432+0000] {processor.py:157} INFO - Started process (PID=81805) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:33:20.433+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:33:20.435+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:33:20.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:33:20.450+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:33:20.464+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:33:20.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:33:20.474+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:33:20.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:33:20.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T22:33:50.898+0000] {processor.py:157} INFO - Started process (PID=81831) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:33:50.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:33:50.903+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:33:50.902+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:33:50.915+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:33:50.936+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:33:50.936+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:33:50.952+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:33:50.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:33:50.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.069 seconds
[2024-07-19T22:34:21.405+0000] {processor.py:157} INFO - Started process (PID=81856) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:34:21.406+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:34:21.410+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:34:21.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:34:21.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:34:21.436+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:34:21.435+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:34:21.448+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:34:21.448+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:34:21.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T22:34:51.877+0000] {processor.py:157} INFO - Started process (PID=81881) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:34:51.878+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:34:51.880+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:34:51.880+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:34:51.893+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:34:51.909+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:34:51.909+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:34:51.918+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:34:51.918+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:34:51.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T22:35:22.299+0000] {processor.py:157} INFO - Started process (PID=81906) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:35:22.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:35:22.304+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:35:22.303+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:35:22.317+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:35:22.331+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:35:22.331+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:35:22.342+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:35:22.342+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:35:22.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T22:35:52.747+0000] {processor.py:157} INFO - Started process (PID=81931) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:35:52.748+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:35:52.749+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:35:52.749+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:35:52.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:35:52.773+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:35:52.773+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:35:52.782+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:35:52.782+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:35:52.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T22:36:23.293+0000] {processor.py:157} INFO - Started process (PID=81956) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:36:23.295+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:36:23.297+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:36:23.296+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:36:23.306+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:36:23.324+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:36:23.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:36:23.336+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:36:23.336+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:36:23.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T22:36:53.761+0000] {processor.py:157} INFO - Started process (PID=81981) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:36:53.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:36:53.764+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:36:53.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:36:53.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:36:53.792+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:36:53.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:36:53.805+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:36:53.805+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:36:53.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T22:37:24.272+0000] {processor.py:157} INFO - Started process (PID=82006) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:37:24.274+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:37:24.276+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:37:24.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:37:24.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:37:24.306+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:37:24.306+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:37:24.319+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:37:24.319+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:37:24.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T22:37:54.791+0000] {processor.py:157} INFO - Started process (PID=82031) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:37:54.791+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:37:54.794+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:37:54.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:37:54.806+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:37:54.824+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:37:54.824+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:37:54.834+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:37:54.834+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:37:54.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T22:38:25.226+0000] {processor.py:157} INFO - Started process (PID=82056) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:38:25.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:38:25.229+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:38:25.229+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:38:25.247+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:38:25.260+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:38:25.260+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:38:25.271+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:38:25.271+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:38:25.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T22:38:55.760+0000] {processor.py:157} INFO - Started process (PID=82081) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:38:55.761+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:38:55.763+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:38:55.763+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:38:55.777+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:38:55.792+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:38:55.792+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:38:55.800+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:38:55.800+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:38:55.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T22:39:26.274+0000] {processor.py:157} INFO - Started process (PID=82106) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:39:26.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:39:26.277+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:39:26.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:39:26.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:39:26.305+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:39:26.305+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:39:26.316+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:39:26.315+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:39:26.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T22:39:56.738+0000] {processor.py:157} INFO - Started process (PID=82131) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:39:56.740+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:39:56.741+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:39:56.741+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:39:56.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:39:56.769+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:39:56.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:39:56.779+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:39:56.779+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:39:56.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T22:40:27.170+0000] {processor.py:157} INFO - Started process (PID=82156) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:40:27.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:40:27.172+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:40:27.171+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:40:27.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:40:27.198+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:40:27.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:40:27.210+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:40:27.210+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:40:27.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T22:40:57.612+0000] {processor.py:157} INFO - Started process (PID=82181) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:40:57.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:40:57.615+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:40:57.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:40:57.624+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:40:57.640+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:40:57.639+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:40:57.649+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:40:57.649+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:40:57.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T22:41:28.015+0000] {processor.py:157} INFO - Started process (PID=82206) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:41:28.016+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:41:28.018+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:41:28.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:41:28.027+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:41:28.043+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:41:28.043+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:41:28.056+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:41:28.056+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:41:28.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T22:41:58.530+0000] {processor.py:157} INFO - Started process (PID=82231) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:41:58.534+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:41:58.537+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:41:58.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:41:58.551+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:41:58.575+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:41:58.575+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:41:58.587+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:41:58.587+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:41:58.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.079 seconds
[2024-07-19T22:58:36.284+0000] {processor.py:157} INFO - Started process (PID=82256) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:58:36.285+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:58:36.288+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:58:36.287+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:58:36.305+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:58:36.319+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:58:36.319+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:58:36.331+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:58:36.331+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:58:36.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.060 seconds
[2024-07-19T22:59:06.769+0000] {processor.py:157} INFO - Started process (PID=82283) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:59:06.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:59:06.772+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:59:06.772+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:59:06.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:59:06.799+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:59:06.799+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:59:06.810+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:59:06.810+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:59:06.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T22:59:37.251+0000] {processor.py:157} INFO - Started process (PID=82308) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:59:37.252+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T22:59:37.253+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:59:37.253+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:59:37.266+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T22:59:37.280+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:59:37.280+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T22:59:37.291+0000] {logging_mixin.py:151} INFO - [2024-07-19T22:59:37.291+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T22:59:37.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:00:07.624+0000] {processor.py:157} INFO - Started process (PID=82333) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:00:07.626+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:00:07.627+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:00:07.627+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:00:07.644+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:00:07.657+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:00:07.657+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:00:07.666+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:00:07.666+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:00:07.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T23:00:38.028+0000] {processor.py:157} INFO - Started process (PID=82358) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:00:38.030+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:00:38.033+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:00:38.032+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:00:38.047+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:00:38.066+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:00:38.066+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:00:38.077+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:00:38.077+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:00:38.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T23:01:08.551+0000] {processor.py:157} INFO - Started process (PID=82383) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:01:08.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:01:08.554+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:01:08.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:01:08.570+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:01:08.585+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:01:08.585+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:01:08.597+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:01:08.597+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:01:08.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T23:01:38.989+0000] {processor.py:157} INFO - Started process (PID=82408) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:01:38.989+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:01:38.991+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:01:38.991+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:01:39.002+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:01:39.018+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:01:39.018+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:01:39.029+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:01:39.029+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:01:39.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:06:57.341+0000] {processor.py:157} INFO - Started process (PID=82435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:06:57.341+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:06:57.343+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:06:57.343+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:06:57.356+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:06:57.370+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:06:57.370+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:06:57.378+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:06:57.378+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:06:57.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T23:07:27.758+0000] {processor.py:157} INFO - Started process (PID=82459) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:07:27.759+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:07:27.761+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:07:27.761+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:07:27.773+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:07:27.789+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:07:27.789+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:07:27.801+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:07:27.801+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:07:27.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T23:07:58.301+0000] {processor.py:157} INFO - Started process (PID=82485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:07:58.303+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:07:58.305+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:07:58.305+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:07:58.321+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:07:58.340+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:07:58.340+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:07:58.353+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:07:58.353+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:07:58.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.066 seconds
[2024-07-19T23:08:28.850+0000] {processor.py:157} INFO - Started process (PID=82510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:08:28.851+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:08:28.853+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:08:28.852+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:08:28.868+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:08:28.885+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:08:28.885+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:08:28.894+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:08:28.894+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:08:28.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T23:08:59.298+0000] {processor.py:157} INFO - Started process (PID=82535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:08:59.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:08:59.300+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:08:59.300+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:08:59.314+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:08:59.328+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:08:59.328+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:08:59.340+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:08:59.340+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:08:59.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T23:09:29.725+0000] {processor.py:157} INFO - Started process (PID=82560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:09:29.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:09:29.727+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:09:29.727+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:09:29.739+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:09:29.755+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:09:29.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:09:29.765+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:09:29.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:09:29.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T23:10:00.242+0000] {processor.py:157} INFO - Started process (PID=82585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:10:00.245+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:10:00.247+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:10:00.247+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:10:00.255+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:10:00.271+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:10:00.271+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:10:00.281+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:10:00.281+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:10:00.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T23:10:30.708+0000] {processor.py:157} INFO - Started process (PID=82610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:10:30.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:10:30.711+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:10:30.711+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:10:30.722+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:10:30.735+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:10:30.735+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:10:30.745+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:10:30.745+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:10:30.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.046 seconds
[2024-07-19T23:11:01.166+0000] {processor.py:157} INFO - Started process (PID=82635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:11:01.166+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:11:01.169+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:11:01.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:11:01.182+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:11:01.197+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:11:01.197+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:11:01.207+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:11:01.207+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:11:01.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T23:11:31.612+0000] {processor.py:157} INFO - Started process (PID=82660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:11:31.613+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:11:31.614+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:11:31.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:11:31.629+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:11:31.645+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:11:31.644+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:11:31.654+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:11:31.654+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:11:31.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T23:12:01.981+0000] {processor.py:157} INFO - Started process (PID=82685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:12:01.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:12:01.983+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:12:01.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:12:01.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:12:02.012+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:12:02.012+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:12:02.024+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:12:02.023+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:12:02.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T23:12:32.434+0000] {processor.py:157} INFO - Started process (PID=82710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:12:32.435+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:12:32.438+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:12:32.438+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:12:32.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:12:32.467+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:12:32.467+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:12:32.478+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:12:32.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:12:32.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T23:13:02.852+0000] {processor.py:157} INFO - Started process (PID=82735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:13:02.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:13:02.855+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:13:02.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:13:02.866+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:13:02.880+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:13:02.880+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:13:02.890+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:13:02.890+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:13:02.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T23:13:33.334+0000] {processor.py:157} INFO - Started process (PID=82760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:13:33.337+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:13:33.339+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:13:33.338+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:13:33.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:13:33.366+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:13:33.366+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:13:33.376+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:13:33.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:13:33.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T23:14:03.825+0000] {processor.py:157} INFO - Started process (PID=82785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:14:03.826+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:14:03.828+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:14:03.828+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:14:03.838+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:14:03.850+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:14:03.850+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:14:03.862+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:14:03.862+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:14:03.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T23:14:34.231+0000] {processor.py:157} INFO - Started process (PID=82810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:14:34.231+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:14:34.233+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:14:34.233+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:14:34.249+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:14:34.263+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:14:34.263+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:14:34.274+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:14:34.274+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:14:34.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:15:04.635+0000] {processor.py:157} INFO - Started process (PID=82835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:15:04.636+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:15:04.638+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:15:04.638+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:15:04.650+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:15:04.664+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:15:04.664+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:15:04.677+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:15:04.677+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:15:04.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T23:15:35.041+0000] {processor.py:157} INFO - Started process (PID=82860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:15:35.043+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:15:35.046+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:15:35.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:15:35.056+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:15:35.071+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:15:35.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:15:35.085+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:15:35.085+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:15:35.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T23:16:05.503+0000] {processor.py:157} INFO - Started process (PID=82885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:16:05.507+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:16:05.509+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:16:05.509+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:16:05.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:16:05.534+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:16:05.534+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:16:05.544+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:16:05.544+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:16:05.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:16:35.981+0000] {processor.py:157} INFO - Started process (PID=82910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:16:35.981+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:16:35.983+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:16:35.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:16:35.997+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:16:36.016+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:16:36.016+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:16:36.027+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:16:36.026+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:16:36.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T23:17:06.438+0000] {processor.py:157} INFO - Started process (PID=82935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:17:06.439+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:17:06.441+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:17:06.441+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:17:06.454+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:17:06.468+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:17:06.468+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:17:06.478+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:17:06.478+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:17:06.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T23:17:36.885+0000] {processor.py:157} INFO - Started process (PID=82960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:17:36.886+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:17:36.887+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:17:36.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:17:36.900+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:17:36.913+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:17:36.913+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:17:36.925+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:17:36.925+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:17:36.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T23:18:07.366+0000] {processor.py:157} INFO - Started process (PID=82985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:18:07.367+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:18:07.369+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:18:07.369+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:18:07.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:18:07.401+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:18:07.401+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:18:07.412+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:18:07.412+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:18:07.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T23:18:37.860+0000] {processor.py:157} INFO - Started process (PID=83010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:18:37.861+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:18:37.863+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:18:37.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:18:37.874+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:18:37.890+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:18:37.890+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:18:37.900+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:18:37.900+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:18:37.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:19:08.402+0000] {processor.py:157} INFO - Started process (PID=83035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:19:08.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:19:08.406+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:19:08.406+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:19:08.415+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:19:08.432+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:19:08.432+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:19:08.442+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:19:08.442+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:19:08.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T23:19:38.892+0000] {processor.py:157} INFO - Started process (PID=83060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:19:38.894+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:19:38.896+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:19:38.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:19:38.909+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:19:38.924+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:19:38.924+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:19:38.933+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:19:38.933+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:19:38.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:20:09.405+0000] {processor.py:157} INFO - Started process (PID=83085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:20:09.405+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:20:09.407+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:20:09.407+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:20:09.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:20:09.434+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:20:09.434+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:20:09.444+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:20:09.444+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:20:09.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T23:20:39.958+0000] {processor.py:157} INFO - Started process (PID=83110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:20:39.959+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:20:39.960+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:20:39.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:20:39.971+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:20:39.990+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:20:39.990+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:20:40.000+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:20:40.000+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:20:40.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T23:21:10.431+0000] {processor.py:157} INFO - Started process (PID=83135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:21:10.432+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:21:10.434+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:21:10.434+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:21:10.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:21:10.460+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:21:10.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:21:10.470+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:21:10.470+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:21:10.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T23:21:40.943+0000] {processor.py:157} INFO - Started process (PID=83160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:21:40.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:21:40.946+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:21:40.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:21:40.957+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:21:40.973+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:21:40.973+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:21:40.982+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:21:40.982+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:21:40.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T23:22:11.339+0000] {processor.py:157} INFO - Started process (PID=83185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:22:11.340+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:22:11.341+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:22:11.341+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:22:11.354+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:22:11.367+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:22:11.367+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:22:11.376+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:22:11.376+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:22:11.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T23:22:41.805+0000] {processor.py:157} INFO - Started process (PID=83210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:22:41.808+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:22:41.809+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:22:41.809+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:22:41.820+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:22:41.835+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:22:41.835+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:22:41.845+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:22:41.844+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:22:41.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T23:23:12.248+0000] {processor.py:157} INFO - Started process (PID=83235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:23:12.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:23:12.251+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:23:12.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:23:12.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:23:12.280+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:23:12.279+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:23:12.289+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:23:12.289+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:23:12.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T23:23:42.740+0000] {processor.py:157} INFO - Started process (PID=83260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:23:42.743+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:23:42.745+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:23:42.745+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:23:42.754+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:23:42.769+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:23:42.769+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:23:42.781+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:23:42.781+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:23:42.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T23:24:13.235+0000] {processor.py:157} INFO - Started process (PID=83285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:24:13.236+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:24:13.239+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:24:13.239+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:24:13.253+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:24:13.268+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:24:13.268+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:24:13.280+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:24:13.280+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:24:13.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T23:24:43.645+0000] {processor.py:157} INFO - Started process (PID=83310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:24:43.648+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:24:43.650+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:24:43.650+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:24:43.662+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:24:43.677+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:24:43.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:24:43.689+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:24:43.689+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:24:43.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T23:25:14.145+0000] {processor.py:157} INFO - Started process (PID=83335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:25:14.151+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:25:14.154+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:25:14.154+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:25:14.164+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:25:14.177+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:25:14.177+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:25:14.186+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:25:14.186+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:25:14.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T23:25:44.645+0000] {processor.py:157} INFO - Started process (PID=83360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:25:44.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:25:44.648+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:25:44.647+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:25:44.664+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:25:44.677+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:25:44.677+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:25:44.686+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:25:44.686+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:25:44.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T23:26:15.081+0000] {processor.py:157} INFO - Started process (PID=83385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:26:15.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:26:15.085+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:26:15.084+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:26:15.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:26:15.116+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:26:15.116+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:26:15.126+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:26:15.126+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:26:15.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T23:26:45.533+0000] {processor.py:157} INFO - Started process (PID=83410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:26:45.535+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:26:45.537+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:26:45.536+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:26:45.546+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:26:45.562+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:26:45.562+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:26:45.572+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:26:45.572+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:26:45.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T23:27:16.040+0000] {processor.py:157} INFO - Started process (PID=83435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:27:16.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:27:16.044+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:27:16.044+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:27:16.060+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:27:16.079+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:27:16.079+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:27:16.089+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:27:16.089+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:27:16.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
[2024-07-19T23:27:46.507+0000] {processor.py:157} INFO - Started process (PID=83460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:27:46.509+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:27:46.510+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:27:46.510+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:27:46.520+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:27:46.535+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:27:46.535+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:27:46.543+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:27:46.543+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:27:46.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T23:28:16.981+0000] {processor.py:157} INFO - Started process (PID=83485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:28:16.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:28:16.983+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:28:16.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:28:16.994+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:28:17.010+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:28:17.010+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:28:17.020+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:28:17.020+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:28:17.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T23:28:47.478+0000] {processor.py:157} INFO - Started process (PID=83510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:28:47.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:28:47.481+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:28:47.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:28:47.491+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:28:47.510+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:28:47.509+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:28:47.521+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:28:47.521+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:28:47.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T23:29:17.928+0000] {processor.py:157} INFO - Started process (PID=83535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:29:17.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:29:17.937+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:29:17.937+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:29:17.947+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:29:17.960+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:29:17.960+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:29:17.970+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:29:17.970+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:29:17.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T23:29:48.436+0000] {processor.py:157} INFO - Started process (PID=83560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:29:48.438+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:29:48.440+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:29:48.439+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:29:48.449+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:29:48.464+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:29:48.464+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:29:48.473+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:29:48.473+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:29:48.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T23:30:18.935+0000] {processor.py:157} INFO - Started process (PID=83585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:30:18.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:30:18.939+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:30:18.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:30:18.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:30:18.969+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:30:18.969+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:30:18.981+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:30:18.981+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:30:18.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T23:30:49.427+0000] {processor.py:157} INFO - Started process (PID=83610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:30:49.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:30:49.430+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:30:49.430+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:30:49.447+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:30:49.460+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:30:49.460+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:30:49.469+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:30:49.469+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:30:49.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:31:19.891+0000] {processor.py:157} INFO - Started process (PID=83635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:31:19.891+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:31:19.893+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:31:19.893+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:31:19.903+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:31:19.922+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:31:19.922+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:31:19.933+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:31:19.932+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:31:19.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T23:31:50.292+0000] {processor.py:157} INFO - Started process (PID=83660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:31:50.293+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:31:50.295+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:31:50.295+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:31:50.307+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:31:50.324+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:31:50.324+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:31:50.335+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:31:50.335+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:31:50.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T23:32:20.788+0000] {processor.py:157} INFO - Started process (PID=83685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:32:20.788+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:32:20.790+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:32:20.790+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:32:20.802+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:32:20.819+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:32:20.819+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:32:20.830+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:32:20.830+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:32:20.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:32:51.272+0000] {processor.py:157} INFO - Started process (PID=83710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:32:51.276+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:32:51.278+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:32:51.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:32:51.289+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:32:51.302+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:32:51.302+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:32:51.311+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:32:51.311+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:32:51.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T23:33:21.723+0000] {processor.py:157} INFO - Started process (PID=83735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:33:21.724+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:33:21.726+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:33:21.725+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:33:21.741+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:33:21.755+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:33:21.755+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:33:21.765+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:33:21.765+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:33:21.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:33:52.137+0000] {processor.py:157} INFO - Started process (PID=83760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:33:52.138+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:33:52.140+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:33:52.140+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:33:52.152+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:33:52.167+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:33:52.167+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:33:52.177+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:33:52.177+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:33:52.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:34:22.607+0000] {processor.py:157} INFO - Started process (PID=83785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:34:22.608+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:34:22.609+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:34:22.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:34:22.619+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:34:22.634+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:34:22.634+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:34:22.645+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:34:22.645+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:34:22.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T23:34:53.073+0000] {processor.py:157} INFO - Started process (PID=83810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:34:53.076+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:34:53.079+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:34:53.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:34:53.091+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:34:53.109+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:34:53.109+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:34:53.123+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:34:53.123+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:34:53.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.063 seconds
[2024-07-19T23:35:23.613+0000] {processor.py:157} INFO - Started process (PID=83835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:35:23.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:35:23.616+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:35:23.615+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:35:23.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:35:23.646+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:35:23.646+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:35:23.657+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:35:23.657+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:35:23.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T23:35:54.020+0000] {processor.py:157} INFO - Started process (PID=83860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:35:54.022+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:35:54.025+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:35:54.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:35:54.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:35:54.060+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:35:54.060+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:35:54.071+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:35:54.071+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:35:54.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T23:36:24.490+0000] {processor.py:157} INFO - Started process (PID=83885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:36:24.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:36:24.493+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:36:24.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:36:24.508+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:36:24.522+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:36:24.522+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:36:24.533+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:36:24.533+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:36:24.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T23:36:55.002+0000] {processor.py:157} INFO - Started process (PID=83910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:36:55.003+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:36:55.005+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:36:55.005+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:36:55.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:36:55.035+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:36:55.035+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:36:55.048+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:36:55.048+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:36:55.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T23:37:25.454+0000] {processor.py:157} INFO - Started process (PID=83935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:37:25.455+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:37:25.457+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:37:25.456+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:37:25.467+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:37:25.485+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:37:25.485+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:37:25.497+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:37:25.497+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:37:25.504+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:37:55.957+0000] {processor.py:157} INFO - Started process (PID=83960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:37:55.960+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:37:55.962+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:37:55.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:37:55.970+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:37:55.986+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:37:55.986+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:37:55.997+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:37:55.996+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:37:56.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T23:38:26.383+0000] {processor.py:157} INFO - Started process (PID=83985) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:38:26.384+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:38:26.386+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:38:26.386+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:38:26.397+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:38:26.414+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:38:26.413+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:38:26.423+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:38:26.423+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:38:26.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T23:38:56.843+0000] {processor.py:157} INFO - Started process (PID=84010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:38:56.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:38:56.845+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:38:56.845+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:38:56.861+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:38:56.875+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:38:56.875+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:38:56.884+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:38:56.884+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:38:56.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:39:27.249+0000] {processor.py:157} INFO - Started process (PID=84035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:39:27.250+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:39:27.252+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:39:27.251+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:39:27.264+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:39:27.281+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:39:27.281+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:39:27.293+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:39:27.293+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:39:27.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T23:39:57.762+0000] {processor.py:157} INFO - Started process (PID=84060) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:39:57.765+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:39:57.771+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:39:57.771+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:39:57.782+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:39:57.798+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:39:57.798+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:39:57.808+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:39:57.808+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:39:57.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T23:40:28.194+0000] {processor.py:157} INFO - Started process (PID=84085) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:40:28.194+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:40:28.196+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:40:28.196+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:40:28.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:40:28.223+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:40:28.223+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:40:28.236+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:40:28.236+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:40:28.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:40:58.666+0000] {processor.py:157} INFO - Started process (PID=84110) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:40:58.667+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:40:58.669+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:40:58.669+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:40:58.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:40:58.699+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:40:58.699+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:40:58.710+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:40:58.710+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:40:58.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T23:41:29.170+0000] {processor.py:157} INFO - Started process (PID=84135) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:41:29.171+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:41:29.173+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:41:29.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:41:29.181+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:41:29.198+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:41:29.198+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:41:29.208+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:41:29.208+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:41:29.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T23:41:59.647+0000] {processor.py:157} INFO - Started process (PID=84160) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:41:59.649+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:41:59.651+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:41:59.651+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:41:59.661+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:41:59.678+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:41:59.678+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:41:59.688+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:41:59.688+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:41:59.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T23:42:30.130+0000] {processor.py:157} INFO - Started process (PID=84185) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:42:30.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:42:30.133+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:42:30.133+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:42:30.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:42:30.159+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:42:30.159+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:42:30.169+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:42:30.169+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:42:30.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T23:43:00.581+0000] {processor.py:157} INFO - Started process (PID=84210) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:43:00.582+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:43:00.583+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:43:00.583+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:43:00.598+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:43:00.613+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:43:00.613+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:43:00.626+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:43:00.626+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:43:00.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.057 seconds
[2024-07-19T23:43:31.023+0000] {processor.py:157} INFO - Started process (PID=84235) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:43:31.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:43:31.025+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:43:31.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:43:31.035+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:43:31.053+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:43:31.053+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:43:31.066+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:43:31.066+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:43:31.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:44:01.426+0000] {processor.py:157} INFO - Started process (PID=84260) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:44:01.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:44:01.430+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:44:01.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:44:01.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:44:01.457+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:44:01.457+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:44:01.467+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:44:01.467+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:44:01.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T23:44:31.951+0000] {processor.py:157} INFO - Started process (PID=84285) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:44:31.953+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:44:31.955+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:44:31.955+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:44:31.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:44:31.983+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:44:31.983+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:44:31.995+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:44:31.995+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:44:32.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.056 seconds
[2024-07-19T23:45:02.369+0000] {processor.py:157} INFO - Started process (PID=84310) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:45:02.370+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:45:02.372+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:45:02.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:45:02.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:45:02.398+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:45:02.398+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:45:02.409+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:45:02.409+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:45:02.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T23:45:32.909+0000] {processor.py:157} INFO - Started process (PID=84335) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:45:32.910+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:45:32.912+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:45:32.912+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:45:32.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:45:32.941+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:45:32.941+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:45:32.952+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:45:32.952+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:45:32.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T23:46:03.349+0000] {processor.py:157} INFO - Started process (PID=84360) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:46:03.349+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:46:03.351+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:46:03.351+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:46:03.361+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:46:03.377+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:46:03.377+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:46:03.389+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:46:03.389+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:46:03.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T23:46:33.839+0000] {processor.py:157} INFO - Started process (PID=84385) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:46:33.840+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:46:33.842+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:46:33.842+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:46:33.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:46:33.867+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:46:33.867+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:46:33.877+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:46:33.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:46:33.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T23:47:04.352+0000] {processor.py:157} INFO - Started process (PID=84410) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:47:04.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:47:04.354+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:47:04.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:47:04.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:47:04.383+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:47:04.383+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:47:04.394+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:47:04.394+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:47:04.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T23:47:34.735+0000] {processor.py:157} INFO - Started process (PID=84435) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:47:34.737+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:47:34.739+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:47:34.739+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:47:34.750+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:47:34.766+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:47:34.766+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:47:34.775+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:47:34.775+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:47:34.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.051 seconds
[2024-07-19T23:48:05.171+0000] {processor.py:157} INFO - Started process (PID=84460) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:48:05.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:48:05.181+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:48:05.181+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:48:05.190+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:48:05.205+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:48:05.205+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:48:05.215+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:48:05.215+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:48:05.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:48:35.587+0000] {processor.py:157} INFO - Started process (PID=84485) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:48:35.588+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:48:35.590+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:48:35.589+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:48:35.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:48:35.614+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:48:35.614+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:48:35.623+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:48:35.623+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:48:35.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T23:49:06.014+0000] {processor.py:157} INFO - Started process (PID=84510) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:49:06.015+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:49:06.017+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:49:06.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:49:06.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:49:06.046+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:49:06.046+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:49:06.057+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:49:06.057+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:49:06.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:49:36.513+0000] {processor.py:157} INFO - Started process (PID=84535) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:49:36.515+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:49:36.517+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:49:36.516+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:49:36.526+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:49:36.542+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:49:36.541+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:49:36.551+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:49:36.551+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:49:36.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.048 seconds
[2024-07-19T23:50:06.929+0000] {processor.py:157} INFO - Started process (PID=84560) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:50:06.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:50:06.932+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:50:06.932+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:50:06.941+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:50:06.958+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:50:06.958+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:50:06.971+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:50:06.971+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:50:06.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:50:37.410+0000] {processor.py:157} INFO - Started process (PID=84585) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:50:37.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:50:37.413+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:50:37.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:50:37.424+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:50:37.441+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:50:37.441+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:50:37.453+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:50:37.453+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:50:37.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T23:51:07.832+0000] {processor.py:157} INFO - Started process (PID=84610) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:51:07.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:51:07.835+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:51:07.835+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:51:07.850+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:51:07.866+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:51:07.866+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:51:07.876+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:51:07.876+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:51:07.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.058 seconds
[2024-07-19T23:51:38.299+0000] {processor.py:157} INFO - Started process (PID=84635) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:51:38.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:51:38.302+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:51:38.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:51:38.316+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:51:38.337+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:51:38.337+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:51:38.351+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:51:38.351+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:51:38.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.064 seconds
[2024-07-19T23:52:08.829+0000] {processor.py:157} INFO - Started process (PID=84660) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:52:08.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:52:08.831+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:52:08.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:52:08.842+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:52:08.855+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:52:08.855+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:52:08.868+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:52:08.867+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:52:08.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T23:52:39.256+0000] {processor.py:157} INFO - Started process (PID=84685) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:52:39.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:52:39.259+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:52:39.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:52:39.274+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:52:39.288+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:52:39.287+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:52:39.299+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:52:39.299+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:52:39.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.052 seconds
[2024-07-19T23:53:09.773+0000] {processor.py:157} INFO - Started process (PID=84710) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:53:09.774+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:53:09.775+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:53:09.775+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:53:09.792+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:53:09.807+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:53:09.807+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:53:09.817+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:53:09.817+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:53:09.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.055 seconds
[2024-07-19T23:53:40.271+0000] {processor.py:157} INFO - Started process (PID=84735) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:53:40.272+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:53:40.273+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:53:40.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:53:40.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:53:40.300+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:53:40.300+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:53:40.312+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:53:40.312+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:53:40.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:54:10.691+0000] {processor.py:157} INFO - Started process (PID=84760) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:54:10.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:54:10.694+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:54:10.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:54:10.703+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:54:10.719+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:54:10.719+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:54:10.729+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:54:10.729+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:54:10.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T23:54:41.213+0000] {processor.py:157} INFO - Started process (PID=84785) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:54:41.214+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:54:41.216+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:54:41.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:54:41.226+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:54:41.243+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:54:41.243+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:54:41.255+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:54:41.255+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:54:41.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:55:11.657+0000] {processor.py:157} INFO - Started process (PID=84810) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:55:11.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:55:11.660+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:55:11.660+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:55:11.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:55:11.688+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:55:11.688+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:55:11.700+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:55:11.700+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:55:11.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T23:55:42.105+0000] {processor.py:157} INFO - Started process (PID=84835) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:55:42.106+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:55:42.108+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:55:42.108+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:55:42.123+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:55:42.136+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:55:42.136+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:55:42.147+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:55:42.147+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:55:42.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T23:56:12.522+0000] {processor.py:157} INFO - Started process (PID=84860) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:56:12.524+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:56:12.525+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:56:12.525+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:56:12.539+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:56:12.551+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:56:12.551+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:56:12.560+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:56:12.560+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:56:12.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.049 seconds
[2024-07-19T23:56:42.993+0000] {processor.py:157} INFO - Started process (PID=84885) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:56:42.994+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:56:42.995+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:56:42.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:56:43.009+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:56:43.021+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:56:43.021+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:56:43.033+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:56:43.033+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:56:43.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.053 seconds
[2024-07-19T23:57:13.518+0000] {processor.py:157} INFO - Started process (PID=84910) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:57:13.519+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:57:13.521+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:57:13.520+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:57:13.537+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:57:13.550+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:57:13.550+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:57:13.561+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:57:13.561+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:57:13.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T23:57:44.039+0000] {processor.py:157} INFO - Started process (PID=84935) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:57:44.040+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:57:44.041+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:57:44.041+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:57:44.058+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:57:44.071+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:57:44.071+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:57:44.083+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:57:44.083+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:57:44.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T23:58:14.509+0000] {processor.py:157} INFO - Started process (PID=84960) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:58:14.510+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:58:14.512+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:58:14.512+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:58:14.521+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:58:14.537+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:58:14.537+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:58:14.547+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:58:14.547+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:58:14.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.047 seconds
[2024-07-19T23:58:44.923+0000] {processor.py:157} INFO - Started process (PID=84984) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:58:44.925+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:58:44.927+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:58:44.927+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:58:44.938+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:58:44.954+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:58:44.953+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:58:44.963+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:58:44.963+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:58:44.971+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.050 seconds
[2024-07-19T23:59:15.356+0000] {processor.py:157} INFO - Started process (PID=85010) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:59:15.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:59:15.360+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:59:15.359+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:59:15.370+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:59:15.387+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:59:15.387+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:59:15.399+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:59:15.399+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:59:15.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.054 seconds
[2024-07-19T23:59:45.826+0000] {processor.py:157} INFO - Started process (PID=85035) to work on /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:59:45.828+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/spark-jobs_.py for tasks to queue
[2024-07-19T23:59:45.830+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:59:45.830+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:59:45.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['spark_data_processing_pipeline']) retrieved from /opt/airflow/dags/spark-jobs_.py
[2024-07-19T23:59:45.862+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:59:45.862+0000] {dag.py:2915} INFO - Sync 1 DAGs
[2024-07-19T23:59:45.874+0000] {logging_mixin.py:151} INFO - [2024-07-19T23:59:45.874+0000] {dag.py:3696} INFO - Setting next_dagrun for spark_data_processing_pipeline to 2024-07-19T01:00:00+00:00, run_after=2024-07-20T01:00:00+00:00
[2024-07-19T23:59:45.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/spark-jobs_.py took 0.062 seconds
